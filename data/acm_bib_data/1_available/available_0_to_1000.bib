@software{10.1145/3159287,
author = {Hadian, Ali and Nobari, Sadegh and Minaei-Bidgoli, Behrouz and Qu, Qiang},
title = {Software for ROLL: Fast In-Memory Generation of Gigantic Scale-free Networks},
year = {2016},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3159287},
abstract = {
    <p>You can retrieve the zip file for this Artifact by clicking on the Zip Link above or by going to the github repository listed below. </p> ROLL(available at 
<ext-link xlink:href="https://github.com/alihadian/ROLL">
 https://github.com/alihadian/ROLL
</ext-link>) 
<break></break> 
<break></break>Tested in Ubuntu Linux 14.04 and 16.04. No specific hardware needed. The code can be compiled using Maven. 
<break></break> 
<break></break> The package includes scripts that enable: 
<p>
 <list> 
  <list-item>
   graph generation
  </list-item> 
  <list-item>
   run experiments.
  </list-item> 
 </list></p>Executing ./runAll.sh initiates the data generation process and the process of executing all the experiments that were part of the paper. No parameters needed. There is a master script (runAll.sh) that runs all experiments. The scripts generate all result data from to plot the graphs of the paper. For more information, please visit the project's GitHub page: 
<ext-link xlink:href="https://github.com/alihadian/ROLL">
 https://github.com/alihadian/ROLL
</ext-link> 
<break></break> 
<break></break> The code associated with this paper is in the src folder. Use ./runAll.sh to execute the code it. The experiments of the paper can be reproduced using the runAll.sh script. For that to work, maven and JDK 8+ is required. Note that generating the entire set of charts can take over a month. However, the data points of each chart are generated in order of execution time, so that partial results for each chart can be obtained in a shorter time by simply killing the application and using the partial data that is stored in the corresponding output files. 
<break></break> 
<break></break> 
<bold>
 Data Documentation:
</bold> 
<break></break>ROLL is a graph GENERATOR. Therefore, it does not require any input dataset. 
<break></break> 
<break></break> 
<bold>
 Linked Article:
</bold> 
<p>
 <list> 
  <list-item>
   <ext-link xlink:href="https://github.com/alihadian/ROLL">
     ROLL: Fast In-Memory Generation of Gigantic Scale-free Networks 
   </ext-link>
  </list-item> 
 </list></p> 
<bold>
 Provenance:
</bold> ROLL is developed by Ali Hadian. Contact the developer at 
<ext-link xlink:href="https://github.com/alihadian/ROLL">
 http://hadian.org
</ext-link> 
<break></break> 
<break></break> 
<bold>
 Copyright:
</bold> Held by Authors 
<break></break> 
<break></break> 
<bold>
 License:
</bold> 
<break></break> Licensed under the Apache License, Version 2.0. This repository is adapted with ACM reproducibility. Owner of artifact grants ACM permission to serve the artifact to users of the ACM Digital Library. 
<break></break> 
<break></break> This code is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ACM, THE AUTHORS AND THEIR AFFILIATED INSTITUTES DISCLAIM ANY LIABILITY OF ANY KIND FOR ANY DAMAGES WHATSOEVER RESULTING FROM THE USE OF THIS SOFTWARE.<p></p>
},
keywords = {Algorithms, Barabasi-Albert, Complex Networks, Graph, Graph Generation, Random Graphs}
}

@software{10.5281/zenodo.1112358,
author = {Buchwald, Sebastian and Fried, Andreas and Hack, Sebastian},
title = {Synthesizing an Instruction Selection Rule Library from Semantic Specifications},
year = {2017},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.1112358},
abstract = {
    <p>This is the software accompanying the paper of the same name, to appear at CGO 2018. The goal of the software is to automatically synthesize rules for translating a compiler's intermediate representation into the assembly language of a processor (a process called ”instruction selection“). The software is distributed along with benchmarks in a Docker container. For some benchmarks, a copy of the SPEC CPU2000 benchmark suite is required.</p>
},
keywords = {Compiler, Instruction Selection, Program Synthesis}
}

@software{10.6084/m9.figshare.5673880.v1,
author = {Zhang, Feng and Xue, Jingling},
title = {Artifact of: “POKER:Permutation-based SIMD Execution of Intensive Tree Search by Path Encoding”},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.5673880.v1},
abstract = {
    <p>This is the artifact for the paper titled “POKER: Permutation-based SIMD Execution of Intensive Tree Search by Path Encoding\'{Y} accepted at CGO 2018. This artifact helps reproduce the results presented in Figures 7 - 9 and Tables 2 - 3 in Section 4. For more information on how to use it, please refer to our paper and the README.txt file in this package. Please note that POKER is a work in progress. This artifact is a snapshot of this work and thus is only applicable under the experimental settings described in this paper. Please feel free to contact the authors if you have any questions.</p>
},
keywords = {Intensive Tree Search, Permute, SIMD}
}

@software{10.1145/3211992,
author = {Lee, Woosuk and Heo, Kihong and Alur, Rajeev and Naik, Mayur},
title = {Replication Package for PLDI'18 of Euphony},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3211992},
abstract = {
    <p>This is the replication package for our paper titled "Accelerating Search-Based Program Synthesis using Learned Probabilistic Models". The package includes a virtual machine image along with instructions how to use our tool and reproduce the claims in our paper. Using this package, one can reproduce Table 4, 5, 6, 7 and Figure 8 in the paper.</p>
},
keywords = {Domain-specific languages, Statistical methods, Synthesis, Transfer learning}
}

@software{10.1145/3211982,
author = {Vilk, John and Berger, Emery D.},
title = {Software Artifact for BLeak: Automatically Debugging Memory Leaks in Web Applications},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3211982},
abstract = {
    <p>The artifact consists of a VirtualBox VM image (OVA file) containing the BLeak software and source code, evaluation data, instructions, and all open source evaluation applications and input files.</p>
},
keywords = {BLeak, debugging, JavaScript, leak debugging, leak detection, memory leaks, web applications, web browsers}
}

@software{10.1145/3211994,
author = {Wang, Di and Hoffmann, Jan and Reps, Thomas},
title = {PMAF: An Algebraic Framework for Static Analysis of Probabilistic Programs},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3211994},
abstract = {
    <p>PMAF is an algebraic framework for static analysis of probabilistic programs. PMAF takes an interpretation of a pre-Markov algebra (PMA) and a program as its input, and then performs the analysis specified by the algebra on the program automatically via a fixpoint computation. We have instantiated PMAF on three PMAs, obtaining tolls for: Bayesian inference, the Markov decision problem, and linear expectation-invariant analysis.</p>
},
keywords = {Expectation invariant, Pre-Markov algebra, Probabilistic program, Program analysis}
}

@software{10.1145/3212003,
author = {Zhu, He and Magill, Stephen and Jagannathan, Suresh},
title = {Artifact for paper: A Data-Driven CHC Solver (PLDI 2018)},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3212003},
abstract = {
    <p>LinearArbitrary-SeaHorn: A CHC solver for LLVM-based languages</p>
},
keywords = {Constrained Horn Clauses (CHCs), Data-Driven Analysis, Invariant Inference, Program Verification}
}

@software{10.1145/3211981,
author = {Panchekha, Pavel and Geller, Adam T. and Ernst, Michael D. and Tatlock, Zachary and Kamil, Shoaib},
title = {Replication of Evaluation for VizAssert},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3211981},
abstract = {
    <p>Fully reproduces the experiments that are introduced in the paper, including: automatically verifying (or producing counterexamples for) 14 industry-standard assertions on 51 professionally-designed web pages; and testing VizAssert's formalization of line height, margin collapsing, and floating layout against Mozilla Firefox.</p>
},
keywords = {accessibility, CSS, layout, semantics, SMT, usability, verification}
}

@software{10.1145/3211984,
author = {Brutschy, Lucas and Dimitrov, Dimitar and M\"{u}ller, Peter and Vechev, Martin},
title = {C4 Tool Source Code},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3211984},
abstract = {
    <p>This is the source code for the C4 tool that we developed and reported in our "Static Serializability Analysis for Causal Consistency" PLDI '18 paper. For more information, check out the project home page at http://ecracer.inf.ethz.ch/.</p>
},
keywords = {Atomic Visibility, Causal Consistency, Serializability, Static Analysis}
}

@software{10.1145/3211988,
author = {Sanchez-Stern, Alex and Panchekha, Pavel and Lerner, Sorin and Tatlock, Zachary},
title = {Herbgrind Sources &nbsp;at Time Of Submission},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3211988},
abstract = {
    <p>A source archive of Herbgrind, and the version of Herbie used in the paper eval. A more up-to-date version of Herbgrind can be found at github.com/uwplse/herbgrind.git</p>
},
keywords = {debugging, dynamic analysis, floating point}
}

@software{10.1145/3211997,
author = {Gehr, Timon and Misailovic, Sasa and Tsankov, Petar and Vanbever, Laurent and Wiesmann, Pascal and Vechev, Martin},
title = {Artifact for the PLDI'18 paper "Bayonet: Probabilistic Inference for Networks"},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3211997},
abstract = {
    <p>This is the version of Bayonet that was used to generate the results in the paper "Bayonet: Probabilistic Inference for Networks" Find the current version of Bayonet at: http://bayonet.ethz.ch</p>
},
keywords = {Computer Networks, Probabilistic Programming}
}

@software{10.1145/3211990,
author = {Steindorfer, Michael J. and Vinju, Jurgen J.},
title = {Replication Package for Article "To-Many or To-One? All-in-One! Efficient Purely Functional Multi-maps with Type-Heterogeneous Hash-Tries"},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3211990},
abstract = {
    <p># Getting Started Guide The evaluation of our PLDI'18 paper entitled _To-many or To-one__?__ All-in-one! --- Efficient Purely Functional Multi-Maps with Type-Heterogeneous Hash-Tries_ consists of microbenchmarks and a case study in program analysis, both benchmarks execute fully automated. ## Requirements We assume basic familiarity with UNIX terminals and command line tools. The artifact was tested under UNIX operating systems (i.e., Ubuntu Linux 16.04.3.LTS and Apple macOS). The artifact requires the following resources to run: * Command line tools: * java (version 8), * maven, * make, * ant, * R and RScript * Internet connection (for automatically downloading dependencies). The execution time benchmarks are configured to use heap sizes of 8GB, whereas the memory measurments use 16GB. Thus computers or virtual machiens with at least 8GB RAM are recommended. For ease of use, we created a virtual machine with tools, benchmarks, and data setup. As basis we used the **Ubuntu Linux 16.04.3.LTS** distribution, installed in a [**VirtualBox**](https://www.virtualbox.org) virtual machine (version 5.2.6) with the **Oracle VM VirtualBox Extension Pack** installed. Go to [www.virtualbox.org](www.virtualbox.org) for downloading the software and installation instructions. The virtual machine has the following packages installed in order to satisfy our requirements: * `sudo apt install git` * `sudo apt install default-jdk` * `sudo apt install maven` * `sudo apt install openssh-server` * `sudo apt install r-base r-base-dev` ## SSH access to Virtual Machine For more convenient usage of the artifact, the authors are asked to setup remote access via terminal according to the stackoverflow answer [How to SSH to a VirtualBox guest externally through a host__?__](https://stackoverflow.com/questions/5906441/how-to-ssh-to-a-virtualbox-guest-externally-through-a-host). Afterwards, users of the artifact can log into the virtual machine with the following command line: &gt; ssh -p 3022 axiom@localhost When prompted for a password, use the password "axiom" (i.e., the same as the username that is already provided in the commannd line). ## Executing the Benchmarks and Data Post-Processing Pipeline Thh execution of benchmark referred to in the evaluation Sections 4, 5, and 6 of the paper, are entriely automated. The data post-processing of the data used in Sections 4 and 5 (cf. Figures 4, 5 and 6) are automated as well. Getting started with reproducing our resutls requires the execution of following commands in a console/terminal after being logged into our virtual machine: Moving into the artifacts directory: &gt; cd pldi18-artifact Setting up and compiling the artifacts: &gt; make prepare (To manually inspect what the **make** commands do, have a look at *pldi18-artifact/Makefile*.) ### (Quickly) Evaluating Archived Data concerning Sections 4 and 5 Next, one can re-generate the boxplots of the Figures 4, 5 and 6 (page 8 of the paper) based the logs that we obtained when executing the benchmarks ourselves. Our cached results are contained in the folder *data/20170417_1554*. The folder contains the following files: * **results.all-20170417_1554.log**: comma-separated values (CSV) file containing microbenchmark results of runtimes of individual operations * **map_sizes_heterogeneous_exponential_32bit_20170417_1554**: CSV file containing memory footprints in a 32-bit JVM setting. * **map_sizes_heterogeneous_exponential_64bit_20170417_1554**: CSV file containing memory footprints in a 64-bit JVM setting. * **hamt-benchmark-results-20170417_1554.tgz**: an archieve containing the files mentioned above verbose console output from running the benchmarks. The folder addionally contains three PDFs that were generated from the data files referenced above. The files correspond directly to the boxplots of Figures 4, 5, and 6 of page 8 of the paper. The boxplots are named **all-benchmarks-vf_champ_multimap_hhamt_by_vf_(scala|clojure|champ_map_as_multimap-map)-boxplot-speedup.pdf** and were generated with the following command, which should finish in a few seconds: &gt; make postprocessing_cached The reviewer may delete the three PDFs and re-generate them by with the command. An R script that is located under *benchmark/resources/r/benchmarks.r* performs the data post-processing and generation of the plots. ### (Relatively Quickly) Re-executing the whole Pipeline with a Reduced Dataset concerning Sections 4 and 5 The following commands re-execute the benchmarks for a reduced data set (with not statistically significant results) for the data structure sizes 16, 2048 and 1048576: Running reduced set of microbenchmarks: &gt; make run_microbenchmarks_short Benchmarking should approximately be finished in 15 to 30 minutes. After the benchmarks finished, the *data* directory should contain a new timestamped sub-folder with the benchmark results. After executing the following post-processing command, the folder should once again contain three PDFs / figures with boxplots: Running result analysis and post-processing: &gt; make postprocessing Note, that the results are neither statistically significant, nor do the cover a representative set of data structures size or data points in general. Nevertheless, the shape the boxplots may be similar to the figures in the paper. ### (Extremely Long) Re-executing the whole Pipeline with the Full Dataset concerning Sections 4 and 5 Running reduced set of microbenchmarks: &gt; make run_microbenchmarks Running result analysis and post-processing: &gt; make postprocessing Benchmarking the full data set can take up to two days of processing and should be performed on a dedicated machine without load or extraneous processes running in order to yield reliable results (see paper section about experimental setup and related work). ### (Relatively Quickly) Re-executing the Static Analysis Case Study concerning Section 6 Running case study benchmarks: &gt; make run_static_analysis_case_study Executing the case study benchmark I guess takes approximatley 1 to 2 hours. The benchmark results should be shown in tabular form in the terminal at the end of the benchmark run, and also serialized to disk (to a CSV file named *results.all-real-world-$TIMESTAMP.log*). Post-processing the data of this benchmark was not automated, and instead done by hand. However, it should be observable that the benchmark results for CHAMP and AXIOM are roughly the same. Note that abbreviations used in the benchmark setup do not match the names in the paper, i.e., CHART is used for CHAMP, and VF_CHAMP_MULTIMAP_HHAMT is used for AXIOM. The results cover the first three columns of Table 1. Colums 3-6 of Table 1 were also extracted manually with an instrumented version of the benchmark (cf. file *benchmark/src/main/java/dom/multimap/DominatorsSetMultimap_Default_Instrumented.java*). ## Other Relevant Items of our Artifact Our AXIOM hash trie implementations can be found under *code/capsule-experimental/src/main/java/io/usethesource/capsule/experimental/multimap/TrieSetMultimap_HHAMT.java*, for people interested in manually inspecting the implementation. The packages *benchmark/src/main/scala/io/usethesource/criterion/impl/persistent/scala* and *benchmark/src/main/java/io/usethesource/criterion/impl/persistent/clojure* contain simple interface facades that enables cross-library benchmarks under a common API. The benchmark implementations can be found in the *benchmark* project. File *benchmark/src/main/java/dom/multimap/DominatorsSetMultimap_Default.java* implements the real-word experiment (Section 6 of the paper), and file *benchmark/src/main/java/dom/multimap/DominatorsSetMultimap_Default_Instrumented.java* was used to extracting further statistics (colums 4-6 of Table 1). File *JmhSetMultimapBenchmarks.java* measures the runtimes of individual operations, whereas *CalculateHeterogeneousFootprints.java* performs footprint measurements (cf. page 8, Figures 4, 5, and 6). Note that the Java benchmark classes contain default parameters for their invocation, however the actual parameters are set in *runMicrobenchmarks.sh* and *runStaticProgramAnalysisCaseStudy.sh*.</p>
},
keywords = {Data structures, functional programming, graph, hashtable, JVM., many-to-many relation, multi-map, optimization, performance, persistent data structures}
}

@software{10.1145/3212005,
author = {Pombrio, Justin and Krishnamurthi, Shriram},
title = {PLDI 2018 Artifact for Inferring Type Rules for Syntactic Sugar},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3212005},
abstract = {
    <p>This is the artifact for the paper "Inferring Type Rules for Syntactic Sugar" by Justin Pombrio and Shriram Krishnamurthi. Type systems and syntactic sugar are both valuable to programmers, but sometimes at odds. While sugar is a valuable mechanism for implementing realistic languages, the expansion process obscures program source structure. As a result, type errors can reference terms the programmers did not write (and even constructs they do not know), baffling them. The language developer must also manually construct type rules for the sugars, to give a typed account of the surface language. We address these problems by presenting a process for automatically reconstructing type rules for the surface language using rules for the core. We have implemented this theory, and show several interesting case studies.</p>
},
keywords = {Macros, Programming Languages, Resugaring, Syntactic Sugar, Type Systems}
}

@software{10.5281/zenodo.1218718,
author = {Liu, Peizun and Wahl, Thomas},
title = {CUBA: Interprocedural Context-Unbounded Analysis of Concurrent Programs (Artifact)},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.1218718},
abstract = {
    <p>This is the artifact package for the article: CUBA: Interprocedural Context-Unbounded Analysis of Concurrent Programs. It includes: 1. The tool implemented in the article. In particular, -- the source code, -- executable binaries, -- an installation guide, -- documentation. 2. A brief introduction to the syntax used in our input programs. 3. A brief tutorial. 4. A set of benchmarks used and a guide to run the experiments.</p>
},
keywords = {Concurrent Program, Context Bound, Interprocedural Analysis, Recursion, Stack}
}

@software{10.1145/3289157,
author = {He, Kun and Simon, Gwendal and Maille, Patrick},
title = {Code and dataset for Broadtatou MMSys2018},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3289157},
abstract = {
    <p>Code and dataset for Broadtatou MMSys2018</p>
},
keywords = {CDN, Traffic reduction, Watermarked video}
}

@software{10.5525/gla.researchdata.596,
author = {Ahsan, Saba and McQuistin, Stephen and Perkins, Colin and Ott, Joerg},
title = {Source code for DASHing Towards Hollywood},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5525/gla.researchdata.596},
abstract = {
    <p>This artefact includes all of the source code used in generating the results described in this paper, alongside a Makefile that describes and performs the process of performing the experiments, processing and graphing the results, and producing the paper.</p>
},
keywords = {DASH, dynamic adaptive streaming over HTTP, head-of-line blocking, multimedia streaming, transport layer multistreaming}
}

@software{10.5281/zenodo.1320453,
author = {Habchi, Sarra and Blanc, Xavier and Rouvoy, Romain},
title = {Additional data},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.1320453},
abstract = {
    <p>The repository includes the survey questions and answers, the interview guide, and the coding results</p>

},
keywords = {Android, linter, performance, static analysis.}
}

@software{10.5281/zenodo.1321181,
author = {Beyer, Dirk and Lemberger, Thomas},
title = {Replication Package for Article "CPA-SymExec: Efficient Symbolic Execution in CPAchecker"},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.1321181},
abstract = {
    <p>Replication Package for Article “CPA-SymExec: Efficient Symbolic Execution in CPAchecker” by Dirk Beyer and Thomas Lemberger</p>
<p>It contains all tools and data that are necessary to reproduce the results in our article. The included README.md contains detailed replication instructions.</p>

},
keywords = {Program analysis, Software engineering, Software verification, SV-Benchmarks, Symbolic execution, Test-case generation}
}

@software{10.5281/zenodo.1322090,
author = {Beyer, Dirk and Friedberger, Karlheinz},
title = {Replication Package for Article "Domain-Independent Multi-Threaded Software Model Checking"},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.1322090},
abstract = {
    <p>Replication Package for Article “Domain-Independent Multi-Threaded Software Model Checking” by Dirk Beyer and Karlheinz Friedberger</p>
<p>It contains all tools and data that are necessary to reproduce the results in our article. The included README.md contains detailed replication instructions.</p>

},
keywords = {Block-Abstraction Memoization, Multithreading, Parallel Algorithm, Program Analysis, Software Verification}
}

@software{10.5281/zenodo.1341421,
author = {Jiang, Bo and Liu, Ye and Chan, W. K.},
title = {The ContractFuzzer Tool for ASE 18 paper ContractFuzzer: Fuzzing Smart Contracts for Vulnerability Detection},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.1341421},
abstract = {
    <p>The first version of ContractFuzzer Tool for ASE 18 paper “ContractFuzzer: Fuzzing Smart Contracts for Vulnerability Detection”.</p>

},
keywords = {blockchain, fuzzer, fuzzing, smart contract, vulnerability detection}
}

@software{10.1145/3291643,
author = {Bizjak, Ale\v{s} and Gratzer, Daniel and Krebbers, Robbert and Birkedal, Lars},
title = {Coq development for Iron: Managing Obligations in Higher-Order Concurrent Separation Logic},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291643},
abstract = {
    <p>This is the artifact for the paper Iron: Managing Obligations in Higher-Order Concurrent Separation Logic. The artifact comes as a virtual machine image with prebuilt sources, and also as a .zip archive containing sources and all of the dependencies. The latest version of the artifact and the paper can be downloaded at https://iris-project.org/iron/ .</p>

},
keywords = {concurrency, Coq formalization, resource management, Separation logic}
}

@software{10.1145/3291650,
author = {Crary, Karl},
title = {Fully Abstract Module Compilation, formal proofs},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291650},
abstract = {
    <p>Machine-checkable Coq proofs of the theorems in Fully Abstract Module Compilation, by Karl Crary.</p>

},
keywords = {full abstraction, Modules, phase separation}
}

@software{10.5281/zenodo.2229779,
author = {Lim, Jay P. and Nagarakatte, Santosh},
title = {CASM_Verify},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.2229779},
abstract = {
    <p>This is the artifact of the tool, CASM_Verify, for the paper, “Automatic Equivalence Checking for Assembly Implementations of Cryptography Libraries,” which will appear in CGO 2019.</p>
<p>CASM_Verify is a tool that automatically checks whether the equivalence of highly optimized assembly implementation of cryptographic implementations are equivalent to the reference implementation.</p>
<p>The artifact contains the source code of CASM_Verify, the benchmarks used for the evaluation, and the Dockerfile that can automatically create a Docker image containing all the required software and CASM_Verify.</p>
<p>To use CASM_Verify without Docker, install Python3 and z3.</p>

},
keywords = {CGO 2019}
}

@software{10.5281/zenodo.2240193,
author = {Qiao, Bo and Reiche, Oliver and Hannig, Frank and Teich, J\"{u}rgen},
title = {From Loop Fusion to Kernel Fusion: A Domain-specific Approach to Locality Optimization},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.2240193},
abstract = {
    <p>This artifact describes the steps to reproduce the results for the CUDA code generation with kernel fusion in Hipacc (an image processing DSL and source-to-source compiler embedded in C++), as presented in the CGO19 paper “From Loop Fusion to Kernel Fusion: A Domain-specific Approach to Locality Optimization”. We provide the original binaries as well as the source code to regenerate the binaries, which can be executed on x86_64 Linux system with CUDA enabled GPUs. Furthermore, we include two python scripts to run the application and compute the statistics as depicted in Figure 6 in the paper.</p>
<p>Hardware Dependencies: CUDA enabled GPUs are required. We used three Nvidia cards, as discussed in Section 5.1 in the paper: (a) Geforce GTX 745 facilitates 384 CUDA cores with a base clock of 1,033 MHz and 900 MHz memory clock. (b) Geforce GTX 680 has 1,536 CUDA cores with a base clock of 1,058 MHz and 3,004 MHz memory clock. (c) Tesla K20c has 2,496 CUDA cores with a base clock of 706 MHz and 2,600 MHz memory clock. For all three GPUs, the total amount of shared memory per block is 48 Kbytes, the total number of registers available per block is 65,536. GPUs with similar configurations are expected to generate comparable results.</p>
<p>Software Dependencies: Clang/LLVM (6.0), compiler_rt and libcxx for Linux (6.0). CMake (3.4 or later), Git (2.7 or later). Nvidia CUDA Driver (9.0 or later). OpenCV for producing visual output in the samples.</p>

},
keywords = {DSL, Image Processing, Kernel Fusion}
}

@software{10.1145/3325965,
author = {Yoga, Adarsh and Nagarakatte, Santosh},
title = {TaskProf2: A Parallelism Profiler and an Adviser for Task Parallel Programs.},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3325965},
abstract = {
    <p>TaskProf2 is a parallelism profiler and an adviser for task parallel programs that use the Intel Threading Building Blocks (TBB). As a parallelism profiler, it identifies regions with serialization bottlenecks, tasking overheads, and the secondary effects of execution. As an adviser, it automatically identifies a set of code regions that matter in improving parallelism with its what-if analyses.</p>
},
keywords = {differential analysis, parallelism, profiler, what-if analyses}
}

@software{10.5281/zenodo.2640864,
author = {Gershuni, Elazar and Amit, Nadav and Gurfinkel, Arie and Narodytska, Nina and Navas, Jorge A. and Rinetzky, Noam and Ryzhyk, Leonid and Sagiv, Mooly},
title = {Tool implementation for paper: "Simple and Precise Static Analysis of Untrusted Linux Kernel Extensions"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.2640864},
abstract = {
    <p>C++ implementation of the analyzer described in the paper.</p>
},
keywords = {ebpf, kernel extensions, linux, static analysis}
}

@software{10.1145/3325966,
author = {Khan, Tanvir Ahmed and Zhao, Yifan and Pokam, Gilles and Mozafari, Barzan and Kasikci, Baris},
title = {Software Artifact for Huron: Hybrid False Sharing Detection and Repair},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3325966},
abstract = {
    <p>The artifact consists of a VirtualBox virtual machine disk (VMDK file) containing the Huron software and source code, evaluation data, instructions, and all open source evaluation applications and input files.</p>
},
keywords = {False sharing, Performance optimization}
}

@software{10.1145/3325967,
author = {Kapus, Timotej and Ish-Shalom, Oren and Itzhaky, Shachar and Rinetzky, Noam and Cadar, Cristian},
title = {Replication Package for Cumputing Summaries of String Loops},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3325967},
abstract = {
    <p>The artefact contains a docker image that has the implementation of loop summarisation described in the paper set up. See the README file for more details.</p>
},
keywords = {Loop Summarisation, Optimisation, Refactoring, Strings, Symbolic Execution, Synthesis}
}

@software{10.1145/3325970,
author = {Cauligi, Sunjay and Soeller, Gary and Johannesmeyer, Brian and Brown, Fraser and Wahby, Riad S. and Renner, John and Gr\'{e}goire, Benjamin and Barthe, Gilles and Jhala, Ranjit and Stefan, Deian},
title = {Evaluation Artifact for FaCT: A DSL for Timing-Sensitive Computation},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3325970},
abstract = {
    <p>We provide a virtual machine image that contains our compiler and our case studies. The image comes with instructions for building the compiler, building the case studies, and running the evaluation.</p>
},
keywords = {cryptography, domain-specific language, program transformation}
}

@software{10.1145/3325968,
author = {Scalas, Alceste and Yoshida, Nobuko and Benussi, Elias},
title = {Effpi: a toolkit for verified message-passing programs in Dotty},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3325968},
abstract = {
    <p>This artifact contains the source code of Effpi: a toolkit for strongly-typed concurrent programming in Dotty (a.k.a. the future Scala 3 programming language), with model-checking-based verification capabilities. The toolkit is described in sections 1 and 5 of the companion paper: Alceste Scalas, Nobuko Yoshida, and Elias Benussi. Verified Message-Passing Programs with Dependent Behavioural Types. PLDI 2019. https://doi.org/10.1145/3314221.3322484 This artifact contains instruction for reproducing the benchmarks in the companion paper: see README.txt It also contains a ready-to-use virtual machine (based on a minimal Ubuntu installation) with Effpi's software dependencies. For the latest version of Effpi, visit: https://alcestes.github.io/effpi</p>
},
keywords = {actors, behavioural types, dependent types, Dotty, model checking, processes, Scala, temporal logic}
}

@software{10.1145/3325971,
author = {Heo, Kihong and Raghothaman, Mukund and Si, Xujie and Naik, Mayur},
title = {Replication Package for Article: Continuously Reasoning about Programs using Differential Bayesian Inference},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3325971},
abstract = {
    <p>This directory contains the artifact of the paper "Continuously Reasoning about Programs using Differential Bayesian Inference" published in PLDI 2019.</p>
},
keywords = {alarm prioritization, alarm relevance, continuous integration, software evolution, Static analysis}
}

@software{10.1145/3325977,
author = {Knoth, Tristan and Wang, Di and Polikarpova, Nadia and Hoffmann, Jan},
title = {Replication package for: Resource-Guided Program Synthesis},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3325977},
abstract = {
    <p>Included is the source for resyn, a program synthesizer that generates functional programs from refinement-type signatures. Resyn also takes an upper bound on the codes' resource usage; using a novel resource type system to guide the search process.</p>
},
keywords = {Automatic amortized resource analysis, Program synthesis, refinement types.}
}

@software{10.1145/3325978,
author = {Lahav, Ori and Margalit, Roy},
title = {Rocker: Robustness Checker},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3325978},
abstract = {
    <p>A program to transform TPL programs with C/C++11 release/acquire semantics to promela. The promela program can then be verified using Spin model checker.</p>
},
keywords = {C/C++11, D, release/acquire, robustness, weak memory models}
}

@software{10.1145/3325981,
author = {Le, Ton Chanh and Zheng, Guolong and Nguyen, ThanhVu},
title = {Replication Package for Article: SLING: Using Dynamic Analysis to Infer Program Invariants in Separation Logic},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3325981},
abstract = {
    <p>SLING is a tool for dynamically inferring separation logic specifications. Current version of SLING works with C or C++. It uses LLDB to obtain traces and Python to infer separation logic invariants based on the traces.</p>
},
keywords = {dynamic invariant generation, program analysis, separation logic}
}

@software{10.5281/zenodo.2645128,
author = {Liu, Lun and Millstein, Todd and Musuvathi, Madanlal},
title = {schotspot-aarch64: First Release for Artifact Registration for PLDI 2019},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.2645128},
abstract = {
    <p>This is the first release of the artifact of the PLDI 2019 paper "Accelerating Sequential Consistency for Java with Speculative Compilation". For the latest updates please check out the GitHub repo: https://github.com/Lun-Liu/schotspot-aarch64</p>
},
keywords = {Java virtual machine, memory consistency, sequential consistency, speculative compilation, volatile by default}
}

@software{10.1145/3325964,
author = {Kazerounian, Milod and Guria, Sankha Narayan and Vazou, Niki and Foster, Jeffrey S. and Van Horn, David},
title = {Replication package for paper: Type-Level Computations for Ruby Libraries},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3325964},
abstract = {
    <p>We provide a virtual machine containing the necessary materials to recreate the data presented in the paper, including: CompRDL, library type annotations, and annotated benchmark apps.</p>
},
keywords = {database queries, dynamic languages, libraries, Ruby, type-level computations, types}
}

@software{10.1145/3325972,
author = {Krishnaswami, Neelakantan R. and Yallop, Jeremy},
title = {Replication package for paper: A typed, algebraic approach to parsing},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3325972},
abstract = {
    <p>The artifact is a Docker image that makes it possible to explore the library described in the paper and re-run the performance experiments to reproduce the results.</p>
},
keywords = {context-free languages, functional programming, multi-stage programming, parser combinators, parsing, type theory}
}

@software{10.1145/3325979,
author = {Kokologiannakis, Michalis and Raad, Azalea and Vafeiadis, Viktor},
title = {Replication package for Article: "Model Checking for Weakly Consistent Libraries"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3325979},
abstract = {
    <p>We consider our paper's artifact to be the set of benchmarks we used in the paper, as well as the results we got by running particular versions of model checking tools (Nidhugg, Tracer, RCMC, and GenMC) on the benchmarks set. We do not consider the artifact of the paper to be GenMC, as it will evolve over time. We have made GenMC publicly available on GitHub (https://github.com/MPI-SWS/genmc), to further facilitate access to the tool. The artifact consists of a Virtual Machine (VM) containing binaries for Nidhugg, Tracer, RCMC, and GenMC, along with all the benchmarks used in the submitted version of our paper.</p>
},
keywords = {Model checking, weak memory models}
}

@software{10.1145/3325982,
author = {Mercadier, Darius and Dagand, Pierre-\'{E}variste},
title = {Replication Package for Article: Usuba: high-throughput \&amp; constant-time ciphers, by construction},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3325982},
abstract = {
    <p>This artifact builds a docker image, which, once built, will contain the necessary software to reproduce the results of the paper "Usuba: high-throughput &amp; constant-time ciphers, by construction". The docker image contains Usubac, the compiler for Usuba, and its sources, the Usuba sources of the ciphers presented if our paper, as well as the benchmarks evaluating our work.</p>
},
keywords = {Bitslicing, Block and stream ciphers, Dataflow languages, Domain specific languages, Optimizing Compiler, Vectorization}
}

@software{10.1145/3325983,
author = {Zhu, He and Xiong, Zikang and Magill, Stephen and Jagannathan, Suresh},
title = {Replication Package for Article: An Inductive Synthesis Framework for Verifiable Reinforcement Learning},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3325983},
abstract = {
    <p>A toolset for verify safety properties of reinforcement learning system.</p>
},
keywords = {Invariant Inference, Program Synthesis, Program Verification, Reinforcement Learning, Runtime Shielding}
}

@software{10.5281/zenodo.2646525,
author = {Rowe, Reuben N. S. and F\'{e}r\'{e}e, Hugo and Thompson, Simon J. and Owens, Scott},
title = {ROTOR: A Reliable OCaml Tool for OCaml Refactoring - Trustworthy Refactoring for OCaml},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.2646525},
abstract = {
    <p>ROTOR is a refactoring tool for the OCaml language that is written in OCaml.</p>
},
keywords = {OCaml, Refactoring}
}

@software{10.5281/zenodo.2646617,
author = {Dasgupta, Sandeep and Park, Daejun and Kasampalis, Theodoros and Adve, Vikram S. and Ro\c{s}u, Grigore},
title = {Replication package for the article "A Complete Formal Semantics of x86-64 User-Level Instruction Set Architecture"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.2646617},
abstract = {
    <p>We present the most complete and thoroughly tested formal semantics of x86-64 to date. Our semantics faithfully formalizes all the non-deprecated, sequential user-level instructions of the x86-64 Haswell instruction set architecture. This totals 3155 instruction variants, corresponding to 774 mnemonics. The semantics is fully executable and has been tested against more than 7,000 instruction-level test cases and the GCC torture test suite. This extensive testing paid off, revealing bugs in both the x86-64 reference manual and other existing semantics. We also illustrate potential applications of our semantics in different formal analyses, and discuss how it can be useful for processor verification</p>
},
keywords = {Formal Semantics, ISA specification, x86-64}
}

@software{10.5281/zenodo.2646720,
author = {Churchill, Berkeley and Padon, Oded and Sharma, Rahul and Aiken, Alex},
title = {Semantic Alignment Equivalence Checker},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.2646720},
abstract = {
    <p>An equivalence checker for x86-64 using semantic program alignment, as presented in the 2019 PLDI paper "Semantic Program Alignment for Equivalence Checking".</p>
},
keywords = {equivalence checking, formal verification, x86-64}
}

@software{10.1145/3325984,
author = {Nguy?n, Ph\'{u}c C. and Gilray, Thomas and Tobin-Hochstadt, Sam and Van Horn, David},
title = {Checkers used in: Size-Change Termination as a Contract},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3325984},
abstract = {
    <p>The dynamic and static checkers for size-change termination, and the tests used in the paper.</p>
},
keywords = {dynamic analysis, static analysis, termination checker}
}

@software{10.1145/3325973,
author = {Sakka, Laith and Sundararajah, Kirshanthan and Newton, Ryan R. and Kulkarni, Milind},
title = {Grafter: Clang tool that perform sound, fine-grained traversal fusion for heterogeneous trees},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3325973},
abstract = {
    <p>Grafter is clang tool that performs source to source transformation, namely traversals fusion. Grafter parse programs written in subset of C++, and write back the transformed code into the same files. The artifact includes the source code of Grafter in addition to the instructions on how to build it and use it. It also includes a pre-build version on a VM, with instructions on how to regenerate the experiments in the initial version of the paper.</p>
},
keywords = {Clang tool., Traversal Fusion}
}

@software{10.1145/3325974,
author = {Vollmer, Michael and Koparkar, Chaitanya and Rainey, Mike and Sakka, Laith and Kulkarni, Milind and Newton, Ryan R.},
title = {Artifact for "LoCal: A Language for Programs Operating on Serialized Data"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3325974},
abstract = {
    <p>The artifact for our paper is the Gibbon compiler. It also includes the benchmarks presented in the paper, and some scripts to run them and plot appropriate graphs.</p>
},
keywords = {Compilers, Program Optimization, Tree Traversals}
}

@software{10.1145/3325985,
author = {Loring, Blake and Mitchell, Duncan and Kinder, Johannes},
title = {Artifact for PLDI 2019 paper: Sound Regular Expression Semantics for Dynamic Symbolic Execution of JavaScript},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3325985},
abstract = {
    <p>The central contribution of this paper is a modification to the ExpoSE symbolic execution engine adding support for complex JavaScript regular expressions. The support for these regular expressions will often improve dynamic symbolic execution of JavaScript applications as they are widely used. A core part of this support is the introduction of a CEGAR loop on top of the SMT solver that automatically refines SMT problems to account for incorrect matching precedence. This artifact submission accompanies our PLDI 2019 paper. Our artifact is a virtual machine image with the paper software and experiments pre-installed.</p>
},
keywords = {Dynamic symbolic execution, JavaScript, regular expressions, SMT}
}

@software{10.5281/zenodo.2642857,
author = {van Tonder, Rijnard and Le Goues, Claire},
title = {Lightweight Multi-Language Syntax Transformation with Parser Parser Combinators: PLDI 2019 Artifact},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.2642857},
abstract = {
    <p>The PLDI 2019 VM artifact is archived for the associated paper and it's emphasis is to produce results consistent with those in the paper. It includes a research-grade implementation, associated transformations, and repository data to reproduce the tables in the paper. For those interested in actively trying or using the out the tool, consider the newer, actively maintained variety of this software at https://github.com/comby-tools/comby.</p>
},
keywords = {parsers, refactoring, rewriting, syntax, transformation}
}

@software{10.1145/3325980,
author = {Hallahan, William T. and Xue, Anton and Bland, Maxwell Troy and Jhala, Ranjit and Piskac, Ruzica},
title = {G2: Lazy Counterfactual Symbolic Execution},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3325980},
abstract = {
    <p>An artifact, consisting of code and benchmarks, for Lazy Counterfactual Symbolic Execution, by William T. Hallahan, Anton Xue, Maxwell Troy Bland, Ranjit Jhala, and Ruzica Piskac.</p>
},
keywords = {counterexamples, counterfactual, Haskell, lazy, symbolic execution}
}

@software{10.1145/3325986,
author = {Prokopec, Aleksandar and Ros\`{a}, Andrea and Leopoldseder, David and Duboscq, Gilles and T?ma, Petr and Studener, Martin and Bulej, Lubom\'{\i}r and Zheng, Yudi and Villaz\'{o}n, Alex and Simon, Doug and W\"{u}rthinger, Thomas and Binder, Walter},
title = {Renaissance: Benchmarking Suite for Parallel Applications on the JVM},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3325986},
abstract = {
    <p>Renaissance is a new benchmark suite composed of modern, real-world, concurrent, and object-oriented workloads that exercise various concurrency primitives of the JVM, with the goal of revealing optimization opportunities that were not visible with prior benchmark workloads. The artifact contains the Renaissance suite together with tools used to analyze the workloads and compare performance of two production level JIT compilers. The artifact also contains complete data sets of experiments described in the associated paper and scripts used to process those data sets for the figures and tables presented in the paper.</p>
},
keywords = {benchmarks, JIT compilation, parallelism}
}

@software{10.1145/3325989,
author = {Kuhlenschmidt, Andre and Almahallawi, Deyaaeldeen and Siek, Jeremy G.},
title = {Benchmarks Replication for Toward Efficient Gradual Typing for Structural Types via Coercions},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3325989},
abstract = {
    <p>We setup the benchmarks that we performed for our paper in a virtual machine. This virtual machine provides documentation of our benchmarking setup and allows reviewers to spot check the results (expect some variation due to the overheads of virtualization). If more accurate results are required in the future, the benchmark suite is setup as a docker image to ease reproduction.</p>
},
keywords = {compilation, efficiency, gradual typing}
}

@software{10.5281/zenodo.2644665,
author = {Mohammadi, Mahdi Soltan and Yuki, Tomofumi and Cheshmi, Kazem and Davis, Eddie C. and Hall, Mary and Dehnavi, Maryam Mehri and Nandy, Payal and Olschanowsky, Catherine and Venkat, Anand and Strout, Michelle Mills},
title = {Replication Package for Article: "Sparse Computation Data Dependence Simplification for Efficient Compiler-Generated Inspectors"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.2644665},
abstract = {
    <p>We use four packages to implement our approach: IEGenLib library, ISL library, CHiLL compiler framework, and Omega+ codegen included in the CHiLL. CHiLL is a source-to-source compiler framework for composing and applying high-level loop transformations to improve the performance of nested loops written in C. We use CHiLL to extract the dependence relations from the benchmarks. The CHiLL compiler also includes the Omega+ library, a modified version of Omega, which is an integer set manipulation library with limited support for constraints that involve uninterpreted function calls. We have used Omega+'s codegen capability to generate the DAG construction portion of the wavefront inspector code. ISL is a library for manipulating integer sets and relations that only contain affine constraints. It can act as a constraint solver by testing the emptiness of integer sets. It is also equipped with other operations on integer sets for detecting equalities and testing subset relationships. ISL does not support uninterpreted functions, and thus cannot directly represent the dependence constraints in sparse matrix code. IEGenLib is a set manipulation library that can manipulate integer sets/relations that contain uninterpreted function symbols. It uses ISL for some of its functionalities. We implemented the detection of unsatisfiable dependences and finding the equalities utilizing the IEGenLib and ISL libraries. The following briefly describes how our driver, illustrated in Figure 3 of the paper, generates wavefront parallelization inspectors. First, the driver extracts the dependences using CHiLL, and stores them in IEGenLib data structures. The driver also reads the JSON file with user-defined, domain-specific knowledge about index arrays, and stores them in IEGenLib environment variables. Then, it makes a call to an IEGenLib function to simplify the dependences. IEGenLib instantiates universally quantified assertions using the procedure described in Section 5 to prove unsatisfiability and to detect equalities. The uninterpreted functions are removed by replacing each call with a fresh variable, and functional consistency is encoded with additional constraints, before calling ISL to test for satisfiability and to expose equalities. Once the satisfiable, simplified, dependences are obtained, the driver tests each pair of the remaining dependences using IEGenLib for subsets and discards any dependence subsumed by another. Finally, the inspectors for the remaining dependences are generated by Omega+. Since, the outermost loop in the inspectors that we generate are embarrassingly parallel, the driver turns Omega+ generated code into a parallel inspector by simply adding an "omp parallel for" pragma before the outermost loop. The reason why the inspectors are obviously parallel is that each iteration of their outermost loop just connects dependence edges for the row (column) of the same iteration in the dependence graph structure. There are number of different source codes and data sources in this artifact: (1) IEGenLib library: used as a platform for some parts of the implementations. IEGenLib has its own licensing that can be referred to. (2) CHiLL compiler framework: used as a platform for some parts of the implementations. CHiLL has its own licensing that can be referred to. (3) ISL library that is included as part of IEGenLib. ISL has its own licensing that can be referred to. (4) Sparse computations benchmark suit (inside data directory) that have several different sources, and their sources are referenced in the paper. (5) Other codes and scripts, the drivers, built scripts, etc, are implemented by authors.</p>
},
keywords = {CHiLL, Codegen+, data dependence simplification, dependence analysis, IEGenLib, inspector-executor strategies, ISL, Omega+, Presburger arithmetic with uninterpreted functions, SMT solvers, sparse matrices}
}

@software{10.1145/3325976,
author = {Dhulipala, Laxman and Blelloch, Guy E. and Shun, Julian},
title = {Artifact for "Low-Latency Graph Streaming using Compressed Purely-Functional Trees"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3325976},
abstract = {
    <p>This repository provides experiments, scripts, and instructions for reproducing the experiments in our paper, *Low-Latency Graph Streaming Using Compressed Purely-Functional Trees*. Our paper introduces Aspen, a graph-streaming system based on compressed purely-functional trees. Aspen is designed for maintaining a dynamic graph subject to updates by a single writer, while supporting multiple concurrent readers. Due to the fact that the graph is purely-functional, all operations in Aspen are strictly serializable. In the Getting Started Guide, we include functionality to reproduce the main results presented in our paper. In the Step-By-Step Instructions, we also include the codes and instructions used for running experiments on very large graphs (hundreds of billions of edges). Due to the size of these graphs, and the memory footprint requirement on the machine, and the time to download, convert, and process these graphs, we expect that most users will not perform these steps, but we include them for completeness, and to ensure that our results for very large graphs are reproducible. We have made all graphs used in our paper publicly-available to ensure that our results are reproducible and can be built upon.</p>
},
keywords = {dynamic graph processing, graph streaming, parallel graph algorithms}
}

@software{10.1145/3325988,
author = {Abdulla, Parosh Aziz and Arora, Jatin and Atig, Mohamed Faouzi and Krishna, Shankaranarayanan},
title = {Replication Package for Article: Verification of Programs under Release Acquire Semantics},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3325988},
abstract = {
    <p>The artifact consists of a virtual machine (VM) containing binaries of four model checking tools (VBMC, Cdschecker, Rcmc, and Tracer) along with several scripts in order to reproduce the experimental results in the paper titled  Verification of Concurrent Programs under the Release-Acquire Semantics .</p>
},
keywords = {Bounded Model Checking, Concurrent Program, Release Acquire Semantics, Undecidability, View Bounding}
}

@software{10.1145/3325990,
author = {Gysi, Tobias and Grosser, Tobias and Brandner, Laurin and Hoefler, Torsten},
title = {Replication Package for Article: A Fast Analytical Model of Fully Associative Caches},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3325990},
abstract = {
    <p>The artifact contains the sources, benchmarks, and scripts necessary to reproduce the results of the paper "A Fast Analytical Model of Fully Associative Caches".</p>
},
keywords = {cache model, performance tool, static analysis}
}

@software{10.5281/zenodo.2649613,
author = {Smolka, Steffen and Kumar, Praveen and Kahn, David M. and Foster, Nate and Hsu, Justin and Kozen, Dexter and Silva, Alexandra},
title = {McNetKAT: Scalable Verification of Probabilistic Networks},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.2649613},
abstract = {
    <p>This is the artifact associated with the following paper: Steffen Smolka, Praveen Kumar, David M. Kahn, Nate Foster, Justin Hsu, Dexter Kozen, and Alexandra Silva. 2019. Scalable Verification of Probabilistic Networks. In PLDI  19. https://doi.org/10.1145/3314221.3314639. Please refer to artifact-page/index.html for instruction on how to install McNetKAT and reproduce the experiments from the paper.</p>
},
keywords = {McNetKAT, Network verification, Probabilistic Programming}
}

@software{10.5281/zenodo.2669678,
author = {Hsiao, Luke and Wu, Sen and Chiang, Nicholas and R\'{e}, Christopher and Levis, Philip},
title = {Software for Automating the Generation of Hardware Component Datasheets},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.2669678},
abstract = {
    <p>This artifact provides a Python package and datasets which can be used to replicate our methodology for automating the generation of hardware component knowledge bases. We describe how the software and datasets can be obtained, how the software and dependencies can be installed, and how the software can be used to run our experiments. Our artifact outlines the workflow from the input data (PDF and HTML documents, along with gold labels) to the final quality metrics we used to evaluate the approach. We also include scripts used for our analysis and performance experiments.</p>
},
keywords = {design tools, hardware components, knowledge base construction}
}

@software{10.5281/zenodo.2648959,
author = {Daruwalla, Kyle and Zhuo, Heng and Schulz, Carly and Lipasti, Mikko},
title = {BitBench Artifact Evaluation},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.2648959},
abstract = {
    <p>A ZIP file containing the source files and scripts to verify the results of BitBench.</p>
},
keywords = {bitstream computing, high level synthesis, pulse density modulation, stochastic computing, verilog}
}

@software{10.5281/zenodo.2678161,
author = {Das, Sourav and Unnithan, R. Harikrishnan and Menon, Arjun and Rebeiro, Chester and Veezhinathan, Kamakoti},
title = {SHAKTI-MS Artifacts},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.2678161},
abstract = {
    <p>Artifacts for SHAKTI-MS: A RISC-V Processor for Memory Safety in C</p>
},
keywords = {c, compiler, LLVM, memory corruption, security}
}

@software{10.5281/zenodo.2713721,
author = {Fuchs, Per and Hijma, Pieter and Grelck, Clemens},
title = {Heat Dissipation in Chapel},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.2713721},
abstract = {
    <p>Software belonging to Implementing Stencil Problems in Chapel: An Experience Report. The software contains several versions of a heat dissipation problem written in Chapel: the versions that were used to perform the measurements in the paper and versions based on feedback from the Chapel team.</p>
},
keywords = {Chapel, cluster computing, performance study, stencil operation}
}

@software{10.5281/zenodo.2678129,
author = {Yadavalli, S. Bharadwaj and Smith, Aaron},
title = {LLVM-MCTOLL},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.2678129},
abstract = {
    <p>MCTOLL is an LLVM-based static analysis tools that raises x64 and Arm32 binaries to LLVM bitcode.</p>
},
keywords = {Binary Translation, LLVM, Static Analysis}
}

@software{10.6084/m9.figshare.8226332,
author = {Shi, August and Bell, Jonathan and Marinov, Darko},
title = {Mitigating the Effects of Flaky Tests on Mutation Testing (Dataset and Tool)},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.8226332},
abstract = {
    <p>Mutation testing is widely used in research as a metric for evaluating the quality of test suites. Mutation testing runs the test suite on generated mutants (variants of the code under test), where a test suite kills a mutant if any of the tests fail when run on the mutant. Mutation testing implicitly assumes that tests exhibit deterministic behavior, in terms of their coverage and the outcome of a test (not) killing a certain mutant. Such an assumption does not hold in the presence of flaky tests, whose outcomes can non-deterministically differ even when run on the same code under test. Without reliable test outcomes, mutation testing can result in unreliable results, e.g., in our experiments, mutation scores vary by four percentage points on average between repeated executions, and 9\% of mutant-test pairs have an unknown status. Many modern software projects suffer from flaky tests. We propose techniques that manage flakiness throughout the mutation testing process, largely based on strategically re-running tests. We implement our techniques by modifying the open-source mutation testing tool, PIT. Our evaluation on 30 projects shows that our techniques reduce the number of "unknown" (flaky) mutants by 79.4\%. This artifact contains the dataset and tool that accompany this ISSTA 2019 paper.</p>
},
keywords = {Flaky tests, mutation testing, non-deterministic coverage}
}

@software{10.1145/3339065,
author = {Cai, Haipeng and Zhang, Ziyi and Li, Li and Fu, Xiaoqin},
title = {Artifact for Study of Application Incompatibilities in Android},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3339065},
abstract = {
    <p>This package includes the artifact associated with the article title "A Large-Scale Study of Application Incompatibilities in Android". The content of the package includes the source code and experimental datasets used in the study. A README document enclosed gives details on how to use the package for replicating the study results and reusing the code and data for future studies.</p>
},
keywords = {Android, compatibility, evolution, execution, installation}
}

@software{10.1145/3339071,
author = {Piskachev, Goran and Do, Lisa Nguyen Quang and Bodden, Eric},
title = {Replication Package for Artifact: Codebase-Adaptive Detection of Security-Relevant Methods},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3339071},
abstract = {
    <p>The artifact has a Virtual Machine containing (1) prepared Java program to execute the fully automatic SWAN approach on given test set, (2) 12 Java frameworks used in the paper for the evaluation, (3) generated methods from those frameworks, (4) manually annotated lists of methods used in the evaluation of the paper, (5) IntelliJ IDEA IDE with pre-installed SWAN-Assist plugin and example project, and (6) Java program for running the Suggester Algorithm proposed in the paper. All these component can be used to repeat the experiments from the paper. (1), (5) and (6) can be reused with other Java datasets. (3) and (4) can be used as datasets in other applications. Additionally, there is a manual for running the components of the artifact.</p>
},
keywords = {Java, machine learning, security, static code analysis}
}

@software{10.1145/3339067,
author = {Schwahn, Oliver and Coppik, Nicolas and Winter, Stefan and Suri, Neeraj},
title = {Artifact for Article: Assessing the State and Improving the Art of Parallel Testing for C},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3339067},
abstract = {
    <p>This is the artifact for the paper "Assessing the State and Improving the Art of Parallel Testing for C" by Oliver Schwahn, Nicolas Coppik, Stefan Winter, and Neeraj Suri. The provided artifact contains the prototype implementations and raw data used for the paper packaged as a Docker image. The ZIP file includes our Docker image along with a more detailed README.txt and some utility shell scripts to simplify Docker handling and package installation. The Docker image contains a complete setup for building and executing our tools as well as the repository study and library raw data and scripts. Please refer to the aforementioned README.txt for the full documentation and detailed instructions. The Docker image and its contents are provided as is without any warranty for academic purposes. The user-space included in the Docker image was installed from the Ubuntu software repository. The source code for the Debian repository study and the libraries was downloaded from the Debian software repository. The source code for additional third-party tools, libraries, and programs was downloaded from their respective distribution archives or GitHub, e.g., llvm.org, https://github.com/coccinelle/coccinelle, https://github.com/AlDanial/cloc, https://cran.r-project.org, https://pypi.org/, https://www.rust-lang.org, https://crates.io Note that all included third-party software is subject to their respecive licenses.</p>
},
keywords = {Parallel Test Execution, Parallel Testing, Software Repository Analysis, Static Analysis, Static Dependency Detection}
}

@software{10.1145/3339068,
author = {Li, Xia and Li, Wei and Zhang, Yuqun and Zhang, Lingming},
title = {Replication Package for Article: "DeepFL: Integrating Multiple Fault Diagnosis Dimensions for Deep Fault Localization"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3339068},
abstract = {
    <p>This artifact is used to implement our fault localization technique "DeepFL". It includes two main components: (1) DeepFL execution and (2) Result analysis.</p>
},
keywords = {Deep learning, Fault localization, Mutation testing}
}

@software{10.1145/3339073,
author = {Ghanbari, Ali and Benton, Samuel and Zhang, Lingming},
title = {PraPR},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3339073},
abstract = {
    <p>PraPR (Practical Program Repair) is a JVM bytecode-level, mutation-based automated program repair tool. PraPR exhaustively mutates suspicious statements and uses test cases to validate the patches. PraPR mutators are either traditional mutation operators from mutation testing or simple program transformations that frequently occur in real-world bug fix commits.</p>
},
keywords = {Automated Program Repair, JVM Bytecode, Mutation Testing}
}

@software{10.5281/zenodo.3237378,
author = {Liu, Kui and Koyuncu, Anil and Kim, Dongsun and Bissyand\'{e}, Tegawend\'{e} F.},
title = {Replication package of TBar},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3237378},
abstract = {
    <p>Template-based Automated Program Repair Tool</p>
},
keywords = {fix pattern, program repair}
}

@software{10.5281/zenodo.3239998,
author = {Lee, Sungho and Ryu, Sukyoung},
title = {Adlib: Static Analyzer to Detect Vunlerable Patterns in AdSDKs},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3239998},
abstract = {
    <p>Adlib is a static analyzer for AdSDKs. AdSDKs have powerful APIs, but the APIs may open to the malicious advertisements. Using predefined vulnerable patterns, Adlib constructs callgraphs and performs data flow analysis to find the vulnerable APIs that open to and can be abused by advertisements.</p>
},
keywords = {AdSDKs, Advertising Platform Vulnerabilities, Hybrid Applications, Malicious Advertisements}
}

@software{10.1145/3339070,
author = {Kechagia, Maria and Devroey, Xavier and Panichella, Annibale and Gousios, Georgios and van Deursen, Arie},
title = {Replication Package for Article: Effective and Efficient API Misuse Detection via Exception Propagation and Search-Based Testing},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3339070},
abstract = {
    <p>Effective and efficient detection of API misuses in Java client programs by combining static exception propagation and search-based testing. The artifact includes the main components for the exception propagation and the search-based testing. A tutorial is also provided for running the experiments.</p>
},
keywords = {API misuse, search-based software testing, software crash, static exception propagation}
}

@software{10.5281/zenodo.3258225,
author = {L\r{a}ng, John and Prasetya, I. S. W. B.},
title = {ALICE Data Point Processing Framework},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3258225},
abstract = {
    <p>This is version 5.0.0 of the ALICE Data Point Processing Framework (ADAPRO), an open source (licensed under Apache 2.0) C++ software framework, originally developed at CERN. This archive contains the source code, example applications, tests, documentation, and the Promela and DIVINE models of ADAPRO.</p>

},
keywords = {ESEC/FSE 2019}
}

@software{10.5281/zenodo.3258821,
author = {Zhou, Shurui and Vasilescu, Bogdan and K\"{a}stner, Christian},
title = {shuiblue/ForkingEfficiencyPaper: data},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3258821},
abstract = {
    <p>No description provided.</p>

},
keywords = {ESEC/FSE 2019}
}

@software{10.1145/3339069,
author = {Padhye, Rohan and Lemieux, Caroline and Sen, Koushik and Papadakis, Mike and Le Traon, Yves},
title = {Replication Package for "Semantic Fuzzing with Zest"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3339069},
abstract = {
    <p>The artifact is a Docker image that contains the Zest fuzzing engine, benchmark programs evaluated in the paper, scripts to run all the experiments described in the paper, and a data-set containing the results of the experiments when they were run on the authors' machine.</p>
},
keywords = {property-based testing, random testing, Structure-aware fuzzing}
}

@software{10.1145/3339066,
author = {Fazzini, Mattia and Xin, Qi and Orso, Alessandro},
title = {Replication Package for Article: Automated API-Usage Update for Android Apps},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3339066},
abstract = {
    <p>This artifact contains instructions on how to replicate the empirical evaluation of our work titled "Automated API-Usage Update for Android Apps".</p>
},
keywords = {API analysis, automated update, Mobile apps}
}

@software{10.5281/zenodo.3261842,
author = {Safwan, Khadijah Al and Servant, Francisco},
title = {Replication package for research paper "Decomposing the Rationale of Code Commits: The Software Developer's Perspective "},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3261842},
abstract = {
    <p>The replication package for our human study of rationale for code commits. This package includes: - Interview scripts -- Screening questionnaire -- Interview questions (interviewee) -- Interview questions (interviewer) -- Preliminary model of rationale for code commits - Online survey -- Survey questions -- Rationale model</p>
},
keywords = {code commits, human study, rationale, revision control}
}

@software{10.5281/zenodo.3262370,
author = {Mordahl, Austin and Oh, Jeho and Koc, Ugur and Wei, Shiyi and Gazzillo, Paul},
title = {Artifacts for: An Empirical Study of Real-World Variability Bugs Detected by Variability-Oblivious Tools},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3262370},
abstract = {
    <p>This repository provides the implementation of the final three steps of the automated framework presented in our FSE'2019 paper (included as ./PDF). The first step, Sample Generation, relies on the work done by Jeho et al. [31], so we do not include it here. Instead, we provide the results of that step in ./cases, and provide the rest of the framework, which runs off-the-shelf bug detectors, deduplicates their results, automatically extracts relevant features, and outputs those results in a unified format. See INSTALL.md for instructions on running the experiments. This is a single version uploaded for archival purposes, but refer to https://github.com/paulgazz/kconfig_case_studies for the most current version, with any necessary bug fixes.</p>
},
keywords = {configurable C software, static analysis, variability bugs}
}

@software{10.1145/3339072,
author = {Sharma, Aman and Nasre, Rupesh},
title = {QADroid: Regression Event Selection for Android Applications},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3339072},
abstract = {
    <p>We present here the artifacts that supports our ISSTA 19 paper. We proposed QADroid. We implemented QaDroid using Soot and FlowDroid, and tested it over multiple versions of Android apps. We compared the regression selection of events in QADroid against the total number of events. The artifacts provides the experimental setup used and the steps to run QADroid on Android apps.</p>
},
keywords = {Android apps, Regression Analysis, Software Engineering}
}

@software{10.5281/zenodo.3267950,
author = {Banerjee, Subarno and Clapp, Lazaro and Sridharan, Manu},
title = {NullAway: Practical Type-Based Null Safety for Java},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3267950},
abstract = {
    <p>NullAway is a tool to help eliminate NullPointerExceptions (NPEs) in your Java code. To use NullAway, first add @Nullable annotations in your code wherever a field, method parameter, or return value may be null. Given these annotations, NullAway performs a series of type-based, local checks to ensure that any pointer that gets dereferenced in your code cannot be null. NullAway is similar to the type-based nullability checking in the Kotlin and Swift languages, and the Checker Framework and Eradicate null checkers for Java. NullAway is fast. It is built as a plugin to Error Prone and can run on every single build of your code. In our measurements, the build-time overhead of running NullAway is usually less than 10\%. NullAway is also practical: it does not prevent all possible NPEs in your code, but it catches most of the NPEs we have observed in production while imposing a reasonable annotation burden.</p>
},
keywords = {java, null safety, pluggable type systems, static code analysis}
}

@software{10.6084/m9.figshare.8753420,
author = {DeFreez, Daniel and Baldwin, Haaken Martinson and Rubio-Gonz\'{a}lez, Cindy and Thakur, Aditya V.},
title = {EESI},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.8753420},
abstract = {
    <p>This repository contains the tool EESI. This is the software artifact that accompanies the paper "Effective Error-Handling Specification Inference via Domain Knowledge Expansion" by Daniel DeFreez, Haaken Martinson Baldwin, Cindy Rubio-Gonz lez, and Aditya V. Thakur.</p>
},
keywords = {bug finding, error handling, static analysis}
}

@software{10.1145/3342526,
author = {Sozeau, Matthieu and Mangin, Cyprien},
title = {Equations Reloaded Accompanying Material},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3342526},
abstract = {
    <p>This artifact contains the code of version 1.2 of Equations along with extended versions of all the examples presented in the article. It also includes a version of the Normalization of Predicative System F development.</p>
},
keywords = {Coq, Dependent Pattern-Matching, Well-Founded Recursion}
}

@software{10.1145/3342529,
author = {Hameer, Aliya and Pientka, Brigitte},
title = {Learn-OCaml Extensions and Repository for Article Teaching the Art of Functional Programming using Automated Grading (Experience Report)},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3342529},
abstract = {
    <p>Software sources and Docker image for the extensions to Learn-OCaml described in the paper Teaching the Art of Functional Programming using Automated Grading (Experience Report).</p>
},
keywords = {automated grading, functional programming, OCaml, online programming platforms, programming education, programming style, test-driven development}
}

@software{10.1145/3342533,
author = {Flatt, Matthew and Derici, Caner and Dybvig, R. Kent and Keep, Andrew W. and Massaccesi, Gustavo E. and Spall, Sarah and Tobin-Hochstadt, Sam and Zeppieri, Jon},
title = {Artifact: Rebuilding Racket on Chez Scheme (Experience Report)},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3342533},
abstract = {
    <p>Source code and Docker image for Racket, Chez Scheme, and Racket on Chez Scheme, including benchmark sources and scripts.</p>
},
keywords = {Racket, Scheme}
}

@software{10.5281/zenodo.3257080,
author = {Eremondi, Joseph and Tanter, \'{E}ric and Garcia, Ronald},
title = {Redex Model: Approximate Normalization for Gradual Dependent Types},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3257080},
abstract = {
    <p>This artifact contains an implementation of the core calculus from the paper, built using the Racket Redex library.</p>
},
keywords = {dependent types, gradual types, racket, redex, type systems}
}

@software{10.1145/3342520,
author = {P\'{e}drot, Pierre-Marie and Tabareau, Nicolas and Fehrmann, Hans Jacob and Tanter, \'{E}ric},
title = {Coq plugin for the Reasonably Exceptional Type Theory},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3342520},
abstract = {
    <p>This plugin allows to automatically translate Coq terms in such a way that they can now use exceptions in a controlled way. This can be useful for programming, e.g. to allow failure locally and prove after the fact that assuming a few properties the translated term does not fail, without endangering reduction nor polluting the type signature as a monadic translation would do.</p>
},
keywords = {Coq, effects, exceptions, plugin, type theory}
}

@software{10.1145/3342522,
author = {Zhang, Hengchu and Roth, Edo and Haeberlen, Andreas and Pierce, Benjamin C. and Roth, Aaron},
title = {Prototype Implementation of Fuzzi: A Three-Level Logic for Differential Privacy},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3342522},
abstract = {
    <p>The prototype implementation contains a typechecker, and a transpiler for typechecking and translating Fuzzi code into Python code for execution.</p>
},
keywords = {apRHL, Differential privacy, Fuzz, Fuzzi, static analysis, typechecking}
}

@software{10.1145/3342523,
author = {Bahr, Patrick and Graulund, Christian Uldal and M\o{}gelberg, Rasmus Ejlers},
title = {Coq formalisation for Simply RaTT},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3342523},
abstract = {
    <p>This artefact is a Coq formalisation of the results in the paper "Simply RaTT: A Fitch-style Modal Calculus for Reactive Programming Without Space Leaks".</p>
},
keywords = {Coq, functional reactive programming, logical relation, operational semantics, type system}
}

@software{10.5281/zenodo.3257707,
author = {Swierstra, Wouter and Baanen, Tim},
title = {Source code},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3257707},
abstract = {
    <p>This artefact contains the proofs and programs associated with the ICFP '19 paper 'A Predicate Transformer Semantics for Effects'</p>
},
keywords = {Agda, effects, free monads, predicate transformers, program calculation, programming with dependent types, refinement, weakest precondition semantics}
}

@software{10.1145/3342521,
author = {Mokhov, Andrey and Lukyanov, Georgy and Marlow, Simon and Dimino, Jeremie},
title = {Software packages and proofs for the paper "Selective Applicative Functors"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3342521},
abstract = {
    <p>This artefact comprises a Docker image containing a snapshot of the software packages related to the paper "Selective Applicative Functors" and all their dependencies.</p>
},
keywords = {applicative functors, effects, monads, selective functors}
}

@software{10.1145/3342524,
author = {Vezzosi, Andrea and M\"{o}rtberg, Anders and Abel, Andreas},
title = {Source code for examples from article Cubical Agda: A Dependently Typed Programming Language with Univalence and Higher Inductive Types},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3342524},
abstract = {
    <p>The artifact contains complete source files implementing the examples from the article. It also contains a Dockerfile to setup a working environment where they can be tested.</p>
},
keywords = {Cubical Agda, Dependent Type Theory, Homotopy Type Theory, Univalence}
}

@software{10.1145/3342525,
author = {Kiss, Csongor and Field, Tony and Eisenbach, Susan and Peyton Jones, Simon},
title = {Fork of GHC implementing -XUnsaturatedTypeFamilies for the paper 'Higher-Order Type-Level Programming in Haskell'},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3342525},
abstract = {
    <p>The artefact contains two files 1. The source code (ghc-icfp-src.tar.gz) for the fork of GHC which implements UnsaturatedTypeFamilies 2. A prebuilt docker image (ghc-icfp-docker.tar.gz) which can be loaded to run the examples from the paper. The nix expression which was used to build the docker image can be found in the `build-docker` subdirectory.</p>
},
keywords = {GHC, Haskell, type-level programming}
}

@software{10.1145/3342527,
author = {Delaware, Benjamin and Suriyakarn, Sorawit and Pit-Claudel, Cl\'{e}ment and Ye, Qianchuan and Chlipala, Adam},
title = {Virtual machine and source code for Narcissus: Correct-by-Construction Derivation of Decoders and Encoders from Binary Formats},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3342527},
abstract = {
    <p>This artifact contains our source code, as well as a virtual machine with our code and benchmarks. The README provides the following: * Instructions on running the virtual machine and stepping through the tutorial in our paper (Section 1.1   A tour of Narcissus), * Guidance on how to reproduce the benchmarks in our paper (Section 6), * Directions to build and use our library in general, outside of the virtual machine, * Links from the definitions, lemmas, and rules in the paper to the actual implementation in our code, and * Instructions on how to set up our virtual machine and its environment from scratch.</p>
},
keywords = {Deductive Synthesis, Parser Combinators, Program Synthesis, Serialization and Deserialization}
}

@software{10.1145/3342528,
author = {Qu, Weihao and Gaboardi, Marco and Garg, Deepak},
title = {A Type Checker BiARel for 'Relational Cost Analysis for Functional-Imperative Programs'},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3342528},
abstract = {
    <p>This software is an implementation of the type-and-effect system ARel proposed in 'Relational Cost Analysis for Functional-Imperative Programs', written in OCaml. It uses SMT solver alt-ergo and uses the front end Why3 to solve the constraint generated from the bidirectional type checker.</p>
},
keywords = {refinement types, relational type systems, type-and-effect systems}
}

@software{10.1145/3342532,
author = {Timany, Amin and Birkedal, Lars},
title = {Coq formalization for the paper: Mechanized Relational Verification of Concurrent Programs with Continuations},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3342532},
abstract = {
    <p>This artifact includes the Coq formalization of the theory presented in the paper.</p>
},
keywords = {Concurrency, Continuations, Logical relations}
}

@software{10.1145/3342534,
author = {Sherman, Benjamin and Michel, Jesse and Carbin, Michael},
title = {Artifact for Article: Sound and Robust Solid Modeling via Exact Real Arithmetic and Continuity},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3342534},
abstract = {
    <p>The artifact consists of the following: - The MarshallB programming system, a programming language interpreter written in OCaml. Our artifact permits running a REPL for the language. - The StoneWorks library for MarshallB, which is several files of MarshallB code. Our artifact permits processing these files, ensuring they typecheck, and allowing them to be used at the REPL. - Standalone MarshallB files and commands to execute the case studies from the paper, for which the paper describes computational results that we produced using MarshallB.</p>
},
keywords = {constructive analysis, continuity, exact real arithmetic, solid modeling, synthetic topology}
}

@software{10.1145/3342535,
author = {Weirich, Stephanie and Choudhury, Pritam and Voizard, Antoine and Eisenberg, Richard A.},
title = {Replication Package for Article: A Role for Dependent Types in Haskell},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3342535},
abstract = {
    <p>This archive contains the artifact submitted with the paper "A Role for Dependent Types in Haskell" (DOI: 10.1145/3341705). The artifact consists of the entire mechanization, using the Coq proof assistant, of the results presented in the paper. It contains both a Docker image and a copy of the source code.</p>
},
keywords = {Coq, Dependent Types, Functional Languages, Haskell, Mechanized Metatheory, Type Theory}
}

@software{10.1145/3342536,
author = {Gratzer, Daniel and Sterling, Jonathan and Birkedal, Lars},
title = {blott: An Implementation of a Modal Dependent Type Theory},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3342536},
abstract = {
    <p>An experimental OCaml implementation of the modal dependent type theory described in "Implementing a Modal Dependent Type Theory".</p>
},
keywords = {implementation, modalities, normalization-by-evaluation, OCaml, type theory, type-checker}
}

@software{10.1145/3342537,
author = {Orchard, Dominic and Liepelt, Vilem-Benjamin and Eades III, Harley},
title = {Language implementation for Quantitative Program Reasoning with Graded Modal Types},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3342537},
abstract = {
    <p>This artefact provides a snapshot of the Granule language implementation, which provides a type-checker and interpreter (gr), as well as an interactive shell (grin). This is the core implementation of the theory described in the paper. Included are many example programs, including literate Granule files which replay the examples from Section 2 and Section 8 of the paper ("examples/intro.gr.md" and "examples/further-examples.gr.md"). The artefact includes the source (written in Haskell) and a Docker image, along with instructions on how to setup the Docker or install from source yourself.</p>
},
keywords = {coeffects, graded modal types, Granule, implementation, linear types}
}

@software{10.1145/3342519,
author = {Walia, Rajan and Narayanan, Praveen and Carette, Jacques and Tobin-Hochstadt, Sam and Shan, Chung-chieh},
title = {Replication Package for Article: From High-Level Inference Algorithms to Efficient Code},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3342519},
abstract = {
    <p>Our artifact runs and analyzes the benchmarks described in Section 6 of our paper, and produces new PDF versions of the data plotted there.</p>
},
keywords = {arrays, collapsed Gibbs sampling, conjugacy, loop optimization, map-reduce, marginalization, multidimensional distributions, plates, probabilistic programs}
}

@software{10.1145/3342531,
author = {Miltner, Anders and Maina, Solomon and Fisher, Kathleen and Pierce, Benjamin C. and Walker, David and Zdancewic, Steve},
title = {Replication Package for Artifact: Synthesizing Symmetric Lenses},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3342531},
abstract = {
    <p>The Artifact contains Boomerang extended with Symmetric combinators, and Symmetric Optician. This tool allows people to write and synthesize symmetric lenses on string data.</p>
},
keywords = {Bidirectional Programming, Information Theory, Program Synthesis, Type Systems, Type-Directed Synthesis}
}

@software{10.1145/3345841,
author = {Pauck, Felix and Wehrheim, Heike},
title = {Replication Package for Article: Together Strong: Cooperative Android App Analysis},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3345841},
abstract = {
    <p>The artifact includes all the software and data used and generated during the evaluation of the associated paper. Thus, the tools used and results achieved are contained. Along with that detailed instructions are provided which describe how to use the tools and how to review or reproduce the results.</p>
},
keywords = {Android Taint Analysis, CoDiDroid, Cooperation, Precision, Tools}
}

@software{10.5281/zenodo.3264974,
author = {Kr\"{u}ger, Jacob and \c{C}al\i{}kl\i{}, G\"{u}l and Berger, Thorsten and Leich, Thomas and Saake, Gunter},
title = {Artifact for the ESEC/FSE 2019 Paper: Effects of Explicit Feature Traceability on Program Comprehension},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3264974},
abstract = {
    <p>This is the artifact for our ESEC/FSE 2019 paper "Effects of Explicit Feature Traceability on Program Comprehension", providing 1) the experiment as reusable source code and 2) the anonymized results of our experiment. For more details on how to use the source code and interpret the data, please refer to the readme file.</p>
},
keywords = {Experiment, Feature Traceability, Program Comprehension}
}

@software{10.6084/m9.figshare.8242877,
author = {Cotroneo, Domenico and De Simone, Luigi and Liguori, Pietro and Natella, Roberto and Bidokhti, Nematollah},
title = {Replication Package for Article: How Bad Can a Bug Get? An Empirical Analysis of Software Failures in the OpenStack Cloud Computing Platform},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.8242877},
abstract = {
    <p>The artifact includes tools to repeat the fault-injection experiments presented in the paper "How Bad Can a Bug Get  An Empirical Analysis of Software Failures in the OpenStack Cloud Computing Platform" (ESEC/FSE '19). Please note that this artifact does not include a fault injection tool since we transferred the ownership of the tool to our industry partners. Therefore, the artifact includes pre-injected source-code files. Before every fault injection test, an original source-code file is replaced with a pre-injected file, and it is restored after the test.</p>
},
keywords = {Cloud computing, Fault injection, Software fault tolerance}
}

@software{10.1145/3345842,
author = {Rigger, Manuel and Marr, Stefan and Adams, Bram and M\"{o}ssenb\"{o}ck, Hanspeter},
title = {Artifact: Understanding GCC Builtins to Develop Better Tools},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3345842},
abstract = {
    <p>This artifact is associated with the paper "Understanding GCC Builtins to Develop Better Tools" and provides the builtin raw data, the preprocessed data, and aggregated data of builtin usages. It also contains a record of the manual decisions made as part of this study. Furthermore, it contains all the scripts and applications to reproduce the paper's results.</p>
},
keywords = {C GitHub projects, compiler intrinsics, GCC builtins}
}

@software{10.5281/zenodo.3257172,
author = {Koyuncu, Anil and Liu, Kui and Bissyand\'{e}, Tegawend\'{e} F. and Kim, Dongsun and Monperrus, Martin and Klein, Jacques and Le Traon, Yves},
title = {iFixR a patch generation system for user-reported bugs},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3257172},
abstract = {
    <p>Dataset and code to run iFixR</p>
},
keywords = {bug-report.program-repair}
}

@software{10.5281/zenodo.3262201,
author = {Kalhauge, Christian Gram and Palsberg, Jens},
title = {Artifact from "Binary Reduction of Dependency Graphs"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3262201},
abstract = {
    <p>This is the artifact is supplementing the "Binary Reduction of Dependency Graphs" paper by Christian Gram Kalhauge and Jens Palsberg ESCE/FSE 2019. It contains the source code for tool, the evaluation procedure, and the benchmarks.</p>
},
keywords = {debugging, dependencies, reduction}
}

@software{10.5281/zenodo.3334854,
author = {Durieux, Thomas and Madeiral, Fernanda and Martinez, Matias and Abreu, Rui},
title = {RepairThemAll},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3334854},
abstract = {
    <p>RepairThemAll is a framework to execute 11 automatic repair tools on 5 benchmarks of Java Bugs.</p>
},
keywords = {Automatic Program Repair, Benchmark of bugs, Patch Generation}
}

@software{10.5281/zenodo.3336282,
author = {Bui, Nghi D. Q. and Yu, Yijun and Jiang, Lingxiao},
title = {SAR: Learning Cross-Language API Mappings with Little Knowledge},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3336282},
abstract = {
    <p>Providing the 2 corpus of the 2 languages, the tool will automatically infer the API mappings.</p>
},
keywords = {adversarial learning, API mapping, code learning, cross language, generative adversarial networks, program representation learning}
}

@software{10.6084/m9.figshare.7749356,
author = {He, Sen and Manns, Glenna and Saunders, John and Wang, Wei and Pollock, Lori and Soffa, Mary Lou},
title = {Code and Dataset for PT4Cloud},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.7749356},
abstract = {
    <p>This artifact contain code and data used to generate the data in the paper, which are the evaluation results of PT4Cloud. The code can be resused for other functions. The main componnent of the code include the function for KL-Divergence and multinomial likelihood, implemented in PT4CloudArtifacts.py in function "DistSimilarity"", and the function for bootstrapping the confidence band is implemented in "pt4cloud_figures.py" in function "bootstrap_conf_band."</p>
},
keywords = {cloud computing, non-parametric statistics, performance testing, resource contention}
}

@software{10.1145/3345840,
author = {Kapus, Timotej and Cadar, Cristian},
title = {Replication package for Segmented Memory Model},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3345840},
abstract = {
    <p>The artefact consists of a dokcer image that has the experiments described in the paper set-up and ready to run. In addition we provide the raw data and plotting utilities to get the graphs in the paper. See the README file for further details.</p>
},
keywords = {KLEE, m4, make, memory model, SQLite, symbolic execution}
}

@software{10.5281/zenodo.3262095,
author = {Menghi, Claudio and Nejati, Shiva and Gaaloul, Khouloud and Briand, Lionel C.},
title = {Replication Package for Article: Generating Automated and Online Test Oracles for Simulink Models with Continuous and Uncertain Behaviors},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3262095},
abstract = {
    <p>SOCRaTeS automatically converts functional requirements into oracles specified in Simulink. The oracles evaluate test outputs of the CPS model in an automated and online manner and generate fitness values that provide engineers with a degree of satisfaction or failure for each test input. Engineers can stop running a test in the middle when SOCRaTeS concludes that the test fitness is going to remain below a given threshold for the rest of its execution.</p>
},
keywords = {Formal language definitions., Software and its engineering, Software verification and validation}
}

@software{10.6084/m9.figshare.8427044,
author = {Liew, Daniel and Cadar, Cristian and Donaldson, Alastair F. and Stinnett, J. Ryan},
title = {JFS paper artifact},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.8427044},
abstract = {
    <p>This artifact contains * Experiment data * Scripts for building solvers * Code for processing data.</p>
},
keywords = {constraint solving, coverage, coverage-guided, floating-point, fuzzing, ieee-754, jfs, smt}
}

@software{10.5281/zenodo.3265783,
author = {Fucci, Davide and Mollaalizadehbahnemiri, Alireza and Maalej, Walid},
title = {Library Package for Article: On Using Machine Learning to Identify Knowledge in API Reference Documentation},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3265783},
abstract = {
    <p>This project provides NLP tools based on LSTM for Multi-Lable Calssification of Documents.</p>
},
keywords = {Knowledge Identification, LSTM, Multi-Lable Classification, NLP}
}

@software{10.5281/zenodo.3364750,
author = {Near, Joseph P. and Darais, David and Abuah, Chike and Stevens, Tim and Gaddamadugu, Pranav and Wang, Lun and Somani, Neel and Zhang, Mu and Sharma, Nikhil and Shan, Alex and Song, Dawn},
title = {Replication Package for Article: Duet: An Expressive Higher-Order Language and Linear Type System for Statically Enforcing Differential Privacy},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3364750},
abstract = {
    <p>Duet is an expressive higher-order language, linear type system and tool for automatically verifying differential privacy of arbitrary higher-order programs. In addition to general purpose programming, it supports encoding machine learning algorithms such as stochastic gradient descent, as well as common auxiliary data analysis tasks such as clipping, normalization and hyperparameter tuning. Current version is available at the GitHub repository: https://github.com/uvm-plaid/duet</p>
},
keywords = {Differential privacy, machine learning, typechecking}
}

@software{10.5281/zenodo.3363914,
author = {Astrauskas, Vytautas and M\"{u}ller, Peter and Poli, Federico and Summers, Alexander J.},
title = {Software Artefact for the OOPSLA'19 Paper Titled "Leveraging Rust Types for Modular Specification and Verification"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3363914},
abstract = {
    <p>This artefact contains a virtual machine that can be used to reproduce the evaluation of our paper. You can find the instructions in the README.pdf file. If you are interested in building on top of our research results, you can find the latest version of Prusti in our GitHub repository: https://github.com/viperproject/prusti-dev.</p>
},
keywords = {Rust, verification, Viper}
}

@software{10.5281/zenodo.3365991,
author = {Nanevski, Aleksandar and Banerjee, Anindya and Delbianco, Germ\'{a}n Andr\'{e}s and F\'{a}bregas, Ignacio},
title = {Specifying Concurrent Programs in Separation Logic: Morphisms and Simulations (Artefact).},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3365991},
abstract = {
    <p>This artefact is a companion to: Aleksandar Nanevski, Anindya Banerjee, Germ n Andr s Delbianco, and Ignacio F bregas. 2019. Specifying Concurrent Programs in Separation Logic: Morphisms and Simulations. Proc. ACM Program. Lang. 3, OOPSLA, Article 161 (October 2019), 30 pages. https://doi.org/10.1145/3360587 The artefact contains all the Coq sources of the developments presented in the submission, including the meta-theory of FCSL, and the example case studies. It also contains additional examples that the main body submission does not discuss. Some, such as readers/writers locks, are presented in the Extended Technical Report [arXiv:1904.07136], which has also been included in the artefact.</p>
},
keywords = {Coq, FCSL, Hoare/Separation Logics, Program Logics for Concurrency}
}

@software{10.5281/zenodo.3369233,
author = {Keidel, Sven and Erdweg, Sebastian},
title = {Artifact: Sound and Reusable Components for Abstract Interpretation},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3369233},
abstract = {
    <p>The artifact contains the library of analysis components (Section 6) and the code of the case studies (Section 7).</p>
},
keywords = {Abstract Interpretation, Soundness, Static Analysis}
}

@software{10.5281/zenodo.3368627,
author = {Antonopoulos, Timos and Koskinen, Eric and Le, Ton Chanh},
title = {Knotical: An Inference System of Trace Refinement Relations},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3368627},
abstract = {
    <p>This is an artifact for the paper "Specification and Inference of Trace Refinement Relations", which is accepted to OOPSLA 2019. The artifact is licensed under the MIT license. The development repository is located at https://github.com/knotical/knotical.</p>
},
keywords = {Kleene Algebra with Tests, program refinement, relational reasoning, trace refinement}
}

@software{10.5281/zenodo.3362424,
author = {Caires, Lu\'{\i}s and Toninho, Bernardo},
title = {Refinement Kinds: Type-safe Programming with Practical Type-level Computation (Artifact)},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3362424},
abstract = {
    <p>This is the artifact for the paper Refinement Kinds: Type-safe Programming with Practical Type-level Computation. The artifact consists of a prototype kind and type-checker (which also includes an evaluator) for the language described in the paper. The artifact is distributed as a Docker image that bundles the source code, all its dependencies, the code examples from the paper and various additional examples. See the README for a getting started and syntax guides.</p>
},
keywords = {Refinement Kinds, Type Theory, Type-level Computation, Typed Meta-Programming}
}

@software{10.5281/zenodo.3365412,
author = {Bender, John and Palsberg, Jens},
title = {JAM Model: Herd and Coq Instantiations},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3365412},
abstract = {
    <p>The artifact is a virtual machine image with all necessary dependencies to use the Herd and Coq models and reproduce the results of our paper.</p>
},
keywords = {coq, herd, mechanized, memory models}
}

@software{10.5281/zenodo.3366380,
author = {Barik, Rajkishore and Sridharan, Manu and Ramanathan, Murali Krishna and Chabbi, Milind},
title = {Optimization of Swift Protocols},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3366380},
abstract = {
    <p>Swift, an increasingly-popular programming language, advocates the use of protocols, which define a set of required methods and properties for conforming types. Protocols are commonly used in Swift programs for abstracting away implementation details; e.g., in an industrial app, they are heavily used to enable mock objects for unit testing. Unfortunately, heavy use of protocols can result in significant performance overhead. Beyond the dynamic dispatch often associated with such a feature, Swift allows for both value and reference types to conform to a protocol, leading to significant boxing and unboxing overheads. In this paper, we describe three new optimizations and transformations we have developed to reduce the overhead of Swift protocols. Within a procedure, we define LocalVar, a data-flow analysis and transformation to remove both dynamic dispatch and boxing overheads. We also describe Param, which optimizes the case of protocol-typed method parameters using specialization. Finally, we describe SoleType, a transformation that injects casts when a global analysis (like type-hierarchy analysis) discovers some protocol variable must have some concrete type. We also describe how these optimizations work fruitfully together and with existing Swift optimizations to deliver further speedups. We perform elaborate experimentation and demonstrate that our optimizations deliver an average 1.56x speedup on a suite of Swift benchmarks that use protocols. Further, we applied the optimizations to a production iOS Swift application used by millions of customers daily. For a set of performance spans defined by the developers of the application, the optimized version showed speedups ranging from 6.9\% to 55.49\%. A version of our optimizations has been accepted as part of the official Swift compiler distribution.</p>
},
keywords = {boxing/unboxing, protocols, SIL, Swift, virtual method disptach}
}

@software{10.5281/zenodo.3363988,
author = {Marcozzi, Micha\"{e}l and Tang, Qiyi and Donaldson, Alastair F. and Cadar, Cristian},
title = {Replication Package for "Compiler Fuzzing: How Much Does It Matter?"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3363988},
abstract = {
    <p>This artifact provides the bug impact measurement infrastructure and the experimental data presented in the following paper: Micha l Marcozzi, Qiyi Tang, Alastair F. Donaldson, and Cristian Cadar. 2019. Compiler Fuzzing: How Much Does It Matter . Proc. ACM Program. Lang. 3, OOPSLA, Article 155 (October 2019), 29 pages. https://doi.org/10.1145/3360581 The paper introduces the first quantitative and qualitative study of the tangible impact of fuzzer-found compiler bugs. It follows a novel methodology where the impact of a miscompilation bug is evaluated based on (1) whether the bug appears to trigger during compilation; (2) the extent to which generated assembly code changes syntactically due to triggering of the bug; and (3) how likely such changes are to cause runtime divergences during execution. The study is conducted with respect to the compilation of more than 10 million lines of C/C++ code from 309 Debian packages, using 12\% (27) of the historical and now fixed miscompilation bugs found by four state-of-the-art fuzzers in the Clang/LLVM compiler, as well as 18 other bugs found by the Alive formal verification tool or human users. This artifact provides the necessary software and data to replicate this study for the 45 Clang/LLVM miscompilation bugs over the 309 Debian packages. In addition to enabling the easy replication of the paper results, the provided bug impact measurement infrastructure can also be used to measure the impact of miscompilation bugs over Debian packages that have not been considered in the paper. It can also be extended to perform differential testing for multiple compilers or optimisation options of a compiler.</p>
},
keywords = {bug impact, Clang, compilers, fuzzing, LLVM, software testing}
}

@software{10.5281/zenodo.3364086,
author = {Padhye, Rohan and Lemieux, Caroline and Sen, Koushik and Simon, Laurent and Vijayakumar, Hayawardh},
title = {Replication Package for "FuzzFactory: Domain-Specific Fuzzing with Waypoints"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3364086},
abstract = {
    <p>The artifact contains a Docker image for supporting various claims made in the paper. In particular, the Docker image contains a snapshot of the AFL fuzzing tool, a snapshot of FuzzFactory (which itself is a fork of AFL), a snapshot of Google's fuzzer-test-suite, scripts to replicate the experiments described in the paper, and a "pre-baked" data dump of the results of experiments that were conducted on the author's machine (this data can be used to reproduce the plots that are included in the paper).</p>
},
keywords = {domain-specific fuzzing, fuzz testing, waypoints}
}

@software{10.5281/zenodo.3366234,
author = {Rapoport, Marianna and Lhot\'{a}k, Ond?ej},
title = {Coq type soundness proof for 'A Path to DOT: Formalizint Fully Path-Dependent Types'},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3366234},
abstract = {
    <p>Our paper presents pDOT, a generalization of the Dependent Object Types (DOT) calculus that formalizes Scala. The pDOT calculus extends DOT with support for path-dependent types on paths of arbitrary length. This artifact presents the Coq formalization of the pDOT type-safety proof as presented in Section 5 of the paper.</p>
},
keywords = {Coq, DOT, paths, Scala, type safety}
}

@software{10.5281/zenodo.3366904,
author = {Siraichi, Marcos Yukio and Santos, Vin\'{\i}cius Fernandes dos and Collange, Caroline and Pereira, Fernando Magno Quint\~{a}o},
title = {Experiment and Software to Reproduce: Qubit Allocation as a Combination of Subgraph Isomorphism and Token Swapping},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3366904},
abstract = {
    <p>This artifact is composed of mainly scripts, benchmarks, and configuration data used to generate the data of this paper. The scripts set up the environment, downloading the necessary software and dependencies using Git and APT (since package managers are specific for different distros, it may not work on all of them), and compiling them all. In the end, you will have in hands: (i) "enfield", an OpenQASM source-to-source compiler; (ii) all the benchmarks used; (iii) helper scripts. Ideally, you would run the script for reproducing the experiments as is, but you may also change the configuration data for custom experiments.</p>
},
keywords = {Compilers, Quantum Computing, Qubit Allocation}
}

@software{10.5281/zenodo.3368504,
author = {Sergey, Ilya and Nagaraj, Vaivaswatha and Johannsen, Jacob and Kumar, Amrit and Trunov, Anton and Hao, Ken Chan Guan},
title = {Benchmarks accompanying the OOPSLA 2019 paper Safer Smart Contract Programming with Scilla},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3368504},
abstract = {
    <p>This is the artefact accompanying the OOPSLA 2019 paper entitled "Safer Smart Contract Programming with Scilla". The artefact contains scripts for reproducing the quantitative comparison with Ethereum Virtual Machine, reported in the paper.</p>
},
keywords = {Benchmarks, EVM, Scilla, Smart Contracts, Zilliqa}
}

@software{10.5281/zenodo.3374030,
author = {Pan, Rong and Hu, Qinheping and Xu, Gaowei and D'Antoni, Loris},
title = {RFixer: a tool for repairing complex regular expressions using examples},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3374030},
abstract = {
    <p>This artifact contains the virtual machine image that has RFixer installed. RFixer is a tool for repairing complex regular expressions using examples. Given an incorrect regular expression and sets of positive and negative examples, RFixer synthesizes the closest regular expression to the original one that is consistent with the examples. The paper "Automatic Repair of Regular Expressions" that describes RFixer is conditionally accepted at OOPSLA 2019. The Step-by-Step Instructions in the README file explains how to reproduce the paper's results.</p>
},
keywords = {Program Repair, Program Synthesis, Regular Expressions}
}

@software{10.5281/zenodo.3374036,
author = {Shajii, Ariya and Numanagi?, Ibrahim and Baghdadi, Riyadh and Berger, Bonnie and Amarasinghe, Saman},
title = {Seq (OOPSLA 2019 Artifact)},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3374036},
abstract = {
    <p>This is the artifact submitted alongside the Seq paper to OOPSLA 2019, which consists of a VM containing an alpha build of Seq, as well as a usage guide. Seq is a programming language for computational genomics and bioinformatics. With a Python-compatible syntax and a host of domain-specific features and optimizations, Seq makes writing high-performance genomics software as easy as writing Python code, and achieves performance comparable to (and in many cases better than) C/C++.</p>
},
keywords = {artifact, bioinformatics, compiler, domain-specific language, genomics, programming language}
}

@software{10.5281/zenodo.3363977,
author = {Huang, Mingzhang and Fu, Hongfei and Chatterjee, Krishnendu and Goharshady, Amir Kafshdar},
title = {Software Artifact Accompanying the Article "Modular Verification for Almost-Sure Termination of Probabilistic Programs"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3363977},
abstract = {
    <p>Please see the readme file.</p>
},
keywords = {modular analysis, probabilistic programs, Termination analysis}
}

@software{10.5281/zenodo.3364114,
author = {Mastrangelo, Luis and Hauswirth, Matthias and Nystrom, Nathaniel},
title = {Casting about in the Dark - Artifact Evaluation},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3364114},
abstract = {
    <p>Companion dataset artifact used in the paper "Casting about in the Dark".</p>
},
keywords = {cast, Java, type safety}
}

@software{10.5281/zenodo.3366212,
author = {Adams, Ulf},
title = {Implementations of Ryu \&amp; Ryu Printf},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3366212},
abstract = {
    <p>A set of C and Java libraries implementing Ryu and Ryu Printf.</p>
},
keywords = {c, conversion, float, java, printf, string}
}

@software{10.5281/zenodo.3368188,
author = {Vukotic, Ivana and Rahli, Vincent and Esteves-Ver\'{\i}ssimo, Paulo},
title = {Asphalion: Trustworthy Shielding Against Byzantine Faults},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3368188},
abstract = {
    <p>Asphalion is a Coq-based framework for verifying the correctness of implementations of fault-tolerant systems. It especially provides features to verify the correctness of hybrid fault-tolerant systems (such as the MinBFT protocol http://www.di.fc.ul.pt/~bessani/publications/tc11-minimal.pdf), where normal components (that can for example fail arbitrarily) trust some special components (that can for example only crash on failure) to provide properties in a trustworthy manner. Asphalion allows running such trusted-trustworthy components inside Intel SGX enclaves. More details are provided here: https://vrahli.github.io/articles/asphalion.pdf and here: https://vrahli.github.io/articles/asphalion-long.pdf</p>
},
keywords = {Byzantine fault-tolerance, Compositional reasoning, Coq, Crash fault-tolerance, Distributed systems, Fault-tolerance, Formal verification, Hybrid fault-tolerance, Intel SGX, Knowledge calculus, MinBFT, State machine replication, Trusted components}
}

@software{10.5281/zenodo.3368779,
author = {Wang, Shengyi and Cao, Qinxiang and Mohan, Anshuman and Hobor, Aquinas},
title = {Coq library supporting the paper "Certifying Graph-Manipulating C Programs via Localizations within Data Structures"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3368779},
abstract = {
    <p>This Docker machine contains a compiled and ready-to-use version of our Coq code library. Our work aims to provide a comprehensive solution to the problem of formally verifying programs that manipulate mathematical graphs. The codebase contains a number of worked examples showing how our library can be used to verify real C programs. The overview file provides a helpful starter guide to understanding and replicating our verifications.</p>
},
keywords = {CompCert, Coq, Graph-manipulating programs, Separation logic, VST}
}

@software{10.5281/zenodo.3369915,
author = {Bastian, Th\'{e}ophile and Kell, Stephen and Zappa Nardelli, Francesco},
title = {Reliable and Fast DWARF-Based Stack Unwinding (Artifact)},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3369915},
abstract = {
    <p>This VM contains the tools to reproduce the experiments of the submission: Reliable and Fast DWARF-based Stack Unwinding</p>
},
keywords = {debugging, DWARF, stack unwinding}
}

@software{10.5281/zenodo.3370063,
author = {Konnov, Igor and Kukovec, Jure and Tran, Thanh-Hai},
title = {Artifact - TLA+ Model Checking Made Symbolic},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3370063},
abstract = {
    <p>This artifact version, named "25_ae", contains the same materials which we submitted in the artifact evaluation, and two new files README, and LICENSE. Our artifact comes in the form of a virtual machine (user: oopsla19, pass: ae). Our model checker v0.5.0 is already installed on the VM. After the rebuttal, we agreed with the reviewers to add new optimizations in our model checker, and new benchmarks in the second submission. However, these changes are included only in the later version of our artifact, named "25_v2". Please follow the link 10.5281/zenodo.3370071 for the new version called "25_v2", which contains updates in our second submission.</p>
},
keywords = {artifact, model checking, SMT, TLA+}
}

@software{10.5281/zenodo.3370297,
author = {Kokologiannakis, Michalis and Raad, Azalea and Vafeiadis, Viktor},
title = {Replication package for 'Effective Lock Handling in Stateless Model Checking'},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3370297},
abstract = {
    <p>This is the artifact accompanying the paper "Effective Lock Handling in Stateless Model Checking". Our paper's artifact is the set of benchmarks we used in the paper, as well as the results we got by running particular versions of model checking tools (i.e., GenMC and LAPOR) on the benchmarks' set.</p>
},
keywords = {Model checking, mutual exclusion locks, weak memory models}
}

@software{10.5281/zenodo.3377079,
author = {Lu, Jingbo and Xue, Jingling},
title = {Replication package for article: Precision-Preserving Yet Fast Object-Sensitive Pointer Analysis with Partial Context Sensitivity},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3377079},
abstract = {
    <p>This artifact is provided to enable the reproducing of results in Section 4 of the companion paper "Precision-Preserving Yet Fast Object-Sensitive Pointer Analysis with Partial Context Sensitivity". To use this artifact, please start by reading Getting-Started-Guide.pdf and Step-by-Step-Instructions.pdf in the artifact package.</p>
},
keywords = {Dacapo, Soot}
}

@software{10.5281/zenodo.3362696,
author = {Song, Dowon and Lee, Myungho and Oh, Hakjoo},
title = {Automatic and Scalable Detection of Logical Errors in Functional Programming Assignments},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3362696},
abstract = {
    <p>This is an artifact for the paper "Automatic and Scalable Detection of Logical Errors in Functional Programming Assignments" submitted to OOPSLA 2019. It provides VM and documentation for reproducing the evaluation results in the paper. The VM contains source codes for implementing the algorithm, benchmarks used in evaluation, and a python script for reproducing the Table 1 and Table 2 in the paper. Specially, you can see that the main parts of our algorithm are implemented in the following files: 1. engine/TestML/testGenerator.ml: Our overall algorithm and symbolic test case generation 2. engine/TestML/sym_exec.ml: Symbolic verification</p>
},
keywords = {Automated Test Case Generation, Program Synthesis, Symbolic Execution}
}

@software{10.5281/zenodo.3369573,
author = {Goel, Aviral and Vitek, Jan},
title = {Replication Package for Article: On the Design, Implementation and Use of Laziness in R},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3369573},
abstract = {
    <p>The artifact is a Docker image. It performs a dynamic analysis on packages written in the R language, and analyzes the generated data. The artifact uses this data to generate an HTML report containing the graphs and data appearing in our paper. The report is served by the Docker container on localhost:8000.</p>
},
keywords = {Corpus Analysis, Delayed or Lazy Evaluation, Empirical Study, Large-scale, R Language}
}

@software{10.5281/zenodo.3370437,
author = {Biswas, Ranadeep and Enea, Constantin},
title = {Database Testing Tool for Article: On the Complexity of Checking Transactional Consistency},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3370437},
abstract = {
    <p>The artifact contains a database testing tool named `dbcop` which provides three functionalities: 1. A random generator for client programs to run on a database. 2. A `trait`(equivalent to java interface) to run client programs on a database and log its executions. A user can use this trait to write an implementation specific to a database. 3. A verifier that checks conformance of a given execution to a consistency model. `dbcop` offers two subcommands: `generate` and `verify`. 1. `generate` generates client programs to run on a database. 2. `verify` verifies consistency of the executions of these client programs. The artifact is packaged as a Docker image. The image includes our tool and the database-generated executions (histories) used in the experimental evaluation reported in the paper.</p>
},
keywords = {axiomatic specifications, consistency, testing, transactional databases}
}

@software{10.5281/zenodo.3374034,
author = {Wei, Guannan and Chen, Yuxuan and Rompf, Tiark},
title = {Replication Package for Article: Staged Abstract Interpreter},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3374034},
abstract = {
    <p>The artifact contains programs that show how to stage an abstract interpreter step-by-step, as well as programs to reproduce the performance evaluation in the paper.</p>
},
keywords = {abstract interpreters, multi-stage programming, Scala}
}

@software{10.5281/zenodo.3374835,
author = {Yamazaki, Tetsuro and Nakamaru, Tomoki and Ichikawa, Kazuhiro and Chiba, Shigeru},
title = {Generating a fluent API with syntax checking from an LR grammar (Artifact)},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3374835},
abstract = {
    <p>The artifact for "Generating a fluent API with syntax checking from an LR grammar", which will be published in OOPSLA 2019. "artifact.pdf" mentions the usage of typelevelLR, a fluent-API-style library-skeleton generator, which we implemented for the experiments presented in the paper. This artefact contains all the programs that can be used to reproduce the evaluation of our paper. You can find the instructions in the README.pdf file.</p>
},
keywords = {artifact, fluent API, library skeleton generator, OOPSLA 2019}
}

@software{10.5281/zenodo.3384856,
author = {Abdulla, Parosh Aziz and Atig, Mohamed Faouzi and Jonsson, Bengt and L\r{a}ng, Magnus and Ngo, Tuan Phong and Sagonas, Konstantinos},
title = {Optimal Stateless Model Checking for Reads-From Equivalence under Sequential Consistency},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3384856},
abstract = {
    <p>The artifact reproduces the performance numbers in the paper. It consists of an overview document, which describes its use, and a virtual machine image.</p>
},
keywords = {concurrency, model checking, sequential consistency, testing}
}

@software{10.5281/zenodo.3378067,
author = {Mariano, Benjamin and Reese, Josh and Xu, Siyuan and Nguyen, ThanhVu and Qiu, Xiaokang and Foster, Jeffrey S. and Solar-Lezama, Armando},
title = {Replication Package for "Program Synthesis with Algebraic Library Specifications"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3378067},
abstract = {
    <p>This artifact can be used to recreate the experiments from the paper "Program Synthesis with Algebraic Library Specifications". In particular, the artifact contains the benchmarks we used and scripts for running the experiments, as well as instructions for building the tool from source.</p>
},
keywords = {Algebraic Specification, Java, Sketch-based Program Synthesis, Term Rewriting}
}

@software{10.5281/zenodo.3369436,
author = {K?ikava, Filip and Miller, Heather and Vitek, Jan},
title = {Artifact for Scala Implicits are Everywhere},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3369436},
abstract = {
    <p>Code and data for the OOPLSA 2019 paper.</p>
},
keywords = {analysis, Scala}
}

@software{10.1145/3365461,
author = {Castegren, Elias and Fernandez-Reyes, Kiko},
title = {Source Code for "Developing a Monadic Type Checker for an Object-Oriented Language"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3365461},
abstract = {
    <p>This artifact contains the complete source code for the type checker design presented in "Developing a Monadic Type Checker for an Object-Oriented Language". It is available both as plain Haskell source code and as a VM image with the prerequisites installed. If you don't want to download the VM image, you can also find the code online: https://github.com/parapluu/monadic-typechecker.</p>
},
keywords = {compilers, functional programming, object-oriented languages, type systems}
}

@software{10.1145/3365463,
author = {Diekmann, Lukas and Tratt, Laurence},
title = {Experiment for Article: Default Disambiguation for Online Parsers},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3365463},
abstract = {
    <p>This artefact provides scripts, programs, and other materials needed to reproduce the results from the evaluation section of the paper. The archive also contains a Debian VM which has been pre-configured with all necessary dependencies to run the experiment. For more information, please refer to the README.txt and guide.pdf in the archive.</p>
},
keywords = {language composition, parsing}
}

@software{10.1145/3365460,
author = {Jeanjean, Pierre and Combemale, Benoit and Barais, Olivier},
title = {Artifact for the Paper: From DSL specification to interactive computer programming environment},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3365460},
abstract = {
    <p>This artifact contains the necessary Eclipse plugins to generate and execute REPLs from more traditional DSL specifications. It was made to be run on top of the GEMOC Studio, a customized Eclipse platform that includes technologies to develop, maintain and use executable modeling languages. The GEMOC Studio includes, among others, support and integration for DSL specifications, and an execution engine to execute languages with semantics written in ALE (Action Language for EMF). The current artifact also includes the specifications of two languages that were introduced in the evaluation of the submitted paper: Logo and MiniJava.</p>
},
keywords = {domain specific languages, language engineering, repl}
}

@software{10.1145/3373108,
author = {Bourke, Timothy and Brun, L\'{e}lio and Pouzet, Marc},
title = {Models, Algorithms, and Proofs for "Mechanized Semantics and Verified Compilation for a Dataflow Synchronous Language with Reset"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373108},
abstract = {
    <p>These source files contain the implementation, models, and proof of correctness of a formally verified Lustre compiler. The compiler supports the reset construct which is presented in the POPL 2020 paper. The examples/ subdirectory contains several example programs that can be used to test the compiler. We build on earlier work together with Pierre- variste Dagand, Xavier Leroy, and Lionel Rieg.</p>
},
keywords = {interactive theorem proving (Coq), stream languages, synchronous languages (Lustre), verified compilation}
}

@software{10.1145/3373103,
author = {Forster, Yannick and Kunze, Fabian and Roth, Marc},
title = {Mechanisation of "The Weak Call-By-Value?-Calculus is Reasonable for Both Time and Space"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373103},
abstract = {
    <p>This Coq development contains the mechanised parts of the paper "The Weak Call-By-Value  -Calculus is Reasonable for Both Time and Space". The mechanisation defines two abstract machines that evaluate call by value lambda calculus and analyses the sizes of the states during a machine run and the lengths of the runs, both in relation to the semantics on terms.</p>
},
keywords = {abstract machines, invariance thesis, lambda calculus, time and space complexity, weak call-by-value reduction}
}

@software{10.5281/zenodo.3533037,
author = {Sammler, Michael and Garg, Deepak and Dreyer, Derek and Litak, Tadeusz},
title = {Coq development for "The High-Level Benefits of Low-Level Sandboxing"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3533037},
abstract = {
    <p>This is the artifact for the POPL'20 paper "The High-Level Benefits of Low-Level Sandboxing". It contains the Coq development formalizing the results of the paper.</p>
},
keywords = {Coq, Iris, language-based security, logical relations, robust safety, sandboxing, type systems}
}

@software{10.5281/zenodo.3533633,
author = {Wang, Peixin and Fu, Hongfei and Chatterjee, Krishnendu and Deng, Yuxin and Xu, Ming},
title = {Software Artifact Accompanying the Article: Proving Expected Sensitivity of Probabilistic Programs with Randomized Variable-Dependent Termination Time},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3533633},
abstract = {
    <p>This artifact contains an implementation of the RSM synthesis algorithm as described in the paper. For details, please see the "README.md" file.</p>
},
keywords = {Expected Sensitivity, Martingales, Probabilistic Programs}
}

@software{10.5281/zenodo.3541779,
author = {Jung, Ralf and Dang, Hoang-Hai and Kang, Jeehoon and Dreyer, Derek},
title = {Stacked Borrows: An Aliasing Model for Rust -- Artifact},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3541779},
abstract = {
    <p>This is the artifact accompanying the POPL20 paper "Stacked Borrows: An Aliasing Model for Rust". It consists of a Coq mechanization of the simulation proof sketches that were made in the paper. For more information about that paper, see https://plv.mpi-sws.org/rustbelt/stacked-borrows/.</p>
},
keywords = {alias analysis, Coq, operational semantics, program transformation, Rust, simulation proof}
}

@software{10.1145/3373109,
author = {Wang, Chenglong and Feng, Yu and Bodik, Rastislav and Cheung, Alvin and Dillig, Isil},
title = {Falx: Visualization by Example Tool},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373109},
abstract = {
    <p>Our artifact contains the following materials: * Benchmarks of visualization by example tasks. See Benchmarks section. * Implementation of the synthesis algorithm (named Falx, stored under the artifact directory) in Python3. This is our implementation used in the paper evaluation. * Evaluation log and analysis scripts used in our paper evaluation. * A new implementation of the synthesis algorithm for playing purpose (named Falx-new, stored under the falx-new directory). See Extra: Play with the Tool to learn about this new implementation.</p>
},
keywords = {Program Synthesis, Programming-by-Example, Visualization}
}

@software{10.1145/3373110,
author = {Xia, Li-yao and Zakowski, Yannick and He, Paul and Hur, Chung-Kil and Malecha, Gregory and Pierce, Benjamin C. and Zdancewic, Steve},
title = {Library presented in the paper: Interaction Trees},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373110},
abstract = {
    <p>Interaction Trees is a Coq library, defining a structure for representing recursive and impure programs, featuring an equational theory for reasoning about monadic programs.</p>
},
keywords = {coq, denotational semantics, formal verification, monads}
}

@software{10.1145/3373112,
author = {Raghothaman, Mukund and Mendelson, Jonathan and Zhao, David and Naik, Mayur and Scholz, Bernhard},
title = {Replication Package for Article: Provenance-Guided Synthesis of Datalog Programs},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373112},
abstract = {
    <p>This is the artifact package accompanying our POPL 2020 submission titled Provenance-Guided Synthesis of Datalog Programs. The paper presents a new algorithm to synthesize Datalog programs from input-output examples. We have implemented this algorithm in a tool named ProSynth, and benchmarked them against the existing solvers, ALPS and Difflog. This artifact contains all three tools (ProSynth, ALPS, and Difflog), benchmark files, and scripts to reproduce the experiments described in the paper. In this document, we will describe the outline of these experiments, how to run them, and also describe how one may use ProSynth to solve Datalog synthesis problems of their own.</p>
},
keywords = {Counter-Example Guided Inductive Synthesis (CEGIS), data provenance, Datalog, Program synthesis, SAT solvers, Syntax-Guided Synthesis (SyGuS)}
}

@software{10.1145/3373097,
author = {Barthe, Gilles and Blazy, Sandrine and Gr\'{e}goire, Benjamin and Hutin, R\'{e}mi and Laporte, Vincent and Pichardie, David and Trieu, Alix},
title = {Supplementary material for Article: Formal Verification of a Constant-Time Preserving C Compiler},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373097},
abstract = {
    <p>Supplementary material for Article: Formal Verification of a Constant-Time Preserving C Compiler Contains a modified version of the CompCert 3.4 C compiler for which cryptographic constant-time security has been proved to be preserved as described in the article.</p>
},
keywords = {CompCert compiler, Coq, timing side-channels, verified compilation}
}

@software{10.1145/3373098,
author = {Hu, Jason Z. S. and Lhot\'{a}k, Ond?ej},
title = {Undecidability of D&lt;: and Its Decidable Fragments},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373098},
abstract = {
    <p>The home page of the artifact: https://hustmphrrr.github.io/popl20-artifact/ This artifact formalizes the theorems in our paper, Undecidability of D&lt;: and Its Decidable Fragments. The formalization is done in a combination of Coq 8.8.2 and Agda 2.5.4.2. The artifact ships with 1. the Agda code for undecidability analysis, 2. the Coq code for algorithmic analysis, 3. the HTML files generated from the previous two components, and 4. a VM file with environment set up. The artifact contains necessary instructions on how to install binaries and reproduce our results.</p>
},
keywords = {Agda, algorithmic subtyping, Coq, undecidability}
}

@software{10.1145/3373104,
author = {Migeed, Zeina and Palsberg, Jens},
title = {What Is Decidable about Gradual Types?},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373104},
abstract = {
    <p>In this artifact, we verify the results of the paper "What is Decidable about Gradual Types ". In particular, we verify the results of four algorithmic problems. 1- Singleton 2- Top Choice 3- Finitness 4- Maximality We provide a Haskell implementation for the above problems. In particular, we implement the decision procedures for the first three problems and the semi algorithm for the fourth problem. The results are given by figures 4,6 and 7 while figure 5 contains scalability and performance results. We first verify the results in figures 4,6, and 7 and finally figure 5.</p>
},
keywords = {Algorithms and Complexity, Gradual typing, Type inference, Type theory}
}

@software{10.1145/3373105,
author = {Mathur, Umang and Murali, Adithya and Krogmeier, Paul and Madhusudan, P. and Viswanathan, Mahesh},
title = {Replication Package for Article: Deciding Memory-Safety for Single-Pass Heap Manipulating Programs},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373105},
abstract = {
    <p>Proof of concept implementation of the streaming congruence closure algorithm from Deciding Memory-Safety for Single-Pass Heap Manipulating Programs.</p>
},
keywords = {decidable, memory safety, uninterpreted programs, verification}
}

@software{10.1145/3373107,
author = {Greenberg, Michael and Blatt, Austin J.},
title = {Replication Package for Article: Executable Formal Semantics for the POSIX Shell},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373107},
abstract = {
    <p>A Vagrant box containing a Linux image which has Smoosh installed in /bin/smoosh. Other shells discussed in the paper are installed, as well. The Smoosh test suites is available, as is modernish.</p>
},
keywords = {executable formal semantics, POSIX shell, Smoosh}
}

@software{10.1145/3373113,
author = {Lazarek, Lukas and King, Alexis and Sundar, Samanvitha and Findler, Robert Bruce and Dimoulas, Christos},
title = {Artifact for: Does Blame Shifting Work?},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373113},
abstract = {
    <p>The artifact is a VirtualBox virtual machine appliance that contains all of the source code, benchmarks, and experiment harnesses used in the development of the paper (pre-built and set up). It comes with a README and interactive demo illustrating how the experiment works, as well as pointers for how to extend or modify the experiment.</p>
},
keywords = {blame, Higher-order contracts, programming languages design evaluation, Racket}
}

@software{10.1145/3373115,
author = {Meyer, Roland and Wolff, Sebastian},
title = {seal},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373115},
abstract = {
    <p>Verification tool for lock-free data structures with safe memory reclamation.</p>
},
keywords = {data-structures, epoch-based-reclamation, garbage collection, hazard-pointer, linearizability, lock-free, memory-management, memory-reclamation, static analysis, type-system, verification}
}

@software{10.5281/zenodo.3539237,
author = {Dang, Hoang-Hai and Jourdan, Jacques-Henri and Kaiser, Jan-Oliver and Dreyer, Derek},
title = {RustBelt Meets Relaxed Memory (Artifact)},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3539237},
abstract = {
    <p>This is a virtual machine that contains a snapshot of the RustBelt Relaxed Coq development. In our repository, the snapshot has the tag "RBrlx-POPL20-artifact". More updated information can be found at http://plv.mpi-sws.org/rustbelt/rbrlx/.</p>
},
keywords = {Coq, Iris, relaxed memory model, Rust, RustBelt, semantic soundness}
}

@software{10.5281/zenodo.3544697,
author = {Guo, Zheng and James, Michael and Justo, David and Zhou, Jiaxiao and Wang, Ziteng and Jhala, Ranjit and Polikarpova, Nadia},
title = {Hoogle Plus},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3544697},
abstract = {
    <p>Hoogle Plus implements our Type-Guided Abstraction Refinement technique. It includes two binaries: `hplus`, which serves as a CLI to our synthesis engine; and `webapp`, which serves a basic web interface to our default parameters. There are two scripts to re-run the evaluation, either in part or in full (evaluation-short.sh and evaluation.sh)</p>
},
keywords = {Functional Programming, Haskell, Program Synthesis, Type Systems}
}

@software{10.5281/zenodo.3545194,
author = {Lee, Wonyeol and Yu, Hangyeol and Rival, Xavier and Yang, Hongseok},
title = {Artifact for Article: Towards Verified Stochastic Variational Inference for Probabilistic Programs},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3545194},
abstract = {
    <p>The artifact includes (i) our implementation of the static analysis for model-guide support match, and (ii) the Pyro model-guide pairs used in our experiments. For more details, please refer to `README.txt' in the artifact, and Section 8 of the paper.</p>
},
keywords = {correctness, Probabilistic programming, semantics, static analysis, variational inference}
}

@software{10.5281/zenodo.3570660,
author = {Jung, Ralf and Lepigre, Rodolphe and Parthasarathy, Gaurav and Rapoport, Marianna and Timany, Amin and Dreyer, Derek and Jacobs, Bart},
title = {The Future is Ours: Prophecy Variables in Separation Logic -- Artifact},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3570660},
abstract = {
    <p>This is the artifact accompanying the POPL20 paper "The Future is Ours: Prophecy Variables in Separation Logic". For more information about that paper, see https://plv.mpi-sws.org/prophecies/.</p>
},
keywords = {Iris, linearizability, logical atomicity, Prophecy variables, separation logic}
}

@software{10.1145/3373099,
author = {Farzan, Azadeh and Vandikas, Anthony},
title = {Replication Package for Article: Reductions for Safety Proofs},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373099},
abstract = {
    <p>Contains a tool implementing the verification algorithm described in the paper, as well as a script for reproducing the benchmark times presented in Section 9 of the paper.</p>
},
keywords = {Automata, Automated Verification, Concurrency, Reductions}
}

@software{10.1145/3373102,
author = {Handley, Martin A. T. and Vazou, Niki and Hutton, Graham},
title = {RTick library and proofs described in the paper},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373102},
abstract = {
    <p>This artifact includes: - Source files for the RTick library - The source code for the examples presented throughout the paper, in particular, those summarised in Table 1; - Formalised proofs of the functor, applicative, and monad laws for the Tick datatype; - Formalised proofs of the relationships between the cost relations shown in Figure 2.</p>
},
keywords = {Liquid Haskell, refinement types, resource analysis, static verification}
}

@software{10.1145/3373106,
author = {Saad, Feras A. and Freer, Cameron E. and Rinard, Martin C. and Mansinghka, Vikash K.},
title = {Sampling Algorithms and Experiments for: Optimal Approximate Sampling from Discrete Probability Distributions},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373106},
abstract = {
    <p>This artifact contains implementations of the main algorithms in the paper, implementations of baseline sampling algorithms and experimental pipelines. Please refer to the README for additional details.</p>
},
keywords = {experimental pipelines, performance measurements, sampling algorithms}
}

@software{10.1145/3373096,
author = {Hinrichsen, Jonas Kastberg and Bengtson, Jesper and Krebbers, Robbert},
title = {Coq Mechanisation of Actris: Session-Type Based Reasoning in Separation Logic},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373096},
abstract = {
    <p>This artifact concerns a Coq development, which is based on the Iris framework for concurrent separation logic. The artifact consists of a zip file that contains: - A virtual machine with the artifact installed. - The sources of the artifact that one can build locally. - A link to the git repository of the current version of the artifact.</p>
},
keywords = {actor model, concurrency, Coq, Iris, Message passing, session types}
}

@software{10.1145/3373100,
author = {Kim, Sung Kook and Venet, Arnaud J. and Thakur, Aditya V.},
title = {Replication Package for Article: Deterministic Parallel Fixpoint Computation},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373100},
abstract = {
    <p>The main purpose of this artifact is to share the implementation of algorithms in the paper. The paper describes how the fixpoint computation in abstract interpretation can be parallelized without non-determinism. The provided implementation is a fully functioning end-to-end static analysis tool. The artifact also contains data and figures in the paper, and scripts to reconstruct them.</p>
},
keywords = {abstract interpretation, chaotic iteration, concurrency, concurrent iteration strategy, program analysis, weak partial order}
}

@software{10.1145/3373111,
author = {Jaber, Guilhem},
title = {Prototype of SyTeCi},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373111},
abstract = {
    <p>This prototype generates, from two programs M_1,M_2 written in a fragment of ML, the Structured-Memory Transition Machine A_S as described in this paper. It is represented using the dot format of graphviz. One can then check that no failed states are reachable in A_S to prove that M_1,M_2 are contextually equivalent. In the restricted fragment described in the paper cited above, the prototype can also generates the set of constrained Horn clauses corresponding to the non-reachability of failed states of A_S. These constrained Horn clauses are written in an extension of the SMT-LIB2 formate described here, than can be checked by the SMT-sover z3.</p>
},
keywords = {Contextual Equivalence, Operational Game Semantics}
}

@software{10.5281/zenodo.3544373,
author = {Sozeau, Matthieu and Boulier, Simon and Forster, Yannick and Tabareau, Nicolas and Winterhalter, Th\'{e}o},
title = {Snapshot of MetaCoq associated to the article},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3544373},
abstract = {
    <p>This archive contains the whole development of MetaCoq. If you only want to browse the files a "light" documentation is available in html/toc.html which provides access to all the development files. Otherwise, to run interactively, the development can be compiled with Coq 8.9.1 and Equations 1.2. Detailed installation instructions for the version of the package on opam are below, what follows is a short summary of the development and installation instructions for the popl artifact sources version.</p>
},
keywords = {Metatheory
Type-checking
Proof Assistants}
}

@software{10.1145/3373101,
author = {Song, Youngju and Cho, Minki and Kim, Dongjoo and Kim, Yonghyun and Kang, Jeehoon and Hur, Chung-Kil},
title = {Replication Package for Article: "CompCertM: CompCert with C-Assembly Linking and Lightweight Modular Verification"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373101},
abstract = {
    <p>This artifact is a replication package for the article "CompCertM: CompCert with C-Assembly Linking and Lightweight Modular Verification".</p>
},
keywords = {CompCert, Compositional Compiler Correctness, Coq, Verified Compilation}
}

@software{10.5281/zenodo.3543712,
author = {Chang, Stephen and Ballantyne, Michael and Turner, Milo and Bowman, William J.},
title = {Artifact for: Dependent Type Systems as Macros},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3543712},
abstract = {
    <p>Implementation of the Turnstile+ framework, and the Cur proof assistant</p>
},
keywords = {dependent types, macros, proof assistants, type systems}
}

@software{10.5281/zenodo.3546500,
author = {Darais, David and Sweet, Ian and Liu, Chang and Hicks, Michael},
title = {OblivML},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3546500},
abstract = {
    <p>OblivML is an extension of the  obliv language with additional programming constructs. The repository also contains examples of ORAM and an Oblivious Stack (OStack). It is the artifact for the associated POPL 2020 paper, A Language for Probabilistically Oblivious Computation.</p>
},
keywords = {Noninterference., Oblivious Computation, Probability, Type Systems}
}

@software{10.1145/3373116,
author = {Arntzenius, Michael and Krishnaswami, Neel},
title = {Artifact for Article: Semina\"{\i}ve Evaluation for a Higher-Order Functional Language},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373116},
abstract = {
    <p>A virtual machine containing the source code for an implementation of Datafun along with the tools necessary to build it and run a simple benchmark suite demonstrating an asymptotic speedup resulting from the seminaive optimization (along with auxilliary optimizations) described in the paper.</p>
},
keywords = {Datafun, Datalog, functional languages, incremental computation, relational languages, semina\"{\i}ve evaluation}
}

@software{10.5281/zenodo.3572539,
author = {Mackay, Julian and Potanin, Alex and Aldrich, Jonathan and Groves, Lindsay},
title = {Proof of Decidable Subtyping for Path Dependent Types},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3572539},
abstract = {
    <p>A proof of subtype decidability for the Wyv_self and Wyv_fix variants of Wyvern, formalised in Coq. The associated type systems are described in greater detail in the associated paper: Decidable Subtyping for Path Dependent Types.</p>
},
keywords = {Formal Methods, Functional Programming Languages, Object Oriented Lanaguages, Programming Languages, Proofs, Scala, Type Systems, Type Theory, Wyvern}
}

@software{10.17863/CAM.46071,
author = {Savage, Joe and Jones, Timothy M.},
title = {Research data supporting "HALO: Post-Link Heap-Layout Optimisation"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.17863/CAM.46071},
abstract = {
    <p>Source code for the HALO optimisation pipeline. This includes a client for the Pin binary instrumentation framework, a patch for the BOLT binary optimiser, a custom memory allocator, and scripts to assist in applying our optimisations and extracting performance results. See the README.md file within the repository for a more detailed description and usage instructions.</p>
},
keywords = {binary analysis, binary optimisation, data layout optimisation}
}

@software{10.5281/zenodo.3588624,
author = {Forsberg, Fredrik Nordvall and Xu, Chuangjie and Ghani, Neil},
title = {Agda formalisation for article: Three Equivalent Ordinal Notation Systems in Cubical Agda},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3588624},
abstract = {
    <p>This is the complete cubical Agda formalisation of our CPP'20 paper "Three equivalent ordinal notation systems in cubical Agda".</p>
},
keywords = {Agda, higher inductive types, inductive-inductive definitions, ordinals, Type theory, univalence}
}

@software{10.5281/zenodo.3542289,
author = {Cheng, Lin and Ilbeyi, Berkin and Bolz-Tereick, Carl Friedrich and Batten, Christopher},
title = {Replication package for Type Freezing: Exploiting Attribute Type Monomorphism in Tracing JIT Compilers},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3542289},
abstract = {
    <p>In this artifact we provide the source code of type freezing equipped PyPy, our microbenchmarks, and PyPy benchmarks we used in our paper -- Type Freezing: Exploiting Attribute Type Monomorphism in Tracing JIT Compilers. Along with the source code, we also provide a prebuilt Docker image. Be noted that running performance experiments inside Docker can have unexpected behaviors. Please refer to the README file for how to import the docker image, translate PyPy from source code, and run the experiments we did in this paper.</p>
},
keywords = {dynamic languages, just-in-time compiler, PyPy, type monomorphism}
}

@software{10.5281/zenodo.3597890,
author = {Cowan, Meghan and Moreau, Thierry and Chen, Tianqi and Bornholt, James and Ceze, Luis},
title = {Replication Package for Automatic Generation of High-Performance Quantized Machine Learning Kernels},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3597890},
abstract = {
    <p>This artifact contains the source code for generating quantized operators for ARM devices as well as scripts to reproduce the experimental results. Quantized microkernels are synthesized for ARM NEON, which are used by TVM, a machine learning compiler.</p>
},
keywords = {code generation, program synthesis, Quantization}
}

@software{10.1145/3373117,
author = {Annenkov, Danil and Nielsen, Jakob Botsch and Spitters, Bas},
title = {Coq development for Article "ConCert: A Smart Contract Certification Framework in Coq"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373117},
abstract = {
    <p>A framework for smart contract verification in Coq. Main components =============== * 'smart-contract-interactions' folder - contains a model/executable specification of smart con-tract execution in Coq (see Jakob Botsch Nielsen, Bas Spitters. Smart Contract Interactions in Coq. FMBC'19). * 'theories' folder - contains an embedding of the  smart language into Coq, a proof of soundness, integration with the execution model, examples. Some highlights =============== theories/Ast.v contains definition of the  smart language (Section 2.2). theories/EvalE.v contains an interpreter for  smart language (Section 2.2, Figure 2). theories/pcuic/PCUICTranslate.v contains the translation from  smart expression to PCUIC terms (Section 2.3, Figure 3). theories/pcuic/PCUICCorrectness.v contatins proofs of Theorem 1, Corollary 2 and Theorem 3. theories/pcuic/PCUICCorrectnessAux.v contatins proofs of Lemmas 1 and 2. theories/Wf.v contains well-formedness conditions (Definition 1) theories/examples/crowdfunding contains a crowdfunding contract given as a deep embedding using notations and proofs of functional correctness properties on the corresponding shallow embedding (Section 3). theories/examples/AcornExamples.v contains Examples of library code and contracts originating from the actual Acorn implementation, including verification of Acorn list functions (Section 4). theories/examples/ExecFrameworkIntegration.v contains integration with the execution framework (instances, wrappers) and properties of the crowdfunding contract with relation to the execution model (Section 5). smart-contract-interactions is a folder containing the execution framework itself. also, see theories/examples/Demo.v for demonstration of how to use our framework to write definitions using the deep embedding, convert them to Coq functions, compute with the interpreter and prove simple properties using the shallow embedding.</p>
},
keywords = {blockchain, Coq proof assistant, program verification, smart contracts}
}

@software{10.1145/3373120,
author = {Haj-Ali, Ameer and Ahmed, Nesreen K. and Willke, Ted and Shao, Yakun Sophia and Asanovic, Krste and Stoica, Ion},
title = {GitHub Version 0.0.1: NeuroVectorizer: End-to-End Vectorization with Deep Reinforcement Learning},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373120},
abstract = {
    <p>This artifact can be used to produce similar results to ours. It runs training of our NeuroVectorizer framework that trains end-to-end from the code to the optimal factors. Data is provided in the README. It is best if you keep using the updated github repo for fixes/updates.</p>
},
keywords = {Automatic Vectorization., Code Optimization, Deep Reinforcement Learning, LLVM}
}

@software{10.5281/zenodo.3558339,
author = {Dakkak, Abdul and Wickham-Jones, Tom and Hwu, Wen-mei},
title = {Artifact for The Design and Implementation of the Wolfram Language Compiler},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3558339},
abstract = {
    <p>Benchmark source code for the CGO'20 paper</p>
},
keywords = {compiler, mathematica, wolfram}
}

@software{10.5281/zenodo.3581199,
author = {Zhang, Yunming and Brahmakshatriya, Ajay and Chen, Xinyi and Dhulipala, Laxman and Kamil, Shoaib and Amarasinghe, Saman and Shun, Julian},
title = {Optimizing Ordered Graph Algorithms with GraphIt},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3581199},
abstract = {
    <p>Instructions to test the compiler extension and replicate the performance numbers.</p>
},
keywords = {Compiler Optimizations, Graph Processing}
}

@software{10.1145/3373122,
author = {Taneja, Jubi and Liu, Zhengyang and Regehr, John},
title = {Replication Package for Article: Testing Static Analyses for Precision and Soundness},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373122},
abstract = {
    <p>This artifact provides the source code that implements our work on testing precision and soundness of LLVM s dataflow analyses. Our work builds on the open source superoptimizer, Souper and evaluates LLVM 8.0. We use SPEC CPU 2017 benchmarks version 1.0.1 to evaluate the precision and soundness, and measure the impact of maximal precision on code generation by testing some open source applications like, Gzip, Bzip2, Stockfish, and SQLite . We provide a Dockerfile in our artifact to automatically build the Docker image, which takes care of installing all required dependencies, benchmark suite, and Souper for the experimental evaluation.</p>
},
keywords = {Dataflow analysis, Precision, Soundness}
}

@software{10.1145/3373121,
author = {Ismail, Mohamed and Suh, G. Edward},
title = {Artifact for Article: Efficient Nursery Sizing for Managed Languages on Multi-core Processors with Shared Caches},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373121},
abstract = {
    <p>Our artifact provides a full framework to evaluate the performance of our Dynamic Nursery Allocator. The framework is provided as a Docker image to ensure repeatability and to make setup and running it easy on any platform. Our framework consists of: (1) The compiled PyPy binary that supports DNA along with the PyPy source code and the DNA source code, (2) The Python and PyPy benchmark suite programs used in the evaluation, (3) Scripts to setup the experiments and automate running the benchmarks, (4) An analysis script to summarize the results as CSV files, and (5) Graphing scripts to generate graphs from the CSV files. We additionally provide reference CSV files with the results presented in the paper for inspection and comparison.</p>
},
keywords = {automatic memory management, managed languages, PyPy, Python, shared caches}
}

@software{10.5281/zenodo.3605359,
author = {Kang, Seokwon and Choi, Kyunghwan and Park, Yongjun},
title = {[Evaluation Package] PreScaler: An Efficient System-aware Precision Scaling Framework on Heterogeneous Systems},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3605359},
abstract = {
    <p>This package provides all the binaries, libraries, benchmarks, and scripts, for evaluating the PreScaler implementations. These require target heterogeneous systems that contain Intel CPUs and NVIDIA GPUs. This package provides PreScaler artifact in two forms: ocker images and native binaries for several different system environments. These include installation scripts for software dependencies except NVIDIA Graphic Driver and CUDA toolkit. When you use a Docker image, all the software dependencies are preinstalled.</p>
},
keywords = {Compiler, HSA, OpenCL, Precision Scaling, Profile-guided, Runtime}
}

@software{10.5281/zenodo.3608382,
author = {Chen, Hanfeng and Krolik, Alexander and Kemme, Bettina and Verbrugge, Clark and Hendren, Laurie},
title = {Replication Package for Article: Improving Database Query Performance with Automatic Fusion},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3608382},
abstract = {
    <p>This artifact is created for showing the reproducibility of our experiments in the paper. We provide the details of scripts and original data used in the experiments. There are mainly two systems: HorsePower and RDBMS MonetDB. We supply step-by-step instructions to configure and deploy both systems in the experiments.</p>
},
keywords = {Array programming, Compiler optimizations, IR, Loop fusion, SQL database queries}
}

@software{10.1145/3373124,
author = {Castro-Perez, David and Yoshida, Nobuko},
title = {Tool and Benchmarks for Article: Compiling First-Order Functions to Session-Typed Parallel Code},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373124},
abstract = {
    <p>This is the artifact for the paper 'Compiling First-Order Functions to Session-Typed Parallel Code'. It contains a prototyle EDSL for the language described in the paper, as well as the benchmarks that we used for its evaluation.</p>
},
keywords = {arrows, Haskell, multiparty session types, parallel programming}
}

@software{10.5281/zenodo.3579301,
author = {L\'{o}pez-G\'{o}mez, Javier and Fern\'{a}ndez, Javier and Astorga, David del Rio and Vassilev, Vassil and Naumann, Axel and Garc\'{\i}a, J. Daniel},
title = {Replication Package for Article: Relaxing the One Definition Rule in Interpreted C++},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3579301},
abstract = {
    <p>This package contains the required scripts and source code to run the required evaluation tests -both, those included in the paper, and additional tests-. For convenience, we provide a VM image in OVA format that contains all the required dependencies. Users should import the image and see the README file for further instructions. Alternatively, the `master' branch can be built from sources in the Cling repository.</p>
},
keywords = {C++, Cling, interpreter, One-Definition-Rule}
}

@software{10.5281/zenodo.3607141,
author = {Chida, Nariyoshi and Kawakoya, Yuhei and Ikarashi, Dai and Takahashi, Kenji and Sen, Koushik},
title = {PoC Implementation of parser generators based on existing/SG/CM-stateful packrat parsing},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3607141},
abstract = {
    <p>This is an artifact of the paper titled "Is Stateful Packrat Parsing Really Linear in Practice  -- A Counter-Example, an Improved Grammar, and Its Parsing Algorithms --".</p>
},
keywords = {Parser Generator, Parsing Expression Grammar, Stateful Packrat Parser}
}

@software{10.1145/3373126,
author = {Thakur, Manas and Nandivada, V. Krishna},
title = {Artifact for Paper: Mix Your Contexts Well},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373126},
abstract = {
    <p>Our artifact includes Java code for our techniques proposed in this paper: lsrvH and lsrvkobjH. We have also provided the code for our implementation of the object-sensitive analysis (kobjH). Instructions to use can be found in the included appendix.pdf and README.txt.</p>
},
keywords = {Context-sensitivity, Java, Static analysis}
}

@software{10.1145/3373123,
author = {Serrano, Manuel and Findler, Robert Bruce},
title = {Replication package for: Dynamic Property Caches, A Step towards Faster JavaScript Proxy Objects},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373123},
abstract = {
    <p>The artifact associated with the submission Dynamic Property Caches is the Hop JavaScript static native compiler and the test suite that is described and used in the paper. The compiler and the tests are packaged in a way that facilitates the reproduction of the experimental results of the paper. The artifact contains two automatic procedures. One that re-runs the portion of the performance evaluation for Hop and V8 and one that re-runs the full experiment.</p>
},
keywords = {ahead-of-time compilation., AOT, compiler, compiler optimization, dynamic languages, JavaScript, runtime representation}
}

@software{10.1145/3373127,
author = {Matsumura, Kazuaki and Zohouri, Hamid Reza and Wahib, Mohamed and Endo, Toshio and Matsuoka, Satoshi},
title = {AN5D-Artifact},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373127},
abstract = {
    <p>The artifact contains the set of stencil benchmarks evaluated in this paperand scripts to automatically optimize, compile, run and extract the results for all benchmarks. The generated code can be compiled using NVIDIA CUDA compiler (NVCC) and evaluated on NVIDIA GPUs. For each benchmark, execution performance and result of verifying the output of computation against CPU-only execution are printed by the host code.</p>
},
keywords = {Automatic Code Generation, GPU, Stencil Computation, Temporal Blocking}
}

@software{10.1145/3373125,
author = {Pizzuti, Federico and Steuwer, Michel and Dubach, Christophe},
title = {Replication Packager for 'Generating Fast Sparse Matrix Vector Multiplicationfrom a High Level Generic Functional IR'},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373125},
abstract = {
    <p>The artefact contains the version of the Lift compiler used within the paper, together with the reference cuSparse benchmark and detailed instructions on how to reproduce the experiment</p>
},
keywords = {Code Generation, Dependent Types, GPU programming, Sparse Matrix}
}

@software{10.5281/zenodo.3597725,
author = {Kr\"{u}ger, Stefan and Ali, Karim and Bodden, Eric},
title = {CogniCrypt_GEN - Generating Code for the Secure Use of Crypto APIs (Artefact)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3597725},
abstract = {
    <p>In this artefact, we present Cognicrypt_GEN, a code generation approach that allows for the generation of functionally correct, type-safe, and secure Java code that implements common use cases of cryptographic APIs. To implement a given use case, Cognicrypt_GEN requires two artefacts: a) a set of API-usage rules in the specification language CrySL and b) a Java code template specifying which CRYSL rules are to be used and how. The artefact comes with an Eclipse environment, in which Cognicrypt_GEN may be executed with all eleven use cases from the original paper. It further contains the artefacts to all use cases to allow for modification and extension. We finally include a tutorial on how Cognicrypt_GEN is used.</p>
},
keywords = {Code Generation, Cryptography, Eclipse, Java}
}

@software{10.6084/m9.figshare.12518474,
author = {Macias, Konner and Mathur, Mihir and Bruce, Bobby R. and Zhang, Tianyi and Kim, Miryung},
title = {WebJShrink},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.12518474},
abstract = {
    <p>This contains the WebJShrink code. WebJShrink is documented in the paper “WebJShrink: A Web Service for Debloating Java Bytecode”, by Konner Macias, Mihir Mathur, Bobby R. Bruce, Tianyi Zhang, and Miryung Kim. This paper is currently under review at ESEC/FSE 2020’s demo-track.</p>
<p>Please consult README.md on how to setup an instance of WebJShrink.</p>
<p>WebJShrink builds upon JShrink: https://doi.org/10.6084/m9.figshare.12435542.v3</p>

},
keywords = {debloating, Java bytecode, JShrink, WebJShrink}
}

@software{10.1145/3395630,
author = {Kang, Jeehoon and Jung, Jaehwang},
title = {Implementation and Benchmark suite for Article: A Marriage of Pointer- and Epoch-Based Reclamation},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395630},
abstract = {
    <h2 id="a-marriage-of-pointer--and-epoch-based-reclamation">A Marriage of Pointer- and Epoch-Based Reclamation</h2>
<p>This is the artifact for</p>
<p>Jeehoon Kang and Jaehwang Jung, A Marriage of Pointer- and Epoch-Based Reclamation, PLDI 2020.</p>
<p>The latest developments are on <a href="https://github.com/kaist-cp/pebr-benchmark" class="uri">https://github.com/kaist-cp/pebr-benchmark</a>.</p>
<h3 id="summary">Summary</h3>
<p>On Ubuntu 18.04,</p>
<pre><code>sudo apt install build-essential python3-pip
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
pip3 install --user pandas plotnine
python3 bench.py
python3 plot.py</code></pre>
<h3 id="dependencies">Dependencies</h3>
<ul>
<li>Linux &gt;= 4.14 for <a href="http://man7.org/linux/man-pages/man2/membarrier.2.html"><code>MEMBARRIER_CMD_PRIVATE_EXPEDITED</code> and <code>MEMBARRIER_CMD_REGISTER_PRIVATE_EXPEDITED</code></a>, used in the implementation of PEBR.
<ul>
<li><strong>IMPORTANT</strong>: Docker disables this feature by default. To enable, please use <code>--security-opt seccomp:unconfined</code> option when launching Docker.</li>
</ul></li>
<li><a href="https://rustup.rs/"><code>rustup</code></a> for building the implementation of NR, EBR, PEBR and data structures
<ul>
<li>Rust requires GCC for linking in Linux.</li>
</ul></li>
<li>Python &gt;= 3.6, pandas and plotnine for benchmark runner and plotting scripts</li>
</ul>
<h3 id="usage">Usage</h3>
<p>To build the benchmark,</p>
<pre><code>git submodule update --init --recursive # not needed if you got the archived source code
cargo build --release                   # remove --release for debug build</code></pre>
<p>To run a single test,</p>
<pre><code>./target/release/pebr-benchmark -d &lt;data structure&gt; -m &lt;reclamation scheme&gt; -t &lt;threads&gt;</code></pre>
<p>where</p>
<ul>
<li>data structure: HList, HMList, HHSList, HashMap, NMTree, BonsaiTree</li>
<li>reclamation scheme: NR, EBR, PEBR</li>
</ul>
<p>For detailed usage information,</p>
<pre><code>./target/release/pebr-benchmark -h</code></pre>
<p>To run the entire benchmark,</p>
<pre><code>python3 bench.py</code></pre>
<p>This takes several hours and creates raw CSV data under <code>./results/</code>.</p>
<p>To generate plots,</p>
<pre><code>python3 plot.py</code></pre>
<p>This creates plots presented in the paper under <code>./results/</code>.</p>
<h3 id="debug">Debug</h3>
<p>We used <code>./sanitize.sh</code> to debug our implementation. This script runs the benchmark with <a href="https://github.com/japaric/rust-san">LLVM address sanitizer for Rust</a> and uses parameters that impose high stress on PEBR by triggering more frequent ejection.</p>
<p>Note that sanitizer may report memory leaks when used against <code>-m EBR</code>. This is because of a minor bug in original Crossbeam but it doesn't affect performance of our benchmark.</p>
<h3 id="project-structure">Project structure</h3>
<ul>
<li><p><code>./crossbeam-pebr</code> is the fork of <a href="https://github.com/crossbeam-rs/crossbeam">Crossbeam</a> that implements PEBR. The main implementation of PEBR lies under <code>./crossbeam-pebr/crossbeam-epoch</code>.</p></li>
<li><p><code>./crossbeam-ebr</code> is the original Crossbeam source code.</p></li>
<li><p><code>./src</code> contains the benchmark driver (<code>./src/main.rs</code>) and the implementation of data structures based on PEBR (<code>./src/pebr/</code>) and original Crossbeam (<code>./src/ebr/</code>).</p></li>
</ul>
<h3 id="results">Results</h3>
<p><code>./paper-results</code> contains the raw results and graphs used in the paper.</p>
<h3 id="note">Note</h3>
<ul>
<li><p>On Windows, the benchmark uses the default memory allocator instead of jemalloc since <a href="https://crates.io/crates/jemallocator">the Rust library for jemalloc</a> does not support Windows.</p></li>
<li><p>The benchmark run by <code>./sanitize.sh</code> will generate inaccurate memory usage report since it uses the default memory allocator instead of jemalloc. The memory tracker relies on jemalloc's functionalities which doesn't keep track of allocations by the default allocator.</p></li>
</ul>

},
keywords = {epoch-based reclamation, garbage collection, hazard pointer, pointer-based reclamation, safe memory reclamation}
}

@software{10.1145/3395631,
author = {Hu, Qinheping and Cyphert, John and D'Antoni, Loris and Reps, Thomas},
title = {Artifact for article: Exact and Approximate Methods for Proving Unrealizability of Syntax-Guided Synthesis Problems},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395631},
abstract = {
    <p>This artifact contains Nay, a synthesizer which can prove unrealizability of unrealizable SyGuS problems. For detail can be found in this paper:https://arxiv.org/abs/2004.00878</p>

},
keywords = {program synthesis, syntax guided synthesis, unrealizability}
}

@software{10.1145/3395632,
author = {Flatt, Matthew and Dybvig, R. Kent},
title = {Replication Package for Article: Compiler and Runtime Support for Continuation Marks},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395632},
abstract = {
    <p>The artifact contains the full source code for Racket and Chez Scheme and variants as described in the paper, and it provides benchmarks that can be used to support the following claims:</p>
<ul>
<li><p>The implementation of continuation marks is compatible with a high-performance implementation of first-class, delimited continuations.</p></li>
<li><p>Compiler and runtime support for continuation marks can improve the performance of applications.</p></li>
<li><p>Specific optimizations described in the paper improve the performance of continuation marks and applications that use them.</p></li>
</ul>

},
keywords = {context inspection, Dynamic binding}
}

@software{10.1145/3395633,
author = {Durst, David and Feldman, Matthew and Huff, Dillon and Akeley, David and Daly, Ross and Bernstein, Gilbert Louis and Patrignani, Marco and Fatahalian, Kayvon and Hanrahan, Pat},
title = {Replication Package for Article: Type-Directed Scheduling of Streaming Accelerators},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395633},
abstract = {
    <p>This is the artifact for the PLDI 2020 paper "Type-Directed Scheduling of Streaming Accelerators". The artifact is a virtual machine that supports the claims, including reproducing the results, of the submission version of the paper. Please go to https://aetherling.org for the latest version of the code.</p>

},
keywords = {FPGAs, hardware description languages, image processing, scheduling, space-time types}
}

@software{10.1145/3395634,
author = {Berry, G\'{e}rard and Serrano, Manuel},
title = {Replication package for: HipHop.js: (A)Synchronous Reactive Web Programming},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395634},
abstract = {
    <p>Our artifact consists of:</p>
<ul>
<li><p>The current HipHop.js implementation, which you can either download fully constructed in the docker file available from the PLDI artifact site (see Part 1 below) or entirely rebuild from the public Hop/HipHop sources files (see Part 3) if you find the 1.3 GB docker file too big or if you want to do it yourself. Once the docker image is downloaded or built, you can validate it by running the standard HipHop implementation test suite (see Part 4).</p></li>
<li><p>The implementation and step-by-step simulation of our Lisinopril medical prescription application described in the paper (Part 2 below). The main Lisinopril HipHop reactive module is exacly the one in the paper. The complete source files can be accessed within the docker image or dowloaded from the web.</p></li>
</ul>

},
keywords = {JavaScript, Reactive Programming, Synchronous Programming, Web Programming}
}

@software{10.1145/3395635,
author = {Phulia, Ankush and Bhagee, Vaibhav and Bansal, Sorav},
title = {Replication package for OOElala: Order-of-Evaluation Based Alias Analysis for Compiler Optimization},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395635},
abstract = {
    <p>This artifact contains the implementation for the algorithm described in the paper, <em>OOElala: Order-of-Evaluation Based Alias Analysis for Compiler Optimization</em>, accepted at PLDI 2020.</p>
<h3 id="terminology">Terminology</h3>
<ul>
<li>We use <code>OOElala</code>, <code>ooelala</code> and <code>clang-unseq</code> interchangeably to refer to the tool/binary which we have implemented and produced as a part of this work.</li>
<li><code>&lt;artifact-home&gt;</code> refers to <code>/home/$USER/ooelala-project</code></li>
</ul>
<h3 id="structure-of-the-artifact">Structure of the artifact</h3>
<p>This artifact directory is structured into the following subdirectories, each of which is described subsequently:</p>
<ul>
<li><em>litmus_tests</em> - This directory contains the implementation of the two examples, which have been introduced in Section 1.1 of the paper, to spearhead the discussion about the key idea of the paper. The makefile is used to run these two examples, as described in detail in the later sections.
<ul>
<li><em>array_min_max</em> - This subdirectory contains the code, for the first example, on the left of the figure.</li>
<li><em>nested_loop</em> - This subdirectory contains the code for an example, which isolates the kernel initialization code described in the second image on the right. The implementation captures the basic idea for the SPEC 2017 example, as discussed in section 1.1 of the paper.</li>
</ul></li>
<li><em>ooelala</em> - This directory contains the source code for our tool, OOELala, which has been implemented over clang/llvm 8.0.0.
<ul>
<li><em>src</em> - This sub-directory contains the source code for the optimizing compiler implementation which includes the AST analysis to identify the must-not-alias predicates and the Alias Analysis which utilises the must-not-alias information to enable further optimisations. This has been added as a sub-module and the specific implementation details can be found in the commit history and commit messages of this sub-module.</li>
<li><em>ubsan</em> - This sub-directory contains the source code for the implementation of the UB Sanitizer which uses the must-not-alias predicates generated after the AST analysis to implement the runtime checks. This has been added as a sub-module and the specific implementation details can be found in the commit history and commit messages of this sub-module.</li>
</ul></li>
<li><em>spec</em> - This directory contains the resources which we use to run the SPEC CPU 2017 benchmarks, with clang and OOELala.
<ul>
<li><em>configs</em> - This subdirectory contains the config files <code>clang-unseq.cfg</code> and <code>clang.cfg</code>, which are used when we build and run the SPEC CPU 2017 suite with OOELala and clang respectively. Additionally, this directory also contains config files <code>clang-ubsan.cfg</code> and <code>clang-ubsan-unseq.cfg</code>, which are used to specify that SPEC should be built and run with clang and OOELala respectively, with UB Sanitizer checks enabled and no optimisations.</li>
<li><em>makefiles</em> - This subdirectory contains the makefiles, which are used to compile and run specific SPEC benchmarks or generate object/LLVM files for some specific source files, in some specific benchmarks. These have been used to identify the patterns discussed in figure 2 of the paper. For running these on SPEC refrate inputs refer to <code>Readme.md</code> in the subdirectory.</li>
<li><em>scripts</em> - This subdirectory contains the scripts which are used to build and run the SPEC 2017 benchmarks and generate the performance numbers presented in table 6 of the paper. This also contains the post processing python script which is used to generate the summary of the aliasing stats, which are presented in Table 5 of the paper. The list of scripts and their functionality is described in the Readme.md file present in this subdirectory.</li>
</ul></li>
<li><em>polybench</em> - This directory contains the resources which we use to run the Polybench benchmark suite, with clang and OOELala
<ul>
<li><em>common</em> - This subdirectory contains the Polybench header file which needs to be included in the benchmarks.</li>
<li><em>scripts</em> - This subdirectory contains the scripts used to build and run the Polybench benchmarks to obtain the speedups listed in Table 4 of the paper. Comparisons between various compilers have been drawn.</li>
<li><em>selected_benchmarks</em> - This represents the selected subset of benchmarks which we have annotated with custom <code>RESTRICT</code> macro predicates (corresponding to <code>CANT_ALIAS</code> used in the paper), used to provide the additional aliasing information, but in no way modifying the behaviour of the program</li>
</ul></li>
<li><em>sample_outputs</em> - This directory contains a set of sample outputs which are obtained on running the SPEC CPU 2017 and the polybench benchmarks. These can be used by the developers to verify the output format
<ul>
<li><em>spec</em> - This contains the results and stats obtained for a sample run of SPEC CPU 2017, with clang and clang-unseq</li>
<li><em>polybench</em> - This contains the results and stats obtained for a sample run of Polybench, with clang and clang-unseq</li>
</ul></li>
<li><em>CANT_ALIAS.md</em> - This is a tutorial which discusses the <em>CANT_ALIAS</em> predicate described in the paper. It outlines the use of the macro and the subtleties associated with that.</li>
</ul>

},
keywords = {Alias Analysis, Clang, Compiler Optimization, LLVM, Polybench, SPEC CPU 2017, Undefined behaviour}
}

@software{10.1145/3395636,
author = {Farvardin, Kavon and Reppy, John},
title = {Replication Package for Article: From Folklore to Fact: Comparing Implementations of Stacks and Continuations},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395636},
abstract = {
    <p>This artifact contains all materials needed to reproduce or extend the results of this work. It includes the raw data and plots corresponding to the results presented in the paper, the full source code of Manticore \&amp; LLVM (plus the benchmark programs and plotting scripts), a Docker image that contains the entire system pre-built, and an extensive README that describes how to build and run our benchmark suite to replicate the experiments in the paper.</p>

},
keywords = {Call stacks, Compilers, Concurrency, Continuations, Functional Programming}
}

@software{10.1145/3395637,
author = {Lahav, Ori and Boker, Udi},
title = {Coq proofs for: Decidable Verification under a Causally Consistent Shared Memory},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395637},
abstract = {
    <p>The artifact consists of the Coq development accompanying the paper. The main result is the equivalence between loSRA (called SRAL in the Coq development) and opSRA (called SRAG in the Coq development) that is given in Lemmas 5.15 and 5.16 in the paper. This final result is included in "SRAL_SRAG.v".</p>

},
keywords = {causal consistency, concurrency, Coq, decidability, release/acquire, shared-memory, verification, weak memory models, well-structured transition systems}
}

@software{10.1145/3395638,
author = {Miltner, Anders and Padhi, Saswat and Millstein, Todd and Walker, David},
title = {Replication Package for Artifact: Data-Driven Inference of Representation Invariants},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395638},
abstract = {
    <p>This archive contains the code and benchmarks for the paper Data-Driven Inference of Representation Invariants.</p>
<p>Instructions for installation and build, instructions for reproduction of the results, and a description of the structure of the repository, are all available in the file $/README.pdf.</p>

},
keywords = {Abstract Data Types, Logical Relations, Type-Directed Synthesis}
}

@software{10.1145/3395639,
author = {Emrich, Frank and Lindley, Sam and Stolarek, Jan and Cheney, James and Coates, Jonathan},
title = {Virtual Machine for paper "FreezeML: Complete and Easy Type Inference for First-Class Polymorphism"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395639},
abstract = {
    <p>The artifact is a virtual machine that contains an implementation of the FreezeML system described in the paper. The artifact also contains a collection of examples presented in the paper so that the results can be easily reproduced.</p>

},
keywords = {first-class polymorphism, impredicative types, type inference}
}

@software{10.1145/3395640,
author = {Sakkas, Georgios and Endres, Madeline and Cosman, Benjamin and Weimer, Westley and Jhala, Ranjit},
title = {Replication Package for Article: Type Error Feedback via Analytic Program Repair},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395640},
abstract = {
    <p>The artifact contains all the necessary code and data in order to reproduce the results from the paper "Type Error Feedback via Analytic Program Repair" as appeared in PLDI 2020. Instructions for installing and running the artifact can be found in the provided README file.</p>

},
keywords = {Machine Learning, Program Repair, Program Synthesis, Type Error Feedback}
}

@software{10.1145/3395641,
author = {Baudart, Guillaume and Mandel, Louis and Atkinson, Eric and Sherman, Benjamin and Pouzet, Marc and Carbin, Michael},
title = {Replication package for Article: Reactive Probabilistic Programming},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395641},
abstract = {
    <p>This is the artifact of the PLDI 2020 paper <em>Reactive Probabilistic Programming</em> by Guillaume Baudart, Louis Mandel, Eric Atkinson, Benjamin Sherman, Marc Pouzet, and Michael Carbin. The archive contains - <code>pldi2020.pdf</code>: Paper with appendices - <code>README.md</code>: Details on how the code is linked to the paper and how to run the code and the benchmarks - <code>ProbZelus-PLDI20.ova</code>: Linux image in the Open Virtualization Format with the ProbZelus compiler and benchmarks - <code>LICENSE.txt</code>: ProbZelus license.</p>
<p>The artifact can be used to check the implementation of the algorithms presented in the paper and to reproduce the evaluation.</p>

},
keywords = {Benchmark, Compiler, Delayed sampling, Inference, Probabilistic programming, Runtime, Sequential Monte Carlo, Synchronous programming}
}

@software{10.1145/3395642,
author = {Brown, Fraser and Renner, John and N\"{o}tzli, Andres and Lerner, Sorin and Shacham, Hovav and Stefan, Deian},
title = {Towards a Verified Range Analysis for JavaScript JITs: Artifact},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395642},
abstract = {
    <p>Artifact for "Towards a Verified Range Analysis for JavaScript JITS"</p>

},
keywords = {verification}
}

@software{10.1145/3395643,
author = {Lee, Sung-Hwan and Cho, Minki and Podkopaev, Anton and Chakraborty, Soham and Hur, Chung-Kil and Lahav, Ori and Vafeiadis, Viktor},
title = {Replication Package for Article: Promising 2.0: Global Optimizations in Relaxed Memory Concurrency},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395643},
abstract = {
    <p>The artifact is a Coq development of the paper Promising 2.0: Global Optimizations and Relaxed Memory Concurrency. It includes (i) a Coq development of Promising 2.0 memory model and (ii) compilation correctness proof of Promising 2.0 to IMM. See README.md for more detail.</p>

},
keywords = {Compiler Optimizations, Operational Semantics, Relaxed Memory Concurrency}
}

@software{10.1145/3395644,
author = {Zhu, Shaopeng and Hung, Shih-Han and Chakrabarti, Shouvanik and Wu, Xiaodi},
title = {Replication Package for: On the Principles of Differentiable Quantum Programming Languages},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395644},
abstract = {
    <p>The artifact includes two parts: (1) A parser and compiler that implements the rules for autodifferentiaton; (2) A simulation that demonstrates the advantage of differentiating quantum programs with control flow. Classical simulation of quantum programs is used in this part for evaluation.</p>

},
keywords = {autodifferentiation, differentiable programming, quantum computing, quantum machine learning, quantum programming languages}
}

@software{10.1145/3395645,
author = {Nandi, Chandrakana and Willsey, Max and Anderson, Adam and Wilcox, James R. and Darulova, Eva and Grossman, Dan and Tatlock, Zachary},
title = {Szalinski: A Tool for Synthesizing Structured CAD Models with Equality Saturation and Inverse Transformations},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395645},
abstract = {
    <h2 id="paper-pldi20main-p471-p">Paper pldi20main-p471-p</h2>
<h3 id="goals-of-the-artifact">Goals of the artifact</h3>
<p>In our paper, we evaluated the following about Szalinski (<code>Section 7</code>):</p>
<ol style="list-style-type: decimal">
<li><p>End-to-End: we ran Szalinski on the flat CSG outputs of a mesh decompiler (Reincarnate). The results are in <code>Table 2</code>.</p></li>
<li><p>Scalability: we evaluated Szalinski on a large dataset of models scraped from a popular online repository (Thingiverse). The results are in <code>Figure    14</code> (first three box plots).</p></li>
<li><p>Sensitivity: we evaluated the usefulness of Szalinski's two main features: CAD rewrites and Inverse Transformations. The results are in <code>Figure 14</code> (last two box plots).</p></li>
</ol>
<p>In support of these results, this artifact reproduces <code>Table 2</code> and <code>Figure 14</code>. In addition, it also generates the output programs in <code>Figure 15</code> that are used in the case studies.</p>
<p>This document contains the following parts:</p>
<ul>
<li><p>System requirements</p></li>
<li>How to run Szalinski</li>
<li>Reproducing Table 2 (takes &lt; 5 minutes)</li>
<li>Reproducing Figure 14 (takes approx. 1.5 hour)</li>
<li>Reproducing Figure 15 (takes &lt; 5 minutes)</li>
<li><p>Validation</p></li>
<li>Reusability</li>
<li>How to set up Szalinski on a different machine (this is also how we set up the VM we submitted for PLDI 2020 AEC)</li>
<li><p>Description of the code and how to modify it</p></li>
<li><p>Notes and remarks</p></li>
</ul>
<h3 id="system-requirements">System requirements</h3>
<ul>
<li>Specs of the machine where we ran the VM: Intel i7-8700K (12 threads @ 4.7GHz), 32GiB RAM</li>
</ul>
<h3 id="running-the-tools">Running the tools</h3>
<h4 id="reproducing-table-2">Reproducing Table 2</h4>
<p>Navigate to the directory that contains the <code>Makefile</code> and type <code>make out/aec-table2/table2.csv</code>. This should take about 3 minutes. This will reproduce <code>Table 2</code> from the paper. To view the content of the table, type <code>cat out/aec-table2/table2.csv | column -t -s,</code> and compare the numbers with <code>Table 2</code> in the paper.</p>
<p><strong>NOTE:</strong> - We suspect that different versions of OpenSCAD use different triangulation algorithms for compiling to mesh which can affect the numbers in the <code>#Tri</code> column.</p>
<h4 id="reproducing-figure-14">Reproducing Figure 14</h4>
<p>We have included in the repo the 2,127 examples from Thingiverse that we evaluated on in the paper. The remainder of the 12,939 scraped from Thingiverse were either malformed or used features not supported by Szalinski. The script (<code>scripts/scrape-thingiverse.sh</code>) scrapes models under the <code>customizable</code> category, from the first 500 pages.</p>
<p><em>NOTE:</em> Running this part takes about an hour. We recommend first reproducing <code>Figure 15</code> and <code>Table 2</code>, both of which take much less time.</p>
<p>Navigate to the directory that contains the <code>Makefile</code> and type <code>make out/fig14.pdf</code>. Open the generated file in a pdf viewer and compare with <code>Figure 14</code> in the paper.</p>
<h4 id="reproducing-figure-15-programs">Reproducing Figure 15 programs</h4>
<p>Navigate to the directory that contains the <code>Makefile</code> and type <code>make aec-fig15</code>. This should take less than a minute. Then look in the <code>out/aec-fig15</code> directory. The optimized programs generated by Szalinski are in the files with extensions <code>normal.csexp.opt</code>. There should be 6 such files. Open them and compare the content with the programs listed in <code>Figure 15</code> of the paper.</p>
<p><strong>NOTE:</strong> - The programs in the paper are sugared and represented more compactly for space. - <code>MapI</code> found in the artifact results corresponds to <code>Tabulate</code> in the paper. - When comparing the results generated by the artifact to the programs in <code>Figure 15</code> of the paper, it is most important to check that the high-level structure in terms of <code>Fold</code> and <code>MapI</code> synthesized by the artifact matches that reported in the paper.</p>
<h4 id="validation">Validation</h4>
<p><code>Section 6</code> of our paper describes Szalinski's validation process. We use OpenSCAD to compile CSG programs to meshes and use CGAL to compute the Hausdorff distance between two meshes.</p>
<p>To validate the programs in <code>Figure 15</code>, run <code>make out/aec-fig15/hausdorff</code>. This should terminate in less than 3 minutes. It should show you the names of the 6 examples in <code>Figure 15</code> and the corresponding Hausdorff distances which are close to zero.</p>
<p>We have also validated all our other results reported in the paper. However, our experience indicates that OpenSCAD's compilation step is often very slow. Therefore, the other commands mentioned in the instruction for reproducing the results do not perform validation by default.</p>
<p>You can validate any example from our evaluation by typing: <code>make out/dir_name/example_name.normal.diff</code>, where <code>dir_name</code> can be <code>aec-table2</code>, <code>aec_fig15</code> or <code>thingiverse</code>, and <code>example_name</code> is the name of whatever example you choose. Then open the generated <code>.diff</code> file and check that the Hausdorff distance is within some epsilon of 0.</p>
<p><strong>NOTE:</strong> For many example, CGAL crashes or is slow at computing the Hausdorff distance. For these, we recommend a manual validation if you are interested. In order to validate an example, type the following: <code>make out/dir_name/example_name.diff.scad</code>. You can open the generated <code>.scad</code> file in OpenSCAD (already installed in the VM). In OpenSCAD, click on the <code>Render</code> button (the second button from the right) in the toolbar. You should either see nothing rendered or some residual thin walls that are artifacts of rounding error prevalent in OpenSCAD.</p>
<h3 id="reusability">Reusability</h3>
<p>Here we provide instructions on how to start using Szalinski including installation and changing the rules and features of the Caddy language.</p>
<h4 id="setup-instructions">Setup instructions</h4>
<p>Following are the steps for setting up Szalinski from scratch on a machine that runs Ubuntu 19.10.</p>
<ul>
<li><p>Install rust. Type <code>curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh</code> in the terminal and follow the subsequent instructions. The version we used is <code>1.41.0</code>. See<code>https://www.rust-lang.org/tools/install</code> for more information.</p></li>
<li><p>Make sure you configure your current shell by typing: <code>source $HOME/.cargo/env</code> (the Rust installation will prompt you to do this).</p></li>
<li><p>Install make by typing: <code>sudo apt-get install make</code></p></li>
<li><p>Install g++ by typing: <code>sudo apt-get install g++</code></p></li>
<li><p>Install jq by typing: <code>sudo apt-get install jq</code></p></li>
<li><p>Install <a href="https://www.cgal.org/download/linux.html">CGAL</a> by typing <code>sudo apt-get install libcgal-dev</code></p></li>
<li><p>Install <a href="https://www.openscad.org/">OpenSCAD</a> by typing <code>sudo apt-get install openscad</code></p></li>
<li><p>Install git by typing <code>sudo apt install git</code></p></li>
<li><p>Install pip by typing <code>sudo apt install python3-pip</code> and then install <code>numpy</code> by typing <code>pip3 install numpy</code> and <code>matplotlib</code> by typing <code>pip3 install matplotlib</code></p></li>
<li><p>We have made a <a href="https://github.com/uwplse/szalinski/tree/pldi2020-aec">github release</a> for the PLDI AEC from where you can get the source.</p></li>
<li><p>Navigate to the project directory where the <code>Makefile</code> is and run the tool as described above.</p></li>
</ul>
<h4 id="changing-caddy-and-modifying-the-rules">Changing Caddy and modifying the rules</h4>
<ul>
<li><p>The Caddy language is defined in <code>cad.rs</code> in the <code>src</code> directory. A simple feature you can add is support for a new primitive or new transformations. You can also change the costs of various language constructs. The definition of the <code>cost</code> function starts at line <code>267</code>.</p></li>
<li><p>As we described in the paper, to verify the correctness of Szalinski, we evaluate Caddy programs to flat Core Caddy and pretty print to CSG. This code is in <code>eval.rs</code>.</p></li>
<li><p><code>solve.rs</code> and <code>permute.rs</code> contains code that solves for first and second degree polynomials in Cartesian and Spherical coordinates, and performs partitioning and permutations of lists.</p></li>
<li><p>The rewrites rules are in <code>rules.rs</code>. Syntactic rewrites are written using the <code>rw!</code> macro. Each rewrite has a name, a left hand side, and a right hand side. You can add / remove rules to see how that affects the final Caddy output of Szalinski. For example, if you comment out the rules for inverse transformations, they will not be propagated and eliminated, and therefore the quality of Szalinski's output will not be as good.</p></li>
</ul>
<h3 id="notes-and-remarks">Notes and remarks</h3>
<p>Szalinski is implemented in <a href="https://www.rust-lang.org/">Rust</a>. As mentioned in <code>Section 6</code> of the paper, it uses <a href="https://www.openscad.org/">OpenSCAD</a> to compile CSG programs to triangular meshes, and <a href="https://www.cgal.org/">CGAL</a> to compute the Hausdorff distance between two meshes.</p>

},
keywords = {CAD, Compiler Optimization, Computational Geometry, Synthesis}
}

@software{10.1145/3395646,
author = {Fragoso Santos, Jos\'{e} and Maksimovi\'{c}, Petar and Ayoun, Sacha-\'{E}lie and Gardner, Philippa},
title = {Gillian, Part I: A Multi-language Platform for Symbolic Execution},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395646},
abstract = {
    <p>This artifact contains the Gillian platform, as it was for the submission of the corresponding PLDI'20 paper.</p>
<p>Note: This artifact is licensed under the GNU General Public License v3.0 and can only be used for academic purposes. The Gillian platform itself is not licensed under the same license.</p>

},
keywords = {bounded verification, bug-finding, C, JavaScript, parametric semantics, Symbolic execution}
}

@software{10.1145/3395647,
author = {Usman, Muhammad and Wang, Wenxi and Vasic, Marko and Wang, Kaiyuan and Vikalo, Haris and Khurshid, Sarfraz},
title = {Replication Package for Article: A Study of the Learnability of Relational Properties: Model Counting Meets Machine Learning (MCML) - PLDI 2020},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395647},
abstract = {
    <p>The artifact contains datasets and code which were used to compute results for this paper (A Study of the Learnability of Relational Properties: Model Counting Meets Machine Learning (MCML) - PLDI 2020). Detailed instructions can be found in README.txt file.</p>

},
keywords = {Alloy, ApproxMC, machine learning, model counting, ProjMC, Relational Properties, SAT solving}
}

@software{10.1145/3395648,
author = {He, Jingxuan and Singh, Gagandeep and P\"{u}schel, Markus and Vechev, Martin},
title = {Reproduction Package for Article: Learning Fast and Precise Numerical Analysis},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395648},
abstract = {
    <p>This material is the artifact for paper "Learning Fast and Precise Numerical Analysis" at PLDI 2020. It contains raw data for main experiments, benchmarks, full source code, and scripts for reproducing main experiments.</p>

},
keywords = {Abstract interpretation, Machine learning, Numerical domains, Performance optimization.}
}

@software{10.1145/3395649,
author = {Porter, Chris and Mururu, Girish and Barua, Prithayan and Pande, Santosh},
title = {Replication Package for article: BlankIt Library Debloating: Getting What You Want Instead of Cutting What You Don’t},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395649},
abstract = {
    <p>These are the docker containers to reproduce the main results of the paper.</p>

},
keywords = {software debloating}
}

@software{10.1145/3395650,
author = {Koenig, Jason R. and Padon, Oded and Immerman, Neil and Aiken, Alex},
title = {Artifact for Article: First-Order Quantified Separators},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395650},
abstract = {
    <p>This artifact contains implementations of the separation algorithm from Section 5, the IC3/PDR implementation from Section 6.3, and the evaluation data from Section 7. This artifact can be used to both reproduce the results of the article as well as run these algorithms on novel distributed protocols.</p>

},
keywords = {first-order logic, invariant inference, software verification}
}

@software{10.1145/3395651,
author = {Cauligi, Sunjay and Disselkoen, Craig and Gleissenthall, Klaus v. and Tullsen, Dean and Stefan, Deian and Rezk, Tamara and Barthe, Gilles},
title = {Pitchfork-Angr},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395651},
abstract = {
    <p>Pitchfork is a static analysis tool, built on angr (https://github.com/angr/angr), which performs speculative symbolic execution. That is, it not only executes the "correct" or "sequential" paths of a program, but also the "mispredicted" or "speculative" paths, subject to some speculation window size. Pitchfork finds paths where secret data is used in either address calculations or branch conditions (and thus leaked), even speculatively - these paths represent Spectre vulnerabilities. Pitchfork covers Spectre v1, Spectre v1.1, and Spectre v4.</p>

},
keywords = {spectre, speculative execution, static analysis, symbolic execution}
}

@software{10.1145/3395652,
author = {Giannarakis, Nick and Loehr, Devon and Beckett, Ryan and Walker, David},
title = {Software Artifact for NV: An Intermediate Language for Verification of Network Control Planes},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395652},
abstract = {
    <p>The artifact contains a VirtualBox VM image with the source code and the binary for the NV framework (the simulator, SMT verifier, etc.). Also included is a modified version of Batfish that can translate router configurations to NV source files.</p>

},
keywords = {intermediate verification language, network simulation, network verification, static analysis}
}

@software{10.1145/3395653,
author = {Lorch, Jacob R. and Chen, Yixuan and Kapritsos, Manos and Parno, Bryan and Qadeer, Shaz and Sharma, Upamanyu and Wilcox, James R. and Zhao, Xueyuan},
title = {Replication Package for Article "Armada: Low-Effort Verification of High-Performance Concurrent Programs"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395653},
abstract = {
    <p>This artifact contains the materials necessary for replication of the paper "Armada: Low-Effort Verification of High-Performance Concurrent Programs". It contains a Docker image containing the source code, executables, external dependencies, and examples. It also contains documentation of the artifact and a description of the Armada language.</p>

},
keywords = {refinement, weak memory models, x86-TSO}
}

@software{10.1145/3395654,
author = {Schuiki, Fabian and Kurth, Andreas and Grosser, Tobias and Benini, Luca},
title = {Replication Package for Paper: LLHD: A Multi-level Intermediate Representation for Hardware Description Languages},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395654},
abstract = {
    <p>A Docker image with the necessary toolchains pre-installed and source codes pre-loaded to reproduce the main results of the LLHD paper, and to serve as a starting point for individual exploration.</p>

},
keywords = {domain-specific languages, hardware, language design, language implementation, new programming models or languages, parallelism}
}

@software{10.1145/3395655,
author = {Krishna, Siddharth and Patel, Nisarg and Shasha, Dennis and Wies, Thomas},
title = {Mechanized proofs accompanying paper: Verifying Concurrent Search Structure Templates},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395655},
abstract = {
    <p>Our artifact consists of two parts: the proofs of template algorithms, to be verified by Iris/Coq, and the proofs of implementations, to be verified by GRASShopper.</p>

},
keywords = {concurrent search structures, Coq, functional correctness, Grasshopper, Iris, mechanized proofs, memory safety}
}

@software{10.1145/3395656,
author = {Breck, Jason and Cyphert, John and Kincaid, Zachary and Reps, Thomas},
title = {Artifact for "Templates and Recurrences: Better Together"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395656},
abstract = {
    <p>This is the artifact for the PLDI 2020 paper, "Templates and Recurrences: Better Together." The artifact is a virtual machine in OVA (Open Virtualization Archive) format. Its operating system is Ubuntu 18. The virtual machine contains an installation of the CHORA static analysis tool, which is the implementation of the technique described by the associated paper. The virtual machine also contains the benchmark programs that were used in the experiments of the associated paper, along with a script that is designed to replicate the paper's experimental results. The virtual machine has a user account with name "chorauser" and password "chorapassword", and allows login via graphical user interface, or via SSH on port 22.</p>

},
keywords = {Invariant generation, Recurrence relation}
}

@software{10.1145/3395657,
author = {Nigam, Rachit and Atapattu, Sachille and Thomas, Samuel and Li, Zhijing and Bauer, Theodore and Ye, Yuwei and Koti, Apurva and Sampson, Adrian and Zhang, Zhiru},
title = {Replication Package for Article: Predictable Accelerator Design with Time-Sensitive Affine types},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395657},
abstract = {
    <p>Contains the following repositories: - Dahlia (v0.0.1): The reference compiler built for the paper. - Dahlia-evaluation: The data and the evaluation scripts. - Dahlia-spatial-comparison: Repository to reproduce Dahlia's Spatial evaluation. - Polyphemus: Server framework used to run FPGA experiments on AWS.</p>

},
keywords = {affine types, high-level synthesis}
}

@software{10.1145/3395658,
author = {Boehm, Hans-J.},
title = {Real arithmetic package and code to check floating point precision},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395658},
abstract = {
    <p>Source code and instructions to run the floating point accuracy test described in the paper. This includes the real arithmetic package, with the described comparison support, and an updated version of the previously described underlying recursive reals package (which diverges on exact comparison of equal real numbers). The real arithmetic package is very similar to that currently used by Google's Android calculator.</p>

},
keywords = {accuracy checking, comparison, decidability, floating point, real numbers}
}

@software{10.1145/3395659,
author = {Yang, Albert Mingkun and \"{O}sterlund, Erik and Wrigstad, Tobias},
title = {Replication Package for Article: Improving Program Locality in the GC using Hotness},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395659},
abstract = {
    <p>It includes our implementation, benchmarks used, and scripts for running benchmarks and collecting/visualizing results.</p>

},
keywords = {garbage collection, load barrier, openjdk, program locality}
}

@software{10.5281/zenodo.3889126,
author = {Krieger, Max},
title = {Comic of "Chatting with Glue: Cognitive Tools for Augmented Conversation"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3889126},
abstract = {
    <p>This is the comic referenced in the paper. It comprises the main content of the paper.</p>

},
keywords = {comic, conversation, media}
}

@software{10.1145/3406882,
author = {Tizpaz-Niari, Saeid and \v{C}ern\'{y}, Pavol and Trivedi, Ashutosh},
title = {DPFuzz: Fuzzing and Debugging for Differential Performance Bugs in Machine Learning Libraries},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3406882},
abstract = {
    <p>DPFuzz is a tool for fuzzing and debugging differential performance bugs. The paper and its overview are included in this folder. Please see the 'DPFuzz-Overview.pdf' to have an overall picture of DPFuzz.</p>

},
keywords = {Debugging, Differential Performance Bugs, Fuzzing, Machine Learning Libraries, Performance}
}

@software{10.1145/3406883,
author = {Ghaleb, Asem and Pattabiraman, Karthik},
title = {Artifact for Article &nbsp;"How Effective Are Smart Contract Analysis Tools? Evaluating Smart Contract Static Analysis Tools using Bug Injection"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3406883},
abstract = {
    <p>This is the artifact for the ISSTA'20 paper "How Effective Are Smart Contract Analysis Tools? Evaluating Smart Contract Static Analysis Tools using Bug Injection". Two main things are covered in the artifact</p>
<ol style="list-style-type: decimal">
<li>How to use the introduced tool, SolidiFI, for injecting bugs and evaluating smart contract static analysis tools</li>
<li>How to reproduce the evaluation experiments presented in the paper.</li>
</ol>

},
keywords = {bug injection, Ethereum, Ethereum security, fault injection, smart
contracts dataset, smart contracts, smart contracts analysis, smart contracts security, solidity code analysis, static analysis tools evaluation}
}

@software{10.1145/3406885,
author = {Mathis, Bj\"{o}rn and Gopinath, Rahul and Zeller, Andreas},
title = {Replication Package for lFuzzer - Learning Input Tokens for Effective Fuzzing},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3406885},
abstract = {
    <p>This package contains the data and tools used for the experiments run to evaluate lFuzzer. The artifact contains two packages, one for reproducing the evaluation and conducting new experiments and one containing the evaluation results of the paper. The reproduction package is a docker container in which the experiments from the paper as well as new experiments can be performed.</p>

},
keywords = {fuzzing, parser, test input generation}
}

@software{10.1145/3406886,
author = {Li, Hui and Wang, Dong and Huang, Tianze and Gao, Yu and Dou, Wensheng and Xu, Lijie and Wang, Wei and Wei, Jun and Zhong, Hua},
title = {Replication Package for Article: Detecting Cache-Related Bugs in Spark Applications},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3406886},
abstract = {
    <p>This artifact contains the source code of CacheCheck. It provides general instructions to use CacheCheck and evaluates experimental results in our paper. More details and newest version is provided on Github (https://github.com/Icysandwich/cachecheck).</p>

},
keywords = {bug detection, cache, performance, Spark}
}

@software{10.1145/3406888,
author = {Lee, Seokhyun and Cha, Sooyoung and Lee, Dain and Oh, Hakjoo},
title = {Replication Package for Article: Effective White-box Testing of Deep Neural Networks with Adaptive Neuron-Selection Strategy},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3406888},
abstract = {
    <p>This article contains source codes and data for the paper "Effective White-box Testing of Deep Neural Networks with Adaptive Neuron-Selection Strategy". It also contains experiment scripts that can reproduce the results in the paper.</p>

},
keywords = {Deep neural networks, Online learning, White-box testing}
}

@software{10.1145/3406889,
author = {Lou, Yiling and Ghanbari, Ali and Li, Xia and Zhang, Lingming and Zhang, Haotian and Hao, Dan and Zhang, Lu},
title = {Tool Package for paper "Can Automated Program Repair Refine Fault Localization? A Unified Debugging Approach "},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3406889},
abstract = {
    <p>The package includes the tool in the paper "Can Automated Program Repair Refine Fault Localization? A Unified Debugging Approach ", including the installation and execution document. More updates please refer to the tool homepage "https://github.com/yilinglou/proFL"</p>

},
keywords = {Automated Debugging Tool, Automated Program Repair, Fault Localization, Unified Debugging}
}

@software{10.1145/3410223,
author = {Darragh, Pierce and Adams, Michael D.},
title = {Parsing with Zippers (Functional Pearl) Paper Artifact},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410223},
abstract = {
    <p>This is the artifact associated with the ICFP 2020 paper "Parsing with Zippers (Functional Pearl)" by Pierce Darragh and Michael D Adams.</p>
<h3 id="organization">Organization</h3>
<p>This artifact is organized into three top-level directories:</p>
<ul>
<li><code>benchmark</code> provides the code for running the benchmarking tests we use in the paper.</li>
<li><code>interact</code> provides a minimal implementation of the Parsing with Zippers algorithm and a set of example grammars that can be used for interactive testing.</li>
<li><code>appendix</code> contains a copy of the code listed in the appendix of the paper.</li>
</ul>
<p>Instructions for compilation, setup, and use appear in the <code>README.md</code> files located within each of these directories.</p>

},
keywords = {Derivatives, Parsing, Parsing with Derivatives, Zippers}
}

@software{10.1145/3410224,
author = {Swamy, Nikhil and Rastogi, Aseem and Fromherz, Aymeric and Merigoux, Denis and Ahman, Danel and Mart\'{\i}nez, Guido},
title = {Replication package for Article: "SteelCore: An Extensible Concurrent Separation Logic for Effectful Dependently Typed Programs"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410224},
abstract = {
    <p>This artifact contains the mechanized proofs for the model presented in the SteelCore paper. More precisely, we implement here a version of our effectful CSL semantics complete with monotonic state, non-determinism and pre- and post-conditions. Examples presented in the paper are also included.</p>
<p>We include both the plain sources with instructions for local installation in the steel-artifact folder, as well as a VM with the full development and Emacs installed in the steel-artifact-vm folder. READMEs with relevant instructions and explanations can be found in each folder.</p>

},
keywords = {Concurrency, Dependent types, Domain-specific languages, Formal semantics, Program verification}
}

@software{10.1145/3410225,
author = {Parreaux, Lionel},
title = {Simple-sub source code, including comparison tests with MLsub},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410225},
abstract = {
    <p>This artifact contains the complete source code of the Simple-sub type inference engine, as presented in our paper "The Simple Essence of Algebraic Subtyping: Principal Type Inference with Subtyping Made Easy (Functional Pearl)". It also includes the source code of the existing MLsub system, as well as some code for generating expressions and systematically testing them against MLsub.</p>

},
keywords = {principal types, subtyping, type inference}
}

@software{10.1145/3410226,
author = {Haudebourg, Timoth\'{e}e and Genet, Thomas and Jensen, Thomas},
title = {Timbuk 4: Regular Language Type Inference with Term Rewriting},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410226},
abstract = {
    <p>Provides Timbuk 4, an implementation of Regular Language Type Inference with Term Rewriting.</p>

},
keywords = {Functional Languages, Higher-Order, Program Verification, Regular Languages, Term Rewriting, Type Inference}
}

@software{10.1145/3410227,
author = {Hagedorn, Bastian and Lenfers, Johannes and Kundefinedhler, Thomas and Qin, Xueying and Gorlatch, Sergei and Steuwer, Michel},
title = {Software Artifact for: Achieving High-Performance the Functional Way - A Functional Pearl on Expressing High-Performance Optimizations as Rewrite Strategies},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410227},
abstract = {
    <p>This artifact contains the source code described in our ICFP'20 publication: Achieving High-Performance the Functional Way - A Functional Pearl on Expressing High-Performance Optimizations as Rewrite Strategies. It contains the RISE and ELEVATE implementations, the Agda code for proving the correctnes of the discussed rewrite rules, and the examples discussed in the paper. Please read the README file for more information.</p>

},
keywords = {ELEVATE, Optimization Strategies, Rewrite Rules, Strategy Languages}
}

@software{10.1145/3410228,
author = {Kov\'{a}cs, Andr\'{a}s},
title = {Implementation of the article "Elaboration with First-Class Implicit Function Types"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410228},
abstract = {
    <p>Implementation for a small dependent type theory with enhanced inference for implicit function types.</p>

},
keywords = {elaboration, impredicative polymorphism, type inference, type theory}
}

@software{10.1145/3410229,
author = {M\'{e}vel, Glen and Jourdan, Jacques-Henri and Pottier, Fran\c{c}ois},
title = {Coq Proof Scripts for Article: Cosmo: A Concurrent Separation Logic for Multicore OCaml},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410229},
abstract = {
    <p>This is the machine-checked implementation of the program logic described in the article “Cosmo: A Concurrent Separation Logic for Multicore OCaml”. It consists of definitions and proofs —including soundness of the said logic— carried in the Coq proof assistant with the Iris Concurrent Separation Logic framework. It also provides a “proof mode”, under the form of a set of tactics, which allows interactive verification within Coq of programs written in the toy language of the article.</p>

},
keywords = {concurrency, program verification, separation logic, weak memory}
}

@software{10.1145/3410230,
author = {Graf, Sebastian and Peyton Jones, Simon and Scott, Ryan G.},
title = {Artifact for "Lower Your Guards: A Compositional Pattern-Match Coverage Checker"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410230},
abstract = {
    <p>The artifact accompanying the ICFP 2020 paper "Lower Your Guards: A Compositional Pattern-Match Coverage Checker". This is packaged as a Docker image that contains a patched version of the Glasgow Haskell Compiler (referred to as GHC-LYG) which implements the Lower Your Guards (LYG) algorithm for pattern-matching coverage checking. The Docker image contains runnable programs corresponding to each of the code examples in the paper along with a Readme file that describes the expected outputs. The image also describes how to reproduce other results from the paper, including the head.hackage results, the compiler performance tests, and the coverage warnings for OCaml and Idris code.</p>
<p>The source code for the Docker image is included in artifact05-source-<md5sum>.tgz, where <md5sum> contains the md5sum checksum of the tarball. Also included is artifact05-image-<md5sum>.tgz, which contains a QEmu virtual machine image that comes with the Docker image pre-installed.</md5sum></md5sum></md5sum></p>

},
keywords = {guards, Haskell, pattern matching, strictness}
}

@software{10.1145/3410231,
author = {Hillerstr\"{o}m, Daniel and Lindley, Sam and Longley, John},
title = {Experiments with Generic Search using Delimited Control},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410231},
abstract = {
    <h3 id="artifact-instructions">Artifact Instructions</h3>
<p>The provided artifact contains the source files along with the raw and processed data for the experiments reported in Section 8 of the paper. The experiments were conducted on a Intel Xeon CPU E5-1620 v2 @ 3.70GHz powered workstation running Ubuntu 16.04 LTS using <a href="https://www.smlnj.org/dist/working/110.97/index.html">SML/NJ v110.97 64-bit</a> and <a href="https://github.com/MLton/mlton/releases/tag/on-20180207-release">MLton 20180207</a> both with factory settings.</p>
<h4 id="directory-structure">Directory structure</h4>
<ul>
<li><code>src/</code> contains the SML source files for the <code>n</code>-Queens and integration benchmarks.</li>
<li><code>raw-data/</code> contains the data generated by running the experiments on our reference machine.</li>
<li><code>data/</code> contains the processed data. The data has been processed using LibreOffice Calc.</li>
</ul>
<h4 id="sources">Sources</h4>
<p>The file <code>src/bench.sml</code> contains some auxiliary functions for configuring and running the benchmarks. The files <code>src/platform_{mlton,smlnj}.sml</code> provide compatibility interfaces to account for the differences in the <code>Cont</code> and <code>GC</code> modules between SML/NJ and MLton. The file <code>src/mlton_driver.sml</code> provides the main entry point for the benchmarks compiled with the MLton. The file <code>src/catchcont.sml</code> contains the implementation of John Longley's <code>catch-with-continue</code> delimited control operator which we use to in place of an effect handler. The file <code>src/genericSearch.sml</code> contains the implementations of the generic search procedures used in the <code>n</code>-Queens benchmarks:</p>
<ul>
<li><code>NaiveSearch</code> is the search procedure referred to as "Na\"{\i}ve" in the paper.</li>
<li><code>FunSearch</code> is the search procedure referred to as "Berger" in the paper.</li>
<li><code>ModSearch</code> is the search procedure referred to as "Pruned" in the paper.</li>
<li><code>CcSearch</code> is the search procedure referred to as "Effectful" in the paper.</li>
</ul>
<p>In addition the <code>n</code>-Queens benchmark file <code>src/queens.ml</code> contains a bespoke implementation.</p>
<p>The <code>queens.cm</code> and <code>integration.cm</code> files are compilation manager files used by the SML/NJ compiler to build the benchmarks, whilst <code>queens.mlb</code> and <code>integration.mlb</code> are ML basis files used by the MLton compiler to build the benchmarks.</p>
<h5 id="queens-benchmarks">Queens benchmarks</h5>
<p>The file <code>src/queens.sml</code> contains source code for the <code>n</code>-Queens benchmarks. There are two predicates: * <code>nQueens</code>: This predicate does not refrain from querying the proposed solution p repeatedly on the same argument <code>i</code>. E.g. <code>(p    0)</code> is evaluated afresh for each comparison with some <code>(p i)</code>, <code>i&gt;0</code>. * <code>nQueens'</code>: This remembers results of earlier queries to <code>p</code>, and in fact asks for each of <code>p 0</code>, <code>p 1</code>, etc once only, in this order.</p>
<h5 id="integration-benchmarks">Integration benchmarks</h5>
<p>The file <code>src/integration.sml</code> contains the source code for the integration benchmarks.</p>
<h4 id="benchmark-execution">Benchmark execution</h4>
<p>SML/NJ and MLton compilers are required in order to build and run the benchmark suite. To build the benchmark programs navigate to the <code>src/</code> directory and type</p>
<pre class="shell"><code>$ make</code></pre>
<p>As a result of the above command the following binary files should be produced: <code>queens.mlton</code>, <code>integration.mlton</code>, <code>queens.amd64-linux</code>, and <code>integration.amd64-linux</code>. The first two are the binaries produced by MLton and the last two are the binaries produced by SML/NJ's compilation manager which suffixes the target binaries with a platform-identifier. Thus if you are using a platform other than amd64 Linux then the target binaries will have different suffixes.</p>
<p>To run either of the MLton binaries type</p>
<pre><code>$ ./queens.mlton
$ ./integration.mlton</code></pre>
<p>To run either of the SML/NJ type (replace the suffix <code>amd64-linux</code> with the identifier for your platform)</p>
<pre><code>$ sml @SMLload queens.amd64-linux
$ sml @SMLload integration.amd64-linux</code></pre>
<p>We provide a simple script to run all benchmarks, simply type</p>
<pre><code>$ ./run_all</code></pre>
<p>If your SML/NJ installation is not amd64 or x86 Linux then you will have to modify lines 4-21 in <code>run_all</code> such that the filenames have the proper suffixes.</p>
<p>Note that every benchmark program has exponential time complexity, so you may want to go brew more than one coffee whilst you wait for them to finish. The expected run-time with the paper configuration is roughly ½-1 day.</p>

},
keywords = {generic search, mlton, sml/nj}
}

@software{10.1145/3410232,
author = {Radanne, Gabriel and Saffrich, Hannes and Thiemann, Peter},
title = {The Affe typechecker},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410232},
abstract = {
    <p>Prototype typechecker for the Affe language, and associated examples</p>

},
keywords = {Functional programming, Linear types, Ownership, Type inference}
}

@software{10.1145/3410233,
author = {Wang, Di and Kahn, David M. and Hoffmann, Jan},
title = {Resource Aware ML},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410233},
abstract = {
    <p>This artifact extends Resource Aware ML (RaML) with the ability to automatically derive worst-case bounds on the expected cost of probabilistic functional programs. RaML is a resource-aware version of a considerable subset of the OCaml programming language, and its frontend accepts input programs in OCaml syntax. This artifact extends the language with (i) a new flip expression for probabilistic branching, and (ii) a new type for <em>symbolic</em> probabilities. This artifact implements a type-based expected cost analysis that infers symbolic bounds, which can be functions of the sizes of values of inductive datatypes and the values of symbolic probabilities.</p>

},
keywords = {analysis of probabilistic programs, expected execution cost, resource-aware type system}
}

@software{10.1145/3410234,
author = {Matsuda, Kazutaka and Wang, Meng},
title = {A prototype implementation and proof scripts for Sparcl: A Language for Partially-Invertible Computation},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410234},
abstract = {
    <p>This artifact consists of two implementations: one is an implementation of the system presented in the paper, and the other is Agda scripts mentioned in Section 3.6.4 to prove type-safety and bijectivity.</p>

},
keywords = {Agda, domain-specific language, Haskell, linear types}
}

@software{10.1145/3410235,
author = {Montagu, Beno\^{\i}t and Jensen, Thomas},
title = {Coq Development for the Article: Stable Relations and Abstract Interpretation of Higher-Order Programs},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410235},
abstract = {
    <p>This is the Coq formalization of the definitions and theorems found in the article ICFP'20 "Stable Relations and Abstract Interpretation of Higher-Order Programs". The artifact contains the sources of the development, and also a QEMU image on which a Debian system is installed, and in which the same development can be built directly.</p>

},
keywords = {abstract interpretation, Coq, lambda-calculus, nominal techniques, relations, static analysis}
}

@software{10.1145/3410236,
author = {Knoth, Tristan and Wang, Di and Reynolds, Adam and Hoffmann, Jan and Polikarpova, Nadia},
title = {Artifact for Liquid Resource Types},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410236},
abstract = {
    <p>A typechecker and set of examples showcasing the liquid resource type system.</p>

},
keywords = {Automated amortized resource analysis, Refinement types, Resource analysis}
}

@software{10.1145/3410237,
author = {Polikarpova, Nadia and Stefan, Deian and Yang, Jean and Itzhaky, Shachar and Hance, Travis and Solar-Lezama, Armando},
title = {Replication package for article: Liquid Information Flow Types},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410237},
abstract = {
    <p>This package contains: 1) a VM image for reproducing the experiments in the paper, and 2) an archive of the source code of the tool.</p>

},
keywords = {information flow control, liquid types, Program synthesis}
}

@software{10.1145/3410238,
author = {Sekiyama, Taro and Tsukada, Takeshi and Igarashi, Atsushi},
title = {Interpreter Artifact for "Signature Restriction for Polymorphic Algebraic Effects"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410238},
abstract = {
    <p>This artifact provides an interpreter of a functional programming language MLSR that supports let-polymorphism, Hindley-Milner type inference, and polymorphic algebraic effects and handlers with signature restriction. The interpreter implements the extended type system in Sections 4 \&amp; 5 of our paper. This artifact does not support the type-and-effect system in Section 6.</p>

},
keywords = {Algebraic Effects and Handlers, Parametric Polymorphism, Polymorphic Effects, Polymorphic Type Assignment}
}

@software{10.1145/3410239,
author = {Santos, Armando and Oliveira, Jos\'{e} N.},
title = {Linear Algebra of Programming Library},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410239},
abstract = {
    <p>This artifact contains 2 zips: - the source code of the Haskell library presented in the paper; - and the evaluation source code used to produce the benchmarking results in the paper.</p>

},
keywords = {Algebra of Programming, Haskell, Linear Algebra, Mathematics, Matrix}
}

@software{10.1145/3410241,
author = {Xie, Ningning and Leijen, Daan},
title = {The "EvEff" Effect library and benchmarks for the paper "Effect Handlers in Haskell, Evidently", Haskell 2020},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410241},
abstract = {
    <p>This is the implementation of the "EvEff" effect library "Control.Ev.Eff" described in the paper "Effect Handlers in Haskell, Evidently", Haskell 2020. It also contains the benchmark programs.</p>

},
keywords = {Algebraic Effects, Effect Handler, EvEff, Evidence Passing Translation}
}

@software{10.1145/3410242,
author = {Par\`{e}s, Yves and Bernardy, Jean-Philippe and Eisenberg, Richard A.},
title = {Kernmantle},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410242},
abstract = {
    <p>Braiding extensible effects together in a pipeline/workflow of tasks</p>

},
keywords = {arrows, effect handlers, Haskell}
}

@software{10.1145/3410244,
author = {Valliappan, Nachiappan and Krook, Robert and Russo, Alejandro and Claessen, Koen},
title = {Haski compiler},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410244},
abstract = {
    <p>The purpose of this artifact is to illustrate the writing of Haski programs in a Haskell environment and the inspection of C code generated by the Haski compiler---discussed in sections 2-6 of the paper. Specifically, this artifact contains the implementation of the Haski compiler and the source of the examples found in these sections. For a more up to date version of this artifact, we encourage the reader to check the repository at https://github.com/OctopiChalmers/haski.</p>

},
keywords = {eDSL, Hakell, Information-flow Control, IoT}
}

@software{10.1145/3410245,
author = {Eisenberg, Richard A.},
title = {Stitch},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410245},
abstract = {
    <p>Stitch is a typed lambda-calculus interpreter, suitable for classroom use. Its implementation uses advanced Haskell techniques; this implementation is the subject of the Haskell Symposium 2020 paper "Stitch: The Sound Type-Indexed Type Checker"</p>

},
keywords = {GADTs, Haskell, type checking}
}

@software{10.17863/CAM.52533,
author = {Licker, Nandor and Jones, Timothy M.},
title = {Replication Package for the Duplo post-link optimiser},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.17863/CAM.52533},
abstract = {
    <p>This artifact contains the sources of the Duplo post-link optimiser, including all of its forked dependencies, along with the benchmarking utilities required to reproduce the results presented in "Duplo: A Framework for OCaml Post-Link Optimisation". The benchmarks evaluate the reduction in code size and increase in performance on widely-used OCaml applications, along with a sizeable subset of the standard operf-macro and operf-micro benchmark suites. The artifact is split into two components. Firstly, it provides a source bundle with instructions to set up the framework and run the optimiser on illustrative examples. Secondly, a QEMU disk image which contains pre-installed versions of the framework and benchmarks, with instructions to reproduce the results reported in the paper.</p>

},
keywords = {LLVM, OCaml, post-link optimiser}
}

@software{10.5281/zenodo.3926703,
author = {Giarrusso, Paolo G. and Stefanesco, L\'{e}o and Timany, Amin and Birkedal, Lars and Krebbers, Robbert},
title = {Scala Step-by-Step: Soundness for DOT with Step-Indexed Logical Relations in Iris — Coq Formalization},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3926703},
abstract = {
    <p>This package contains the mathematical proofs for the associated paper, formalized in the Coq proof assistant, both as a source archive, and as a virtual machine containing the right dependencies to build the proofs.</p>

},
keywords = {Coq, data abstraction, DOT, Iris, logical relations, Scala, step-indexing, type soundness}
}

@software{10.5281/zenodo.3926830,
author = {Lubin, Justin and Collins, Nick and Omar, Cyrus and Chugh, Ravi},
title = {Implementation of Program Sketching with Live Bidirectional Evaluation},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3926830},
abstract = {
    <p>This artifact is the implementation of Smyth, the program synthesizer described in "Program Sketching with Live Bidirectional Evaluation."</p>

},
keywords = {Bidirectional Evaluation, Examples, Program Synthesis, Sketches}
}

@software{10.5281/zenodo.3930143,
author = {Kamps, Sander and Heeren, Bastiaan and Jeuring, Johan},
title = {icfpws20haskellmain-p2-p},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3930143},
abstract = {
    <p>This artifact contains the data that is collected during the research described in the paper "Assessing the quality of evolving Haskell systems by measuring structural inequality"</p>

},
keywords = {Distribution, Evolution, Gini coefficient, Ideal value deviation}
}

@software{10.5281/zenodo.3692205,
author = {Muller, Stefan K. and Singer, Kyle and Goldstein, Noah and Acar, Umut A. and Agrawal, Kunal and Lee, I-Ting Angelina},
title = {Responsive Parallelism with Futures and State - Software Artifact},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3692205},
abstract = {
    <p>This artifact contains a prototype of the I-Cilk runtime for scheduling parallel code with task priorities, a C++ type system for preventing priority inversions, and benchmarks using both of the former. The artifact demonstrates the practicality of the type system in implementing performant parallel code that uses task priorities. The prototype I-Cilk runtime is in the interactive-cilk directory, with the type system located in interactive-cilk/include/cilk/cilk_priority.h.</p>

},
keywords = {futures, Interactive Cilk, priority inversion, responsiveness, task parallelism, type systems}
}

@software{10.5281/zenodo.3742225,
author = {Chowdhary, Sangeeta and Lim, Jay P. and Nagarakatte, Santosh},
title = {PositDebug Artifact: Debugging and Detecting Numerical Errors in Computation with Posits},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3742225},
abstract = {
    <p>This artifact contains a shadow execution framework for finding numerical errors in applications using both posits and floating point. The prototype for posits is called PositDebug and the prototype for floating point programs is called FPSsanitizer.</p>

},
keywords = {cancellation, CORDIC, floating point, FPSanitizer, numerical errors, PositDebug, posits}
}

@software{10.5281/zenodo.3742711,
author = {Antoniadis, Anastasios and Filippakis, Nikos and Krishnan, Paddy and Ramesh, Raghavendra and Allen, Nicholas and Smaragdakis, Yannis},
title = {Artifact: Static Analysis of Enterprise Applications: Frameworks and Caches, the Elephants in the Room},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3742711},
abstract = {
    <p>This artifact contains the evaluation benchmarks for the paper "Static Analysis of Java Enterprise Applications: Frameworks and Caches, the Elephants in the Room" , accepted in the Programming Language Design and Implementation Conference (PLDI'20).</p>
<p>Link to paper preprint</p>
<p>Abstract:</p>
<p>Enterprise applications are a major success domain of Java, and Java</p>
<p>is the default setting for much modern static analysis research. It</p>
<p>would stand to reason that high-quality static analysis of Java</p>
<p>enterprise applications would be commonplace, but this is far from</p>
<p>true. Major analysis frameworks feature virtually no support for</p>
<p>enterprise applications and offer analyses that are woefully</p>
<p>incomplete and vastly imprecise, when at all scalable.</p>
<p>In this work, we present two techniques for drastically enhancing</p>
<p>the completeness and precision of static analysis for Java</p>
<p>enterprise applications. The first technique identifies</p>
<p>domain-specific concepts underlying all enterprise application</p>
<p>frameworks, captures them in an extensible, declarative form, and</p>
<p>achieves modeling of components and entry points in a largely</p>
<p>framework-independent way. The second technique offers precision and</p>
<p>scalability via a sound-modulo-analysis modeling of standard data</p>
<p>structures.</p>
<p>In realistic enterprise applications (an order of magnitude larger than</p>
<p>prior benchmarks in the literature) our techniques achieve high degrees of</p>
<p>completeness (on average more than 4x higher than conventional techniques) and</p>
<p>speedups of about 6x compared to the most precise conventional analysis, with</p>
<p>higher precision on multiple metrics. The result is JackEE, an</p>
<p>enterprise analysis framework that can offer precise, high-completeness</p>
<p>static modeling of realistic enterprise applications.</p>

},
keywords = {Java EE, points-to analysis, static analysis}
}

@software{10.5281/zenodo.3743160,
author = {Premtoon, Varot and Koppel, James and Solar-Lezama, Armando},
title = {Yogo},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3743160},
abstract = {
    <p>Docker container with an executable copy of Yogo, and source code for the Haskell portion (frontend)</p>

},
keywords = {code search, equational reasoning}
}

@software{10.5281/zenodo.3750961,
author = {Ji, Ruyi and Liang, Jingjing and Xiong, Yingfei and Zhang, Lu and Hu, Zhenjiang},
title = {Artifact for paper "Question Selection for Interactive Program Synthesis"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3750961},
abstract = {
    <p>This artifact is comprised of the appendix, source code and experiment scripts of paper "Question Selection for Interactive Program Synthesis". Readers can use them to reproduce the experiment results listed in our paper.</p>

},
keywords = {Interaction, Program Synthesis}
}

@software{10.5281/zenodo.3751586,
author = {Apostolakis, Sotiris and Xu, Ziyang and Tan, Zujun and Chan, Greg and Campanoni, Simone and August, David I.},
title = {SCAF: A Speculation-Aware Collaborative Dependence Analysis Framework},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3751586},
abstract = {
    <p>Artifact archive for the artifact evaluation of the PLDI 2020 paper, titled "SCAF: A Speculation-Aware Collaborative Dependence Analysis Framework". It contains a Dockerfile along with relevant to this paper software to create a docker image used to reproduce the evaluation results presented in this PLDI 2020 paper.</p>

},
keywords = {compilers, program analysis, speculation}
}

@software{10.5281/zenodo.3752546,
author = {Gen\c{c}, Kaan and Bond, Michael D. and Xu, Guoqing Harry},
title = {Artifact for Article: Crafty: Efficient, HTM-Compatible Persistent Transactions},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3752546},
abstract = {
    <p>The artifact contains the source code of our implementation, including the microbenchmarks we evaluated and the code required to generate the graphs seen in the paper. It also contains a Docker image that includes all requirements for building and running the code. Using the Docker image is optional but highly recommended. A README file detailing how to reproduce our results is included.</p>

},
keywords = {Crafty, non-volatile memory, persistent memory, persistent transactions}
}

@software{10.5281/zenodo.3753963,
author = {Huang, Kangjing and Qiu, Xiaokang and Shen, Peiyuan and Wang, Yanjun},
title = {DryadSynth: Release as PLDI 2020 Artifact: Reconciling Enumerative and Deductive Program Synthesis},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3753963},
abstract = {
    <p>DryadSynth: A syntax-guided synthesizer</p>

},
keywords = {deductive synthesis, divide-and-conquer, enumerative synthesis, syntax-guided synthesis}
}

@software{10.5281/zenodo.3754772,
author = {Kragl, Bernhard and Enea, Constantin and Henzinger, Thomas A. and Mutluergil, Suha Orhun and Qadeer, Shaz},
title = {Inductive Sequentialization of Asynchronous Programs (Evaluated Artifact)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3754772},
abstract = {
    <p>Inductive sequentialization is implemented as an extension of the CIVL verifier. This implementation and all examples listed in Table 1 of the paper are part of the open-source project Boogie. This artifact is for long-term archiving purposes and contains a snapshot of Boogie version 2.6.4. Since the project is under active development, we recommend to obtain the most recent version from https://github.com/boogie-org/boogie.</p>
<p>For further information and instructions, see the included README.md file.</p>

},
keywords = {abstraction, asynchrony, concurrency, induction, invariants, layers, movers, reduction, refinement, verification}
}

@software{10.5281/zenodo.3756283,
author = {Dasgupta, Sandeep and Dinesh, Sushant and Venkatesh, Deepan and Adve, Vikram S. and Fletcher, Christopher W.},
title = {Artifact for "Scalable Validation of Binary Lifters"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3756283},
abstract = {
    <p>Snapshot of peer-evaluated artifact corresponding to the published conference paper [1].</p>
<p>[1] Sandeep Dasgupta, Sushant Dinesh, Deepan Venkatesh, Vikram S. Adve, and Christopher W. Fletcher 2020. Scalable Validation of Binary Lifters. In Proceedings of the 2020 ACM SIGPLAN Conference on Programming Language Design and Implementation. ACM. https://doi.org/10.1145/3385412.3385964</p>

},
keywords = {compiler-optimization, detecting-bugs, evaluation, formal-semantics, graph-matching, language-semantics, llvm-ir, mcsema, pldi, reproducing-bugs, reverse-engineering, symbolic-execution-engine, symbolic-summaries, translation-validation, validation, verification-conditions, verification-queries, virtualbox, x86-64}
}

@software{10.5281/zenodo.3756301,
author = {Qin, Boqin and Chen, Yilun and Yu, Zeming and Song, Linhai and Zhang, Yiying},
title = {Replication Package for Article: Understanding Memory and Thread Safety Practices and Issues in Real-World Rust Programs},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3756301},
abstract = {
    <p>The artifact is to support the data in our paper with programs. It contains five directories related to the corresponding sections in the paper. section-2-background-and-related-work contains scripts and raw data to plot Fig. 1 and Fig. 2. section-4-unsafe-usages contains a bench testing for safe and unsafe code, and a script to count unsafe statistics. section-5-memory-safety-issues contains the fix commits of our studied memory bugs, and our reproduced memory bugs. section-6-thread-safety-issues contains the fix commits of our studied blocking and non-blocking bugs, our reproduced blocking and non-blocking bugs, and the code to count cases where locks are manually dropped. section-7-bug-detection contains our detection tools for use-after-free and double-lock.</p>

},
keywords = {Bug Study, Concurrency Bug, Memory Bug, Rust}
}

@software{10.5281/zenodo.3756416,
author = {Wu, Zhenwei and Lu, Kai and Nisbet, Andrew and Zhang, Wenzhe and Luj\'{a}n, Mikel},
title = {PMThreads: Persistent Memory Threads Harnessing Versioned Shadow Copies (Artifact)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3756416},
abstract = {
    <p>This is the artifact for the paper "PMThreads: Persistent Memory Threads Harnessing Versioned Shadow Copies", which is set to be published in PLDI 2020. The artifact contains code, and a Dockerfile for assembling a Docker image with all required dependencies to run the code and reproduce the paper results.</p>

},
keywords = {memory persistence, non-volatile memory}
}

@software{10.5281/zenodo.3756609,
author = {Lee, DongKwon and Lee, Woosuk and Oh, Hakjoo and Yi, Kwangkeun},
title = {Lobster - Optimizing Homomorphic Evaluation Circuits by Program Synthesis and Term Rewriting},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3756609},
abstract = {
    <p>Lobster optimizes homomorphic encryption circuit using aggressive rewrite rules automatically learned by program synthesis technique.</p>

},
keywords = {Homomorphic encryption circuit, Program synthesis, Term rewriting}
}

@software{10.5281/zenodo.3759110,
author = {Vila, Pepe and Ganty, Pierre and Guarnieri, Marco and K\"{o}pf, Boris},
title = {Polca: a tool for learning cache replacement policies as automata models},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3759110},
abstract = {
    <p>Polca implements the automata interface to LearnLib for automatically learning cache replacement policies. It can be connected to CacheQuery for directly interacting with hardware caches. It also contains the learned models, instructions to generate them, and the templates (and results) for (from) the program synthesis evaluation.</p>

},
keywords = {automata, cache, cachequery, learning, learnlib, program synthesis, replacement policy, sketch}
}

@software{10.5281/zenodo.3760403,
author = {Brent, Lexi and Grech, Neville and Lagouvardos, Sifis and Scholz, Bernhard and Smaragdakis, Yannis},
title = {Ethainter: A Smart Contract Security Analyzer for Composite Vulnerabilities},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3760403},
abstract = {
    <p>The artifact is composed of: - A decompiler (modified Gigahorse) - Ethainter implementation - Data for recreating experiments</p>

},
keywords = {Program Analysis, Smart Contracts}
}

@software{10.5281/zenodo.3762236,
author = {Roemer, Jake and Gen\c{c}, Kaan and Bond, Michael D.},
title = {Efficient Predictive Race Detection},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3762236},
abstract = {
    <p>This is the artifact submitted for the Artifact Evaluation process for the PLDI 2020 paper "SmartTrack: Efficient Predictive Race Detection" by Jake Roemer, Kaan Gen\c{c}, and Michael D. Bond. This artifact reproduces the paper's experiments; the SmartTrack source code is available here:</p>
<p>https://github.com/PLaSSticity/SmartTrack-pldi20</p>
<p>The artifact file contains a README with more details. Two key issues encountered by Artifact Evaluation Committee members: (1) many executions needed a lot of time and often timed out (for unknown reasons), and (2) after an execution timed out, it would keep running while the next execution started. Artifact author Jake was not able to reproduce the first problem, but the following change should help with the second problem:</p>
<p>In exp/util/ExecUtil.java, change</p>
<p>Runtime.getRuntime().exec("pkill -6 JikesRVM");</p>
<p>to</p>
<p>if (options.config.isRoadRunner()) { Runtime.getRuntime().exec("pkill -6 --full rragent.jar"); } else { Runtime.getRuntime().exec("pkill -6 JikesRVM"); } and then recompile ExecUtil.java with javac.</p>
<p>Sadly, Jake (artifact author and first author of the paper) passed away in April 2020. Please contact Kaan Gen\c{c} and Mike Bond for questions about the artifact.</p>

},
keywords = {Data race detection, dynamic predictive analysis}
}

@software{10.5281/zenodo.3764961,
author = {Bichsel, Benjamin and Baader, Maximilian and Gehr, Timon and Vechev, Martin},
title = {silq-artifact},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3764961},
abstract = {
    <p>Artifact for PLDI'20 paper "Silq: A High-level Quantum Programming Language with Safe Uncomputation and Intuitive Semantics".</p>

},
keywords = {Quantum Language, Semantics, Uncomputation}
}

@software{10.5281/zenodo.3765314,
author = {Gehr, Timon and Steffen, Samuel and Vechev, Martin},
title = {lpsi-artifact},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3765314},
abstract = {
    <p>Artifact for PLDI'20 paper "λPSI: Exact Inference for Higher-Order Probabilistic Programs".</p>

},
keywords = {Exact, Higher-order, Probabilistic Programming}
}

@software{10.5281/zenodo.3833964,
author = {Fourtounis, George and Triantafyllou, Leonidas and Smaragdakis, Yannis},
title = {Identifying Java Calls in Native Code via Binary Scanning (artifact)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3833964},
abstract = {
    <p>This is the artifact for the paper "Identifying Java Calls in Native Code via Binary Scanning" (ISSTA 2020). It contains a Doop installation, the benchmarks used in the "Evaluation" section of the paper, and instructions on how to replicate the paper results.</p>

},
keywords = {binary, Java, native code, static analysis}
}

@software{10.5281/zenodo.3862978,
author = {Vanover, Jackson and Deng, Xuan and Rubio-Gonz\'{a}lez, Cindy},
title = {FPDiff: Discvovering Discrepancies in Numerical Libraries},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3862978},
abstract = {
    <p>FPDiff is a tool for automated, end-to-end differential testing that, given only library source code as input, extracts numerical function signatures, synthesizes drivers, creates equivalence classes of functions that are synonymous, and executes differential tests over these classes to detect meaningful numerical discrepancies between implementations. FPDiff's current scope covers special functions across numerical libraries written in different programming languages. This artifact in particular includes the following libraries: the C library GSL (The GNU Scientific Library, version 2.6), the Python libraries SciPy (version 1.3.1) and mpmath (version 1.1.0), and the JavaScript library jmat (commit 21d15fc3eb5a924beca612e337f5cb00605c03f3).</p>

},
keywords = {correctness, differential testing, floating point, numerical libraries, numerical methods, software testing}
}

@software{10.5281/zenodo.3895271,
author = {Busse, Frank and Nowack, Martin and Cadar, Cristian},
title = {Replication package for: Running Symbolic Execution Forever},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3895271},
abstract = {
    <p>The artefact contains a Docker image with MoKlee, our memoization extension of KLEE, all benchmarks in LLVM bitcode format, the raw experiment results and scripts to re-create our evaluation and to re-run all experiments.</p>

},
keywords = {binutils, coreutils, findutils, grep, KLEE, libspng, memoization, MoKlee, software testing, symbolic execution, tcpdump}
}

@software{10.5281/zenodo.3895414,
author = {Fang, Chunrong and Liu, Zixi and Shi, Yangyang and Huang, Jeff and Shi, Qingkai},
title = {Replication Package for Article: Functional Code Clone Detection with Syntax and Semantics Fusion Learning},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3895414},
abstract = {
    <p>The FCDetector is a functional code clone detection tool with syntax and semantics fusion learning.</p>

},
keywords = {code clone detection, code representation, functional clone detection}
}

@software{10.5281/zenodo.3895797,
author = {Gopinath, Rahul and Kampmann, Alexander and Havrikov, Nikolas and Soremekun, Ezekiel O. and Zeller, Andreas},
title = {Replication package for Abstracting Failure Inducing Inputs},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3895797},
abstract = {
    <p>This artifact contains the implementation of the algorithm in the paper "Abstracting Failure Inducing Inputs". The artifact is a Vagrant box (a virtual machine) that contains the complete implementation and the subjects that can be evaluated directly. A complete worked out example in a Jupyter notebook is included in the VM along with a complete Jupyter installation so that the notebook can be viewed directly.</p>

},
keywords = {debugging, error diagnosis, failure-inducing inputs, grammars}
}

@software{10.5281/zenodo.3897315,
author = {Riganelli, Oliviero and Mottadelli, Simone Paolo and Rota, Claudio and Micucci, Daniela and Mariani, Leonardo},
title = {DLD: Data Loss Detector},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3897315},
abstract = {
    <p>Android apps must work correctly even if their execution is interrupted by external events. For instance, an app must work properly even if a phone call is received, or after its layout is redrawn because the smartphone has been rotated. Since these events may require destroying, when the execution is interrupted, and recreating, when the execution is resumed, the foreground activity of the app, the only way to prevent the loss of state information is to save and restore it. This behavior must be explicitly implemented by app developers, who often miss to implement it properly, releasing apps affected by data loss problems, that is, apps that may lose state information when their execution is interrupted. Although several techniques can be used to automatically generate test cases for Android apps, the obtained test cases seldom include the interactions and the checks necessary to exercise and reveal data loss faults. Data Loss Detector (DLD) is a test case generation technique that integrates an exploration strategy, data-loss-revealing actions, and two customized oracle strategies for the detection of data loss failures.</p>

},
keywords = {Android, Data Loss, Mobile Apps, Test Case Generation, Validation}
}

@software{10.5281/zenodo.3901626,
author = {Hildebrandt, Carl and Elbaum, Sebastian and Bezzo, Nicola and Dwyer, Matthew B.},
title = {Feasible and Stressful Trajectory Generation for Mobile Robots - Artifact},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3901626},
abstract = {
    <p>This artifact can be used to replicate the results found in the paper: "Feasible and Stressful Trajectory Generation for Mobile Robots". For more information on the content consult the readme file.</p>

},
keywords = {Kinematic and Dynamic Models, Robotics, Stress Testing, Test Generation}
}

@software{10.6084/m9.figshare.12089217,
author = {Rocha, Rodrigo C. O. and Petoumenos, Pavlos and Wang, Zheng and Cole, Murray and Leather, Hugh},
title = {Artifact for "Effective function merging in the SSA form"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.12089217},
abstract = {
    <p>This artifact includes a modified version of the open-source LLVM compiler framework. It includes a prototype implementation of our novel function merging technique, called SalSSA. It also includes an implementation of the state-of-the-art function merging technique. This artifact also provides Makefile scripts to run spec2006 using these function merging techniques and scripts to compare them.</p>

},
keywords = {code size, compiler optimization, function merging, link-time optimization, LTO}
}

@software{10.1145/3410246,
author = {Trabish, David and Kapus, Timotej and Rinetzky, Noam and Cadar, Cristian},
title = {Replication Package for Article: Past-Sensitive Pointer Analysis for Symbolic Execution},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410246},
abstract = {
    <p>The artifact contains the docker image with the source code and the evaluation-related data, and instructions for replicating the experiments.</p>

},
keywords = {Pointer Analysis, Symbolic Execution}
}

@software{10.1145/3410247,
author = {Babakol, Timur and Canino, Anthony and Mahmoud, Khaled and Saxena, Rachit and Liu, Yu David},
title = {Experimental Replication of Experiments for Article: Calm Energy Accounting for Multithreaded Java Applications},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410247},
abstract = {
    <p>Contained in this artifact is a Docker image that reproduces the data with instructions for usage and a link to our public repository where our source and data are stored.</p>

},
keywords = {Concurrency, Energy Accounting, Energy Profiling, Power Disturbance, Software Performance}
}

@software{10.1145/3410248,
author = {Ghamizi, Salah and Cordy, Maxime and Gubri, Martin and Papadakis, Mike and Boystov, Andrey and Le Traon, Yves and Goujon, Anne},
title = {Replication package for "Search-Based Adversarial Testing and Improvement of Constrained Credit Scoring Systems", accepted at ESEC/FSE 2020},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410248},
abstract = {
    <p>CoEva2 is a multi-objective search technique to generate adversarial attacks against real-life systems. It uses domain specific constraints and domain specific objectives to craft the attacks. The paper tackles an industrial system and dataset under NDA that we cannot disclose (related to overdraft and credit scoring). In accordance with the Artifact Chair, we are providing a replication study on a public dataset called <em>Lending Club Loan data</em>. It shows both how to implement our approach on available datasets and that our results are valid for other contexts.</p>

},
keywords = {Adversarial attacks, Credit Scoring, FinTech, Random Forest, Search-based}
}

@software{10.1145/3410249,
author = {Liu, Ye and Li, Yi and Lin, Shang-Wei and Zhao, Rong},
title = {Replication Data for Article: Towards Automated Verification of Smart Contract Fairness},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410249},
abstract = {
    <p>This package contains the dataset, raw logs, and instructions for replicating the experiments in the paper titled “Towards Automated Verification of Smart Contract Fairness”.</p>

},
keywords = {fairness, program verification, Smart contract}
}

@software{10.1145/3410251,
author = {She, Dongdong and Krishna, Rahul and Yan, Lu and Jana, Suman and Ray, Baishakhi},
title = {Replication package for MTFuzz: Fuzzing with a Multi-Task Neural Network},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410251},
abstract = {
    <p>We provide source code for MTFuzz to foster further research in this area. We also provide 10 tested programs to reproduce results reported in our paper.</p>

},
keywords = {Fuzzing, Machine learning, Mutli-task learning}
}

@software{10.1184/R1/12543308.v1,
author = {Zhang, Changjian and Garlan, David and Kang, Eunsuk},
title = {Software for Paper: A Behavioral Notion of Robustness for Software Systems},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1184/R1/12543308.v1},
abstract = {
    <p>The prototype implementation for FSE 2020 paper: A Behavioral Notion of Robustness for Software Systems.</p>

},
keywords = {Formal methods, Software modeling and design, Software robustness, Specification and modeling languages}
}

@software{10.17605/OSF.IO/CHM2K,
author = {Badihi, Sahar and Akinotcho, Faridah and Li, Yi and Rubin, Julia},
title = {Implementation for ARDiff: Scaling Program Equivalence Checking via Iterative Abstraction and Refinement of Common Code},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.17605/OSF.IO/CHM2K},
abstract = {
    <p>This contains the implementation of three equivalence checking techniques: two state-of-the-art, Differential Symbolic Execution (DSE) and one based on Impacted Summaries, as well our novel technique ARDiff</p>

},
keywords = {abstraction-refinement, constraint solver, DSE, equivalence checking, impacted, JPF-symbc, static analysis, symbolic execution, z3}
}

@software{10.5281/zenodo.3843611,
author = {Zhang, Yuhao and Ren, Luyao and Chen, Liqian and Xiong, Yingfei and Cheung, Shing-Chi and Xie, Tao},
title = {DEBAR: Detecting Numerical Bugs in Neural Network Architectures},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3843611},
abstract = {
    <p>This artifact contains the implementation of DEBAR and the evaluation in our ESEC/FSE 2020 paper: Detecting Numerical Bugs in Neural Network Architectures.</p>

},
keywords = {Neural Network, Numerical Bugs, Static Analysis}
}

@software{10.5281/zenodo.3872848,
author = {Helm, Dominik and K\"{u}bler, Florian and Reif, Michael and Eichberg, Michael and Mezini, Mira},
title = {Artifact for Modular Collaborative Program Analysis in OPAL},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3872848},
abstract = {
    <p>This is the artifact that was used to obtain the results of “Modular Collaborative Program Analysis in OPAL”, published at ESEC/FSE 2020.</p>
<p>The Docker container contains the necessary tools (OPAL and DOOP), benchmarks (XCorpus, DoopBenchmarks), scripts to run the tools for the experiments performed in the paper and scripts to clean up the output of these experiments to reproduce the tables from the paper.</p>
<p>Please note that the artifact refers to OPAL as ‘BlaSt’ as this name was used during double-blind review.</p>

},
keywords = {Blackboard System, Composition, Modularization, Parallelization, Static Analysis}
}

@software{10.5281/zenodo.3872902,
author = {Gaaloul, Khouloud and Menghi, Claudio and Nejati, Shiva and Briand, Lionel C. and Wolfe, David},
title = {Replication Package for Article: Mining Assumptions for Software Components using Machine Learning},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3872902},
abstract = {
    <p>EPIcuRus (assumPtIon geneRation approach for CPS) automatically synthesizes environment assumptions for a component under analysis. EPIcuRus combines search-based testing, machine learning, and model checking. The core of EPIcuRus is a decision tree algorithm that infers environment assumptions from a test suite including test cases and their verdicts. The test cases are generated using search-based testing, and the assumptions inferred by decision trees are validated through model checking. To improve the efficiency and effectiveness of the assumption generation process, EPIcuRus implements a novel test case generation technique, namely Important Features Boundary Test (IFBT), that guides the test generation based on the feedback produced by machine learning.</p>

},
keywords = {Decision trees, Environment assumptions, Machine learning, Model checking, Search-based software testing}
}

@software{10.5281/zenodo.3874077,
author = {Pan, Rangeet and Rajan, Hridesh},
title = {Replication Package for the Article: On Decomposing a Deep Neural Network into Modules},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3874077},
abstract = {
    <p>This repository has the source code for the paper “On Decomposing a Deep Neural Network into Modules”</p>

},
keywords = {decomposing, deep neural networks, modularity, modules}
}

@software{10.5281/zenodo.3874834,
author = {Gao, Jun and Li, Li and Kong, Pingfan and Bissyand\'{e}, Tegawend\'{e} F. and Klein, Jacques},
title = {DICIDer},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3874834},
abstract = {
    <p>DICIDer is a tool takes as input an Android APK file and outputs a list of DICI paths that trace how direct inter-app code invocations are planned in the analyzed app.</p>

},
keywords = {Android, DICI, Reflection}
}

@software{10.5281/zenodo.3876048,
author = {Ben Khadra, M. Ammar and Stoffel, Dominik and Kunz, Wolfgang},
title = {Supplemental artifacts of the paper: Efficient Binary-Level Coverage Analysis},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3876048},
abstract = {
    <p>The archive contains the artifacts accompanying the paper: “Efficient Binary-Level Coverage Analysis”. The artifacts are organized as follows:</p>
<ul>
<li><p><code>sample-binaries</code>. Folder that contains sample binaries patched with bcov.</p></li>
<li><p><code>dataset.tar.gz</code>. Package that contains experimental data in csv format.</p></li>
<li><p><code>figures</code>. Folder that contains the python script used to generate the figures of our paper. It assumes that the dataset was first extracted to the folder <code>dataset</code>.</p></li>
<li><p><code>install.sh</code>. This script builds and installs bcov together with its dependencies.</p></li>
<li><p><code>experiment-01.sh</code>. This script patches our sample binaries and shows how coverage data can be collected. It assumes that bcov was installed using the previous script.</p></li>
<li><p><code>bcov.tar.gz</code>. Source code of the first public version of <code>bcov</code>. The tool is distributed under an MIT license.</p></li>
</ul>

},
keywords = {code coverage analysis, experimental dataset, jump table analysis, reverse engineering, static binary instrumentation, supplemental artifacts}
}

@software{10.5281/zenodo.3876969,
author = {Gopinath, Rahul and Mathis, Bj\"{o}rn and Zeller, Andreas},
title = {Replication package for Mining Input Grammars from Dynamic Control Flow},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3876969},
abstract = {
    <p>A vagrant virtual box that is sufficient for reproduction of the results in Mining Input Grammars from Dynamic Control Flow</p>

},
keywords = {context-free grammar, fuzzing, mining, software testing}
}

@software{10.5281/zenodo.3877079,
author = {Terragni, Valerio and Jahangirova, Gunel and Tonella, Paolo and Pezz\`{e}, Mauro},
title = {Gassert: Evolutionary Improvement of Assertion Oracles},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3877079},
abstract = {
    <p>Gassert tool, presented in the paper “Evolutionary Improvement of Assertion Oracles” published at ESEC/FSE 2020.</p>

},
keywords = {esec-fse2020, gasser, oracle improvement, software testing, test generation}
}

@software{10.5281/zenodo.3877326,
author = {Chen, Qingrong and Wang, Teng and Legunsen, Owolabi and Li, Shanshan and Xu, Tianyin},
title = {Artifacts of Paper "Understanding and Discovering Software Configuration Dependencies in Cloud and Datacenter Systems"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3877326},
abstract = {
    <p>This package contains all the artifacts (i.e.&nbsp;codes \&amp; datasets) we use in our paper “Understanding and Discovering Software Configuration Dependencies in Cloud and Datacenter Systems” accepted to FSE 2020.</p>

},
keywords = {configuration dependencies, Hadoop, OpenStack, static analysis tools}
}

@software{10.5281/zenodo.3878164,
author = {Vassallo, Carmine and Proksch, Sebastian and Jancso, Anna and Gall, Harald C. and Di Penta, Massimiliano},
title = {Replication Package for "Configuration Smells in Continuous Delivery Pipelines: A Linter and A Six-Month Study on GitLab"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3878164},
abstract = {
    <p>This is the replication package of the paper “Configuration Smells in Continuous Delivery Pipelines: A Linter and A Six-Month Study on GitLab” accepted for publication at ESEC/FSE 2020. We describe the artifacts of our paper and how to use them to replicate the results of our study. When appropriate, we also link the description of the artifacts to relevant sections in the paper.</p>

},
keywords = {Anti-patterns, Configuration, Continuous Delivery, Continuous Integration, DevOps, GitLab, Linter}
}

@software{10.5281/zenodo.3894559,
author = {P\^{a}rundefinedachi, Profir-Petru and Dash, Santanu Kumar and Allamanis, Miltiadis and Barr, Earl T.},
title = {Source Code for Flexeme: Untangling Commits using Lexical Flows},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3894559},
abstract = {
    <p>This project provides several implementations for commit untagling and proposes a new representation of git patches by projecting the patch onto a PDG.</p>
<p><em>Repository Structure</em></p>
<p>We provide an artificial corpus and a way of building such corpora in ./tangle_concerns.</p>
<p>We provide a reference implementation to obtain a 𝛿-PDG and augmenting a 𝛿-PDG with name-flow information to obtain a Delta Name-flow Graph (𝛿-NFG) in ./deltaPDG, the later is ./deltaPDG/Util/merge_nameflow.py.</p>
<p>We provide the binary of the PDG extractor for C# code under ./extractor. NOTE: this requires MS Windows to run.</p>
<p>We provide a reimplementation of the method described by Herzig et al.[1] adapted to the C# setting in ./confidence_voters. In the same folder we provide our adaptation that works on our proposed 𝛿-PDG as ./confidence_voters/confidence_voters_graph_only.py.</p>
<p>We provide a reimplementation of the method described by Barnett et al.[2] in ./du_chain/DU_chains_closure.py. We remark that we do not provide special treatment to trivial partitions as defined by Barnett et al.&nbsp;which may impact observed performance.</p>
<p>We provide our proposed method under ./wl_kernel/wl_kernel_untangle.py.</p>
<p>Evaluation drivers are provided under ./Util/[cv/graph]_evaluation_driver.py.</p>
<p>We provide our evaluation analysis scripts under ./analysis as a jupyter notebook.</p>

},
keywords = {clustering-application, commit-untangling, graph-kernels-application, pdg}
}

@software{10.5281/zenodo.3895761,
author = {Shanker, Kripa and Joseph, Arun and Ganapathy, Vinod},
title = {Replication package for "An evaluation of methods to port legacy code to SGX enclaves"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3895761},
abstract = {
    <p>This artifact contains the code of the benchmarks used in the evaluation, as well as the source code of Porpoise, the instruction wrapper prototype used in the experiments reported in the paper.</p>

},
keywords = {enclaves, Porpoise, porting, programming, SGX}
}

@software{10.5281/zenodo.3896795,
author = {Mandrioli, Claudio and Maggio, Martina},
title = {Replication package for article: Testing Self-Adaptive Software with Probabilistic Guarantees on Performance Metrics},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3896795},
abstract = {
    <p>The artifact contains the code to replicate the experiments from the paper “Testing Self-Adaptive Software with Probabilistic Guarantees on Performance Metrics”. The experiments concerns two different adaptive softwre: Self -Adaptive Video Encoder, and Tele-Assistance System. The two subdirectories of the repository contain the code for the two artifacts.</p>

},
keywords = {Self-Adaptive Software, Testing}
}

@software{10.5281/zenodo.3901405,
author = {Zhang, Ziqi and Li, Yuanchun and Guo, Yao and Chen, Xiangqun and Liu, Yunxin},
title = {Replication Package for artifact: Dynamic Slicing for Deep Neural Networks},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3901405},
abstract = {
    <p>This is the artifact for the paper “Dynamic Slicing for Deep Neural Networks”. More details are in README.md</p>

},
keywords = {data flow analysis, deep neural networks, dynamic slicing, Program slicing}
}

@software{10.5281/zenodo.3902142,
author = {Kampmann, Alexander and Havrikov, Nikolas and Soremekun, Ezekiel O. and Zeller, Andreas},
title = {Replication Package for Article: "When Does My Program Do This? Learning Circumstances of Software Behavior"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3902142},
abstract = {
    <p>Alhazen is a tool which generates an explanation, in terms of input features, for program behavior. Details are given in our publication “When Does My Program Do This? Learning Circumstances of Software Behavior” The artifact consists of two parts: (1) The full data we used in our submission. (2) The program code used to obtain this data. Usage instructions are in a readme within the artifact.</p>

},
keywords = {debugging, error diagnosis, machine learning, software behavior}
}

@software{10.5281/zenodo.3902978,
author = {Cha, Sooyoung and Oh, Hakjoo},
title = {Replication Package for Article: Making Symbolic Execution Promising by Learning Aggressive State-Pruning Strategy},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3902978},
abstract = {
    <p>This is an artifact for the paper “Making Symbolic Execution Promising by Learning Aggressive State-Pruning Strategy” submitted to FSE 2020. It provides a VirtualBox image containing all resources to reproduce the main experimental results in our paper.</p>

},
keywords = {Online Learning, Symbolic Execution}
}

@software{10.5281/zenodo.3905131,
author = {Shahbazian, Arman and Karthik, Suhrid and Brun, Yuriy and Medvidovic, Nenad},
title = {Replication package for "eQual: Informing early design decisions"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3905131},
abstract = {
    <p>This artifact contains the replication package for the paper titled “eQual: Informing early design decisions” (http://dx.doi.org/10.1145/3368089.3409749) published in ESEC/FSE 2020. The artifact contains a proof, data, analysis scripts, and all materials used in the user studies.</p>

},
keywords = {design analysis, design decisions, eQual, optimization, software design}
}

@software{10.5281/zenodo.3905204,
author = {Zhai, Yizhuo and Hao, Yu and Zhang, Hang and Wang, Daimeng and Song, Chengyu and Qian, Zhiyun and Lesani, Mohsen and Krishnamurthy, Srikanth V. and Yu, Paul},
title = {seclab-ucr/UBITect: First release of UBITect},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3905204},
abstract = {
    <p>This is the first release of UBITect, please follow the README.md to install and conduct the experiment.</p>

},
keywords = {bug detection, symbolic execution, type qualifier, Use-before-Initialization}
}

@software{10.5281/zenodo.3908793,
author = {Yan, Shenao and Tao, Guanhong and Liu, Xuwei and Zhai, Juan and Ma, Shiqing and Xu, Lei and Zhang, Xiangyu},
title = { 'Replication Package for Article: Correlations between Deep Neural Network Model Coverage Criteria and Model Quality'},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3908793},
abstract = {
    <p>This artifact includes two parts: ‘all-data.zip’ and ‘DNN/Testing/CovTesting-v1.1.zip’. ‘all-data.zip’ contains the data used for the experiments. ‘DNN/Testing/CovTesting-v1.1.zip’ contains the necessary codes. Please refer to the ‘README.md’ in ‘DNN/Testing/CovTesting-v1.1.zip’ to use this software. You can also refer to https://github.com/RU-System-Software-and-Security/CovTesting for more information.</p>

},
keywords = {Deep Neural Networks, Software Testing}
}

@software{10.5281/zenodo.3911750,
author = {Uesbeck, P. Merlin and Peterson, Cole S. and Sharif, Bonita and Stefik, Andreas},
title = {A Randomized Controlled Trial on the Effects of EmbeddedComputer Language Switching Replication Packet},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3911750},
abstract = {
    <p>A replication packet for the paper “A Randomized Controlled Trial on the Effects of Embedded Computer Language Switching” please review the README inside the zip archive.</p>

},
keywords = {analysis, computer language switching, data, database programming, experience, experiment software, polyglot programming, productivity, programming languages, randomized controlled trial, software}
}

@software{10.5281/zenodo.3912064,
author = {Biswas, Sumon and Rajan, Hridesh},
title = {Accepted Artifact Package for ESEC/FSE 2020 paper: Do the Machine Learning Models on a Crowd Sourced Platform Exhibit Bias? An Empirical Study on Model Fairness},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3912064},
abstract = {
    <p>The artifact contains code and data for the machine learning models used to analyze fairness.</p>

},
keywords = {fairness, machine learning, models}
}

@software{10.5281/zenodo.3923232,
author = {Zhang, Mingxue and Meng, Wei},
title = {Compiled Binary and Analysis Scripts of JSObserver on macOS 10.14 and Debian 9.11 (stretch)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3923232},
abstract = {
    <p>This is a pre-built version of JSObserver, which is a browser-based analysis framework that collects JavaScript write operation logs and function definition logs. It also contains analysis scripts that detect JavaScript global identifier conflicts (i.e., variable value conflicts, variable type conflicts and function definition conflicts) using the logs.</p>

},
keywords = {Analysis scripts, Compiled binary, JSObserver, Python}
}

@software{10.5281/zenodo.3947858,
author = {Rigger, Manuel and Su, Zhendong},
title = {ESEC/FSE 20 Artifact for "Detecting Optimization Bugs in Database Engines via Non-Optimizing Reference Engine Construction"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3947858},
abstract = {
    <p>The artifact consists of two main components:</p>
<ol type="1">
<li>SQLancer, the tool which we created, and in which we implemented NoREC, to find all bugs reported in the associated paper.</li>
<li>A SQLite database with a list of bugs that we reported and additional meta information.</li>
</ol>

},
keywords = {NoREC, SQLancer}
}

@software{10.5281/zenodo.3949286,
author = {Zhao, Yixue and Chen, Justin and Sejfia, Adriana and Schmitt Laser, Marcelo and Zhang, Jie and Sarro, Federica and Harman, Mark and Medvidovic, Nenad},
title = {FrUITeR's artifacts},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3949286},
abstract = {
    <p>FrUITeR’s artifacts accepted at ESEC/FSE 2020 for the paper “FrUITeR: A Framework for Evaluating UI Test Reuse”</p>

},
keywords = {Mobile Application, Open Science, Software Testing, Test Reuse}
}

@software{10.5281/zenodo.3949340,
author = {Wang, Zan and Yan, Ming and Chen, Junjie and Liu, Shuang and Zhang, Dongdi},
title = {Replication Packages for Article &nbsp;"Deep Learning Library Testing via Effective Model Generation"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3949340},
abstract = {
    <p>This artifact includes the code and datasets of LEMON. File named LEMON-V1.0.0.zip includes all the scripts in LEMON, and file named LEMON_datasets_models.zip includes datasets sampled from ImageNet or collected from GitHub by authors. More details can be seen in https://github.com/Jacob-yen/LEMON</p>

},
keywords = {Deep Learning Testing, Library Testing, Model Generation, Mutation, Search-based Software Testing}
}

@software{10.5281/zenodo.3951724,
author = {Hermann, Ben and Winter, Stefan and Siegmund, Janet},
title = {Community Expectations for Research Artifacts and Evaluation Processes (Additional Material)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3951724},
abstract = {
    <p>Raw and derived data on calls for artifacts and a survey conducted with artifact reviewers. The purpose of the artifact is to support the replicability of the conducted study, but also to allow for future studies in the same area.</p>

},
keywords = {Artifact Evaluation, Replicability, Reproducibility, Study}
}

@software{10.5281/zenodo.3966486,
author = {Trimananda, Rahmadi and Aqajari, Seyed Amir Hossein and Chuang, Jason and Demsky, Brian and Xu, Guoqing Harry and Lu, Shan},
title = {IoTCheck},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3966486},
abstract = {
    <p>IoTCheck is a framework that model-checks smart home apps. Please see https://github.com/uci-plrg/iotcheck for further instructions for downloads and installation.</p>

},
keywords = {concurrency, model checking, program analysis, smart home apps}
}

@software{10.5281/zenodo.3993789,
author = {Kr\"{u}ger, Jacob and Berger, Thorsten},
title = {Artifact for the ESEC/FSE 2020 Paper: An Empirical Analysis of the Costs of Clone- and Platform-Oriented Software Reuse},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3993789},
abstract = {
    <p>This dataset comprises the supplementary material for the paper “An Empirical Analysis of the Costs of Clone- and Platform-Oriented Software Reuse” by Jacob Kr\"{u}ger and Thorsten Berger, accepted at ESEC/FSE 2020.</p>

},
keywords = {clone \&amp; own, costs, empirical study, platform, software product line}
}

@software{10.5281/zenodo.4016963,
author = {Riccio, Vincenzo and Tonella, Paolo},
title = {Replication Package for Article: "Model-Based Exploration of the Frontier of Behaviours for Deep Learning System Testing"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4016963},
abstract = {
    <p>This artifact contains the tools and the data of the paper “Model-Based Exploration of the Frontier of Behaviours for Deep Learning System Testing” by V. Riccio and P. Tonella, published in the Proceedings of the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2020). It is structured as follows: - DeepJanus-MNIST: contains the DeepJanus tool adapted to the handwritten digit classification case study and the instructions on how to use it; - DeepJanus-BNG: contains the DeepJanus tool adapted to the self-driving car case study and the instructions on how to use it; - experiments: contains the raw experimental data reported in the paper and the scripts to obtain the data.</p>

},
keywords = {deep learning, model based testing, search based software engineering, software testing}
}

@software{10.5281/zenodo.4021473,
author = {Harel-Canada, Fabrice and Wang, Lingxiao and Gulzar, Muhammad Ali and Gu, Quanquan and Kim, Miryung},
title = {Replication Package for Article: Is Neuron Coverage a Meaningful Measure for Testing Deep Neural Networks?},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4021473},
abstract = {
    <p>This artifact contains the code which generates adversarial test suites and measures its attack success, naturalness (IS + FID), and output impartiality. It also includes the notebooks used to generate figures and the correlations, which were then extracted into a google sheet. The MNIST and CIFAR10 data can be easily downloaded from source, but the udacity driving dataset was included as it may not always be available through the original competition github repo.</p>
<p>Any potential updates will be maintained here: https://github.com/fabriceyhc/nc_diversity_attacks</p>

},
keywords = {Adversarial Attack, Machine Learning, Neuron Coverage, Software Engineering, Testing}
}

@software{10.5281/zenodo.4022892,
author = {Erlenhov, Linda and Neto, Francisco Gomes de Oliveira and Leitner, Philipp},
title = {Replication package to An Empirical Study of Bots in Software Development – Characteristics and Challenges from a Practitioner's Perspective},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4022892},
abstract = {
    <p>Replication package for the analysis from the survey results in the paper “An Empirical Study of Bots in Software Development – Characteristics and Challenges from a Practitioner’s Perspective” Read the README.MD for instructions The replication package contains both R scripts and original data collected in the study.</p>

},
keywords = {Empirical study, Software bot, Software engineering}
}

@software{10.5281/zenodo.4023299,
author = {Cha, Alan and Wittern, Erik and Baudart, Guillaume and Davis, James C. and Mandel, Louis and Laredo, Jim A.},
title = {A Principled Approach to GraphQL Query Cost Analysis Research Paper Artifact},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4023299},
abstract = {
    <p>The artifact contains 1) a GraphQL query-response corpus, containing 10,000 anonymized query and response pairs against the GitHub and Yelp APIs that were used in our experiments, 2) a randomized GraphQL query generator that was used to create the corpus, 3) configurations for the static analyses (ours as well as those we compared against) that were used in our experiments, 4) experiment data and the scripts that were used to create our plots, 5) scripts to fetch the GraphQL schemas that were used in our experiments, and 6) scripts that will use the aforementioned components to rerun our experiments.</p>

},
keywords = {API management, cost estimation, GraphQL, query complexity, random query generation}
}

@software{10.5281/zenodo.4024268,
author = {Beyer, Dirk and Friedberger, Karlheinz},
title = {Replication Artifact for Article 'Domain-Independent Interprocedural Program Analysis using Block-Abstraction Memoization'},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4024268},
abstract = {
    <p>This file is the replication package for the article “Domain-Independent Interprocedural Program Analysis using Block-Abstraction Memoization”, Proc. ESEC/FSE 2020. ACM. It contain the necessary tools and tasks to re-evaluate the benchmark results of the article. More details can be found in the artifact’s readme file.</p>

},
keywords = {CPAchecker, Interprocedural Analysis, Procedure Summary, Program Analysis, Software Verification}
}

@software{10.5281/zenodo.4028454,
author = {Baranov, Eduard and Legay, Axel and Meel, Kuldeep S.},
title = {Baital},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4028454},
abstract = {
    <p>Baital is a sampler generator for configurable systems. It generates a set of testing samples for large configurable systems with high t-wise coverage. The tool takes a set of constraints on features of the configurable system represented as a CNF formula in Dimacs format and provides a set of configurations of a specified size and computes their t-wise coverage.</p>

},
keywords = {Configurable software, t-wise coverage, Weighted sampling}
}

@software{10.5281/zenodo.4031225,
author = {Cambronero, Jos\'{e} P. and Cito, J\"{u}rgen and Rinard, Martin C.},
title = {AMS Artifact},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4031225},
abstract = {
    <p>Software artifact for AMS (Generating AutoML Search Spaces from Weak Specifications), camera-ready modifications incorporated.</p>

},
keywords = {automated machine learning, search-based software engineering, software engineering}
}

@software{10.5522/04/11927208.v2,
author = {Guizzo, Giovani and Sarro, Federica and Harman, Mark},
title = {Replication package for "Cost Measures Matter for Mutation Testing Study Validity", accepted at FSE 2020},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5522/04/11927208.v2},
abstract = {
    <p>This is a replication package for the experiments reported in 2020 FSE paper “Cost Measures Matter for Mutation Testing Study Validity”.</p>
<p>It contains all the subject programs, experimental scripts, and results data.</p>

},
keywords = {Cost Reduction, Execution Time, Mutant Reduction, Mutation Analysis, Mutation Testing, Number of Mutants, Software Testing}
}

@software{10.6084/m9.figshare.11911287.v1,
author = {B\"{o}hme, Marcel and Falk, Brandon},
title = {Replication Package for "Fuzzing: On the Exponential Cost of Vulnerability Discovery"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.11911287.v1},
abstract = {
    <p>Data, figures, and R scripts to evaluate the data and regenerate the figures.</p>

},
keywords = {empirical study, fuzzing, scalability, simulation study}
}

@software{10.6084/m9.figshare.11944875.v1,
author = {Laaber, Christoph and W\"{u}rsten, Stefan and Gall, Harald C. and Leitner, Philipp},
title = {Replication Package "Dynamically Reconfiguring Software Microbenchmarks: Reducing Execution Time Without Sacrificing Result Quality"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.11944875.v1},
abstract = {
    <p>Full replication package including all scripts and data, as well as the modified JMH version implementing dynamic reconfiguration.</p>

},
keywords = {JMH, microbenchmark configuration, performance testing, software microbenchmarking, software performance}
}

@software{10.6084/m9.figshare.11948619.v1,
author = {Mahajan, Sonal and Abolhassani, Negarsadat and Prasad, Mukul R.},
title = {Data Artifacts for the Paper, "Recommending Stack Overflow Posts for Fixing Runtime Exceptions using Failure Scenario Matching"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.11948619.v1},
abstract = {
    <p>We present the artifacts for our ESEC/FSE 2020 paper, “Recommending Stack Overflow Posts for Fixing Runtime Exceptions using Failure Scenario Matching”. In this artifact package, we present our data repository including the input and output artifacts of our MAESTRO tool. Particularly, the package the includes raw survey data, input benchmark, indexed Stack Overflow posts, scripts for reproducing key results in the paper, configurations used for running competitors, and steps to verify user ratings.</p>

},
keywords = {code search, crowd intelligence, data artifact, runtime exceptions, stack overflow, static analysis}
}

@software{10.6084/m9.figshare.12376931.v1,
author = {Garc\'{\i}a, Sergio and Str\"{u}ber, Daniel and Brugali, Davide and Berger, Thorsten and Pelliccione, Patrizio},
title = {Replication Package for Article "Robotics Software Engineering: A Perspective from the Service Robotics Domain"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.12376931.v1},
abstract = {
    <p>This is a replication package for the article “Robotics Software Engineering: A Perspective from the Service Robotics Domain.”</p>
<p>We provide several artifacts within the same package, divided into two categories: “Interview material” and “Survey material.” The first contains the artifacts related to our interviews, that is, the interviews’ guidelines (pdf format) and our codebook (docx format). The later contains the artifacts related to our online survey, i.e., the questionnaire (pdf format), the raw (anonymized) data in CSV format, and the R script we used to format, analyze, and represent such data.</p>

},
keywords = {challenges, empirical study, interviews, practices, robotics, software engineering, survey}
}

@software{10.6084/m9.figshare.12415622.v2,
author = {B\"{o}hme, Marcel and Man\`{e}s, Valentin J. M. and Cha, Sang Kil},
title = {Source and Results of "Boosting Fuzzer Efficiency An Information-Theoretic Perspective"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.12415622.v2},
abstract = {
    <p>Entropic is an information-theoretic power schedule implemented into LibFuzzer. It boosts performance by changing how weights are assigned to the seeds in the corpus. Seeds revealing more ‘‘information’’ about globally rare features are assigned a higher weight.</p>

},
keywords = {efficiency, entropy, fuzzing, information theory, software testing}
}

@software{10.6084/m9.figshare.12433667.v1,
author = {Nguyen, Tam and Vu, Phong and Nguyen, Tung},
title = {Replication Package for Article: Code Recommendation for Exception Handling},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.12433667.v1},
abstract = {
    <p>We provide a dataset of 750 exception related bugs and fixes manually curated from 21 mobile apps. By providing real-world exception-handling bugs and fixes, we hope to provide the research community a corpus of knowledge that will leverage and accelerate further research in exception handling. We also provide ExAssist, a code recommendation tool for exception handling. ExAssist can predict what types of exception could occur in a given piece of code and recommend proper exception handling code for such exceptions. The tool could be used by programmers when programming or other researchers in exception handling.</p>

},
keywords = {Bug Fixing, Code Recommendation, Exception Handling}
}

@software{10.6084/m9.figshare.12435542.v1,
author = {Bruce, Bobby R. and Zhang, Tianyi and Arora, Jaspreet and Xu, Guoqing Harry and Kim, Miryung},
title = {Replication Package for "JShrink: In-depth Investigation into Debloating Modern Java Applications"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.12435542.v1},
abstract = {
    <p>JShrink is a tool used to reduce the size of (debloat) Java bytecode. The tool was primarily developed to test previously discussed Java bytecode debloating techniques, by incorporating them in a single tool (JShrink) and evaluating their performance on modern Java applications.</p>
<p>The artifact contains the JShrink code, instructions for complilation, scripts to replicate experiment execution, and documentation where appropriate.</p>

},
keywords = {debloating, Java bytecode, reachability analysis, size reduction}
}

@software{10.6084/m9.figshare.12521408.v1,
author = {Chakraborty, Joymallya and Majumder, Suvodeep and Yu, Zhe and Menzies, Tim},
title = {Replication Package for Fairway},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.12521408.v1},
abstract = {
    <p>Source code for the ESEC/FSE paper ‘’Fairway: A Way to Build Fair ML Software’’</p>

},
keywords = {Bias Mitigation, Fairness Metrics, Software Fairness}
}

@software{10.1145/3410252,
author = {Fritsche, Lars and Kosiol, Jens and M\"{o}ller, Adrian and Sch\"{u}rr, Andy and Taentzer, Gabriele},
title = {Artifact Evaluation for 'A Precedence-Driven Approach for Concurrent Model Synchronization Scenarios using Triple Graph Grammars'},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410252},
abstract = {
    <p>This artifact contains the evaluation of our paper ‘A Precedence-Driven Approach for Concurrent Model Synchronization Scenarios using Triple Graph Grammars’ in the form of a virtual machine and a step-by-step guide.</p>

},
keywords = {concurrent model synchronization, eMoflon, model-driven engineering, triple graph grammar}
}

@software{10.1145/3410254,
author = {Ghzouli, Razan and Berger, Thorsten and Johnsen, Einar Broch and Dragule, Swaib and W\k{a}sowski, Andrzej},
title = {Replication package for article: Behavior Trees in Action: A Study of Robotics Applications},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410254},
abstract = {
    <p>In the submitted artifact, you can find the scripts to replicate our paper results under “notebooks” folder. Check the “artifacts-instructions” document on how to run the scripts. Also, you can find the behavior tree models that were analyzed in our paper under “rawdata” folder.</p>

},
keywords = {Behavior tree models, Behavior trees, BehaviorTree.CPP, pyTreesRos}
}

@software{10.1145/3410255,
author = {Kazerounian, Milod and Ren, Brianna M. and Foster, Jeffrey S.},
title = {Replication Package for Sound, Heuristic Type Annotation Inference for Ruby},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410255},
abstract = {
    <p>A Vagrant Virtual Machine which, when built, contains InferDL and the 10 benchmarks we applied it to in the paper. Find specific instructions on how to run InferDL on each benchmark in the submitted Github README.</p>

},
keywords = {dynamic languages, ruby, type inference, types}
}

@software{10.1145/3410256,
author = {van Binsbergen, L. Thomas and Liu, Lu-Chi and van Doesburg, Robert and van Engers, Tom},
title = {eFLINT Haskell Implementation},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410256},
abstract = {
    <p>Haskell implementation of the eFLINT language, providing an interpreter for exploring normative behaviour, testing normative models and interacting with a normative model for runtime verification and simulation</p>

},
keywords = {DSL, eFLINT, executable norm specifications, Haskell, interpreter, REPL}
}

@software{10.1145/3410257,
author = {van Binsbergen, L. Thomas and Verano Merino, Mauricio and Jeanjean, Pierre and van der Storm, Tijs and Combemale, Benoit and Barais, Olivier},
title = {Language implementations and tooling for article: A principled approach to REPL interpreters},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410257},
abstract = {
    <p>This artifact contains the implementation of three case studies: MiniJava, QL, and eFlint, as described in our paper “A principled approach to REPL interpreters”. Moreover, it has a customized version of Bacat\'{a} and the Jupyter notebook platform.</p>

},
keywords = {bacat\'{a}, computational notebooks, domain-specific language, eflint, end-user programming, executable specifications, GDPR, haskell, interactive computing, interpreters, jupyter, language workbenches, literate programming, meta-languages, normative modeling, notebooks, policy enforcement, rascal, REPLs, software language engineering}
}

@software{10.13020/D6QX07,
author = {Kramer, Lucas and Van Wyk, Eric},
title = {Silver artifacts for strategic tree rewriting and monadifiation in attribute grammars},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.13020/D6QX07},
abstract = {
    <p>Silver artifacts for strategic tree rewriting in attribute grammars and the monadification of attribute grammars.</p>

},
keywords = {attribute grammars, monadification, strategic tree rewriting}
}

@software{10.5281/zenodo.3973073,
author = {Fl\"{u}ckiger, Olivier and Chari, Guido and Yee, Ming-Ho and Je\v{c}men, Jan and Hain, Jakob and Vitek, Jan},
title = {Artifact of "Contextual Dispatch for Function Specialization},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3973073},
abstract = {
    <p>This is the artifact to accompany our OOPSLA 2020 submission on “Contextual Dispatch for Function Specialization”. The artifact consists of a virtual machine for the R language, called \v{R}, a suite of benchmarks written in R, as well as an R script to interpret and plot the results.</p>

},
keywords = {benchmark, contextual dispatch, R, specialization, virtual machine, \v{R}}
}

@software{10.5281/zenodo.3975566,
author = {Turo\v{n}ov\'{a}, Lenka and Hol\'{\i}k, Luk\'{a}\v{s} and Leng\'{a}l, Ond\v{r}ej and Saarikivi, Olli and Veanes, Margus and Vojnar, Tom\'{a}\v{s}},
title = {Artifact for the OOPSLA'20 paper "Regex Matching with Counting-Set Automata"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3975566},
abstract = {
    <p>The artifact contains a regular expression matching engine (called CsA) optimized for regular expressions with counters. It also includes other tools—RE2, grep, SRM, and the .NET default regular expression matcher—and provides comparison of CsA with these tools.</p>

},
keywords = {counting-set automata, derivatives, malware detection, regex, regular expression matching}
}

@software{10.5281/zenodo.4032185,
author = {Urban, Caterina and Christakis, Maria and W\"{u}stholz, Valentin and Zhang, Fuyuan},
title = {Perfectly Parallel Fairness Certification of Neural Networks - Artifact},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4032185},
abstract = {
    <p>This is the artifact accompanying the published paper.</p>

},
keywords = {Abstract Interpretation, Fairness, Neural Networks, Static Analysis}
}

@software{10.5281/zenodo.4032401,
author = {Rigger, Manuel and Su, Zhendong},
title = {OOPSLA 20 Artifact for "Finding Bugs in Database Systems via Query Partitioning"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4032401},
abstract = {
    <p>The artifact consists of two main components:</p>
<ol type="1">
<li>SQLancer, the tool which we created and extended, and in which we implemented Ternary Logic Partitioning (TLP), to find all bugs reported in the paper.</li>
<li>A SQLite database with a list of bugs that we reported and additional meta information.</li>
</ol>

},
keywords = {Query Partitioning, SQLancer, Ternary Logic Partitioning}
}

@software{10.5281/zenodo.4032445,
author = {Smits, Jeff and Visser, Eelco},
title = {Replication image for paper: Gradually Typing Strategies},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4032445},
abstract = {
    <p>This is the artifact for the paper Gradually Typing Strategies, accepted at International Conference on Software Language Engineering.</p>
<h3 id="table-of-contents">Table of Contents</h3>
<ul>
<li>Preliminary PDF version of the accepted paper.</li>
<li>VirtualBox image, containing:
<ul>
<li>A linux installation,</li>
<li>Spoofax 2.5.11 (the latest stable Spoofax version) pre-installed,</li>
<li>The StrategoGT Spoofax project, a prototype alternative Stratego language definition with the gradual type system,</li>
<li>The StrategoGT Spoofax tests project with example and test files, including the examples from the paper and the case study from the paper.</li>
</ul></li>
</ul>

},
keywords = {gradual types, gradual typing, Spoofax, Stratego}
}

@software{10.5281/zenodo.4032454,
author = {Zhou, Fangyi and Ferreira, Francisco and Hu, Raymond and Neykova, Rumyana and Yoshida, Nobuko},
title = {Statically Verified Refinements for Multiparty Protocols},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4032454},
abstract = {
    <p>Our paper presents Session<em>, a toolchain for specifying message passing protocols using Refined Multiparty Session Types and safely implementing the distributed endpoint programs in F</em>. This is the accompanying artifact containing the toolchain sources, and examples and sources used in the evaluation of the paper. For a more detailed description, see https://github.com/sessionstar/oopsla20-artifact/blob/master/README.md</p>

},
keywords = {Code Generation, F*, Multiparty Session Types (MPST), Refinement Types}
}

@software{10.5281/zenodo.4032625,
author = {Flanagan, Cormac and Freund, Stephen N.},
title = {Software Artifact for "The Anchor Verifier for Blocking and Non-Blocking Concurrent Software"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4032625},
abstract = {
    <p>This is the software artifact accompanying the paper “The Anchor Verifier for Blocking and Non-Blocking Concurrent Software” published at OOPSLA 2020.</p>

},
keywords = {Anchor verifier, concurrent program verification, reduction, synchronization}
}

@software{10.5281/zenodo.4033001,
author = {Kallas, Konstantinos and Niksic, Filip and Stanford, Caleb and Alur, Rajeev},
title = {Artifact for DiffStream: Differential Output Testing for Stream Processing Programs},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4033001},
abstract = {
    <p>A differential testing library for Apache Flink programs. This artifact is provided as a VM.</p>
<p>The tool and the underlying methodology are described in the OOPSLA paper: DiffStream: Differential Output Testing for Stream Processing Programs</p>
<p>For further information and instructions, see the README after opening the VM.</p>

},
keywords = {Apache Flink, Differential Testing, Runtime Verification, Stream Processing}
}

@software{10.5281/zenodo.4033220,
author = {Verano Merino, Mauricio and van der Storm, Tijs},
title = {Kogi– Block-Based Syntax from Context-Free Grammars},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4033220},
abstract = {
    <p>The current artifact contains Kogi’s implementation, as described in the SLE paper (Block-Based Syntax from Context-Free Grammars). Kogi is a tool for deriving a block-based environment from a context-free grammar specification described in our SLE paper. Kogi uses Google Blockly for rendering block-based environments and Rascal’s concrete syntax formalism for describing context-free grammars. Remarkably, this release contains an optimization to make BBEs more usable by simplifying grammar chain rules.</p>

},
keywords = {app inventor, block-based environments, Blockly, DSLs, google blockly, grammars, language workbenches, Rascal, scratch, syntax, visual languages}
}

@software{10.5281/zenodo.4033367,
author = {Andersen, Leif and Ballantyne, Michael and Felleisen, Matthias},
title = {Artifact: Adding Interactive Visual Syntax to Textual Code},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4033367},
abstract = {
    <p>Many programming problems call for coding geometrical thoughts: tables, hierarchical structures, nests of objects, trees, forests, graphs, and so on. Linear text does not do justice to such thoughts. But, it has been the dominant programming medium for the past and will remain so for the foreseeable future.</p>
<p>This paper proposes a mechanism for conveniently extending textual programming languages with problem-specific visual syntax. It argues the necessity of this language feature, demonstrates the feasibility with a robust prototype, and sketches a design plan for adapting the idea to other languages.</p>

},
keywords = {Domain Specific Language}
}

@software{10.5281/zenodo.4033626,
author = {Pit-Claudel, Cl\'{e}ment},
title = {Artifact for Alectryon paper at SLE 2020 (Untangling Mechanized Proofs)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4033626},
abstract = {
    <p>A virtual machine submitted to SLE 2020’s artifact evaluation committee. Includes a snapshot of the Alectryon repository and datasets and scripts to reproduce the paper’s listings and figures.</p>

},
keywords = {formal verification, literate programming, proof presentation, proofbrowsing}
}

@software{10.5281/zenodo.4034438,
author = {Zhou, Yaoda and Oliveira, Bruno C. d. S. and Zhao, Jinxu},
title = {Revisiting Iso-Recursive Subtyping},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4034438},
abstract = {
    <p>This artifact contains the Coq formulation associated with the paper “Revisiting Iso-Recursive Subtyping”. For details, please refer to readme.</p>

},
keywords = {Coq, Formulation, Iso-recursive types}
}

@software{10.5281/zenodo.4034724,
author = {Zhang, Hengchu and Roth, Edo and Haeberlen, Andreas and Pierce, Benjamin C. and Roth, Aaron},
title = {Replication Package for Article: Testing Differential Privacy with Dual Interpreters},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4034724},
abstract = {
    <p>This package contains the Haskell implementation of DPCheck — an automated testing framework for differential privacy.</p>

},
keywords = {differential privacy, symbolic execution}
}

@software{10.5281/zenodo.4035150,
author = {Coblenz, Michael and Aldrich, Jonathan and Myers, Brad A. and Sunshine, Joshua},
title = {Replication Package for Article: Can Advanced Type Systems Be Usable? An Empirical Study of Ownership, Assets, and Typestate in Obsidian},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4035150},
abstract = {
    <p>The artifact consists of all the materials one would need to replicate the experiment in the paper. It includes a copy of the Obsidian repository as well as all of the materials the experiment participants received. It also includes the data generated by the participants during the study.</p>

},
keywords = {assets, blockchain, empirical studies of programming languages, linear types, Obsidian, ownership, permissions, smart contracts, typestate}
}

@software{10.5281/zenodo.4036303,
author = {Brody, Shaked and Alon, Uri and Yahav, Eran},
title = {A Structural Model for Contextual Code Changes articat},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4036303},
abstract = {
    <p>This artifact contains the PyTorch implementation of the neural network C3PO, along with all the required code and data to reproduce our results of the paper. Our code can be easily extended to other programming languages since the PyTorch network is agnostic to the input programming language. We also provide a with C# extractor for preprocessing the (raw) input code and explain how to implement such an extractor for other input programming languages.</p>

},
keywords = {Edit Completions, Machine Learning, Neural Models of Code}
}

@software{10.5281/zenodo.4037278,
author = {Turcotte, Alexi and Goel, Aviral and K\v{r}ikava, Filip and Vitek, Jan},
title = {Designing Types for R, Empirically (Data, Software, and Experiment Artifact)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4037278},
abstract = {
    <p>This artifact supports the paper “Designing Types for R, Empirically”, which appears at OOPSLA’20. The purpose of this artifact is to showcase the tools used to infer R function types, to showcase contractr, our function-types-as-contracts assertion package for R, and detail and replicate the experiments from the paper. In the artifact, you’ll find a “Getting Started Guide” to quickly sanity check the installation, and a detailed set of instructions on how to use our tracer (Typetracer), contractr, and how to replicate the experiments at whichever scale you like.</p>

},
keywords = {contracts, corpus analysis, dynamic analysis, empirical study, language design, R, type systems, types}
}

@software{10.5281/zenodo.4038334,
author = {Peleg, Hila and Gabay, Roi and Itzhaky, Shachar and Yahav, Eran},
title = {Artifact for: Programming with a Read-Eval-Synth Loop},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4038334},
abstract = {
    <p>Contains the RESL tool and reproduction of empirical experiments.</p>

},
keywords = {program synthesis, resl}
}

@software{10.5281/zenodo.4039085,
author = {Bembenek, Aaron and Greenberg, Michael and Chong, Stephen},
title = {Formulog: Datalog for SMT-Based Static Analysis (OOPSLA 2020 Artifact)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4039085},
abstract = {
    <p>This artifact corresponds to the paper “Formulog: Datalog for SMT-Based Static Analysis” by Aaron Bembenek, Michael Greenberg, and Stephen Chong, which has been accepted at OOPSLA 2020. It includes the Formulog runtime and material for running the empirical experiments described in the paper.</p>

},
keywords = {Datalog, Formulog, SMT solving}
}

@software{10.5281/zenodo.4039224,
author = {Barke, Shraddha and Peleg, Hila and Polikarpova, Nadia},
title = {Source Code Artifact for the paper: Just-in-Time Learning for Bottom-Up Enumerative Synthesis},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4039224},
abstract = {
    <p>The artifact replicates the experiments in the first revision of the paper.</p>

},
keywords = {Domain-specific languages, Probabilistic models, Program Synthesis}
}

@software{10.5281/zenodo.4039826,
author = {Sprenger, Christoph and Klenze, Tobias and Eilers, Marco and Wolf, Felix A. and M\"{u}ller, Peter and Clochard, Martin and Basin, David},
title = {Artifact for "Igloo: Soundly Linking Compositional Refinement and Separation Logic for Distributed System Verification"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4039826},
abstract = {
    <p>This artifact contains the entire Igloo framework formalized in Isabelle/HOL 2020 as well as our case studies (in Isabelle/HOL, VeriFast and Nagini). All necessary tools are pre-installed in the virtual machine.</p>

},
keywords = {distributed systems, formal methods, modeling, program verification, proof assistants}
}

@software{10.5281/zenodo.4040341,
author = {Jeon, Minseok and Lee, Myungho and Oh, Hakjoo},
title = {Learning Graph-based Heuristics for Pointer Analysis without Handcrafting Application-Specific Features},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4040341},
abstract = {
    <p>This is the artifact of our technique Graphick in the paper “Learning Graph-based Heuristics for Pointer Analysis without Handcrafting Application-Specific Features”.</p>
<p>The zip file (Graphick.zip) contains a bootable VirtualBox image (Graphick.ova) with all of the necessary libraries installed. To reproduce the majority of our evaluations, 50 GB of free storage and 32 GB of free memory are required. Using a smaller size of memory may not be able to reproduce the analysis results for the large programs (e.g., briss) used in our evaluation.</p>
<p>The manual pdf file (manual.pdf) in Graphick.zip provides a getting started guide (Section 1) and step by step instructions (Section 2). Please, follow the instructions to reproduce the evaluation results.</p>
<p>Note that this artifact is exactly the version that we submitted to OOPSLA Artifact when our paper was first conditionally accepted; the table numbers do not match with our latest revised paper. To reduce the confusion, we also include the corresponding old version of our paper (Graphick-old.pdf) in the zip file that the table numbers are matched. For the newly added evaluations of our final paper, we will upload a new implementation that reproduces all the evaluations.</p>

},
keywords = {Context sensitivity, Data-driven static analysis, Heap abstraction, Machine learning for program analysis, Pointer analysis}
}

@software{10.5281/zenodo.4043041,
author = {Mukherjee, Suvam and Deligiannis, Pantazis and Biswas, Arpita and Lal, Akash},
title = {Learning-Based Controlled Concurrency Testing},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4043041},
abstract = {
    <p>Concurrency bugs are notoriously hard to detect and reproduce. Controlled concurrency testing (CCT) techniques aim to offer a solution, where a scheduler explores the space of possible interleavings of a concurrent program looking for bugs. Since the set of possible interleavings is typically very large, these schedulers employ heuristics that prioritize the search to “interesting” subspaces. However, current heuristics are typically tuned to specific bug patterns, which limits their effectiveness in practice.</p>
<p>In this artifact, we present QL, a learning-based CCT framework where the likelihood of an action being selected by the scheduler is influenced by earlier explorations. We leverage the classical Q-learning algorithm to explore the space of possible interleavings, allowing the exploration to adapt to the program under test, unlike previous techniques. We have implemented and evaluated QL on a set of microbenchmarks, complex protocols, as well as production cloud services. In our experiments, we found QL to consistently outperform the state-of-the-art in CCT.</p>

},
keywords = {concurrency, model checking, reinforcement learning, testing}
}

@software{10.5281/zenodo.4043646,
author = {Marntirosian, Koar and Schrijvers, Tom and Oliveira, Bruno C. d. S. and Karachalias, Georgios},
title = {Resolution as Intersection Subtyping via Modus Ponens},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4043646},
abstract = {
    <p>This artifact consists of supplementary material for the article “Resolution as Intersection Subtyping via Modus Ponens”.</p>
<p>It contains a prototype implementation of λiMP, a mechanization of the metatheory of our calculus (declarative) and a mechanization of the metatheory for the subtyping algorithm of our calculus.</p>

},
keywords = {coherence, family polymorphism, intersection types, modus ponens, nested composition, resolution}
}

@software{10.5281/zenodo.4046893,
author = {Castro-Perez, David and Yoshida, Nobuko},
title = {CAMP: Cost-Aware Multiparty Session Protocols (artifact)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4046893},
abstract = {
    <p>This is the artifact for the paper ‘CAMP: Cost-Aware Multiparty Session Protocols’. The artifact comprises:</p>
<ul>
<li>A library for specifying cost-aware multiparty protocols.</li>
<li>The raw data used for comparing the cost models with real execution costs.</li>
<li>The cost-aware protocol specifications of the benchmarks that we studied.</li>
</ul>
<p>The library for specifying cost-aware protocols also provides functions for extracting cost equations from them, and for estimating recursive protocol latencies (i.e.&nbsp;average cost per protocol iteration). We provide a script for extracting cost equations, and instantiating them using the parameters used in the paper.</p>

},
keywords = {cost models, message optimisations, parallel programming, session types}
}

@software{10.5281/zenodo.4048298,
author = {Griesemer, Robert and Hu, Raymond and Kokke, Wen and Lange, Julien and Taylor, Ian Lance and Toninho, Bernardo and Wadler, Philip and Yoshida, Nobuko},
title = {Featherweight Go (Artifact)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4048298},
abstract = {
    <p>This paper presents Featherweight Go (FG) and Featherweight Generic Go (FGG), a core calculus of Go and a proposal for extending it with generics. The calculi are in the same vein as Featherweight Java (FJ), but where Featherweight Generic Java (FGJ) was translated into FJ via erasure, FGG translates into FG via monomorphisation (which is also formalised). The two calculi are proven sound using the normal progress and preservation arguments. Additionally a bisimulation is shown to exist between a FGG program and its monomorphisation (if it exists); in other words that monomorphisation preserves the semantics of the program.</p>
<p>The artifact consists of an implementation of type checkers and interpreters for FG and FGG, as well as a monomorphisation procedure (including the check if it is possible). It includes the examples from the paper, and a comparison using the Go compiler as reference. Type preservation and bisimulation for these programs are tested dynamically. Additionally, the same is tested for all well-typed programs up to a certain size (which are generated in a manner similar to property-based testing).</p>

},
keywords = {Generics, Go, Monomorphisation}
}

@software{10.5281/zenodo.4051784,
author = {Majumdar, Rupak and Yoshida, Nobuko and Zufferey, Damien},
title = {Multiparty Motion Coordination: From Choreographies to Robotics Programs (Artifact)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4051784},
abstract = {
    <p>Software artifact for the paper “Multiparty Motion Coordination: From Choreographies to Robotics Programs” submitted to OOPSLA 2020</p>
<p>The artifact has been packaged into a virtual machine (Ubuntu 20.04). The username and password for the virtual machine is “pgcd”.</p>

},
keywords = {Message-passing, Motion Primitives, Robotics, Session Types and Choreography, Verification}
}

@software{10.5281/zenodo.4059797,
author = {Lagouvardos, Sifis and Grech, Neville and Tsatiris, Ilias and Smaragdakis, Yannis},
title = {Precise Static Modeling of Ethereum "Memory" (artifact)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4059797},
abstract = {
    <p>Our artifact is bundled as a Docker image, containing the gigahorse decompiler, as well as our client analyses for tainted ERC20 Token <code>transfer</code>, Gas of Fallback Functions, Repeated Calls. The artifact also contains the contract sources and bytecodes for the contracts that were manually inspected for the evaluation of our paper.</p>

},
keywords = {ethereum, EVM, static analysis}
}

@software{10.5281/zenodo.4060109,
author = {Kabir, Ifaz and Li, Yufeng and Lhot\'{a}k, Ond\v{r}ej},
title = {ιDOT: A DOT Calculus with Object Initialization (Coq Formalization)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4060109},
abstract = {
    <p>This is the artifact for our OOPSLA’20 paper that presents ιDOT, a Dependent Object Types calculus with a type and effect system to ensure safe initialization of objects. This artifact contains the proof of type safety for the ιDOT calculus, formalized in the Coq proof assistant.</p>

},
keywords = {Coq, dependent object types, DOT, effect systems, iDOT, initialization, Scala, type safety, type soundness, type systems}
}

@software{10.5281/zenodo.4060132,
author = {Holtzen, Steven and Van den Broeck, Guy and Millstein, Todd},
title = {Software Artifact for: Scaling Exact Inference for Discrete Probabilistic Programs},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4060132},
abstract = {
    <p>This artifact contains a working copy of the software described in the paper, along with a guide for reproducing the key experimental results.</p>

},
keywords = {probabilistic programming}
}

@software{10.5281/zenodo.4060186,
author = {Bartell, Sean and Dietz, Will and Adve, Vikram S.},
title = {Artifact for Guided Linking: Dynamic Linking Without the Costs},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4060186},
abstract = {
    <p>Artifact for the paper “Guided Linking: Dynamic Linking Without the Costs”, conditionally accepted to OOPSLA 2020. This is the accepted version of the artifact, but the final version of the paper will include major terminology changes and improvements to the evaluation (such as Profile-Guided Optimization). An updated artifact, suitable for reproducing the results in the final paper, will be available at a later date.</p>

},
keywords = {compiler, dynamic linking, guided linking, ld.so, llvm, nixos, nixpkgs, optimization, shared libraries}
}

@software{10.5281/zenodo.4061106,
author = {Xiang, Tongtong and Luo, Jeff Y. and Dietl, Werner},
title = {PUnits: Precise Inference of Expressive Units of Measurement Types},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4061106},
abstract = {
    <p>PUnits is a pluggable type system for expressive units of measurement types and a precise, whole-program inference approach for these types. It can be used in three modes: (1) modularly check the correctness of a program, (2) ensure a possible unit typing exists, (3) annotate a program with units. Annotation mode allows human inspection and is essential since having a valid typing does not guarantee that the inferred specification expresses design intent. PUnits is the first units type system with this capability. This artifact is a docker image containing all required software and benchmarks to reproduce the results of the paper.</p>

},
keywords = {Dimensional analysis, Pluggable type system, Scientific computing, Type inference, Units of measurements}
}

@software{10.5281/zenodo.4061655,
author = {Fl\"{u}ckiger, Olivier and W\"{a}lchli, Andreas and Krynski, Sebasti\'{a}n and Vitek, Jan},
title = {Artifact of "Sampling Optimized Code for Type Feedback"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4061655},
abstract = {
    <p>This is the artifact to accompany our DLS 2020 submission on “Sampling Optimized Code for Type Feedback”. The artifact consists of a virtual machine for the R language, called \v{R}, a suite of benchmarks written in R, as well as an R script to interpret and plot the results. The \v{R} VM is included in source format with build instruction, and a compiled version is attached in the form of an OCI compliant image in image.tgz. See the README in artifact.tgz for instructions.</p>

},
keywords = {sampling profiler, speculative optimizations, virtual machine}
}

@software{10.5281/zenodo.4063694,
author = {Sotiropoulos, Thodoris and Chaliasos, Stefanos and Mitropoulos, Dimitris and Spinellis, Diomidis},
title = {Replication Package for Article: A Model for Detecting Faults in Build Specifications},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4063694},
abstract = {
    <p>This artifact contains the source code of the system, namely BuildFS, described in the article “A Model for Detecting Faults in Build Specifications”. BuildFS was designed to detect faults in Make and Gradle build specifications. In addition to that, the artifact includes all the scripts used to re-run the evaluation of BuildFS as described in the article. Specifically, these scripts apply BuildFS to 612 open-source Make and Gradle projects taken from the Github and Debian ecosystems, and evaluate BuildFS in terms of</p>
<ul>
<li>Effectiveness</li>
<li>Efficiency</li>
<li>Comparison with the-state-of-the-art</li>
</ul>

},
keywords = {Build, Fault, Gradle, Make}
}

@software{10.5281/zenodo.4067001,
author = {Ballantyne, Michael and King, Alexis and Felleisen, Matthias},
title = {Artifact for OOPSLA '20 "Macros For Domain-Specific Languages"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4067001},
abstract = {
    <p>This artifact contains the library, case studies, and examples presented in the paper.</p>

},
keywords = {extensible domain specific languages, hygiene, macros}
}

@software{10.5281/zenodo.4068065,
author = {Rouvoet, Arjen and van Antwerpen, Hendrik and Bach Poulsen, Casper and Krebbers, Robbert and Visser, Eelco},
title = {Knowing when to Ask: MiniStatix implementation and case studies},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4068065},
abstract = {
    <p>We implement the small-step operational semantics of the core constraint language of Statix in Haskell and present ‘MiniStatix’. We evaluate this semantics using three case studies specifying name binding aspects of Java, Scala and Rust.</p>

},
keywords = {case study, Haskell, MiniStatix, Name binding, Statix}
}

@software{10.5281/zenodo.4081681,
author = {Geisler, Dietrich and Yoon, Irene and Kabra, Aditi and He, Horace and Sanders, Yinnon and Sampson, Adrian},
title = {Replication Package for Article: Geometry Types for Graphics Programming},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4081681},
abstract = {
    <p>The purpose of this package is to replicate the results of the paper “Geometry Types for Graphics Programming” and provide a research compiler from the Gator language to GLSL. This artifact includes, in a VM, the results included with the above paper, the tools for replicating these results, and a work-in-progress compiler from Gator to GLSL. The intent of this package is to help with replication and make the Gator language available and useable for those interested.</p>

},
keywords = {Compilers, Graphics Programming, Language Design, Programming Languages}
}

@software{10.5281/zenodo.4088252,
author = {Atkinson, Eric and Carbin, Michael},
title = {Artifact for "Programming and Reasoning with Partial Observability"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4088252},
abstract = {
    <p>This is the artifact that accompanies the OOPSLA 2020 paper “Programming and Reasoning with Partial Observability”.</p>

},
keywords = {partial observability, uncertainty}
}

@software{10.5281/zenodo.4139038,
author = {Perianez-Pascual, Jorge and Rodriguez-Echeverria, Roberto and Burgue\~{n}o, Loli and Cabot, Jordi},
title = {Towards the Optical Character Recognition of DSLs - Artifact (img2DSL)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4139038},
abstract = {
    <p>img2DSL is an image recognition toolkit designed to study how Optical Character Recognition can be applied to images that contain DSL snippets. Using the Object Constraint Language (OCL) as an example of textual DSL and given a dataset of Ecore models (and its OCL expressions), this toolkit encodes the OCL expressions into images and tests how different strategies improve the default OCR quality. In this project we use Tesseract as OCR engine and the different strategies are different OCR models and custom algorithms.</p>
<p>In order to evaluate the toolkit and the quality of its different strategies, we load the recognized expressions in the USE tool to measure of how many expressions are valid after the recognition</p>

},
keywords = {domain-specific-languages, optical character recognition, text recognition}
}

@software{10.5281/zenodo.4139829,
author = {Oeyen, Bjarno and Van den Vonder, Sam and De Meuter, Wolfgang},
title = {Reactive Sorting Networks (Supplementary Material)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4139829},
abstract = {
    <p>Supplementary material for the paper titled “Reactive Sorting Networks”, published in the Proceedings of the 7th ACM SIGPLAN International Workshop on Reactive and Event-Based Languages and Systems, REBLS@SPLASH 2020.</p>

},
keywords = {Higher-Order Programming, Reactive Programming, Reactor Composition, Sorting Networks}
}

@software{10.5281/zenodo.4160965,
author = {Rossouw, Christoff and Fischer, Bernd},
title = {Software Artifact for article: Test Case Generation from Context-Free Grammars using Generalized Traversal of LR-Automata},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4160965},
abstract = {
    <p>Python scripts used to reproduce results from paper. Output files from evaluation and grammars used.</p>

},
keywords = {mutation testing, push-down automata, test case generation}
}

@software{10.5281/zenodo.4240798,
author = {de Medeiros, S\'{e}rgio Queiroz and Olarte, Carlos},
title = {RESPEG: Rewriting Semantics for PEGs},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4240798},
abstract = {
    <p>We give a rewriting logic semantics for Paring Expression Grammars (PEGs) and implement such rewrite theory in Maude (a rewriting engine). The proposed rewrite theory formalizes the notion of local and global cuts that may help the designer of the grammar to control the backtracks during parsing.</p>

},
keywords = {Parsing Expression Grammars, Rewriting logic}
}

@software{10.5281/zenodo.4244899,
author = {Coulon, Fabien and Auvolat, Alex and Combemale, Benoit and Bromberg, Y\'{e}rom-David and Ta\"{\i}ani, Fran\c{c}ois and Barais, Olivier and Plouzeau, No\"{e}l},
title = {Artifact for the Paper: Modular and distributed IDE},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4244899},
abstract = {
    <p>This artifact includes Eclipse plugins allowing to generates microservices from DSL specifications, the necessary to setup a local Kubernetes cluster, and a Web application embedding a configurator to manage the deployment of the microservices on the local cluster and embedding a program editor interacting with the microservices.</p>

},
keywords = {Generative approach, IDE, Microservice}
}

@software{10.1145/3410258,
author = {Kim, Jinwoo and Hu, Qinheping and D'Antoni, Loris and Reps, Thomas},
title = {Software artifact for paper: Semantics-Guided Synthesis},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410258},
abstract = {
    <p>This artifact is the software repository for the 2021 POPL paper ‘Semantics-Guided Synthesis’. It consists of the tool Messy described in the paper, which converts SemGuS problems into solvable CHCs, as well as the benchmarks used in the paper.</p>
<p>This version of the tool is a prototype, and does not contain a separate front-end; SemGuS problems and benchmarks are written in our own DSL.</p>

},
keywords = {Program Synthesis, Semantics-Guided Synthesis (SemGuS), Unrealizability}
}

@software{10.1145/3410259,
author = {Rosemann, Julian and Moll, Simon and Hack, Sebastian},
title = {Docker Image for Quantitative Evaluation},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410259},
abstract = {
    <p>This is a x86_64 docker image. It contains the source code, pre-built binaries and evaluation data sets used in the quantative evaluation of the paper “An Abstract Interpretation for SPMD Divergence on Reducible Control Flow Graphs”. SPEC ACCEL is not included in the image for licensing issues but there are instructions to copy your own version of it into the docker container.</p>

},
keywords = {Analysis, LLVM, RV}
}

@software{10.1145/3410260,
author = {de Vilhena, Paulo Em\'{\i}lio and Pottier, Fran\c{c}ois},
title = {Artifact for A Separation Logic for Effect Handlers},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410260},
abstract = {
    <p>This artifact contains the Coq/Iris proofs that accompany the paper “A Separation Logic for Effect Handlers”.</p>

},
keywords = {Coq, effect handlers, Iris, program verification, separation logic}
}

@software{10.1145/3410262,
author = {Doenges, Ryan and Arashloo, Mina Tahmasbi and Bautista, Santiago and Chang, Alexander and Ni, Newton and Parkinson, Samwise and Peterson, Rudy and Solko-Breslin, Alaia and Xu, Amanda and Foster, Nate},
title = {Artifact for "Petr4: Formal Foundations for P4 Data Planes"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410262},
abstract = {
    <p>This artifact includes source code and tests for Petr4. For more information visit https://cornell-netlab.github.io/petr4/, where a full VM is also available, or check out the gh-pages branch of the artifact.</p>

},
keywords = {p4}
}

@software{10.1145/3410263,
author = {Barri\`{e}re, Aur\`{e}le and Blazy, Sandrine and Fl\"{u}ckiger, Olivier and Pichardie, David and Vitek, Jan},
title = {CoreJIT: a Replication Package for Article "Formally Verified Speculation and Deoptimization in a JIT Compiler "},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410263},
abstract = {
    <p>This is the development of CoreJIT, a formally verified JIT compiler.</p>

},
keywords = {just-in-time compilation, verified compilation}
}

@software{10.1145/3410264,
author = {Vassena, Marco and Disselkoen, Craig and Gleissenthall, Klaus von and Cauligi, Sunjay and K\i{}c\i{}, Rami G\"{o}khan and Jhala, Ranjit and Tullsen, Dean and Stefan, Deian},
title = {Replication package for article: Automatically Eliminating Speculative Leaks from Cryptographic Code with Blade},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410264},
abstract = {
    <p>See README.pdf included in the artifact for reviewer instructions. Included are the instructions and the VM image representing the artifact. Alternately, to set up the software on your own machine, see https://github.com/PLSysSec/blade-benchmarks/blob/master/README.md.</p>

},
keywords = {Constant-time, Lucet, Spectre, Speculative execution, WebAssembly}
}

@software{10.1145/3410265,
author = {Choudhury, Pritam and Eades III, Harley and Eisenberg, Richard A. and Weirich, Stephanie},
title = {Artifact for "A Graded Dependent Type System with a Usage-Aware Semantics"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410265},
abstract = {
    <p>This artifact contains Coq proofs for the type soundness proof described in Section 7.2.</p>

},
keywords = {dependent types, graded modal types, type soundness}
}

@software{10.1145/3410266,
author = {Sherman, Benjamin and Michel, Jesse and Carbin, Michael},
title = {Implementation of $\lambda_S$: Computable Semantics for Differentiable Programming with Higher-Order Functions and Datatypes},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410266},
abstract = {
    <p>This is the artifact for the paper “<span class="math inline"><em>λ</em><sub><em>S</em></sub></span>: Computable semantics for differentiable programming with higher-order functions and datatypes”. This repository contains the implementation of <span class="math inline"><em>λ</em><sub><em>S</em></sub></span> as an embedded language within Haskell. We name this library “smooth”.</p>

},
keywords = {Automatic Differentiation, Constructive Analysis, Diffeological Spaces}
}

@software{10.1145/3410267,
author = {Margalit, Roy and Lahav, Ori},
title = {Rocker},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410267},
abstract = {
    <p>Robustness Checker</p>

},
keywords = {C++11, C/C++11, C11, D, RC20, robustness, weak memory models}
}

@software{10.1145/3410268,
author = {Barthe, Gilles and Chadha, Rohit and Krogmeier, Paul and Sistla, A. Prasad and Viswanathan, Mahesh},
title = {Software Artifact for Deciding Accuracy of Differential Privacy Schemes},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410268},
abstract = {
    <p>This artifact is a tool for verifying accuracy of differential privacy mechanisms. The main code is written in C++ and some auxiliary functions are written in OCaml. Running the tool requires Mathematica. The tool’s code consists of two parts. The first part reads a program from a file and generates a table that captures the program’s I/O behavior. The second part analyzes the program and uses the I/O table to write a Mathematica script that contains verification conditions for accuracy. Lastly, the tool runs Mathematica on the generated script.</p>

},
keywords = {accuracy, decidability, differential privacy, logic, verification}
}

@software{10.5281/zenodo.4067194,
author = {Lim, Jay P. and Aanjaneya, Mridul and Gustafson, John and Nagarakatte, Santosh},
title = {Artifact for the paper: An Approach to Generate Correctly Rounded Math Libraries for New Floating Point Variants},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4067194},
abstract = {
    <p>RLibm is a math library generator and a library that provides the correctly rounded result for all inputs. Currently, RLibm supports a number of elementary functions for bfloat16, posit16, and float representations.</p>

},
keywords = {elementary functions, floating point, polynomial approximation, posits}
}

@software{10.5281/zenodo.4068078,
author = {Gregersen, Simon Oddershede and Bay, Johan and Timany, Amin and Birkedal, Lars},
title = {Mechanized Logical Relations for Termination-Insensitive Noninterference (Artifact)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4068078},
abstract = {
    <p>A mechanized logical relations model for an expressive information-flow control type system with recursive types, existential types, label polymorphism, and impredicative type polymorphism for a higher-order programming language with higher-order state. The semantic model of the type system can be used to show that well-typed programs satisfy termination-insensitive noninterference but also to show that composing syntactically well-typed and syntactically ill-typed—but semantically sound—components is secure.</p>
<p>The model is defined using the Iris program logic framework. To capture termination-insensitivity, we make us of our theory of Modal Weakest Precondition. All of the theory and examples are formalized in the Coq proof assistant.</p>

},
keywords = {Coq, Information-Flow Control, Iris, Logical Relations, Program Logics}
}

@software{10.5281/zenodo.4071954,
author = {Rouvoet, Arjen and Krebbers, Robbert and Visser, Eelco},
title = {Intrinsically Typed Compilation with Nameless Labels: Virtual Machine},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4071954},
abstract = {
    <p>We present the library for separation logic, the model of nameless labels, and the implementation of the compiler backend in Agda.</p>

},
keywords = {Agda, Co-de-Bruijn, Compilation, Intrinsically-Typed, Labels, Proof relevant, Separation Logic}
}

@software{10.5281/zenodo.4072013,
author = {Willsey, Max and Nandi, Chandrakana and Wang, Yisu Remy and Flatt, Oliver and Tatlock, Zachary and Panchekha, Pavel},
title = {Artifact for "Fast and Extensible Equality Saturation"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4072013},
abstract = {
    <p>https://zenodo.org/record/4072013</p>

},
keywords = {e-graphs, equality saturation}
}

@software{10.5281/zenodo.4074932,
author = {Moy, Cameron and Nguy\~{\^e}n, Ph\'{u}c C. and Tobin-Hochstadt, Sam and Van Horn, David},
title = {Artifact: Corpse Reviver},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4074932},
abstract = {
    <p>This artifact contains a virtual machine appliance containing the SCV-CR tool and accompanying utilities for reproducing the experimental results reported in the paper.</p>

},
keywords = {contract verification, gradual typing, Typed Racket}
}

@software{10.5281/zenodo.4075076,
author = {Jacobs, Jules},
title = {Paradoxes of Probabilistic Programming: Artifact},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4075076},
abstract = {
    <p>A Julia implementation of the probabilistic programming DSL using infinitesimal probabilities, as described in the associated paper.</p>

},
keywords = {Probabilistic programming}
}

@software{10.5281/zenodo.4118715,
author = {Farka, Franti\v{s}ek and Nanevski, Aleksandar and Banerjee, Anindya and Delbianco, Germ\'{a}n Andr\'{e}s and F\'{a}bregas, Ignacio},
title = {On Algebraic Abstractions for Concurrent Separation Logics (artefact)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4118715},
abstract = {
    <p>The artefact contains Coq sources of the developments presented in the paper. The artefact supports the developments in both a theoretical and practical way. First, it provides a complete bottom-up mechanization of partial commutative monoids (PCM), separating relations, PCM morphisms, and the related constructions. The artefact formalizes all the concepts defined in the paper, Secondly, the artifact demonstrate practical utilisation of the theory of PCMs. Using FCSL (Nanevski et al, 2019) as the opaque type theory, the artefact provides mechanical verification of Ticket lock, the running example developed in the paper. The artefact also contains additional examples that the main body submission does not discuss.</p>

},
keywords = {Coq, Hoare/Separation Logics, Program Logics for Concurrency}
}

@software{10.5281/zenodo.4123035,
author = {Kokologiannakis, Michalis and Kaysin, Ilya and Raad, Azalea and Vafeiadis, Viktor},
title = {Replication Package for "PerSeVerE: Persistency Semantics for Verification under Ext4"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4123035},
abstract = {
    <p>This is the artifact accompanying the paper “PerSeVerE: Persistency Semantics for Verification under Ext4” which is accepted in POPL’21.</p>
<p>We consider our paper’s artifact to be the set of benchmarks and stress tests we used in the paper, as well as the results we got by running a particular version of Persevere (and its naive counterparts) on the benchmarks set. We do not consider the artifact of the paper to be Persevere itself, as it will evolve over time, and the results obtained by running the same benchmarks may differ in the future.</p>
<p>We have made Persevere publicly available on Github (https://github.com/MPI-SWS/genmc), as part of the GenMC tool. For any bugs, comments, or feedback regarding Persevere, please do not hesitate to contact us.</p>

},
keywords = {Filesystems, Persistency, Software Model Checking, Weak Memory Models}
}

@software{10.5281/zenodo.4139601,
author = {Gondelman, L\'{e}on and Gregersen, Simon Oddershede and Nieto, Abel and Timany, Amin and Birkedal, Lars},
title = {Distributed Causal Memory: Modular Specification and Verification in Higher-Order Distributed Separation Logic (Artifact)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4139601},
abstract = {
    <p>A specification and verification of an implementation of a causally-consistent distributeddatabase that supports modular verification of full functional correctness properties of clients and servers. We specify and reason about the causally-consistent distributed database in Aneris, a higher-order distributed separation logic for an ML-like programming language with network primitives for programming distributed systems. We demonstrate that our specifications are useful, by proving the correctness of small, but tricky,synthetic examples involving causal dependency and by verifying a session manager library implemented on top of the distributed database. We use Aneris’s facilities for modular specification and verification to obtain a highly modular development, where each component is verified in isolation, relying only on the specifications(not the implementations) of other components. We have used the Coq formalization of the Aneris logic to formalize all the results presented in the paper in the Coq proof assistant.</p>

},
keywords = {causal consistency, concurrency, Coq, Distributed systems, formal verification, higher-order logic, Iris, separation logic}
}

@software{10.5281/zenodo.4141684,
author = {Jones, Eddie and Ramsay, Steven},
title = {Intensional Datatype Refinement Checker},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4141684},
abstract = {
    <p>The Intensional Datatype Refinement tool is a GHC plugin that checks whether it is possible to type the program according to the refinement type system specified in our paper. This provides a guarantee of pattern-match safety but the complexity of inference is only linear in the size of the program. In addition to reporting a yes/no-instance, it also enable the user to explore a set-constraint style analysis of their program.</p>

},
keywords = {higher-order program verification, refinement types}
}

@software{10.5281/zenodo.4161748,
author = {Angiuli, Carlo and Cavallo, Evan and M\"{o}rtberg, Anders and Zeuner, Max},
title = {Internalizing Representation Independence with Univalence - Artifact},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4161748},
abstract = {
    <p>This artifact is a Docker image containing the Cubical Agda code for the paper “Internalizing Representation Independence with Univalence”.</p>
<p>The image also includes the source code of Agda (2.6.2 prerelease) and the agda/cubical standard library, which are both needed to build our code.</p>

},
keywords = {Cubical Type Theory, Higher Inductive Types, Proof Assistants, Representation Independence, Univalence}
}

@software{10.5281/zenodo.4246174,
author = {Jacobs, Koen and Timany, Amin and Devriese, Dominique},
title = {Artifact POPL21 - Fully Abstract from Static to Gradual},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4246174},
abstract = {
    <p>This artifact contains a Coq/Iris proof of the fact that the embedding of STLCmu (the simply typed lambda calculus with equirecursive types) into GTLCmu (its gradualization) is fully abstract. It accompanies the paper “Fully abstract from Static to Gradual”.</p>

},
keywords = {Coq, full abstraction, gradual typing, GTLC}
}

@software{10.5281/zenodo.4265963,
author = {Ahman, Danel and Pretnar, Matija},
title = {Software artefact for the POPL 2021 paper "Asynchronous Effects"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4265963},
abstract = {
    <p>This is a software artefact for the POPL 2021 paper:</p>
<p>Danel Ahman and Matija Pretnar. 2021. Asynchronous Effects. Proc. ACM Program. Lang. 5, POPL, Article 24 (January 2021), 28 pages.</p>
<p>This software artefact comprises:</p>
<ul>
<li>an Agda formalisation of the core calculus presented in the POPL submission;</li>
<li>a prototype implementation of the core calculus in OCaml, called \AE{}ff; and</li>
<li>a Docker image that includes all necessary dependencies to use the artefact.</li>
</ul>
<p>For more information about the artefact and how to use it, see the README.md file in the attached archive.</p>

},
keywords = {Algebraic effects, Asynchrony, Concurrency, Interrupt handling, Signals}
}

@software{10.5281/zenodo.4268196,
author = {Mathur, Umang and Pavlogiannis, Andreas and Viswanathan, Mahesh},
title = {Replication package for article: Optimal Prediction of Synchronization Preserving Races},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4268196},
abstract = {
    <p>The artifact contains the implementation of the race detection algorithm presented in the above paper, as well as the experimental evaluation of the algorithm against other algorithms in the literature</p>

},
keywords = {complexity, concurrency, dynamic analysis, race detection}
}

@software{10.5281/zenodo.4268852,
author = {Arora, Jatin and Westrick, Sam and Acar, Umut A.},
title = {Replication Instructions for Article: Provably Space Efficient Parallel Functional Programming},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4268852},
abstract = {
    <p>Replication of the results presented in the article: Provably Space Efficient Parallel Functional Programming</p>

},
keywords = {disentanglement, functional programming, memory management, parallel computing}
}

@software{10.5281/zenodo.4268896,
author = {Hietala, Kesha and Rand, Robert and Hung, Shih-Han and Wu, Xiaodi and Hicks, Michael},
title = {A Verified Optimizer for Quantum Circuits -- Software Artifact},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4268896},
abstract = {
    <p>Artifact virtual machine for “A Verified Optimizer for Quantum Circuits.” Paper available at https://arxiv.org/pdf/1912.02250.pdf. See https://github.com/inQWIRE/SQIR/tree/POPL2021 for information on running our tool.</p>

},
keywords = {Certified Compilation, Circuit Optimization, Formal Verification, Programming Languages, Quantum Computing}
}

@software{10.5281/zenodo.4269171,
author = {Lee, Woosuk},
title = {Artifacts for "Combining the Top-down Propagation and Bottom-up Enumeration for Inductive Program Synthesis"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4269171},
abstract = {
    <p>This artifact includes all things necessary􏰛 for reproducing experimental results in the paper “Combining the Top-down Propagation and Bottom-up Enumeration for Inductive Program Synthesis”. The source code for Duet, which is the tool presented in the paper, and the other baseline synthesizers (EUSolver, CVC4, and Euphony), and the scripts for running the experiments are contained.</p>

},
keywords = {Programming-by-example, Syntax-guided synthesis}
}

@software{10.5281/zenodo.4270313,
author = {Chen, Chao-Hong and Sabry, Amr},
title = {Artifact for A Computational Interpretation of Compact Closed Categories: Reversible Programming with Negative and Fractional Types},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4270313},
abstract = {
    <p>This artifact contains formalization of the abstract machines, interpreters, examples and proof of theorems in the paper.</p>

},
keywords = {Agda}
}

@software{10.5281/zenodo.4271370,
author = {Cockx, Jesper and Tabareau, Nicolas and Winterhalter, Th\'{e}o},
title = {Coq formalisation for The Taming of the Rew},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4271370},
abstract = {
    <p>Fork of the MetaCoq repository extended with rewrite rules. The README explains how to build and what files are important with respect to the paper “The Taming of the Rew: A Type Theory with Computational Assumptions”.</p>

},
keywords = {coq, foramlisation, metacoq, proof, rewrite rules}
}

@software{10.5281/zenodo.4273768,
author = {Reynaud, Alban and Scherer, Gabriel and Yallop, Jeremy},
title = {Artifact accompanying the paper "A practical mode system for recursive definitions".},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4273768},
abstract = {
    <p>The paper studies a specific feature of some functional programming languages, namely recursive definitions of things that are not immediate functions (recursive records, functions preceded by local declarations or various other language constructs, etc.). We propose a new system of inference rules to characterize valid definitions, to avoid runtime errors when evaluating the definitions. An algorithm can be directly derived from our inference rules to check the validity of recursive definitions. The check has been integrated in the OCaml compiler – more precisely, the implementation work for the OCaml compiler led to the present paper.</p>
<p>The artifact provides evidence for the claims in the paper, principally:</p>
<p>Do the formal system presented in the paper and the implementation in OCaml compiler correspond to each other?</p>
<p>The artifact contains various versions of the OCaml compiler (and compilers for some other languages discussed in the paper), instructions for confirming that our system fixes the bugs claimed in the paper, examples that illustrate how the system works, references to the parts of the implementation that correspond to parts of the formal system, and evidence for the empirical claims that the paper makes about the prevalence and character of recursive value definitions in existing programs.</p>

},
keywords = {call-by-value, functional programming, ML, OCaml, recursion, semantics, types}
}

@software{10.5281/zenodo.4283027,
author = {Georges, A\"{\i}na Linn and Gu\'{e}neau, Arma\"{e}l and Van Strydonck, Thomas and Timany, Amin and Trieu, Alix and Huyghebaert, Sander and Devriese, Dominique and Birkedal, Lars},
title = {Artifact of Conference Paper: Efficient and Provable Local Capability Revocation using Uninitialized Capabilities},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4283027},
abstract = {
    <p>The artifact is composed of two parts. The first part is the Iris formalization. It contains all the definitions and proofs presented in the paper, mechanized in the Iris framework of Coq. The second part of the artifact corresponds to a CHERI implementation of uninitialized capabilities. The CHERI implementation has been extended with uninitialized capabilities.</p>

},
keywords = {CHERI, Coq, Iris}
}

@software{10.5281/zenodo.4284088,
author = {Silver, Lucas and Zdancewic, Steve},
title = {Dijkstra Monads Forever: Termination-Sensitive Specifications for Interaction Trees},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4284088},
abstract = {
    <p>This artifact contains formal definitions and machine checked proofs for the objects and theorems presented in the paper.</p>

},
keywords = {Algebraic Effects, Coinduction, Coq, Monads, Specifications}
}

@software{10.5281/zenodo.4323505,
author = {Muller, Stefan K. and Hoffmann, Jan},
title = {RaCUDA software and Coq Proofs for "Modeling and Analyzing Evaluation Cost of CUDA Kernels"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4323505},
abstract = {
    <p>Software and proof artifacts for the POPL 2021 paper “Modeling and Analyzing Evaluation Cost of CUDA Kernels”. The artifact is packaged as a virtual machine image in ova format.</p>

},
keywords = {CUDA, performance analysis, program logics, resource-aware type system, thread-level parallelism}
}

@software{10.1145/3410270,
author = {Laurent, Olivier},
title = {Coq Formalization of: An Anti-Locally-Nameless Approach to Formalizing Quantifiers},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410270},
abstract = {
    <p>Provides Coq v8.12.0 formalization files corresponding to the results of the paper “An Anti-Locally-Nameless Approach to Formalizing Quantifiers”. See README.md for more details.</p>

},
keywords = {Coq, first-order logic, normalization, proof theory, quantifiers}
}

@software{10.1145/3410271,
author = {Annenkov, Danil and Milo, Mikkel and Nielsen, Jakob Botsch and Spitters, Bas},
title = {Source Code for Paper: Extracting Smart Contracts Tested and Verified in Coq},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410271},
abstract = {
    <p>The artifact contains the Coq source code for the formal proofs and results described in the paper. It comes with a Docker image (concert.tar) that has all necessary dependencies installed and with the source code already built. In addition, it contains the raw source code with instructions to install it from scratch (the ConCert folder).</p>

},
keywords = {blockchain, code extraction, Coq, formal verification, proof assistants, property-based testing, smart contracts}
}

@software{10.1145/3410272,
author = {Hu, Jason Z. S. and Carette, Jacques},
title = {agda-categories: Category Theory library for Agda},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410272},
abstract = {
    <p>A formalization of category theory in Agda.</p>
<p>This library compiles with Agda 2.6.1.</p>

},
keywords = {Agda, category theory, formal mathematics}
}

@software{10.1145/3410273,
author = {Desharnais, Martin and Brunthaler, Stefan},
title = {Isabelle formalization for article: Towards Efficient and Verified Virtual Machines for Dynamic Languages},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410273},
abstract = {
    <p>Isabelle formalization</p>

},
keywords = {Isabelle/HOL}
}

@software{10.1145/3410274,
author = {Timany, Amin and Birkedal, Lars},
title = {Coq formalization for the paper: Reasoning about Monotonicity in Separation Logic},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410274},
abstract = {
    <p>The Coq formalization of the results presented in the paper Reasoning about Monotonicity in Separation Logic.</p>

},
keywords = {Coq, Iris, monotonicity, partial commutative monoids, program verification, separation logic}
}

@software{10.5281/zenodo.4317021,
author = {Vindum, Simon Friis and Birkedal, Lars},
title = {Coq Formalization for Contextual Refinement of the Michael-Scott Queue},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4317021},
abstract = {
    <p>The Coq Formalization accompanying the paper Contextual Refinement of the Michael-Scott Queue (Proof Pearl).</p>

},
keywords = {concurrency, Coq, Iris, separation logic}
}

@software{10.5281/zenodo.4322752,
author = {Hinrichsen, Jonas Kastberg and Louwrink, Dani\"{e}l and Krebbers, Robbert and Bengtson, Jesper},
title = {Mechanisation artifact for Article: Machine-Checked Semantic Session Typing},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4322752},
abstract = {
    <p>This is the artifact corresponding to the CPP21 paper “Machine-Checked Semantic Session Typing” by Jonas Kastberg Hinrichsen, Dani\"{e}l Louwrink, Robbert Krebbers, and Jesper Bengtson. The latest version of the artifact can be obtained online at https://gitlab.mpi-sws.org/iris/actris. The semantic session type system is a part of the Actris repository and thus the artifact includes both.</p>
<p>The artifact is provided in two forms: - As a virtual machine, including all dependencies. You can import the <code>cpp_vm.ova</code> into VirtualBox (“File – Import Appliance”). After starting the machine, additional instructions can be found in the <code>README</code> file on the Desktop. The VM supports both Emacs and CoqIDE - As a tarball of source file, including the Iris dependency repositories. You can extract <code>cpp_coq.tar.gz</code> anywhere, and then follow the instructions in the <code>README.md</code> file.</p>
<p>The artifact has been tested with VirtualBox version 6.1, which can be downloaded for all major platforms from <a href="https://www.virtualbox.org/wiki/Downloads">virtualbox.org</a></p>
<p>Login information Username: actris Password: password Admin password: admin</p>

},
keywords = {concurrency, Coq, Iris, Message passing, semantic typing, separation logic, session types}
}

@software{10.5281/zenodo.4327209,
author = {Limperg, Jannis},
title = {Supplement to: A Novice-Friendly Induction Tactic for Lean},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4327209},
abstract = {
    <p>The supplement contains an implementation of the new induction tactic for Lean 3 described in the associated paper. In the archive, you will find a snapshot of mathlib, Lean’s de facto standard library, which includes the induction tactic. See the file README.md at the root of the archive for details, including installation and testing instruction.</p>

},
keywords = {induction, Lean, metaprogramming, tactic, type theory}
}

@software{10.1145/3410275,
author = {L\"{u}cke, Martin and Steuwer, Michel and Smith, Aaron},
title = {Replication Package for Article: Integrating a Functional Pattern-Based IR into MLIR},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410275},
abstract = {
    <p>The artifact for this paper includes the MLIR infrastructure with the Rise dialect and corresponding passes. IR to reproduce the experiments of the paper is included. A Dockerfile and scripts are provided to enable easy installation, execution, and plotting of results.</p>

},
keywords = {Intermediate Representation, MLIR, Rise}
}

@software{10.5281/zenodo.4399900,
author = {Miu, Anson and Ferreira, Francisco and Yoshida, Nobuko and Zhou, Fangyi},
title = {Communication-Safe Web Programming in TypeScript with Routed Multiparty Session Types},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4399900},
abstract = {
    <p>Our paper presents STScript, a toolchain that generates TypeScript APIs for communication-safe web development over WebSockets, and RouST, a new session type theory that supports multiparty communications with routing mechanisms.</p>

},
keywords = {API generation, deadlock freedom, session types, TypeScript, web programming, WebSocket}
}

@software{10.5281/zenodo.4416117,
author = {Silva, Anderson Faustino da and de Lima, Bernardo N. B. and Pereira, Fernando Magno Quint\~{a}o},
title = {Replication Package for Article: Exploring the Space of Optimization Sequences for Code-Size Reduction: Insights and Tools},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4416117},
abstract = {
    <p>Predictive compilation is the problem of determining good sequences of analyses and optimizations for particular programs. Although predictive compilers have enjoyed much progress in recent years, their development still faces a difficult challenge: the vastness of the space of possible optimizations that can be matched with each program. The effective exploration of this space is a community task that must be carried out gradually and systematically. Towards this vision, this artifact provides an Docker image that contains an optimization cache for research on code-size reduction. In addition, it provides a set of building blocks so that the user can build his/her own application.</p>

},
keywords = {code size, Compiler, sequence}
}

@software{10.5281/zenodo.4451492,
author = {Panchenko, Maksim and Auler, Rafael and Sakka, Laith and Ottoni, Guilherme},
title = {Replication Package for Article: Lightning BOLT: Powerful, Fast, and Scalable Binary Optimization},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4451492},
abstract = {
    <p>This artifact contains the software required to reproduce the experimental findings of the paper “Lightning BOLT: Powerful, Fast, and Scalable Binary Optimization”, CC 2021. This package is a copy of https://github.com/facebookincubator/BOLT/tree/master/paper/reproduce-bolt-cc2021 revision 4990ee5. Please access the github page for an updated version of this artifact, if available.</p>
<p>The open-source workloads evaluated for this paper are clang 11 and gcc 10. These two workloads need to be bootstrapped (built with themselves). Our goal is to demonstrate reductions in wall time and memory consumption when running BOLT on these workloads with different techniques: parallelization and selective optimizations. This is accomplished with the first experiment (exp1.sh script, Figures 3, 4 and 5 in the paper). The second experiment (exp2.sh script, Figures 6 and 7 in the paper) shows how can we trade BOLT speed for output binary performance.</p>

},
keywords = {Binary Optimization, Compilers, Performance}
}

@software{10.5281/zenodo.4456774,
author = {Merigoux, Denis and Monat, Rapha\"{e}l and Protzenko, Jonathan},
title = {A Modern Compiler for the French Tax Code - Artifact},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4456774},
abstract = {
    <p>In France, income tax is computed from taxpayers’ individual returns, using an algorithm that is authored, designed and maintained by the French Public Finances Directorate (DGFiP). This algorithm relies on a legacy custom language and compiler originally designed in 1990, which unlike French wine, did not age well with time. Owing to the shortcomings of the input language and the technical limitations of the compiler, the algorithm is proving harder and harder to maintain, relying on ad-hoc behaviors and workarounds to implement the most recent changes in tax law. Competence loss and aging code also mean that the system does not benefit from any modern compiler techniques that would increase confidence in the implementation.</p>
<p>We overhaul this infrastructure and present Mlang, an open-source compiler toolchain whose goal is to replace the existing infrastructure. Mlang is based on a reverse-engineered formalization of the DGFiP’s system, and has been thoroughly validated against the private DGFiP test suite. As such, Mlang has a formal semantics; eliminates previous hand-written workarounds in C; compiles to modern languages (Python); and enables a variety of instrumentations, providing deep insights about the essence of French income tax computation. The DGFiP is now officially transitioning to Mlang for their production system.</p>
<p>This is the artifact accompanying the published paper at Compiler Construction 2021.</p>

},
keywords = {compiler, legal expert system, tax code}
}

@software{10.5281/zenodo.4458159,
author = {Palmkvist, Viktor and Castegren, Elias and Haller, Philipp and Broman, David},
title = {Resolvable Ambiguity - CC Artifact},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4458159},
abstract = {
    <p>This Docker image contains the software required to reproduce the results in the paper “Resolvable Ambiguity: Principled Resolution of Syntactically Ambiguous Programs” to be published in ACM SIGPLAN 2021 International Conference on Compiler Construction (CC 2021).</p>
<p>Note that as there is an element of randomness in the composition of language fragments, we include the same configuration used for Section 6, but also allow selecting new random combinations. For completeness, we also include the source code of our tool, but as it is not the main focus, it will not be as approachable as running the experiments.</p>

},
keywords = {Ambiguity, Syntax}
}

@software{10.5281/zenodo.4471345,
author = {Abella-Gonz\'{a}lez, Miguel \'{A}. and Carollo-Fern\'{a}ndez, Pedro and Pouchet, Louis-No\"{e}l and Rastello, Fabrice and Rodr\'{\i}guez, Gabriel},
title = {PolyBench/Python},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4471345},
abstract = {
    <p>PolyBench/Python is the reimplementation of PolyBench in the Python programming language. It is a benchmark suite of 30 numerical computations with static control flow, extracted from operations in various application domains (linear algebra computations, image processing, physics simulation, dynamic programming, statistics, etc.).</p>

},
keywords = {Benchmarking, Polyhedral Compilation, Python}
}

@software{10.1145/3410276,
author = {Fuerst, Alexander and Sharma, Prateek},
title = {Artifacts for 'FaasCache: Keeping Serverless Computing Alive with Greedy-Dual Caching'},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410276},
abstract = {
    <p>This contains two experiments. A Python discrete-event simulator, and an edited OpenWhisk that implements Greey-Dual caching</p>

},
keywords = {FaaS, OpenWhisk, Serverless}
}

@software{10.1145/3410277,
author = {Wilkening, Mark and Gupta, Udit and Hsia, Samuel and Trippel, Caroline and Wu, Carole-Jean and Brooks, David and Wei, Gu-Yeon},
title = {Replication Package for Article -- RecSSD: Near Data Processing for Solid State Drive Based Recommendation Inference},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410277},
abstract = {
    <p>RecSSD is composed of a number of open sourced artifacts. First, we implement a fully-functional NDP SLS operator in the open source Cosmos+ OpenSSD system[4], provided in the RecSSD-OpenSSDFirmware repository[7]. To maintain compatibility with the NVMe protocols, the RecSSD interface is implemented within Micron’s UNVMe driver library [10], provided in the RecSSD-UNVMeDriver repository[9]. To evaluate RecSSD, we use a diverse set of eight industry representative recommendation models provided in Deep-RecInfra [18], implemented in Python using Caffe2 [1] and provided in the RecSSD-RecInfra repository[8]. In addition to the models themselves, we instrument the open-source synthetic trace generators from Facebook’s open-sourced DLRM [29] with our locality analysis from production-scale recommendation systems, also included in the RecSSD-RecInfra repository.</p>

},
keywords = {Caffe2, DLRM, OpenSSD, Python, UNVMe}
}

@software{10.1145/3410278,
author = {Luo, Weiyu and Demsky, Brian},
title = {C11Tester Artifact},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410278},
abstract = {
    <p>The artifact contains a c11tester-vagrant directory and a tsan11-tsan11rec-docker directory. The c11tester-vagrant directory is a vagrant repository that compiles source codes for C11Tester, LLVM, the companion compiler pass, and benchmarks for C11Tester. The tsan11-tsan11rec-docker directory contains benchmarks and a docker image with prebuilt LLVMs for tsan11 and tsan11rec.</p>

},
keywords = {C++11, concurrency, data races, memory models}
}

@software{10.1145/3410279,
author = {Ustiugov, Dmitrii and Petrov, Plamen and Kogias, Marios and Bugnion, Edouard and Grot, Boris},
title = {Benchmarking, Analysis, and Optimization of Serverless Function Snapshots},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410279},
abstract = {
    <p>This artifact contains the source code of the vHive-CRI host orchestrator and includes the necessary binary files of its dependencies, namely Firecracker-Containerd shim binaries, Firecracker hypervisor and jailer, default rootfs for Firecracker MicroVMs, MinIO object store server, and client binaries. The reviewers require Ubuntu 18.04 with root access and hardware virtualization support (e.g., VT-x), a platform with the root partition mounted on an SSD is preferred. The artifact lists the instructions to reproduce Fig. 8 for the configuration that uses vanilla Firecracker snapshots and the configuration that uses REAP-based snapshots. The reviewers can run functions from the representative FunctionBench suite, using pre-built Docker images.</p>

},
keywords = {cloud computing, datacenters, serverless, snapshots, virtualization}
}

@software{10.1145/3410280,
author = {Neal, Ian and Quinn, Andrew and Kasikci, Baris},
title = {Replication Package for Article: HIPPOCRATES: Healing Persistent Memory Bugs without Doing Any Harm},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410280},
abstract = {
    <p>This package contains the artifact for HIPPOCRATES. The artifact includes instructions for building and running HIPPOCRATES, as well as scripts and instructions used to reproduce the core results from the original article.</p>

},
keywords = {persistent memory, program repair}
}

@software{10.1145/3410281,
author = {Di, Bang and Liu, Jiawen and Chen, Hao and Li, Dong},
title = {Artifact for PMDebugger: Fast, Flexible, and Comprehensive Bug Detection for Persistent Memory Programs},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410281},
abstract = {
    <p>This is the open-source site for PMDebugger&nbsp;(ASPLOS’21). For the latest version, please see our GitHub page: https://github.com/PASAUCMerced/PMDebugger.</p>

},
keywords = {Crash Consistency, Debugging, Persistent Memory, Testing}
}

@software{10.1145/3410283,
author = {Landgraf, Joshua and Yang, Tiffany and Lin, Will and Rossbach, Christopher J. and Schkufza, Eric},
title = {Artifact for Paper: Compiler-Driven FPGA Virtualization with SYNERGY},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410283},
abstract = {
    <p>This artifact contains the code for all the currently-available SYNERGY (Cascade) backends, including the experimental new backend for F1. The artifact also includes the benchmarks from the paper, data files to run them with, and experiment files to replicate the experiments shown in the paper on the SW and F1 backends. Instructions are documented in README.md, ARTIFACT.md, and experiments/README.md.</p>

},
keywords = {Compilers, FPGAs, Operating Systems, Virtualization}
}

@software{10.5281/zenodo.4321197,
author = {Margaritov, Artemiy and Ustiugov, Dmitrii and Shahab, Amna and Grot, Boris},
title = {Artifact evaluation pack for PTEMagnet (paper #111 in ASPLOS'21)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4321197},
abstract = {
    <p>The artifact contains a Linux kernel patch for enabling PTEMagnet, shell scripts for Linux kernel compilation, a virtual machine disk image with precompiled benchmarks, and Python/shell scripts that are expected to reproduce the results presented in Figure 6 of <a href="https://ease-lab.github.io/ease_website/pubs/PTEMagnet_ASPLOS21.pdf">the paper</a> for non-SPEC benchmarks.</p>

},
keywords = {operating system, virtual memory, virtualization}
}

@software{10.5281/zenodo.4321310,
author = {Panwar, Ashish and Achermann, Reto and Basu, Arkaprava and Bhattacharjee, Abhishek and Gopinath, K. and Gandhi, Jayneel},
title = {Fast Local Page-Tables for Virtualized NUMA Servers with vMitosis},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4321310},
abstract = {
    <p>This repository contains artifacts of the paper Fast Local Page-Tables for Virtualized NUMA Servers with vMitosis by Ashish Panwar, Reto Achermann, Arkaprava Basu, Abhishek Bhattacharjee, K. Gopinath, and Jayneel Gandhi to appear in the 26th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS’21).</p>

},
keywords = {ASPLOS'21, NUMA, Page-Tables, VMItosis-Linux}
}

@software{10.5281/zenodo.4321431,
author = {Sartakov, Vasily A. and Vilanova, Llu\'{\i}s and Pietzuch, Peter},
title = {Replication Package for Article: "CubicleOS: A Library OS with Software Componentisation for Practical Isolation"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4321431},
abstract = {
    <p>This artefact contains the library OS, two applications, the isolation monitor, and scripts to reproduce the experiments from the ASPLOS 2021 paper by V. A. Sartakov, L. Vilanova, R. Pietzuch — ``CubicleOS: A Library OS with Software Componentisation for Practical Isolation’’, which isolates components of a monolithic library OS without the use of message-based IPC primitives.</p>

},
keywords = {compartments, Intel MPK, inter-process communication, isolation}
}

@software{10.5281/zenodo.4321760,
author = {Jia, Zhipeng and Witchel, Emmett},
title = {Nightcore: Efficient and Scalable Serverless Computing for Latency-Sensitive, Interactive Microservices (Artifacts)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4321760},
abstract = {
    <p>Our artifact includes the prototype implementation of Nightcore, the DeathStarBench and HipsterShop microservices ported to Nightcore, and the experiment workflow to run these workloads on AWS EC2 instances.</p>

},
keywords = {Cloud computing, function-as-a-service, microservices, serverless computing}
}

@software{10.5281/zenodo.4321945,
author = {Huang, Yipeng and Holtzen, Steven and Millstein, Todd and Van den Broeck, Guy and Martonosi, Margaret},
title = {Noisy Variational Quantum Algorithm Simulation via Knowledge Compilation for Repeated Inference},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4321945},
abstract = {
    <p>This artifact demonstrates a new way to perform quantum circuit simulation. We convert quantum circuits into probabilistic graphical models, which are then compiled into a format that enables efficient repeated queries.</p>
<p>The artifact consists of a Docker image which includes Google Cirq, a quantum programming framework, which we have extended to use our proposed approach as a quantum circuit simulation backend. Also in the Docker image are two quantum circuit simulators based on existing approaches which we compare against as evaluation baselines.</p>
<p>We offer the Docker image via three routes: a hosted version on Docker Hub provides the latest version of our software and requires minimal setup; a Dockerfile is provided to show how to replicate our environment from scratch; and finally a stable archival version is available on Zenodo.</p>
<p>With minimal setup, you can run test cases in our Docker container showing the validity of our approach. We test our quantum circuit simulation approach using the randomized test harness that Google Cirq uses to test its quantum circuit simulation back ends. We also demonstrate correct simulation results for a benchmark suite of quantum algorithms.</p>
<p>The Docker image contains performance benchmarking experiments that replicate results of our paper at reduced input problem sizes. The experiment scripts generate PDFs showing graphs that plot simulation wall clock time against input quantum circuit sizes. The input problem sizes are large enough to show that our proposed approach achieves a speedup versus existing simulation tools.</p>

},
keywords = {Bayesian networks, knowledge compilation, quantum circuit simulation, quantum computing}
}

@software{10.5281/zenodo.4322031,
author = {Li, Rui and Xu, Yufan and Sukumaran-Rajam, Aravind and Rountev, Atanas and Sadayappan, P.},
title = {Replication Package for Article: Analytical Characterization and Design Space Exploration for Optimization of CNNs},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4322031},
abstract = {
    <p>This artifact includes a software implementation and benchmark specification for reproducing experiment results for paper “Analytical Characterization and Design Space Exploration for Optimization of CNNs”</p>

},
keywords = {Design space exploration, Neural networks, Performance modeling, Tile size optimization}
}

@software{10.5281/zenodo.4322033,
author = {Saileshwar, Gururaj and Fletcher, Christopher W. and Qureshi, Moinuddin},
title = {Code for Streamline Attack: A Fast, Flushless Cache Covert-Channel Attack byEnabling Asynchronous Collusion},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4322033},
abstract = {
    <p>This artifact presents the code and methodology to run the Streamline cache covert-channel attack. We provide the C++ code for the sender and receiver processes engaged in covert communication. Although the attack itself is not specific to an OS, ISA, or micro- architecture, the code is written with the assumption of an x86 Linux system and an Intel CPU that is a Skylake or a newer generation model. The code may be compiled with a standard compiler and run natively to execute the covert-communication. We also provide scripts to run the attack in several configurations demon- strated in Section-IV of our paper (with and without ECC, varying the shared array size and the synchronization period) and provide a Jupyter notebook to visualize the results.</p>
<p>Please use the public GitHub repository of the project https://github.com/gururaj-s/streamline for the most updated version of the code.</p>

},
keywords = {Asynchronous Protocol, Cache Side-Channels, Covert-channel Attacks, Last-Level Cache, Shared Caches}
}

@software{10.5281/zenodo.4322105,
author = {Kasampalis, Theodoros and Park, Daejun and Lin, Zhengyao and Adve, Vikram S. and Ro\c{s}u, Grigore},
title = {Language-Parametric Compiler Validation with Application to LLVM - Artifact Evaluation for ASPLOS 2020},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4322105},
abstract = {
    <p>A VirtualBox VM image that is fully set up to reproduce experiments mentioned in the ASPLOS 2021 paper titled “Language-Parametric Compiler Validation with Application to LLVM”. The included README.md file contains detailed instructions on how to use the artifact both for reproduction of experiments and for general use.</p>

},
keywords = {Compilers, Program Equivalence, Simulation, Translation Validation}
}

@software{10.5281/zenodo.4322233,
author = {Xu, Yi and Izraelevitz, Joseph and Swanson, Steven},
title = {Clobber-NVM: Log Less, Re-execute More},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4322233},
abstract = {
    <p>Clobber-NVM is a failure-atomicity library that ensures data consistency by reexecution. Clobber-NVM’s novel logging strategy, clobber logging, records only those transaction inputs that are overwritten during transaction execution. Then, after a failure, it recovers to a consistent state by restoring overwritten inputs and reexecuting any interrupted transactions. Clobber-NVM utilizes a clobber logging compiler pass for identifying the minimal set of writes that need to be logged.</p>
<p>This artifact includes the Clobber-NVM compiler passes, as well as necessary runtime components. It contains code of all seven benchmarks (four data structures and three applications) reported in the paper. The evaluation results can be reproduced by running the experiments on a machine equipped with at least 24 physical cores per socket and 32 GB of memory. In absence of access to real NVMM (e.g., Intel Optane DC), you need to reserve 32 GB of memory to emulate NVMM. The artifacts also includes a script to download and install main software dependencies. We have evaluated Clobber-NVM on Ubuntu 18.04, with GNU7.3.1, and LLVM 7.0.0.</p>

},
keywords = {Clobber Logging, Compiler, Non-volatile Memory, Persistent Memory, Storage Systems, Undo Logging}
}

@software{10.5281/zenodo.4322285,
author = {Liu, Sihang and Mahar, Suyash and Ray, Baishakhi and Khan, Samira},
title = {PMFuzz: Test Case Generation for Persistent Memory Programs},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4322285},
abstract = {
    <p>PMFuzz is a test case generator for PM programs, aiming to generate high-value test cases for PM testing tools. The generated test cases include both program inputs and initial PM images (normal images and crash images). The key idea of PMFuzz is to perform a targeted fuzzing on PM-related code regions and generate valid PM images by reusing the program logic. After generating the test cases, PMFuzz feeds them to the PM program and uses existing testing tools (XFDetector and PMemcheck) to detect crash consistency and performance bugs. The archived version of this artifact can be accessed using this DOI. We also maintain a GitHub repository at https://pmfuzz.persistentmemory.org/. For the latest version, please check our GitHub repository.</p>

},
keywords = {Crash Consistency, Debugging, Fuzzing, Persistent Memory, Testing}
}

@software{10.5281/zenodo.4329804,
author = {Tang, Wei and Tomesh, Teague and Suchara, Martin and Larson, Jeffrey and Martonosi, Margaret},
title = {Replication Package for Article: CutQC: Using Small Quantum Computers for Large Quantum Circuit Evaluations},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4329804},
abstract = {
    <p>Our artifact provides the source codes for the end-to-end CutQC toolflow. We also provide the benchmarking codes for several sample runtime and fidelity experiments. The HPC parallel version of the code is not provided, as different HPC platforms require very different setups.</p>

},
keywords = {Hybrid Computing, Quantum Circuit Cutting, Quantum Computing (QC)}
}

@software{10.5281/zenodo.4331404,
author = {VanHattum, Alexa and Nigam, Rachit and Lee, Vincent T. and Bornholt, James and Sampson, Adrian},
title = {Diospyros Software Artifact: Vectorization for Digital Signal Processors via Equality Saturation},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4331404},
abstract = {
    <p>Our artifact packages an environment to reproduce the main empirical results of our paper. Specifically, we package: (1) the Diospyros compiler: a search-aided compiler for generating vectorized DSP kernels, (2) implementations of a range of benchmarks in Diospyros, (3) implementation of the Theia open-source application case study, and (4) scripts for recreating the experiments and charts in the paper.</p>

},
keywords = {DSPs, Equality Saturation, Program Synthesis, Vectorization}
}

@software{10.5281/zenodo.4331660,
author = {Jayarajan, Anand and Hau, Kimberly and Goodwin, Andrew and Pekhimenko, Gennady},
title = {LifeStream},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4331660},
abstract = {
    <p>This artifact contains code and a synthetic data set to evaluate LifeStream, Trill, and numerical library-based data processing pipelines.</p>

},
keywords = {LifeStream, Numpy, Python, Scikit-learn, SciPy, stream data analytics, temporal query processing, Trill}
}

@software{10.5281/zenodo.4429956,
author = {Skarlatos, Dimitrios and Zhao, Zirui Neil and Paccagnella, Riccardo and Fletcher, Christopher W. and Torrellas, Josep},
title = {Replication for article: Jamais Vu: Thwarting Microarchitectural Replay Attacks},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4429956},
abstract = {
    <p>Our artifact provides a complete gem5 implementation of Jamais Vu, along with scripts to evaluate the SPEC’17 benchmarks. We also provide a GitHub repository with the gem5 implementation and required scripts to reproduce our simulation results. Finally, we provide a binary analysis infrastructure based on Radare2 that allows the compilation of binaries with the proposed Epoch markings.</p>

},
keywords = {Gem5, Processor design, Replay attack, Side-channel countermeasures}
}

@software{10.5281/zenodo.4432747,
author = {Nigam, Rachit and Thomas, Samuel and Li, Zhijing and Sampson, Adrian},
title = {Replication Package for Article: Compiler Infrastructure for Accelerator Generators},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4432747},
abstract = {
    <p>Our artifact packages an environment that can be used to reproduce the figures in the paper and perform similar evaluations. It is available at the following link:https://zenodo.org/record/4432747</p>
<p>It includes the following: - futil: The Calyx compiler. - fud: Driver for the futil compiler and hardware tools. - Linear algebra PolyBench written in Dahlia</p>

},
keywords = {Accelerator Design, Intermediate Language}
}

@software{10.5281/zenodo.4435970,
author = {Farshin, Alireza and Barbette, Tom and Roozbeh, Amir and Maguire Jr., Gerald Q. and Kosti\'{c}, Dejan},
title = {PacketMill: Toward Per-Core 100-Gbps Networking - Artifact for ASPLOS'21},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4435970},
abstract = {
    <p>This is the artifact for the “PacketMill: Toward per-core 100-Gbps Networking” paper published at ASPLOS’21.</p>
<p>PacketMill is a system that optimizes the performance of network functions via holistic inter-stack optimizations. More specifically, PacketMill provides a new metadata management model, called X-Change, enabling the packet processing frameworks to provide their custom buffer to DPDK and fully bypass rte_mbuf. Additionally, PacketMill performs a set of source-code \&amp; intermediate representation (IR) code optimizations.</p>
<p>Our paper’s artifact contains the source code, the experimental workflow, and additional information to (i) set upPacketMill \&amp; its testbed, (ii) perform some of the experiments presented in the paper, and (iii) validates the reusability \&amp; effectiveness of PacketMill.</p>
<p>For more information, please refer to https://github.com/aliireza/packetmill</p>

},
keywords = {DPDK., FastClick, LLVM, Middleboxes, Packet Processing, PacketMill, X-Change}
}

@software{10.5281/zenodo.4446702,
author = {Bl\"{o}cher, Marcel and Wang, Lin and Eugster, Patrick and Schmidt, Max},
title = {Switches for HIRE: Resource Scheduling for Data Center In-Network Computing},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4446702},
abstract = {
    <p>The artifact consists of three parts. (1) the source code of the HIRE simulator, including the implementations of Yarn++, Sparrow++, K8++, and CoCo++; (2) the runner tool (a Python3 program) that runs the experiments with the configurations presented in the paper and plotting scripts; and (3) Docker configurations to ease the setup. Users can reproduce all simulation results (Fig. 8 and Fig. 7). Furthermore, the artifact can be easily extended/modified to bench- mark other schedulers, INC configurations, and workloads.</p>

},
keywords = {data center, heterogeneity, in-network computing, non-linear resource usage, scheduling}
}

@software{10.5281/zenodo.4501773,
author = {Chen, Daming D. and Lim, Wen Shih and Bakhshalipour, Mohammad and Gibbons, Phillip B. and Hoe, James C. and Parno, Bryan},
title = {Artifact for 'HerQules: Securing Programs via Hardware-Enforced Message Queues'},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4501773},
abstract = {
    <p>Source code, experiment data, and virtual machines with precompiled benchmarks</p>

},
keywords = {compiler, fpga, ipc, llvm, nginx, ripe, spec, zsim}
}

@software{10.5281/zenodo.4504602,
author = {Calciu, Irina and Imran, M. Talha and Puddu, Ivan and Kashyap, Sanidhya and Maruf, Hasan Al and Mutlu, Onur and Kolli, Aasheesh},
title = {Artifacts for Article: Rethinking Software Runtimes for Disaggregated Memory},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4504602},
abstract = {
    <p>These artifacts have been developed for the ASPLOS 2021 article “Rethinking Software Runtimes for Disaggregated Memory”. The artifacts provide tools to track applications and determine their memory accesses: cache-line granularity memory writes and average memory access time (AMAT).</p>

},
keywords = {average memory access time, cache-line granularity dirty data tracking}
}

@software{10.5281/zenodo.4527305,
author = {Patel, Tirthak and Tiwari, Devesh},
title = {QRAFT ASPLOS 21 Code and Dataset},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4527305},
abstract = {
    <p>The artifacts can be divided into three categories: (1) Raw data: circuit metadata and output generated as a direct result of running quantum circuits. (2) Processed and Trained data: the data processed to be fed as input to the machine learning model training, as well as the output data of testing samples using the trained model. (3) Tools: code and scripts used for running circuits on quantum computers, processing the output, as well as training models and generating the final output (prediction of state probabilities).</p>

},
keywords = {NISQ Computing, Quantum Computing, Quantum Error Mitigation}
}

@software{10.5281/zenodo.4537132,
author = {Zhang, Yanqi and Hua, Weizhe and Zhou, Zhuangzhuang and Suh, G. Edward and Delimitrou, Christina},
title = {Replication package for article: Sinan: ML-Based and QoS-Aware Resource Management for Cloud Microservices},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4537132},
abstract = {
    <p>The artifact includes codes and documentation to reproduce the google cloud experiments presented in Sinan: ML-Based and QoS-Aware Resource Management for Cloud Microservices</p>

},
keywords = {cloud computing, cluster management, datacenter, machine learn-ing for systems, mi-croservices, quality of service, resource efficiency, tail latency}
}

@software{10.5281/zenodo.4539728,
author = {Zhang, Mengchi and Alawneh, Ahmad and Rogers, Timothy G.},
title = {Replication package for Article: Judging a Type by Its Pointer: Optimizing Virtual Function Calls on GPUs},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4539728},
abstract = {
    <p>The artifact contains the source code for the SharedOA, COAL, and TypePointer that applied to all workloads. We also include the instructions to configure, build, run, and acquire the workload’s performance. Users can reproduce the results in Figure 6. We also contain a tutorial with examples to apply SharedOA, COAL and TypePointer to show that the three techniques are reusable on other CUDA applications.</p>

},
keywords = {GPU, Object-oriented Programming, Virtual Function Call}
}

@software{10.5281/zenodo.4539743,
author = {Hoseinzadeh, Morteza and Swanson, Steven},
title = {Replication Package for Artifact: Corundum: Statically-Enforced Persistent Memory Safety},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4539743},
abstract = {
    <p>Corundum is a persistent memory programming library in Rust which enforces safety rules statically. The artifact contains the source code of Corundum, the installation scripts for Corundum and other libraries listed in the paper, source code of the workloads, and experiments run scripts.</p>

},
keywords = {debugging, formal verification, persistent memory programming}
}

@software{10.5281/zenodo.4540633,
author = {Meng, Xiaozhu and Liu, Weijie},
title = {Software Artifact for Incremental CFG Patching for Binary Rewriting},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4540633},
abstract = {
    <p>Software artifact needed for paper “Incremental CFG Patching for Binary Rewriting”. It includes scripts for setting environments, software dependencies, and running experiments, and template configuration files for SPEC CPU 2017.</p>

},
keywords = {Docker, Dyninst, Firefox, Spack}
}

@software{10.5281/zenodo.4540866,
author = {Li, Guangpu and Chen, Dongjie and Lu, Shan and Musuvathi, Madanlal and Nath, Suman},
title = {SherLock-v2},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4540866},
abstract = {
    <p>Synchronizations are fundamental to the correctness and performance of concurrent software. They determine which operations can execute concurrently and which can-not—the key to detecting and fixing concurrency bugs, as well as understanding and tuning performance. Unfortunately, correctly identifying all synchronizations has become extremely difficult in modern software systems due to the various forms of concurrency and various types of synchronizations.</p>
<p>Previous work either only infers specific type of synchronization by code analysis or relies on manual effect to annotate the synchronization. This paper proposes SherLock, a tool that automatically infers synchronizations without code analysis or annotation. SherLock leverages the fact that most synchronizations appear around the conflicting operations and encodes the inference problem into a linear system with properties and hypotheses about how synchronizations are typically used. To collect useful observations, SherLock runs the target problem for a small number of runs with feedback-guided delay injection.</p>
<p>We have applied SherLock on 8 C# open-source applications. Without any prior knowledge, SherLock automatically inferred more than 120 unique synchronizations, with few false positives. These inferred synchronizations cover a wide variety of types, including lock operations, fork-join operations, asynchronous operations, framework synchronization, and custom synchronization.</p>

},
keywords = {Happens-before inducing, Synchronization Detection}
}

@software{10.5281/zenodo.4541351,
author = {Duta, Victor and Giuffrida, Cristiano and Bos, Herbert and van der Kouwe, Erik},
title = {Replication Package for Article "PIBE: Practical Kernel Control-Flow Hardening with Profile-Guided Indirect Branch Elimination"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4541351},
abstract = {
    <p>Our artifact provides x86-64 kernel binaries for most of the kernel configurations we evaluated in the paper, along with scripts to configure LMBench, run and benchmark each kernel configuration and regenerate the syscall latencies and overheads discussed in the main tables of the paper. This allows the evaluation of our results on an Intel i7-8700K (Skylake) CPU or similar micro-architectures.</p>
<p>We also provide source code for the tools used during the kernel build process (e.g., binutils, LLVM 10), the code of our LLVM optimization passes and the kernel source code to regenerate the kernel binaries used in the workflow of our evaluation. We sup- ply the user with scripts to regenerate our Apache and LMBench profiling workloads, rebuild the kernel binaries provided in the evaluation or customize the kernels with a user-specified selection of transient mitigations and optimization strategies.</p>
<p>Furthermore, we also provide portable Apache and LMBench profiling workloads to speedup the customization process without the necessity of creating your own profiling workloads.</p>

},
keywords = {kernel, LMBench, profile-guided optimizations, transient execution}
}

@software{10.5281/zenodo.4546175,
author = {Hadidi, Ramyad and Asgari, Bahar and Jijina, Sam and Amyette, Adriana and Shoghi, Nima and Kim, Hyesoon},
title = {Paper Quantifying the Design-Space Tradeoffs in Autonomous Drones artifact, including software, data, and build giude for the open-source drone},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4546175},
abstract = {
    <p>This artifact describes our open-source experimental drone framework that is customizable across its hardware-software stack. The main and first portion of the artifact focuses on building the drone, which compliments the beginning sections of the paper. The build guide consists of two parts: hardware and software. Second, as an example of possible experiments, we provide sample scripts for important metrics measurements such as Linux perf and SLAM. Third, the artifact contains raw data for graphs in the paper.</p>

},
keywords = {autonomous drones, build guide, design-space analysis, open-source platform, power measurements, SLAM}
}

@software{10.5281/zenodo.4556045,
author = {Qiu, Junqiao and Sun, Xiaofan and Sabet, Amir Hossein Nodehi and Zhao, Zhijia},
title = {Replication Package for Article: Scalable FSM Parallelization via Path Fusion and Higher-Order Speculation},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4556045},
abstract = {
    <p>This artifact contains the source code of BoostFSM, including the five FSM parallelization schemes discussed in the paper and some benchmarks along with their inputs used for evaluation. In addition, this artifact provides bash scripts to compile the source code and reproduce the key experimental results reported in the paper. Considering the software dependencies, a software environment with Linux Centos 7 or other similar Linux distributions, GCC, Bash, Pthread, CMake and Boost library, is needed before the evaluation. Moreover, to reproduce all results reported in the paper, especially the speedup comparison and scalability analysis, the artifact needs to run on Intel Xeon Phi processor (Knights Landing/KNL).</p>

},
keywords = {Finite State Machine, FSM, Parallelization, Scalability, Speculation}
}

@software{10.6084/m9.figshare.13392338,
author = {Gorjiara, Hamed and Xu, Guoqing Harry and Demsky, Brian},
title = {Replication Package for Article: Jaaru: Efficiently Model Checking Persistent Memory Programs},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.13392338},
abstract = {
    <p>This artifact contains a vagrant repository that downloads and compiles the source code for Jaaru, its companion compiler pass, and benchmarks. The artifact enables users to reproduce the bugs that are found by in PMDK (i.e., Figure 11 of the paper) and RECIPE (i.e., Figure 12) as well as the performance results to compare with Yat (i.e., Figure 13).</p>

},
keywords = {Crash Consistency, Debugging, Jaaru, Persistent Memory, Testing}
}

@software{10.6084/m9.figshare.8251583,
author = {Hirao, Toshiki and McIntosh, Shane and Ihara, Akinori and Matsumoto, Kenichi},
title = {Replication Package 170 FSE2019},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.8251583},
abstract = {
    <p>This is a replication package for the paper “The Review Linkage Graph for Code Review Analytics: A Recovery Approach and Empirical Study”. This package is comprised of four folders that correspond to the analyses that we conducted in our four research question (RQ1-RQ4).</p>

},
keywords = {Code review, linkage, mining software repository}
}

@software{10.1145/3342530,
author = {Maillard, Kenji and Ahman, Danel and Atkey, Robert and Mart\'{\i}nez, Guido and Hri\c{t}cu, C\u{a}t\u{a}lin and Rivas, Exequiel and Tanter, \'{E}ric},
title = {Accompanying development for the paper: Dijkstra monads for all},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3342530},
abstract = {
    <p>The archive contains a docker image and original source files supporting the paper “Dijkstra monads for all”. The source files comport (1) a modified version of the F* compiler implementing the extension of the paper and examples of F* sources using these extensions (2) a Coq development of Dijkstra monads, implementations of the examples from the paper as well as an implementation of a DSL to derive monad transformers. See <code>ArtifactOverview.md</code> in the archive for more information.</p>

},
keywords = {Coq, Dijkstra monads, F*, monadic effects, program verification}
}

@software{10.1145/3373095,
author = {Maillard, Kenji and Hri\c{t}cu, C\u{a}t\u{a}lin and Rivas, Exequiel and Van Muylder, Antoine},
title = {Coq development for The Next 700 Relational Program Logics},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373095},
abstract = {
    <p>This artifact contains the Coq development supporting the paper “The Next 700 Relational Program Logics” with a formalization of relative monads enriched over orders and relational program logics for state, exception, Imp instantiating the general framework.</p>

},
keywords = {category theory, Coq, relational program logics, relative monad, side-effects}
}

@software{10.1145/3264864,
author = {Borges Jr., Nataniel P. and Hotzkow, Jenny and Zeller, Andreas},
title = {DroidMate-2: A Platform for Android Test Generation (Source Code)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3264864},
abstract = {
    <p>DroidMate-2 is a platform to easily assist both developers and researchers to customize, develop and test new test generators.</p>
<p>DroidMate-2 can be used without app instrumentation or operating system modifications, as a test generator on real devices and emulators for app testing or regression testing. Additionally, it provides sensitive resource monitoring or blocking capabilities through a lightweight app instrumentation, out-of-the-box statement coverage measurement through a fully-fledged app instrumentation and native experiment reproducibility.</p>

},
keywords = {Android, dynamic analysis, test generation}
}

@software{10.5281/zenodo.1307248,
author = {Wei, Guannan and Decker, James and Rompf, Tiark},
title = {Kraks/RefuncAAM: Release v1.0.0},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.1307248},
abstract = {
    <p>This is the release for the camera-ready submission of ICFP ’18.</p>

},
keywords = {Artifact, Functional Programming}
}

@software{10.5281/zenodo.1400702,
author = {Henkel, Jordan and Lahiri, Shuvendu K. and Liblit, Ben and Reps, Thomas},
title = {Artifact for Code Vectors: Understanding Programs Through Embedded Abstracted Symbolic Traces},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.1400702},
abstract = {
    <p>This release is to track the Code Vectors: Understanding Programs Through Embedded Abstracted Symbolic Traces artifact submission. Updated to align with camera ready version.</p>

},
keywords = {Embeddings, Program Understanding, Software Engineering Research}
}

@software{10.5281/zenodo.1419788,
author = {Valiev, Marat and Vasilescu, Bogdan and Herbsleb, James},
title = {Ecosystem-Level Determinants of Sustained Activity in Open-Source Projects: A Case Study of the PyPI Ecosystem},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.1419788},
abstract = {
    <p>Replication pack, FSE2018 submission #164</p>

},
keywords = {Software Engineering}
}

@software{10.5281/zenodo.3898483,
author = {Xu, Rongchen and He, Fei and Wang, Bow-Yaw},
title = {xurongchen/fse20: Artifacts for FSE2020 paper#633},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3898483},
abstract = {
    <p>artifacts track, fse20</p>

},
keywords = {Software Engineering}
}

@software{10.5281/zenodo.3903727,
author = {Mirhosseini, Samim and Parnin, Chris},
title = {docable/docable v1.1},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3903727},
abstract = {
    <p>No description provided.</p>

},
keywords = {Software Engineering}
}

@software{10.5281/zenodo.3907232,
author = {Sharma, Vaibhav and Hussein, Soha and Whalen, Michael W. and McCamant, Stephen and Visser, Willem},
title = {java-ranger: v1.0.0},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3907232},
abstract = {
    <p>This is the version of Java Ranger that was used in the evaluation accepted to FSE 2020.</p>

},
keywords = {Java, Software Engineering, Software Verification}
}

@software{10.5281/zenodo.3923023,
author = {Palmer, Zachary and Park, Theodore and Smith, Scott and Weng, Shiwei},
title = {Higher-Order Demand-Driven Symbolic Evaluation},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3923023},
abstract = {
    <p>The artifact for the paper includes the source code and a ready-to-use qemu image.</p>

},
keywords = {Functional Programming, OCaml}
}

@software{10.1145/3365462,
author = {Garc\'{\i}a, Sergio and Pelliccione, Patrizio and Menghi, Claudio and Berger, Thorsten and Bures, Tomas},
title = {PROMISE: A DSL for Controlling Teams of Mobile Robots},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3365462},
abstract = {
    <p>PROMISE (simPle RObot MIssion SpEcification) is a Domain Specific Language (DSL) to specify missions for teams of multiple robots. PROMISE 1) supports the user with a user-friendly syntax while having well-defined (translational) semantics; 2) enables a rigorous and precise specification, required for the use of planners, analysis tools, simulators or other modules; 3) allows the specification of complex missions by providing executable, combinable tasks and operators; 4) is platform-independent and highly customizable. The DSL is implemented as an Eclipse plugin and it is integrated into a software framework that allows mission decomposition, generation, and execution. We provide PROMISE’s implementation, the framework, and tools as plugins. The package contains a Guidelines.pdf file that contains more information regarding the artifact’s components, installation, and workflow.</p>
<p>This artifact was retrospectively published and linked to the paper.</p>

},
keywords = {domain-specific language, mission specification, Multi-robot}
}

@software{10.1145/3410284,
author = {Szab\'{o}, Tam\'{a}s and Erdweg, Sebastian and Bergmann, G\'{a}bor},
title = {Replication Package for Article: Incremental Whole-Program Analysis in Datalog with Lattices},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410284},
abstract = {
    <p>This is an Ubuntu-based virtual machine with the IncA program analysis framework and benchmark Java programs already set up on it. The artifact can be used to execute the incremental static analyses described in the paper “Incremental Whole-Program Analysis in Datalog with Lattices” and to reproduce the presented measurement results.</p>

},
keywords = {Datalog, Incremental Computing, Static Analysis}
}

@software{10.1145/3410285,
author = {Guria, Sankha Narayan and Foster, Jeffrey S. and Van Horn, David},
title = {Replication Package for Article: RbSyn: Type- and Effect-Guided Program Synthesis},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410285},
abstract = {
    <p>The artifact is a Docker image that contains all of the source code, benchmarks, and experiment harnesses used in the development of the paper (set-up and ready to run). The README contains instructions to reproduce results from the paper, as well as pointers for how to extend or modify the tool and benchmarks.</p>

},
keywords = {program synthesis, Ruby, type and effect systems}
}

@software{10.1145/3410286,
author = {Erdweg, Sebastian and Szab\'{o}, Tam\'{a}s and Pacak, Andr\'{e}},
title = {Artifact: Concise, Type-Safe, and Efficient Structural Diffing},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410286},
abstract = {
    <p>Implementation of the algorithm in Scala; benchmark code and data.</p>

},
keywords = {incremental computing, tree diffing}
}

@software{10.1145/3410287,
author = {Bonaert, Gregory and Dimitrov, Dimitar I. and Baader, Maximilian and Vechev, Martin},
title = {Artifact for PLDI'21 paper #156 "Fast and Precise Certification of Transformers"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410287},
abstract = {
    <p>We present DeepT, a novel method for certifying Transformer networks based on abstract interpretation. The key idea behind DeepT is our new multi-norm Zonotope abstract domain, an extension of the classical Zonotope designed to handle L1 and L2-norm bound perturbations. This artifact contains the source code, Transformer networks, scripts and Jupyter notebooks for the DeepT verifier and can be used to reproduce the core results of the paper “Fast and Precise Certification of Transformers”, published at the PLDI’21 conference.</p>

},
keywords = {Abstract Interpretation, Adversarial attacks, Deep Learning, Robustness Certification, Transformer Networks}
}

@software{10.1145/3410288,
author = {Montagu, Beno\^{\i}t and Jensen, Thomas},
title = {Static Control-Flow Analyzers for the Article: Trace-Based Control-Flow Analysis},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410288},
abstract = {
    <p>The artifact contains prototype implementations of the static analyzers for control-flow analysis (CFA) described in the PLDI’21 article “Trace-Based Control-Flow Analysis”, a collection of program examples, and a procedure to reproduce the experimental results presented in the article. The artifact is a TAR.XZ archive, that contains a README file, a LICENSE file and two components. The first component is the OCaml source code of the analyzers. We also provide a version of the analyzers that runs in a web browser directly. The second component is a docker container that embeds the same sources and a minimal Linux environment so that you can compile the sources and execute the analyzers. The README file describes with details the procedure to build and run the artifact using the docker container.</p>

},
keywords = {CFA, control-flow analysis, lambda-calculus, static analysis, widening}
}

@software{10.1145/3410289,
author = {Baudart, Guillaume and Burroni, Javier and Hirzel, Martin and Mandel, Louis and Shinnar, Avraham},
title = {Replication package for the article: Compiling Stan to Generative Probabilistic Languages and Extension to Deep Probabilistic Programming},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410289},
abstract = {
    <p>This artifact contains the <a href="https://mc-stan.org">Stan</a> (+ extensions) to Pyro and NumPyro compiler presented in the paper, and the code to reproduce the evaluation.</p>
<p>The artifact comprises 3 main parts corresponding to the 3 top-level directories. - <code>stanc3</code>: the fork of the <a href="https://github.com/stan-dev/stanc3">Stanc3 compiler</a> with two new backends targeting <a href="http://pyro.ai/">Pyro</a> and <a href="https://github.com/pyro-ppl/numpyro">NumPyro</a> (clone of https://github.com/deepppl/stanc3) - <code>stan-num-pyro</code>: the Pyro and NumPyro runtime libraries to execute the program (clone of https://github.com/deepppl/stan-num-pyro) - <code>evaluation</code>: code and data to reproduce the evaluation section of the paper (clone of https://github.com/deepppl/evaluation)</p>
<p>In addition the artifact also contains: - <code>README.md</code>: this file - <code>deepstan.tar.gz</code>: a Docker image with the compiler and runtime installed - <code>pldi2021.pdf</code>: the paper - <code>coin.stan</code>: a simple Stan program - <code>coin_infer.py</code>: a Python script to compile and execute <code>coin.stan</code> - <code>requirements.txt</code>: the list of Python dependencies - <code>deepstan.docker</code>: the docker file used to build the image.</p>
<p>To summarize this artifact: - Demonstrates that it is possible to compile Stan programs to generative probabilistic programming languages by providing a modified version of the Stanc3 compiler with two new backends targeting Pyro and NumPyro. - Demonstrates the extension of Stan with deep probabilistic programming and variational inference with explicit guides. - Provides the code used in the evaluation section of the paper to answer the following research questions: - RQ1: Can we compile and run all Stan models? - RQ2: What is the impact of the compilation on accuracy? - RQ3: What is the impact of the compilation on speed? - RQ4: Are explicit variational guides useful? - RQ5: For deep probabilistic models, how does DeepStan compare to hand-written Pyro code?</p>

},
keywords = {Compilation, Deep probabilistic programming, NumPyro, Probabilistic programming, Pyro, Stan, Variational inference}
}

@software{10.1145/3410290,
author = {Anderson, Daniel and Blelloch, Guy E. and Wei, Yuanhao},
title = {Artifact for "Concurrent Deferred Reference Counting with Constant-Time Overhead"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410290},
abstract = {
    <p>This artifact contains a preliminary version of our C++ library for atomic reference-counted pointers and a benchmark suite that evaluates its performance against existing reference-counted pointers and manual SMR techniques.</p>

},
keywords = {automatic memory management, concurrent algorithms, memory reclamation, reference counting}
}

@software{10.1145/3410291,
author = {Yu, Nengkun and Palsberg, Jens},
title = {Software artifact for the paper "Quantum Abstract Interpretation"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410291},
abstract = {
    <p>The artifact allows a user to reproduce the experimental results in the paper “Quantum Abstract Interpretation”.</p>

},
keywords = {abstract interpretation., Quantum programming, scalability}
}

@software{10.1145/3410292,
author = {Cho, Kyeongmin and Lee, Sung-Hwan and Raad, Azalea and Kang, Jeehoon},
title = {Mechanized Proof and Model Checker for Article: Revamping Hardware Persistency Models},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410292},
abstract = {
    <h2 id="revamping-hardware-persistency-models-view-based-and-axiomatic-persistency-models-for-intel-x86-and-armv8">Revamping Hardware Persistency Models: View-Based and Axiomatic Persistency Models for Intel-x86 and Armv8</h2>
<p>This is the artifact for the following paper:</p>
<p>Kyeongmin Cho, Sung-Hwan Lee, Azalea Raad, and Jeehoon Kang. Revamping Hardware Persistency Models: View-Based and Axiomatic Persistency Models for Intel-x86 and Armv8. PLDI 2021.</p>
<h3 id="contributions-paper-1">Contributions (paper §1)</h3>
<ul>
<li>We discuss the shortcomings of the existing persistency models of Intel-x86/Armv8 and present an intuitive account of our solution as view-based models (§2).</li>
<li>We develop x86_view, a new view-based model for Intelx86 concurrency (§3).</li>
<li>We develop Px86_view (§3.5) and PArmv8_view (§6.2), respectively extending the x86_view and Armv8_view models to account for persistent memory.</li>
<li>We present Px86_axiom (§4) and PArmv8_axiom (§6.3), our axiomatic models of Intel-x86 and Armv8 persistency that simplify and repair the state-of-the-art models of the respective architectures. We prove that our axiomatic models are equivalent to the authoritative semantics reviewed by Intel and Arm engineers, modulo our proposed fixes (§4.4 and §6.3). Our proposed fix in PArmv8_axiom has been reviewed by Arm engineers.</li>
<li>We prove that Px86_view and PArmv8_view are equivalent to Px86_axiom and PArmv8_axiom, respectively. The equivalence proof is mechanized in Coq (§5 and §6.4).</li>
<li>We develop a model checker for persistency and use it to verify several representative examples under PArmv8view (§7). We conclude with related and future work (§8).</li>
</ul>
<h3 id="artifacts">Artifacts</h3>
<ul>
<li>Coq formalization (§2-6) of the hardware persistency models (Px86-{view, axiom}, PArmv8-{view, axiom}) and their equivalence proofs</li>
<li>Model checker (§7) for Armv8 persistency</li>
</ul>
<h3 id="getting-started-guide">Getting Started Guide</h3>
<p>Each of Coq formalization and model checker has its own repository: - Coq formalization’s <a href="https://github.com/kaist-cp/view-hw/blob/master/README.md">repository</a> - Model checker’s <a href="https://github.com/kaist-cp/rmem-persistency">repository</a>.</p>
<p>These repositories are forks of <a href="https://github.com/snu-sf/promising-arm">snu-sf/promising-arm</a> and <a href="https://github.com/rems-project/rmem">rems-project/rmem</a>, respectively.</p>
<p>For each repository, you can either manually build it or reuse docker images in which the projects are already built.</p>
<h4 id="manual-build">Manual build</h4>
<p>Please read each repository’s README:</p>
<ul>
<li>Coq formalization’s <a href="https://github.com/kaist-cp/view-hw/blob/master/README.md#installation">README</a></li>
<li>Model checker’s <a href="https://github.com/kaist-cp/rmem-persistency#build">README</a></li>
</ul>
<h4 id="docker-image">Docker image</h4>
<p>Each repository contains a <code>Dockerfile</code>:</p>
<ul>
<li>Coq formalization’s <a href="https://github.com/kaist-cp/view-hw/blob/master/Dockerfile">Dockerfile</a></li>
<li>Model checker’s <a href="https://github.com/kaist-cp/rmem-persistency/blob/master/Dockerfile">Dockerfile</a></li>
</ul>
<p>You can download the prebuilt docker images <a href="https://drive.google.com/drive/folders/1HCojYdChl1qsSTHDrjWdAzS8SE2NRuLC?usp=sharing">here</a>.</p>
<h3 id="step-by-step-instructions">Step-by-Step Instructions</h3>
<ul>
<li>Coq formalization’s <a href="https://github.com/kaist-cp/view-hw/blob/master/README.md#our-results">README</a> explains which part of codes matches one of definitions, lemmas and theorems in the paper.</li>
<li>Model checker’s <a href="https://github.com/kaist-cp/rmem-persistency#run-an-example">README</a> exlains how to run the program to verify each example in the paper. It’s expected that all results come out within 1 second as mentioned in the paper.</li>
</ul>

},
keywords = {Armv8, mechanized proof, model checker, non-volatile random-access memory, NVRAM, persistency semantics, persistent memory, x86}
}

@software{10.1145/3410293,
author = {Wang, Di and Hoffmann, Jan and Reps, Thomas},
title = {Replication Package for Article: Central Moment Analysis for Cost Accumulators in Probabilistic Programs},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410293},
abstract = {
    <p>This artifact provides an implementation of a static analyzer for higher (raw or central) moments of cost accumulators (e.g., running time) in probabilistic programs.</p>

},
keywords = {central moments, cost analysis, Probabilistic programs, tail bounds}
}

@software{10.1145/3410294,
author = {Sotoudeh, Matthew and Thakur, Aditya V.},
title = {Replication Package for Article: Provable Repair of Deep Neural Networks},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410294},
abstract = {
    <p>The zip file contains our artifact as a virtual machine as well as a README with instructions. An updated version of this artifact is stored at https://github.com/95616ARG/PRDNN</p>

},
keywords = {deep learning, machine learning, program repair}
}

@software{10.1145/3410295,
author = {Erbsen, Andres and Gruetter, Samuel and Choi, Joonwon and Wood, Clark and Chlipala, Adam},
title = {Replication Package for Article: Integration Verification across Software and Hardware for a Simple Embedded System},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410295},
abstract = {
    <p>This artifact includes the Coq development described in the paper and all dependencies for generating the FPGA bitstream. All this is packaged as a .vdi disk image that boots into a Linux terminal environment accessible over SSH. The artifact was evaluated by running it in VirtualBox as described in README.txt.</p>

},
keywords = {Embedded Systems, Formal Verification, Hardware-Software Interface, Proof Assistants, RISC-V Instruction-Set Family}
}

@software{10.1145/3410296,
author = {Stanford, Caleb and Veanes, Margus and Bj\o{}rner, Nikolaj},
title = {dZ3: Artifact for "Symbolic Boolean Derivatives for Efficiently Solving Extended Regular Expression Constraints"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410296},
abstract = {
    <p>This is the artifact for the paper: Symbolic Boolean Derivatives for Efficiently Solving Extended Regular Expression Constraints. This artifact is provided as a Docker container for the artifact evaluation for PLDI 2021.</p>
<p>If convenient, you can also view the artifact files online on GitHub at https://github.com/cdstanford/dz3-artifact. The GitHub repository contains everything in the Docker container except the solver binaries, which are too large.</p>

},
keywords = {regex, regular expression, SMT, string, Z3}
}

@software{10.1145/3410297,
author = {Hu, Xiaowen and Zhao, David and Jordan, Herbert and Scholz, Bernhard},
title = {Artifact for Paper: An Efficient Interpreter for Datalog by De-specializing Relations},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410297},
abstract = {
    <p>The artifact provides source code, experiments input and necessary instructions for reproducing the primary results in the paper “An Efficient Interpreter for Datalog by De-specializing Relations”.</p>

},
keywords = {Datalog, interpreter, static analysis}
}

@software{10.1145/3410298,
author = {Koenig, Jason R. and Padon, Oded and Aiken, Alex},
title = {Replication Package for Article: Adaptive Restarts for Stochastic Synthesis},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410298},
abstract = {
    <p>This artifact contains the synthesis evaluation program and Superoptimization Benchmark of synthesis problems, experimental data, code for scraping new synthesis problems, input binaries for scraping, chart generating scripts, and other support scripts.</p>

},
keywords = {binary code, program synthesis, restart algorithms, superoptimization}
}

@software{10.1145/3410299,
author = {Acay, Co\c{s}ku and Recto, Rolph and Gancher, Joshua and Myers, Andrew C. and Shi, Elaine},
title = {Replication Package for Viaduct: An Extensible, Optimizing Compiler for Secure Distributed Programs},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410299},
abstract = {
    <p>This artifact contains code and instructions necessary to replicate experimental results in the article “Viaduct: An Extensible, Optimizing Compiler for Secure Distributed Programs.” We provide a Docker image with the Viaduct compiler and all its dependencies installed, as well as the code samples used in the evaluation. The image also includes scripts for running the experiments from the paper.</p>

},
keywords = {information flow, multiparty computation, zero knowledge}
}

@software{10.1145/3410300,
author = {Wang, Di and Hoffmann, Jan and Reps, Thomas},
title = {Replication Package for Article: Sound Probabilistic Inference via Guide Types},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410300},
abstract = {
    <p>This artifact provides an implementation of a probabilistic programming language that (i) features a coroutine-based paradigm for implementing generative models and custom inference guides (e.g., proposals for importance sampling), and (ii) uses a novel guide-type system to ensure that the distributions specified by a model and its guide have the same support; as a consequence, the model-guide pair is provably sound for probabilistic inference.</p>

},
keywords = {Bayesian inference, coroutines, Probabilistic programming, type systems}
}

@software{10.1145/3410301,
author = {Saad, Feras A. and Rinard, Martin C. and Mansinghka, Vikash K.},
title = {System Implementation and Experiments for SPPL: Probabilistic Programming with Fast Exact Symbolic Inference},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410301},
abstract = {
    <p>This artifact contains an implementation of the SPPL programming language (version 2.0.0), as well as code for experimental results and tutorial figures described in the paper.</p>

},
keywords = {probabilistic programming, symbolic execution}
}

@software{10.1145/3410302,
author = {Ellis, Kevin and Wong, Catherine and Nye, Maxwell and Sabl\'{e}-Meyer, Mathias and Morales, Lucas and Hewitt, Luke and Cary, Luc and Solar-Lezama, Armando and Tenenbaum, Joshua B.},
title = {DreamCoder software and data},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410302},
abstract = {
    <p>Source code for DreamCoder, pretrained checkpoints, and documentation</p>

},
keywords = {artificial intelligence, deep learning, program synthesis}
}

@software{10.1145/3410303,
author = {Nikolaev, Ruslan and Ravindran, Binoy},
title = {Replication Package for Article: Snapshot-Free, Transparent, and Robust Memory Reclamation for Lock-Free Data Structures},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410303},
abstract = {
    <p>The artifact contains a VM image (VirtualBox) with preinstalled Ubuntu 18.04 and the (precompiled) benchmark. The artifact also contains source code and instructions for manual (bare-metal) installations. The artifact also includes our data measurements and scripts for generating plots. Please see README.txt for more details.</p>

},
keywords = {epoch-based reclamation, hazard pointers, lock-free, memory reclamation, non-blocking}
}

@software{10.1145/3410304,
author = {Chatterjee, Krishnendu and Goharshady, Ehsan Kafshdar and Novotn\'{y}, Petr and \v{Z}ikeli\'{c}, undefinedor\dj{}e},
title = {RevTerm},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410304},
abstract = {
    <p>RevTerm is a static analysis tool for proving non-termination of integer C programs (possibly with non-determinism). RevTerm is an implementation of our method for non-termination proving presented in the paper “Proving Non-termination by Program Reversal”.</p>

},
keywords = {Program Termination, Static Analysis}
}

@software{10.1145/3410305,
author = {Malik, Raghav and Singhal, Vidush and Gottfried, Benjamin and Kulkarni, Milind},
title = {COPSE artifact for Vectorized Secure Evaluation of Decision Forests},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410305},
abstract = {
    <p>The artifact is a Docker image that contains prebuilt versions of the benchmarks used to evaluate the paper, as well as a set of scripts to automatically run them and collect data.</p>

},
keywords = {Fully homomorphic encryption, vectorization}
}

@software{10.1145/3410306,
author = {Koenig, J\'{e}r\'{e}mie and Shao, Zhong},
title = {Source code and virtual machine image for CompCertO: Compiling Certified Open C Components},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410306},
abstract = {
    <p>This artifact contains the source code for CompCertO v0.1 and a virtual machine image where all required dependencies have been installed on a Debian GNU/Linux system. The virtual machine image also contains a pre-built version of CompCertO and its documentation, which can immediately be browsed in CoqIDE and Firefox.</p>

},
keywords = {CompCert, Compilers, Compositional compiler correctness, Game semantics, Language interface, Simulation convention, Software verification}
}

@software{10.1145/3410307,
author = {Thakkar, Aalok and Naik, Aaditya and Sands, Nathaniel and Alur, Rajeev and Naik, Mayur and Raghothaman, Mukund},
title = {Example-Guided Synthesis of Relational Queries},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410307},
abstract = {
    <p>Tool for end-to-end automated synthesis of relational queries from input-output examples.</p>

},
keywords = {Program Synthesis, Programming-by-example}
}

@software{10.1145/3410308,
author = {Mirman, Matthew and H\"{a}gele, Alexander and Bielik, Pavol and Gehr, Timon and Vechev, Martin},
title = {Replication Package for Robustness Certification with Generative Models},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410308},
abstract = {
    <p>This is the code necessary to reproduce the experiments found within the paper.</p>

},
keywords = {Abstract Interpretation, Deep Learning, Verification}
}

@software{10.1145/3410309,
author = {Zuo, Gefei and Ma, Jiacheng and Quinn, Andrew and Bhatotia, Pramod and Fonseca, Pedro and Kasikci, Baris},
title = {Software Artifacts for Paper: "Execution Reconstruction: Harnessing Failure Reoccurrences for Failure Reproduction "},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410309},
abstract = {
    <p>Components: 1. README.txt: instructions to walk through the artifact. 2. er-docker.tar.gz: the docker image of the main artifact Inside the docker image, /ER is a snapshot of our source code repository: a. Sherperded Symbolic Execution: modified based on KLEE. (1) <a href="/do/10.1145/3410309/export-citation-abs/lib/">Symbolic Execution Engine</a> (2) <a href="/do/10.1145/3410309/export-citation-abs/runtime/POSIX">POSIX runtime</a> b. Key Data Value Selection: (1) KLEE Constraint Graph to DOT or JSON <a href="/do/10.1145/3410309/export-citation-abs/tools/kleaver">converter</a> (2) Constraint Graph visualization: DOT viewer <a href="https://gephi.org/">Gephi</a> (external tool), <a href="/do/10.1145/3410309/export-citation-abs/utils/visualize/hase.py">Gephi python plugin for better visualization</a> (3) <a href="/do/10.1145/3410309/export-citation-abs/utils/visualize/hase.py">Graph analysis script</a> c.&nbsp;Data Recording (PTWrite) Instrumentation: (1) <a href="/do/10.1145/3410309/export-citation-abs/tools/prepass">cmdline tool</a> (2) <a href="/do/10.1145/3410309/export-citation-abs/lib/Module/PTWritePass.cpp">instrumentation pass</a> d.&nbsp;Software Execution Trace: <a href="/do/10.1145/3410309/export-citation-abs/tools/pathviewer">examination tool</a> e. <a href="/do/10.1145/3410309/export-citation-abs/artifact/">Artifact and Docker image building instructions</a> 3. LICENSE: Software license of ER and its dependencies.</p>
<p>Purpose: ER is a hybrid failure reproduction tool utilizing symbolic execution and record/replay. At runtime, ER collects control-flow traces of reoccurring failures and incrementally traces selective data values everytime failure reoccurs. At offline, ER runs symbolic execution (KLEE) to gather path constraints of the failure-incurring input and reconstruct input data by constraint solving. When the path constraints become too complex for solver to reason, ER analyzes the constraint and instruct runtime data tracing to also record data which if known can simplify the complex constraint.</p>
<p>After such iterative procedures of online tracing and offline symbolic execution, ER generates the failure-incurring input which is guaranteed to reproduce the reoccurring failure.</p>

},
keywords = {debugging, klee, symbolic execution}
}

@software{10.1145/3410310,
author = {Wang, Jinyi and Sun, Yican and Fu, Hongfei and Chatterjee, Krishnendu and Goharshady, Amir Kafshdar},
title = {Replication Package for Article: Quantitative Analysis of Assertion Violations in Probabilistic Programs},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410310},
abstract = {
    <p>This artifact contains our implementation of three synthesis algorithms as described in the paper. Algorithm 1&amp;2 are listed in section 5.1 \&amp; 5.2 and Algorithm 3 is in section 6.</p>

},
keywords = {Assertion, Automated Verification, Probabilistic Programs}
}

@software{10.1145/3410311,
author = {Basu, Nilanjana and Montanari, Claudio and Eriksson, Jakob},
title = {Replication Package for Frequent Background Polling on a Shared Thread, using Light-Weight Compiler Interrupts},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410311},
abstract = {
    <p>The artifact contains the libraries for a Compiler Interrupt pass, \&amp; the code for all experiments reported in the paper.</p>

},
keywords = {Compiler Interrupts, interrupt accuracy and overhead}
}

@software{10.1145/3410312,
author = {Sivaramakrishnan, KC and Dolan, Stephen and White, Leo and Kelly, Tom and Jaffer, Sadiq and Madhavapeddy, Anil},
title = {Replication Package for Article: Retrofitting Effect Handlers onto OCaml},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410312},
abstract = {
    <p>The artifact contains all the materials needed to reproduce and extend the results of the work. It includes the Multicore OCaml compiler, package dependencies, benchmarks, and the scripts to run and produce the results from the paper.</p>

},
keywords = {Concurrency, Effect handlers, Generators, OCaml, Web server}
}

@software{10.1145/3410313,
author = {Zhu, Shaowei and Kincaid, Zachary},
title = {Replication Package for Article: Termination Analysis without the Tears},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410313},
abstract = {
    <p>The artifact is a virtual machine that contains ComPACT, a compositional and monotone termination analysis for C programs. The virtual machine also contains all softwares and their dependencies required to replicate the experimental results of PLDI 2021 paper “Termination Analysis without the Tears”.</p>

},
keywords = {algebraic path problems, Algebraic program analysis, loop summarization, termination analysis}
}

@software{10.1145/3462276,
author = {Omar, Cyrus and Moon, David and Blinn, Andrew and Voysey, Ian and Collins, Nick and Chugh, Ravi},
title = {Evaluted Artifact for: Filling Typed Holes with Live GUIs},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462276},
abstract = {
    <p>Agda proofs and snapshot of Hazel implementation described in the paper.</p>

},
keywords = {GUIs, live programming, macros, typed holes}
}

@software{10.1145/3462278,
author = {Zhao, Jie and Li, Bojie and Nie, Wang and Geng, Zhen and Zhang, Renwei and Gao, Xiong and Cheng, Bin and Wu, Chen and Cheng, Yun and Li, Zheng and Di, Peng and Zhang, Kun and Jin, Xuefeng},
title = {Replication Package for Article: AKG: Automatic Kernel Generation for Neural Processing Units using Polyhedral Transformations},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462278},
abstract = {
    <p>This is the artifact description for our paper “AKG: Automatic Kernel Generation for Neural Processing Units using Polyhedral Transformations”. Our paper presents a fully automatic framework that automatically deploys and tunes deep learning models on NPUs and the target for the experiment is a Huawei Acend910 accelerator. The best way to perform the artifact evaluation is to purchase such an accelerator. One can also ask for a remotely accessible server from Huawei that has been equipped with a kc_air port to allow for the artifact evaluation. The kc_air port provides a RPC (Remote Procedure Call) mechanism on top of an x86 machine and can be used to evaluate some of the results described in the paper.</p>
<p>We recorded the numbers of cycles for each benchmark used in the experiment and compared the performance with two approaches, TVM and the Huawei Ascend libraries. The relation between the number of cycles and 1 microsecond has been formulated under Figure 11 of the paper. The standard TVM cannot be applied to generate code for the Huawei Ascend910 chips. The TVM version is thus not the standard one developed by Tianqi Chen et al.&nbsp;but has been adapted by the engineers of Huawei. We refer to this adapted version as Huawei TVM in the following context. We cannot provide the code or schedule templates generated by Huawei TVM and the vendor libraries because these may violate the to Huawei’s confidentiality agreements. We feel very sorry about this.</p>
<p>However, we have asked for the permission from the company and tried our best to make this artifact evaluation as functional as described in our paper. In this artifact description, we mainly focus on the generated code of our framework: one is allowed to play with our tool by generating code and running the examples used in the experiment of our paper.</p>

},
keywords = {auto-tuning, Deep neural networks, neural processing units, polyhedral model, TVM}
}

@software{10.1184/R1/14356976,
author = {Takashima, Yoshiki and Martins, Ruben and Jia, Limin and P\u{a}s\u{a}reanu, Corina S.},
title = {SyRust Artifact: PLDI2021 Artifact},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1184/R1/14356976},
abstract = {
    <p>This artifact contains software required to replicate the results of the paper “SyRust: Automatic Testing of Rust Libraries with Semantic-Aware Program Synthesis” published at PLDI 2021.</p>
<p>The artifact consists of SyRust source code, configuration files to fully replicate our experiments, post-processing scripts to summarize data, and docker images for maintaining and environment for replicability.</p>

},
keywords = {API Testing, Rust, Security, Software Engineering, Synthesis}
}

@software{10.5281/zenodo.4649822,
author = {Sammler, Michael and Lepigre, Rodolphe and Krebbers, Robbert and Memarian, Kayvan and Dreyer, Derek and Garg, Deepak},
title = {Artifact and Appendix of "RefinedC: Automating the Foundational Verification of C Code with Refined Ownership Types"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4649822},
abstract = {
    <p>This is the artifact for the PLDI’21 paper “RefinedC: Automating the Foundational Verification of C Code with Refined Ownership Types”. It contains the RefinedC tool including its Coq development and the appendix for the paper.</p>

},
keywords = {C programming language, Coq, Iris, ownership types, proof automation, refinement types, separation logic}
}

@software{10.5281/zenodo.4663105,
author = {Kostyukov, Yurii and Mordvinov, Dmitry and Fedyukovich, Grigory},
title = {Artifact Evaluation for "Beyond the Elementary Representations of Program Invariants over Algebraic Data Types" paper},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4663105},
abstract = {
    <p>An <code>Ubuntu20.04.ova</code> file provided is the VM snapshot with an artifact installed.</p>
<p>The artifact is provided to support the result of the Evaluation section of the paper “Beyond the Elementary Representations of Program Invariants over Algebraic Data Types” submitted to PLDI 2021.</p>
<p>Paper results reproduction instructions are contained in the <code>README.txt</code> file.</p>

},
keywords = {algebraic data types, finite models, first-order definability, invariant representation, invariants, tree automata}
}

@software{10.5281/zenodo.4663292,
author = {Stein, Benno and Chang, Bor-Yuh Evan and Sridharan, Manu},
title = {Artifact for Article: Demanded Abstract Interpretation},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4663292},
abstract = {
    <p>The artifact is a docker image containing source code and binaries needed to reproduce the paper’s experiments.</p>

},
keywords = {Abstract interpretation, demand-driven analysis, incremental analysis}
}

@software{10.5281/zenodo.4665859,
author = {Paradis, Anouk and Bichsel, Benjamin and Steffen, Samuel and Vechev, Martin},
title = {Replication Package for Article: Unqomp: Synthesizing Uncomputation in Quantum Circuits},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4665859},
abstract = {
    <p>This is a snapshot of Unqomp, providing the artifact for the PLDI’21 paper “Unqomp: Synthesizing Uncomputation in Quantum Circuits”. For the latest version of Unqomp, refer to https://github.com/eth-sri/Unqomp.</p>
<p>It contains the implementation of Unqomp for Qiskit, as well as all the necessary material to reproduce the evaluation of our paper.</p>

},
keywords = {Quantum Circuits, Synthesis, Uncomputation}
}

@software{10.5281/zenodo.4668317,
author = {Shariffdeen, Ridwan and Noller, Yannic and Grunske, Lars and Roychoudhury, Abhik},
title = {Replication Package for: Concolic Program Repair},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4668317},
abstract = {
    <p>This is the artifact for the PLDI’2021 submission “Concolic Program Repair”. It includes the following content: * the tool CPR, which implements our concolic program repair concept, * all benchmark subjects and scripts to reproduce our evaluation, and * additional documentation to allow the re-usage of CPR, as well as helpful examples.</p>

},
keywords = {patch overfitting, program repair, program synthesis, symbolic execution}
}

@software{10.5281/zenodo.4671078,
author = {Ringer, Talia and Porter, RanDair and Yazdani, Nathaniel and Leo, John and Grossman, Dan},
title = {PUMPKIN Pi},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4671078},
abstract = {
    <p>This is the artifact for the PLDI 2021 paper “Proof Repair Across Type Equivalences.” The anonymized version has been vetted by AEC as functional and reusable. A deanonymized version corresponding to the links in the paper has been uploaded as a second version (version “deanonymized”).</p>

},
keywords = {Coq, interactive theorem provers, proof assistants, proof engineering, proof evolution, proof repair}
}

@software{10.5281/zenodo.4674301,
author = {P\^{\i}rlea, George and Kumar, Amrit and Sergey, Ilya},
title = {CoSplit (PLDI 2021 Artefact)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4674301},
abstract = {
    <p>Virtual machine: The CoSplit.ova file is a virtual machine image containing the full artefact, including the CoSplit static analysis, its integration with the Zilliqa blockchain, the benchmark suite used for evaluation, the Ethereum dataset, and the Jupyter notebook used to analyse the dataset. This is the artefact that was evaluated during the PLDI 2021 Artifact Evaluation process.</p>
<p>The virtual machine image was generated using Virtual Box Version 6.1.18 r142142 and is known to work with that version of the software.</p>
<p>Source code: Please download cosplit-artefact-archive.zip. This includes the full source code, including dependencies, and the Ethereum dataset. The archive produced by GitHub (dranov/cosplit-artefact-v0.1-beta.zip) does not include the dependencies and dataset.</p>

},
keywords = {automatic parallelisation, blockchain, sharding, smart contracts, static analysis}
}

@software{10.5281/zenodo.4678051,
author = {Ye, Guixin and Tang, Zhanyong and Tan, Shin Hwei and Huang, Songfang and Fang, Dingyi and Sun, Xiaoyang and Bian, Lizhong and Wang, Haibo and Wang, Zheng},
title = {COMFORT: v1.0},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4678051},
abstract = {
    <p>COMFORT is a deep-learning-based compiler fuzzer for testing JavaScript engine bugs, including conformance bugs (JS compiler implementations that violate a specification defined in the relevant ECMAScript-262 standard). The corresponding research paper, “Automated Conformance Testing for JavaScript Engines via Deep Compiler Fuzzing,” appeared in PLDI 2021.</p>

},
keywords = {Compiler Fuzzing, Conformance bugs, Deep Learning, JavaScript}
}

@software{10.5281/zenodo.4678459,
author = {Tao, Runzhou and Shi, Yunong and Yao, Jianan and Hui, John and Chong, Frederic T. and Gu, Ronghui},
title = {Artifact for PLDI 2021 Paper Gleipnir: Toward Practical Error Analysis for Quantum Programs},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4678459},
abstract = {
    <p>Artifact for PLDI 2021 Paper Gleipnir: Toward Practical Error Analysis for Quantum Programs The artifact contains the docker image file needed to reproduce the results presented in the paper.</p>

},
keywords = {approximate computing, error analysis, Quantum programming}
}

@software{10.5281/zenodo.4678520,
author = {Xu, Dongpeng and Liu, Binbin and Feng, Weijie and Ming, Jiang and Zheng, Qilong and Li, Jing and Yu, Qiaoyan},
title = {Artifact Evaluation for "Boosting SMT Solver Performance on Mixed-Bitwise-Arithmetic Expressions"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4678520},
abstract = {
    <p>The artifact is for evaluating the result from the paper “Boosting SMT Solver Performance on Mixed-Bitwise-Arithmetic Expressions.” Please read the README file before you run the program.</p>

},
keywords = {Mixed Boolean Arithmetic, Simplification, SMT Solvers}
}

@software{10.5281/zenodo.4679316,
author = {Kalhauge, Christian Gram and Palsberg, Jens},
title = {Artifact from "Logical Bytecode Reduction"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4679316},
abstract = {
    <p>The artifact is a Virtual Box containing the results and everything to reproduce the results of the paper. Furthermore, it contains the source code of jreduce.</p>
<p>More information can be found in the REAMDE file in the artifact or at https://github.com/ucla-pls/pldi21-artifact/blob/master/README.md</p>

},
keywords = {input reduction}
}

@software{10.5281/zenodo.4679743,
author = {Itzhaky, Shachar and Peleg, Hila and Polikarpova, Nadia and Rowe, Reuben N. S. and Sergey, Ilya},
title = {Cypress (PLDI 2021 Artifact): Code and Benchmarks},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4679743},
abstract = {
    <p>Artifact accompanying the the paper Cyclic Program Synthesis published in proceedings of PLDI 2021.</p>

},
keywords = {cyclic proofs, program synthesis, program verification, separation logic}
}

@software{10.5281/zenodo.4679931,
author = {Cho, Minki and Lee, Sung-Hwan and Hur, Chung-Kil and Lahav, Ori},
title = {Artifact for the paper "Modular Data-Race-Freedom Guarantees in the Promising Semantics"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4679931},
abstract = {
    <p>The artifact for the paper “Modular Data-Race-Freedom Guarantees in the Promising Semantics” (PLDI 2021). It contains mechanized proofs in Coq and script code for performance evaulation.</p>

},
keywords = {Compiler Optimizations, Data Race Freedom, Operational Semantics, Relaxed Memory Concurrency}
}

@software{10.5281/zenodo.4679983,
author = {Christensen, Michael and Sherwood, Timothy and Balkind, Jonathan and Hardekopf, Ben},
title = {Replication Package for Artifact: "Wire Sorts: A Language Abstraction for Safe Hardware Composition"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4679983},
abstract = {
    <p>This artifact contains the code for reproducing the results in the paper “Wire Sorts: A Language Abstraction for Safe Hardware Composition.” Its purpose is to demonstrate how our tool can analyze and annotate hardware modules in order to determine their input and output wire sorts (and check these sorts against any user ascriptions), as well as use these sorts to improve intermodular connection checks.</p>

},
keywords = {combinational cycle detection, composition, hardware description languages, modules}
}

@software{10.5281/zenodo.4680045,
author = {Vega, Luis and McMahan, Joseph and Sampson, Adrian and Grossman, Dan and Ceze, Luis},
title = {Replication package for Reticle: A Virtual Machine for Programming Modern FPGAs},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4680045},
abstract = {
    <p>Virtual machine image containing all necessary dependencies for running the evaluation in the paper</p>

},
keywords = {compilers, FPGAs}
}

@software{10.5281/zenodo.4680245,
author = {Friedman, Michal and Petrank, Erez and Ramalhete, Pedro},
title = {Mirror: Making Lock-Free Data Structures Persistent},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4680245},
abstract = {
    <p>This artifact provides a way to test different concurrent, persistent and lock-free data structures that were specifically designed for non-volatile memory.</p>

},
keywords = {concurrent data structures, lock-free, Non-volatile memory}
}

@software{10.5281/zenodo.4680470,
author = {Donaldson, Alastair F. and Thomson, Paul and Teliman, Vasyl and Milizia, Stefano and Maselco, Andr\'{e} Perez and Karpi\'{n}ski, Antoni},
title = {Artifact for "Test-Case Reduction and Deduplication Almost for Free with Transformation-Based Compiler Testing", PLDI 2021},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4680470},
abstract = {
    <p>Artifact associated with PLDI paper, providing the version of the spirv-fuzz tool that was used for evaluation in the paper, together with the ability to reproduce a number of results using the SwiftShader implementation of SPIR-V, as well as data sets associated with the full set of experiments reported in the paper.</p>

},
keywords = {Compilers, metamorphic testing, SPIR-V}
}

@software{10.5281/zenodo.4680746,
author = {Spies, Simon and G\"{a}her, Lennard and Gratzer, Daniel and Tassarotti, Joseph and Krebbers, Robbert and Dreyer, Derek and Birkedal, Lars},
title = {Coq Development for "Transfinite Iris: Resolving an Existential Dilemma of Step-Indexed Separation Logic"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4680746},
abstract = {
    <p>This is the artifact for the paper “Transfinite Iris: Resolving an Existential Dilemma of Step-Indexed Separation Logic”. It contains the Coq mechanization of Transfinite Iris, in particular its soundness proof, program logics, and the examples presented in the paper. The artifact contains the Transfinite Iris development both in a VM image with pre-built sources and as a .zip source archive.</p>

},
keywords = {Coq, Iris, mechanized proofs, separation logic, transfinite step-indexing}
}

@software{10.5281/zenodo.4681027,
author = {Castro-Perez, David and Ferreira, Francisco and Gheri, Lorenzo and Yoshida, Nobuko},
title = {Zooid: a DSL for Certified Multiparty Computation},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4681027},
abstract = {
    <p>This is the implementation and Coq mechanisation of the metathory of Multiparty Session Types (MPST) as described on the paper.</p>

},
keywords = {concur- rent processes, Coq, deadlock freedom, liveness, mechanisation, multiparty session types, protocol compliance}
}

@software{10.5281/zenodo.4681598,
author = {Lasser, Sam and Casinghino, Chris and Fisher, Kathleen and Roux, Cody},
title = {CoStar parser implementation, correctness proofs, and performance evaluation},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4681598},
abstract = {
    <p>Artifact submitted for evaluation along with the PLDI 2021 paper "CoStar: A Verified ALL(*) Parser."</p>

},
keywords = {interactive theorem proving, parsing}
}

@software{10.5281/zenodo.4682081,
author = {Liu, Bozhen and Liu, Peiming and Li, Yanze and Tsai, Chia-Che and Da Silva, Dilma and Huang, Jeff},
title = {Artifact: When Threads Meet Events: Efficient and Precise Static Race Detection with Origins},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4682081},
abstract = {
    <p>This is the artifact of O2 from paper “When Threads Meet Events: Efficient and Precise Static Race Detection with Origins” published in PLDI’21 (https://doi.org/10.1145/3453483.3454073). O2 detects data races in large complex multithreaded and event-driven software. O2 is powered by “origins”, an abstraction that unifies threads and events by treating them as entry points of code paths attributed with data pointers. We have implemented O2 for both C/C++ and JVM applications and applied it to a wide range of open source software (e.g., DaCapo Benchmarks, HDFS, Yarn, Zookeeper, Firefox Focus, Memcached, Linux kernel).</p>

},
keywords = {Data Race Detection, Origins, Pointer Analysis, Static Analysis}
}

@software{10.5281/zenodo.4682172,
author = {Bruno, Rodrigo and Jovanovic, Vojin and Wimmer, Christian and Alonso, Gustavo},
title = {Compiler-Assisted Object Inlining with Value Fields},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4682172},
abstract = {
    <p>Object Oriented Programming has flourished in many areas ranging from web-oriented microservices, data processing, to databases. However, while representing domain entities as objects is appealing to developers, it leads to high data fragmentation as data is loaded into applications as large collections of data objects, resulting in high memory footprint and poor locality.</p>
<p>To minimize memory footprint and increase memory locality, embedding the payload of an object into another object (object inlining) has been considered before but existing techniques present severe limitations that prevent it from becoming a widely adopted technique. We argue that object inlining is mostly useful to optimize the application data-path and that objects in the data-path have value semantics, which unlocks great potential for inlining objects. We therefore propose value fields, an abstraction which allows fields to be marked as having value semantics.</p>
<p>We implement value fields for GraalVM Native Image. Object inlining is implemented as a compiler pipeline phase that mutates both object layouts and application code to access inlined fields. Experimental evaluation shows that applying value fields in real-world frameworks such as Apache Spark, Spring Boot, and Micronaut, requires minimal or even no effort at all from developers. Results show improvements in throughput of up to 3x, memory footprint reduction of up to 40\% and reduced GC pause times of up to 35\%.</p>

},
keywords = {Compiler Optimization, Language Implementation, Memory Management, Object Oriented, Programming Runtime Systems}
}

@software{10.5281/zenodo.4682681,
author = {Prabhu, Sumanth and Fedyukovich, Grigory and Madhukar, Kumar and D'Souza, Deepak},
title = {Artifact for the paper Specification Synthesis with Constrained Horn Clauses},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4682681},
abstract = {
    <p>The artifact is a zip file consisting of: pldi21.ova - a VirtualBox image consisting of tools to reproduce the data from the paper pldi21.md5 - md5sum of pldi21.ova README - instructions on how to use the artifact</p>

},
keywords = {automated verification, inductive invariants, SMT solvers, specification synthesis}
}

@software{10.5281/zenodo.4682811,
author = {Beutner, Raven and Ong, Luke},
title = {Probabilistic Termination Analysis Tools for: On Probabilistic Termination of Functional Programs with Continuous Distributions},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4682811},
abstract = {
    <p>Tools for computing lower bounds on the probability of termination (called LowerBound) and verification of AST of non-affine recursive programs (called astnar) for programs with continuous distributions. The tools build upon the theoretical results in the PLDI paper “On Probabilistic Termination of Functional Programs with Continuous Distributions”.</p>

},
keywords = {almost-sure termination, functional programs, lower bounds, Probabilistic programs, termination}
}

@software{10.5281/zenodo.4685966,
author = {Lim, Jay P. and Nagarakatte, Santosh},
title = {High Performance Correctly Rounded Math Libraries for 32-bit Floating Point Representations},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4685966},
abstract = {
    <p>RLIBM-32 is both a math library that provides correctly rounded result for all inputs and tools used to generate the correct polynomials. The techniques behind the tools will be appearing at PLDI 2021. Currently, RLIBM-32 supports a number of elementary functions for float and posit32 representations.</p>
<h4 id="list-of-float-functions-supported-by-rlibm-32">List of float functions supported by RLIBM-32</h4>
<ol type="1">
<li><p>log(x), log2(x), log10(x)</p></li>
<li><p>exp(x), exp2(x), exp10(x)</p></li>
<li><p>sinh(x), cosh(x)</p></li>
<li><p>sinpi(x), cospi(x)</p></li>
</ol>
<h4 id="list-of-posit32-functions-supported-by-rlibm-32">List of posit32 functions supported by RLIBM-32</h4>
<ol type="1">
<li><p>log(x), log2(x), log10(x)</p></li>
<li><p>exp(x), exp2(x), exp10(x)</p></li>
<li><p>sinh(x), cosh(x)</p></li>
</ol>

},
keywords = {correctly rounded results, elementary functions, floating point, posits}
}

@software{10.5281/zenodo.4763118,
author = {Farzan, Azadeh and Nicolet, Victor},
title = {Phased Synthesis of Divide and Conquer Programs (Software Artifact)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4763118},
abstract = {
    <p>This software artifact implements the automatic methodology described in the paper. A README.md file has been provided with instructions on how to reproduce the results presented in the paper, as well as instructions on how to build the software from the provided sources.</p>

},
keywords = {Divide-And-Conquer Algorithms, Program Synthesis}
}

@software{10.1145/3462281,
author = {Paluri, Pavan Kumar and Dai, Guangli and Cheng, Albert Mo Kim},
title = {Replication Package for ARINC 653-Inspired Regularity-Based Resource Partitioning on Xen},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462281},
abstract = {
    <p>Artifact Description: This artifact encompasses the RRP-Xen Domain-0 user-space packages along with RRP-Xen compliant single and multi-core ARINC 653 scheduler prototypes that are to be run in Xen hypervisor kernel. In addition, this package also includes the tools and scripts for performing RRP-Xen latency throughput experiments.</p>

},
keywords = {ARINC 653, Operating Systems, Real-Time Systems, RRP, Virtualization, Xen}
}

@software{10.5281/zenodo.4697392,
author = {Schuster, Simon and W\"{a}gemann, Peter and Ulbrich, Peter and Schr\"{o}der-Preikschat, Wolfgang},
title = {PragMetis Source Code},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4697392},
abstract = {
    <p>This is the source code of the paper “Annotate Once - Analyze Anywhere: Context-Aware WCET Analysis by User-Defined Abstractions” [1]. Contains the modified T-Crest toolchain (llvm, clang, the platin WCET-analyzer and annotation language interpreter), distirbuted as a single derived work available under the GPLv3.</p>
<p>[1] Simon Schuster, Peter W\"{a}gemann, Peter Ulbrich, Wolfgang Schr\"{o}der-Preikschat. Annotate Once - Analyze Anywhere: Context-Aware WCET Analysis by User-Defined Abstractions. (to appear) In Proceedings of the 22nd International Conference on Languages, Compilers, and Tools for Embedded Systems (LCTES 2021)</p>

},
keywords = {annotations, pragmetis, source code, toolchain, wcet analysis}
}

@software{10.5281/zenodo.4698901,
author = {Pusz, Oskar and Dietrich, Christian and Lohmann, Daniel},
title = {Source Code and Evaluation Data for the Paper: Data-Flow–Sensitive Fault-Space Pruning for the Injection of Transient Hardware Faults},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4698901},
abstract = {
    <p>We provide the data-flow pruner (DFP) presented in our paper. First, we would like to describe the concrete evaluation scenario shortly. We use the fault-injection tool FAIL* (https://github.com/danceos/fail) and have extended it with our pruner. To evaluate DFP we ran FAIL* with a generic experiment after pruning the fault space with the well-known def-use pruner which is already implemented in FAIL<em>. After the execution of the campaign, FAIL</em> created a database with all relevant information about the programs under investigation as well as the results of the fault-injection campaign. The databases are the baseline of our evaluation and can be found in the database-dump/ directory.</p>

},
keywords = {bit flip, fault injection, fault-space pruning, functional correctness, reliability, single event upset}
}

@software{10.5281/zenodo.4737731,
author = {Monniaux, David and Six, Cyril},
title = {Replication package for "Simple, Light, Yet Formally Verified, Global Common Subexpression Elimination and Loop-Invariant Code Motion"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4737731},
abstract = {
    <p>A virtual machine in OVA (Open Virtualization) format containing * The version of CompCert used to perform the experiments, for compiling to x86-64, AArch64, Risc-V and Kalray KV3. * The benchmarks. * Scripts to recreate the tables and figures of the paper.</p>

},
keywords = {AArch64, common subexpression elimination, KV3, Polybench, Risc-V, verified compilation, x86-64}
}

@software{10.5281/zenodo.4740299,
author = {Cai, Xuyi and Wang, Ying and Zhang, Lei},
title = {Replication Package for Article: Optimus: Towards Optimal Layer-Fusion on Deep Learning Processors},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4740299},
abstract = {
    <p>This is the implementation of the paper “Optimus: Towards Optimal Layer-Fusion on Deep Learning Processors”</p>

},
keywords = {embedded processor, layer fusion, memory, neural network}
}

@software{10.5281/zenodo.4744197,
author = {Oh, Deok-Jae and Moon, Yaebin and Lee, Eojin and Ham, Tae Jun and Park, Yongjun and Lee, Jae W. and Ahn, Jung Ho},
title = {Replication Package for Article: MaPHeA: A Lightweight Memory Hierarchy-Aware Profile-Guided Heap Allocation Framework},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4744197},
abstract = {
    <p>MaPHeA (pronounced like “mafia”) is a lightweight memory hierarchy-aware profile-guided heap allocation framework. It is lightweight as it profiles the memory access information of an application via hardware-event sampling instead of heavyweight instrumentation. MaPHeA is memory hierarchy-aware by utilizing a data access profile, which provides detailed information of a memory access, such as the address and the type of the access as well as where the data resides. Using this profiling information, it analyzes which heap objects are performance-critical. For example, MaPHeA can identify the objects that are frequently accessed (i.e., hot) from a certain memory hierarchy (e.g., LLC or main memory) or cause frequent TLB misses. Then, it can guide these hot data to be allocated to fast memory or allocate the TLB-miss-prone objects to a huge page. To realize this, we modify the intermediate representation of the gcc compiler and use a wrapper to replace the default malloc functions with the ones supporting tiered memory.</p>

},
keywords = {heap allocation, heterogeneous memory system, huge page, Profile-guided optimization}
}

@software{10.6084/m9.figshare.14544477,
author = {Rocha, Rodrigo C. O. and Petoumenos, Pavlos and Wang, Zheng and Cole, Murray and Hazelwood, Kim and Leather, Hugh},
title = {Replication Package for Article, "HyFM: Function Merging for Free"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.14544477},
abstract = {
    <p>This artifact contains a description of how to download and replicate the results achieved by the LCTES paper, titled “HyFM: Function Merging for Free”. It also includes the LLVM source code with the SalSSA and HyFM implementation.</p>

},
keywords = {Code-Size Reduction, Function Merging, Interprocedural Optimization, Link-Time Optimization, LLVM}
}

@software{10.1145/3462277,
author = {Renner, John and Sanchez-Stern, Alex and Brown, Fraser and Lerner, Sorin and Stefan, Deian},
title = {Source Code and Case Studies for Scooter \&amp; Sidecar: A Domain-Specific Approach to Writing Secure Database Migrations},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462277},
abstract = {
    <p>The artifact contains the full source code for scooter and sidecar as they were originally submitted to artifact evaluation. Furthermore, the artifact contains several case studies which are discussed in the paper.</p>

},
keywords = {database migration, scooter, sidecar, SMT, verification}
}

@software{10.1145/3462282,
author = {Bernardy, Jean-Philippe and Spiwack, Arnaud},
title = {Artefact for _Evaluating Linear Functions to Symmetric Monoidal Categories_},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462282},
abstract = {
    <p>You will find the following in this archive - The <a href="/do/10.1145/3462282/export-citation-abs/linear-smc/">linear-smc/</a> directory contains the source for the <code>linear-smc</code> library, which defines the port API described in the paper. The library can also be found on <a href="https://hackage.haskell.org/package/linear-smc-1.0.0">Hackage</a> - The <a href="/do/10.1145/3462282/export-citation-abs/linear-smc/examples/">examples/</a> directory contains fully worked out examples - The <code>docker-image.tar.gz</code> file contains a prepackaged Ubuntu-based Docker image with an appropriate version of GHC as well as a compiled version of the library.</p>

},
keywords = {Arrows, Embedded Domain-Specific Languages, Linear Types, Symmetric Monoidal Categories}
}

@software{10.1145/3462283,
author = {Keating, Finnbar and Gale, Michael B.},
title = {rearrange},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462283},
abstract = {
    <p>Haskell code for compile-time detection and resolution of data-flow dependencies.</p>

},
keywords = {data-flow dependence, graded monads, graphs, Haskell, type-level programming}
}

@software{10.1145/3462284,
author = {Teegen, Finn and Prott, Kai-Oliver and Bunkenburg, Niels},
title = {Inversion Plugin for the Glasgow Haskell Compiler (GHC)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462284},
abstract = {
    <p>This plugin for the Glasgow Haskell Compiler (GHC) automatically generates (partial) inverse functions for each definition in every module where the plugin is activated and enables the use of functional patterns in Haskell. It also contains some examples.</p>

},
keywords = {functional patterns, GHC plugin, Haskell, inversion, partial inversion}
}

@software{10.1145/3462285,
author = {Valliappan, Nachiappan and Russo, Alejandro and Lindley, Sam},
title = {Accompanying material: Practical Normalization by Evaluation for EDSLs},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462285},
abstract = {
    <p>Accompanying material that contains the complete Haskell source code and examples in the paper.</p>

},
keywords = {eDSL, Haskell, Normalization by Evaluation, Partial Evaluation}
}

@software{10.1145/3462286,
author = {Willis, Jamie and Wu, Nicolas},
title = {Demo code for "Design Patterns for Parser Combinators (Functional Pearl)"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462286},
abstract = {
    <p>This artifact contains the source code of the toy library Miniparsec, used to compile the examples in the Design Patterns for Parser Combinators paper, as well as the final example of the paper in full in a well-separated structure. The Main.hs file contains some example input that can be ran to observe the outcomes of the paper.</p>

},
keywords = {parser combinators}
}

@software{10.1145/3462287,
author = {Bailey, Toby and Gale, Michael B.},
title = {Chesskell},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462287},
abstract = {
    <p>Chesskell is a Haskell EDSL for describing games of Chess so that the types prevent invalid games from being described.</p>

},
keywords = {Chess, EDSL, First-Class Type Families, Haskell}
}

@software{10.1145/3462288,
author = {Ahmed, Khaled and Lis, Mieszko and Rubin, Julia},
title = {Slicer4J},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462288},
abstract = {
    <p>This is the implementation of Slicer4J, an accurate, low-overhead dynamic slicer for Java programs. Slicer4J automatically generates a backward dynamic slice from a user selected executed statement and variables used in the statement (slicing criterion). Slicer4J relies on soot which currently supports instrumenting programs compiled with up to Java 9.</p>

},
keywords = {dynamic slicing, Java, Program analysis}
}

@software{10.1145/3462289,
author = {Tong, Yanxiang and Qin, Yi and Jiang, Yanyan and Xu, Chang and Cao, Chun and Ma, Xiaoxing},
title = {MoD2: Model-guided Deviation Detector},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462289},
abstract = {
    <p>a tool for timely and accurate detection of model deviation</p>

},
keywords = {Control Theory, Model Deviation, Self-Adaptive Software}
}

@software{10.1145/3462290,
author = {Wang, Guancheng and Shen, Ruobing and Chen, Junjie and Xiong, Yingfei and Zhang, Lu},
title = {Artifact for article: Probabilistic Delta Debugging},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462290},
abstract = {
    <p>The artifact provides a package of the tools (ProbDD) and benchmarks for evaluation in our original paper (Probabilistic Delta Debugging). In our paper, we propose a delta debugging algorithm named ProbDD. Compared with the traditional method (i.e., ddmin), ProbDD models the probability of each element being selected in the optimal subsequence by building a probabilistic model to guide tests and updating the model based on the test results. By evaluating ProbDD on two representative approaches (i.e., HDD and CHISEL), our paper shows that ProbDD can improve the existing approaches in terms of effectiveness and efficiency by replacing ddmin with ProbDD. The artifact has two purposes. The first purpose is to reproduce the main results in our original paper. The baseline in our paper is ddmin algorithm, which is integrated into HDD and CHISEL (i.e., the tools used in our paper). For comparison between our algorithm (i.e., ProbDD) and ddmin, we replace ddmin module with ProbDD in HDD and CHISEL, respectively. In our paper, we used two benchmarks to evaluate ProbDD, i.e., Trees and C Programs. All the mentioned tools and benchmarks are contained in this artifact. We also provide a docker file for convenient reproduction. The users need to install Docker first and then get into the container by running the docker file. More details can be found in a README file of the artifact. The second is to provide an implementation of ProbDD that can be used for delta debugging tasks beyond the evaluation dataset. When a set of elements and a test function is provided, it reduces the elements to a smaller set. More details can be found in a README file of the artifact.</p>

},
keywords = {Delta Debugging, Probabilistic Model}
}

@software{10.1145/3462291,
author = {Chen, Tao and Li, Miqing},
title = {Package for Article: Multi-objectivizing Software Configuration Tuning},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462291},
abstract = {
    <p>We present the basic information needed to download, run, and then interpret the instructions we provide as requested in the ESEC/FSE 2021 Artifact Submission Guidelines. The artifact contains all the subject subjects, data, and a series of guidelines on how to use them.</p>

},
keywords = {Configuration tuning, multi-objectivization, performance optimization, search-based software engineering}
}

@software{10.1145/3462292,
author = {Shi, Lin and Chen, Xiao and Yang, Ye and Jiang, Hanzhi and Jiang, Ziyou and Niu, Nan and Wang, Qing},
title = {Data for article: A First Look at Developers’ Live Chat on Gitter},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462292},
abstract = {
    <p>The artifact contains a dataset including original chat history, automatically disentangled dialogs and manually disentangled dialogs. We hope that the data that we have uncovered will pave the way for other researches, help drive a more in-depth understanding of OSS development collaboration, and promote a better utilization and mining of knowledge embedded in the massive chat history.</p>

},
keywords = {Empirical Study, Live chat, Open source, Team communication}
}

@software{10.1145/3462293,
author = {Wang, Shangwen and Wen, Ming and Lin, Bo and Mao, Xiaoguang},
title = {Replication Package of the Article: Lightweight Global and Local Contexts Guided Method Name Recommendation with Prior Knowledge},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462293},
abstract = {
    <p>It contains the source code of Cognac and the detailed instructions on how to reproduce the study.</p>

},
keywords = {Code embedding, Deep learning, Method name recommendation}
}

@software{10.1145/3462294,
author = {Chen, Ke and Li, Yufei and Chen, Yingfeng and Fan, Changjie and Hu, Zhipeng and Yang, Wei},
title = {Replication Package for Article: GLIB: Towards Automated Test Oracle for Graphically-Rich Applications},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462294},
abstract = {
    <p>This artifact is the implementation for game UI glitch detection, users could either use our pre-trained model to directly detect game UI bugs or train from scratch. It also contains evaluation and salience map error localization.</p>

},
keywords = {Python, PyTorch}
}

@software{10.1145/3462295,
author = {Qiu, Zhengyi and Shao, Shudi and Zhao, Qi and Jin, Guoliang},
title = {ReqRacer: Dynamic framework for detecting and exposing server-side request races in database-backed web applications},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462295},
abstract = {
    <p>This artifact includes scripts to build PHP-Apache-MySQL stack, and ReqRacer source code to generate request logs, query logs, and token logs during the recording phase, off-line analysis scripts to detect potential request races, and scripts to replay racing requests and check the race effects. The artifact includes web application race bug characteristic study results and detailed steps to manually reproduing 12 race bugs in a browser. The artifact also includes links to demo video to help people quickly understand how to use ReqRacer after installation.</p>

},
keywords = {characteristic study, happens-before relationships, race detection, web-application request races}
}

@software{10.1145/3462296,
author = {Rabin, Md Rafiqul Islam and Hellendoorn, Vincent J. and Alipour, Mohammad Amin},
title = {Artifact for Article (SIVAND): Understanding Neural Code Intelligence Through Program Simplification},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462296},
abstract = {
    <p>This artifact contains the code of prediction-preserving simplification and the simplified data using DD module for our paper ‘Understanding Neural Code Intelligence Through Program Simplification’ accepted at ESEC/FSE’21. Delta Debugging (DD) was implemented with Python 2. We have modified the core modules (DD.py, MyDD.py) to run in Python 3 (i.e., Python 3.7.3), and then adopted the DD modules for prediction-preserving program simplification using different models. The approach, SIVAND, is model-agnostic and can be applied to any model by loading a model and making a prediction with the model for a task.</p>
<p>Following is the structure of the artifact:</p>
<p>├── ./ # code for model-agnostic DD framework ├── data/ ├── selected_input # randomly selected test inputs from different datasets ├── simplified_input # traces of simplified inputs for different models ├── summary_result # summary results of all experiments as csv ├── models/ ├── dd-code2seq # DD module with code2seq model ├── dd-code2vec # DD module with code2vec model ├── dd-great # DD module with RNN/Transformer model ├── others/ # related helper functions ├── save/ # images of SIVAND</p>
<p>How to Start: To apply SIVAND (for MethodName task as an example), first update <g_test_file> (path to a file that contains all selected inputs) and <g_deltas_type> (select token or char type delta for DD) in helper.py. Then, modify load_model_M() to load a target model (i.e., code2vec/code2seq) from <model_path>, and prediction_with_M() to get the predicted name, score, and loss value with <model> for an input <file_path>. Also, check whether <code> is parsable into is_parsable(), and load method by language (i.e.&nbsp;Java) from load_method(). Finally, run MyDD.py that will simplify programs one by one and save all simplified traces in the dd_data/ folder.</code></file_path></model></model_path></g_deltas_type></g_test_file></p><code>
<p>More Details: Check models/dd-code2vec/ and models/dd-code2seq/ folders to see how SIVAND works with code2vec and code2seq models for MethodName task on Java program. Similarly, for VarMisuse task (RNN \&amp; Transformer models, Python program), check the models/dd-great/ folder for our modified code.</p>

},
keywords = {Interpretable AI, Models of Code, Program Simplification}
}</code>

@software{10.1145/3462297,
author = {Pickard, Mitchell and Hutton, Graham},
title = {Agda Code for Article: Calculating Dependently-Typed Compilers (Functional Pearl)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462297},
abstract = {
    <p>This artifact contains the Agda calculations from the paper Calculating Dependently-Typed Compilers (Functional Pearl). The repository contains the three examples from the paper, plus a fourth example, a calculation for the Simply-Typed Lambda Calculus.</p>

},
keywords = {compilers, dependent types, program calculation, type theory}
}

@software{10.1145/3462298,
author = {Huang, Xuejing and Oliveira, Bruno C. d. S.},
title = {Replication Package for Article: Distributing Intersection and Union Types with Splits and Duality (Functional Pearl)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462298},
abstract = {
    <p>This artifact includes the Haskell code discussed in the paper and mechanical proofs that support the paper’s claims. For demonstration and reuse purposes, it contains a Coq library for the subtyping formulation presented in the paper, and three Haskell implementations of the subtyping algorithm. A Debian QEmu image is also provided with all the dependencies installed.</p>

},
keywords = {Coq, distributivity, Haskell, intersection types, subtyping, union types}
}

@software{10.1145/3462299,
author = {Serrano, Manuel},
title = {Replication package for article: Of JavaScript AOT Compilation Performance},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462299},
abstract = {
    <p>The artifact contains the Hop distribution where the Hopc ahead-of-time JavaScript compiler is included and the two benchmark suites that are described in the paper. The artifact installation procedure builds the compiler, compiles the benchmarks, and runs them all.</p>

},
keywords = {ahead-of-time, compilation, JavaScript, Scheme}
}

@software{10.1145/3462300,
author = {Fromherz, Aymeric and Rastogi, Aseem and Swamy, Nikhil and Gibson, Sydney and Mart\'{\i}nez, Guido and Merigoux, Denis and Ramananandro, Tahina},
title = {Artifact for Steel: Proof-Oriented Programming in a Dependently Typed Concurrent Separation Logic},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462300},
abstract = {
    <p>This artifact contains the F* development of the Steel framework presented in the corresponding ICFP 21 paper</p>

},
keywords = {Concurrency, Program Proofs, Separation Logic}
}

@software{10.1145/3462301,
author = {Krauter, Nicolas and Raaf, Patrick and Braam, Peter and Salkhordeh, Reza and Erdweg, Sebastian and Brinkmann, Andr\'{e}},
title = {Replication Package for Article: "Persistent Software Transactional Memory in Haskell"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462301},
abstract = {
    <p>This artifact provides the Haskell PSTM solution described in the article “Persistent Software Transactional Memory in Haskell”, as well as benchmark and demo applications that allow to reproduce our results and verify our claims. More specifically, the sources contain multiple components in separate sub-directories:</p>
<ul>
<li><em>ghc_pm</em> contains the adapted GHC version that offers PSTM and the persistent heap</li>
<li><em>ghc-8.10.1</em> provides the reference GHC version, slightly adapted to capture STM commit statistics</li>
<li><em>pstm</em> contains the Haskell definitions of our STM extension</li>
<li><em>haskell-benchs</em> contains the Haskell benchmark applications</li>
<li><em>mnemosyne-gcc</em> contains the used Mnemosyne benchmark applications we compared with</li>
<li><em>Onefile</em> contains the used Onefile benchmark applications we compared with</li>
<li><em>benchmarks</em> contains the scripts to run the benchmarks and is the entry point for reproducing the benchmark figures/tables</li>
<li><em>demos</em> contains some example applications showing how to use PSTM and demonstrate its laziness and persistence capabilities</li>
</ul>
<p>Building the complete environment from the sources, especially the contained GHC versions, can be very time-consuming. To avoid this process and allow long-term reproducibility, the QEMU-VM image (Debian) located in the <em>prebuilt</em> directory provides a ready-to-run environment for the benchmark and demo applications. Moreover, the directory contains a prebuilt Singularity container image that provides all OS-level dependencies for building from the sources directly. For more information on how to build, run or use the artifact, please refer to the contained README file(s).</p>

},
keywords = {non-volatile heap, persistent transactions, PM library comparison benchmarks}
}

@software{10.21979/N9/JKYYUD,
author = {Wu, Xiuheng and Zhu, Chenguang and Li, Yi},
title = {Replication Data for: DIFFBASE: A Differential Factbase for Effective Software Evolution Management},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.21979/N9/JKYYUD},
abstract = {
    <p>Numerous tools and techniques have been developed to extract and analyze information from software development artifacts. Yet, there is a lack of effective method to process, store, and exchange information among different analyses. DiffBase provides a uniform exchangeable representation supporting efficient querying and manipulation, based on the existing concept of program facts. We consider program changes as first-class objects, which establish links between intra-version facts of single program snapshots and provide insights on how certain artifacts evolve over time via inter-version facts. DiffBase includes a series of differential fact extractors and multiple software evolution management tasks have been implemented with DiffBase, demonstrating its usefulness and efficiency.</p>

},
keywords = {Program facts, Software evolution, Software maintenance}
}

@software{10.5281/zenodo.4771438,
author = {Li, Yao and Xia, Li-yao and Weirich, Stephanie},
title = {Artifact for Reasoning about the Garden of Forking Paths},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4771438},
abstract = {
    <p>This is the artifact for the ICFP’21 paper&nbsp;Reasoning about the garden of forking paths.</p>
<p>The source file of the artifact can also be found at:&nbsp;https://github.com/lastland/ClairvoyanceMonad</p>
<p>The artifact contains two files: the source Coq files (ClairvoyanceSrc.tar.gz) and a QEMU-based VM image that contains everything you need to run the proof scripts (ClairvoyanceVM.tar.gz). Detailed instructions on how to use them&nbsp;can be found in a README file within each individual package.</p>
<p>The abstract of the paper:</p>
<p>Lazy evaluation is a powerful tool for functional programmers. It enables the concise expression of on-demand computation and a form of compositionality not available under other evaluation strategies. However, the stateful nature of lazy evaluation makes it hard to analyze a program’s computational cost, either informally or formally. In this work, we present a novel and simple framework for formally reasoning about lazy computation costs based on a recent model of lazy evaluation: clairvoyant call-by-value. The key feature of our framework is its simplicity, as expressed by our definition of the clairvoyance monad. This monad is both simple to define (around 20 lines of Coq) and simple to reason about. We show that this monad can be effectively used to mechanically reason about the computational cost of lazy functional programs written in Coq.</p>

},
keywords = {computation cost, Coq, formal verification, lazy evaluation, monad}
}

@software{10.5281/zenodo.4774332,
author = {Chlipala, Adam},
title = {Code for "Skipping the Binder Bureaucracy with Mixed Embeddings in a Semantics Course (Functional Pearl)"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4774332},
abstract = {
    <p>The associated conference paper introduces a technique used in a course on mechanized semantics and program proof. This artifact is a snapshot of the course’s online textbook, including Coq code illustrating all the main ideas with examples.</p>

},
keywords = {binder encodings, Coq, mechanized semantics, program verification, proof assistants}
}

@software{10.5281/zenodo.4776802,
author = {Handa, Shivam and Kallas, Konstantinos and Vasilakis, Nikos and Rinard, Martin C.},
title = {Artifact for ``An Order-Aware Dataflow Model for Parallel Unix Pipelines''},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4776802},
abstract = {
    <p>The artifact contains the frozen icfp-ae branch of the PaSh git repository. PaSh aims at the correct and automated parallelization of POSIX shell scripts, and was used to generate the results presented in the paper. It includes three key components: (1) a compiler that, given as input a POSIX shell script, emits a POSIX shell script that includes explicit data-parallel fragments for which PaSh has deemed such parallelization semantics-preserving, (2) a set of PaSh-related runtime primitives for supporting the execution of the parallel script fragments, available as in the PATH as normal commands, and (3) a crowd-sourced library of annotations characterizing several properties of common Unix/Linux commands relevant to parallelization.</p>

},
keywords = {Dataflow, Order-awareness, Parallelism, POSIX, Scripting, Shell, Unix}
}

@software{10.5281/zenodo.4777196,
author = {Zakowski, Yannick and Beck, Calvin and Yoon, Irene and Zaichuk, Ilia and Zaliva, Vadim and Zdancewic, Steve},
title = {Specific release of the Vellvm project for the ICFP'21 paper titled: "Modular, Compositional, and Executable Formal Semantics for LLVM IR"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4777196},
abstract = {
    <p>This artifact contains a snapshot of the stable parts of the Vellvm project as described at the time of ICFP’21 in the “Modular, Compositional, and Executable Formal Semantics for LLVM IR”. It contains in particular: - the definition of our formal semantics for LLVM IR - the definition of the executable interpreter for LLVM IR - all the surrounding infrastructure (unverified parsers and interpreters, test suite, etc..) - the associated meta-theory: equational theory of the language, rewriting-based symbolic interpreter, proof of correctness of the interpreter w.r.t. the semantics - QuickChick-based test-infrastructure - Elementary verified optimizations</p>

},
keywords = {Coq, Denotational Semantics, LLVM IR, Verified Compiler}
}

@software{10.5281/zenodo.4777648,
author = {Li, John M. and Appel, Andrew W.},
title = {Replication Package for Article: Deriving Efficient Program Transformations from Rewrite Rules},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4777648},
abstract = {
    <p>The artifact contains (1) an implementation of the tool described in the paper “Deriving Efficient Program Transformations from Rewrite Rules”, (2) three examples that illustrate the use of the tool, and (3) a benchmark suite that supports claims in Section 5 of the paper. The tool is implemented in Coq and is bundled along with the Certicoq compiler.</p>

},
keywords = {compiler correctness, compiler optimization, domain-specific languages, interactive theorem proving, metaprogramming, shrink reduction}
}

@software{10.5281/zenodo.4818970,
author = {Maltbie, Nicholas and Niu, Nan and Van Doren, Matthew and Johnson, Reese},
title = {CSO Dataset Analysis for Article: XAI Tools in the Public Sector: A Case Study on Predicting Combined Sewer Overflows},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4818970},
abstract = {
    <p>This repository is provided as supplementary material for the paper “XAI Tools in the Public Sector: A Case Study on Predicting Combined Sewer Overflows” by Nicholas Maltbie, Nan Niu, Reese Johnson, and Matthew VanDoren.</p>
<p>These are the notes for the CSO case study, how the data is prepared, ML models are tuned and created, and the final interpretability analysis.</p>
<p>This repository contains instructions on how to use the code required to create models for the dataset and then how to apply these models to a sample dataset and gather expandability results for our research.</p>

},
keywords = {AI, Explainability, Goal Question Metric, LSTM, Machine Learning, Requirements Engineering}
}

@software{10.5281/zenodo.4835786,
author = {Soto-Valero, C\'{e}sar and Durieux, Thomas and Baudry, Benoit},
title = {Data and script for the paper "A Longitudinal Analysis of Bloated Java Dependencies"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4835786},
abstract = {
    <p>This repository contains the data and script for the paper “A Longitudinal Analysis of Bloated Java Dependencies”</p>
<p>Repository structure:</p>
<ul>
<li>dataset
<ul>
<li>projects.csv # list of 500 projects used in the paper</li>
<li>commits.csv # list of commits that are analyzed</li>
<li>project_dependabot.json # dependabot commits for each project</li>
<li>project_releases.json # commits associated to a release for each project</li>
</ul></li>
<li>dependency_usage_tree
<ul>
<li><project>
<ul>
<li><commit>
<ul>
<li>depclean.json # the dependency usage tree extracted by Deplean</li>
<li>compile.log.zip # Maven compilation log</li>
<li>depClean.log.zip # Deplean log</li>
</ul></commit></li>
</ul></project></li>
</ul></li>
<li>script
<ul>
<li>create_dataset.js # ceate projects.csv and commits.csv based on project_releases.json and project_dependabot.json</li>
<li>read_dependency_usage_tree.js # extract the information from dependency_usage_tree and generate a csv file</li>
<li>analysis.py # read dependency_usage_tree.csv and generate the macro and table for the paper</li>
</ul></li>
</ul>

},
keywords = {Dependencies, Java, Software bloat}
}

@software{10.5281/zenodo.4885001,
author = {Oh, Jeho and Y\i{}ld\i{}ran, Necip Faz\i{}l and Braha, Julian and Gazzillo, Paul},
title = {Artifact from "Finding Broken Linux Configuration Specifications by Statically Analyzing the Kconfig Language"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4885001},
abstract = {
    <p>Artifact from “Finding Broken Linux Configuration Specifications by Statically Analyzing the Kconfig Language”</p>

},
keywords = {formal verification, Kconfig, software configuration, static analysis}
}

@software{10.5281/zenodo.4888908,
author = {Sokolowski, Daniel and Weisenburger, Pascal and Salvaneschi, Guido},
title = {Automating Serverless Deployments for DevOps Organizations: Root Artifact},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4888908},
abstract = {
    <p>This artifact bundles all material supplementing:</p>
<p>[1] Daniel Sokolowski, Pascal Weisenburger, and Guido Salvaneschi. 2021. Automating Serverless Deployments for DevOps Organizations. In Proceedings of the 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE ’21), August 23–28, 2021, Athens, Greece. ACM, New York, NY, USA, 13 pages. https://doi.org/10.1145/3468264.3468575</p>
<ol type="1">
<li>Dependencies in DevOps Survey 2021</li>
</ol>
<p>https://doi.org/10.5281/zenodo.4873909 provides the dataset, a detailed report, and all analysis and content creation scripts for the contained technical report and all survey-related content in [1]. It supplements Section 2 in [1].</p>
<ol start="2" type="1">
<li>µs Infrastructure as Code</li>
</ol>
<p>https://doi.org/10.5281/zenodo.4902323 is the implementation of µs. It is reusable for IaC deployments and sets the base for future research on reactive IaC deployments. We suggest looking at the contained webpage example project and running it using the provided mjuz/mjuz Docker image. For this, follow the instructions in the README in the webpage’s subdirectory, showcasing an example setup using µs and plain Pulumi with both a centralized and a decentralized deployment. The “decentralized-mjuz” version uses the automated deployment coordination proposed in [1]. The Docker image is available on Docker Hub, but for long-term archiving, it is also included in this root artifact in mjuz-mjuz-docker-image.tar.zip. You can load and register it locally with the tags mjuz/mjuz:latest and mjuz/mjuz:1.0.0 by unzipping the file and running docker load -i mjuz-mjuz-docker-image.tar.</p>
<p>The µs implementation uses – and its Docker image builds upon – the Pulumi for µs CLI: https://doi.org/10.5281/zenodo.4902319. Its demonstration is already covered by the µs artifact in the previous paragraph; still, we include it here for completeness. Its Docker image is available on Docker Hub, too, and included in this artifact in mjuz-pulumi-docker-image.tar.zip. You can load and register it locally with the tags mjuz/pulumi:latest and mjuz/pulumi:1.0.0 by unzipping the file and running docker load -i mjuz-pulumi-docker-image.tar.</p>
<ol start="3" type="1">
<li>µs Performance Evaluation</li>
</ol>
<p>http://doi.org/10.5281/zenodo.4902330 contains the materials used for the performance evaluation of µs in Subsection 8.2 in [1]. It includes the deployment definitions, the measurement scripts, the measured data, and the scripts to generate the paper’s plots from the data.</p>
<ol start="4" type="1">
<li>Pulumi TypeScript Projects using Stack References</li>
</ol>
<p>https://doi.org/10.5281/zenodo.4878577 is the dataset of public GitHub repositories that contain Pulumi TypeScript projects using stack references. It supplements Subsection 8.3 in [1].</p>
<ol start="5" type="1">
<li>Pulumi TypeScript Stack References to µs Converter</li>
</ol>
<p>https://doi.org/10.5281/zenodo.4902171 converts existing stack references and outputs in Pulumi TypeScript projects to µs remotes, wishes, and offers. It supplements Subsection 8.3 in [1], where it is applied to the Pulumi TypeScript Projects using Stack References dataset.</p>

},
keywords = {DevOps, Infrastructure as Code, Software Dependencies, Software Engineering}
}

@software{10.5281/zenodo.4895186,
author = {Kahn, David M. and Hoffmann, Jan},
title = {Prototype Tool from Automatic Amortized Resource Analysis with the Quantum Physicist's Method},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4895186},
abstract = {
    <p>This is a QEmu image and source tarball for running the typechecker from “Automatic Amortized Resource Analysis with the Quantum Physicist’s Method”. The image comes with RaML and the Coin-Or LP solver pre-installed to recreate the experiments from the paper.</p>

},
keywords = {AARA, amortized analysis, automatic amortized resource analysis, physicist's method, potential method, quantum physicist's method, RaML, resource, resource aware ml, type, type inference, typechecker}
}

@software{10.5281/zenodo.4898774,
author = {Vierhauser, Michael and Islam, Md Nafee Al and Agrawal, Ankit and Cleland-Huang, Jane and Mason, James},
title = {Hazard Trees for Human-on-the-Loop Interactions in sUAS Systems},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4898774},
abstract = {
    <p>Traditional safety analysis for Cyber-Physical Systems in general, and for sUAS (small unmanned aerial systems) in particular, typically focuses on system-level hazards with little focus on user-related or user-induced hazards that can cause critical system failures. To address this issue, we have constructed domain-level safety analysis assets for sUAS applications following a rigorous process. In this process, we explicitly, and systematically identified Human Interaction Points (HiPs), Hazard Factors, and Mitigations from system hazards.</p>
<p>We have created eight different hazard trees, each covering a specific aspect of sUAS safety: Collisions: Addresses hazards related to collisions between sUAS, other objects, and terrain. Communication: Addresses hazards related to the loss of communication with sUAS during flight. Hardware/Sensors: Addresses hazards related to sUAS hardware such as cameras used for object detection, GPS, parachutes, etc. Mission Awareness: Addresses hazards related to a mission executed by an sUAS, its mission status, and decision-making during a mission. Mission Planning: Addresses hazards related to mission planning - before the mission is executed, such as planning and assigning flight routes and sUAS task allocation. Preflight Configuration: Addresses hazards related to preflight configuration properties such as geofence settings, or launch parameters. Regulatory Compliance: Addresses hazards related to airspace, flight constraints, and regulations for operating sUAS in an airspace. Weather: Addresses hazards related to weather conditions, temperature, wind or reduced visibility due to adverse weather conditions.</p>

},
keywords = {hazard analysis, Human-sUAS interaction, safety analysis, sUAS}
}

@software{10.5281/zenodo.4899710,
author = {Jiang, Yanjie and Liu, Hui and Zhang, Yuxia and Niu, Nan and Zhao, Yuhai and Zhang, Lu},
title = {Replication Package for smartExpander},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4899710},
abstract = {
    <p>SmartExpander is a tool to decide whether a given abbreviation needs to be expanded at all. The rationale of the approach is that abbreviations should not be expanded if the expansion would result in lengthy identifiers or if developers/maintainers can easily figure out the meaning of the abbreviations. Consequently, we design a sequence of heuristics according to the rationale to pick up such abbreviations that do not require expansion.</p>

},
keywords = {Abbreviation, Cliques, Data Mining, Expansion, Software Quality}
}

@software{10.5281/zenodo.4899935,
author = {Vu, Duc-Ly and Massacci, Fabio and Pashchenko, Ivan and Plate, Henrik and Sabetta, Antonino},
title = {LastPyMile Replication Package},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4899935},
abstract = {
    <p>The artifact consists of several CSV files generated by LastPyMile and the existing security scanning tools (e.g., bandit and PyPI MalwareChecks) and a Jupyter notebook to reproduce the table of comparison between LastPyMile and the current tools (Table 11 in the paper).</p>

},
keywords = {Open source software, PyPI, Python, software supply chain}
}

@software{10.5281/zenodo.4901843,
author = {Patra, Jibesh and Pradel, Michael},
title = {Source code package for 'Semantic Bug Seeding: A Learning-Based Approach for Creating Realistic Bugs'},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4901843},
abstract = {
    <p>The package contains source code and documentation that may be used to run experiments mentioned in the paper.</p>

},
keywords = {bug injection, bugs, dataset, machine learning, token embeddings}
}

@software{10.5281/zenodo.4902179,
author = {Luo, Yicheng and Filieri, Antonio and Zhou, Yuan},
title = {Replication Package for Paper: Symbolic Parallel Adaptive Importance Sampling for Probabilistic Program Analysis},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4902179},
abstract = {
    <p>Replication package and reference implementation for</p>
<p>Yicheng Luo, Antonio Filieri, and Yuan Zhou. Symbolic Parallel Adaptive Importance Sampling for Probabilistic Program Analysis. In Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2021). arXiv:2010.05050.</p>

},
keywords = {importance sampling, JAX, MCMC, probabilistic programming, symbolic execution}
}

@software{10.5281/zenodo.4902383,
author = {Su, Ting and Wang, Jue and Su, Zhendong},
title = {Replication Package for Article: Benchmarking Automated GUI Testing for Android against Real-World Bugs},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4902383},
abstract = {
    <p>Our artifact is named Themis. Themis is a collection of real-world, reproducible crash bugs (collected from open-source Android apps) and a unified, extensible infrastructure for benchmarking automated GUI testing for Android and beyond. Themis now contains 52 critical crash bugs and integrates six state-of-the-art/practice GUI testing tools.</p>

},
keywords = {Android apps, Benchmarking, Crash bugs, GUI testing}
}

@software{10.5281/zenodo.4902728,
author = {Zhang, Changjian and Wagner, Ryan and Orvalho, Pedro and Garlan, David and Manquinho, Vasco and Martins, Ruben and Kang, Eunsuk},
title = {Benchmark for Paper: AlloyMax: Bringing Maximum Satisfaction to Relational Specifications},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4902728},
abstract = {
    <p>This is the reproduction package of the benchmarks used in the work AlloyMax: Bringing Maximum Satisfaction to Relational Specifications. This package contains AlloyMax executable, the necessary libraries, the models used in the paper, and the scripts for running the benchmark.</p>

},
keywords = {Alloy, MaxSAT, Model synthesis, Relational specifications, SAT}
}

@software{10.5281/zenodo.4902806,
author = {Vasilakis, Nikos and Ntousakis, Grigoris and Heller, Veit and Rinard, Martin C.},
title = {Efficient Module-Level Dynamic Analysis for Dynamic Languages with Module Recontextualization (Lya Artifact)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4902806},
abstract = {
    <p>Lya uses a novel set of module transformation techniques, collectively termed module recontextualization, to bolt a high-performance analysis and instrumentation infrastructure onto a conventional production runtime. Lya achieves high performance by analyzing code at a coarser-that-usual granularity, meaning that Lya’s analyses operate at a lower resolution than conventional analysis frameworks but at a significantly better performance—enabling always-on operation on production environments. Such coarse-grained, high-performance analyses have been shown to infer useful information about the execution of multi-library programs. Examples include identifying security vulnerabilities, highlighting performance bottlenecks, and applying corrective actions.</p>

},
keywords = {Analysis, Dynamic, Instrumentation, Performance, Recontextualization, Runtime, Security}
}

@software{10.5281/zenodo.4902828,
author = {Chen, Tianyi and Heo, Kihong and Raghothaman, Mukund},
title = {Boosting Static Analysis Accuracy With Instrumented Test Executions (Paper Artifact)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4902828},
abstract = {
    <p>Artifact associated with the paper “Boosting Static Analysis Accuracy with Instrumented Test Executions”, recently accepted to FSE 2021.</p>

},
keywords = {alarm ranking, Bayesian inference, belief networks, dynamic analysis, Static analysis}
}

@software{10.5281/zenodo.4959920,
author = {Kate, Sayali and Chinn, Michael and Choi, Hongjun and Zhang, Xiangyu and Elbaum, Sebastian},
title = {Artifact for "PHYSFRAME: Type Checking Physical Frames of Reference for Robotic Systems"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4959920},
abstract = {
    <p><strong>Summary</strong></p>
<p>PHYSFRAME is a static analysis tool for detecting reference frame inconsistencies and violations of common practices (i.e., implicit frame conventions) in C/C++ projects that build against the <a href="http://www.ros.org/">Robot Operating System</a>. It requires nothing from the developers except running the tool on their project. The tool automatically models the project, and checks for problems.</p>
<p><strong>Contents</strong></p>
<p>This repository contains the following files and folders:</p>
<ul>
<li>README.md: This file.</li>
<li>LICENSE.txt: BSD 2-Clause license.</li>
<li>STATUS.txt: Describes the ACM artifact badges sought for this artifact.</li>
<li>REQUIREMENTS.md: Describes the hardware and software requirements.</li>
<li>INSTALL.txt: Describes how to install PHYSFRAME using Docker and a minimal working example.</li>
<li>HOWTO.txt: Describes how to use PHYSFRAME with the provided data.</li>
<li>HOWTO-WITH-SCRIPT.txt: Describes how to run scripts to evaluate PHYSFRAME with the provided data.</li>
<li>untar_data.sh: Script to untar files in data/.</li>
<li>evaluate_data.sh: Script to run PHYSFRAME on the provided data.</li>
<li>evaluate_z-score.sh: Script to run PHYSFRAME on the provided data with z-score = 2, 5 or 10.</li>
<li>Dockerfile: a Docker install file for PHYSFRAME.</li>
<li>requirements.txt: List of python dependencies required by PHYSFRAME. Referenced by the Dockerfile.</li>
<li>src/: The python source code for PHYSFRAME, files containing implicit frame conventions.</li>
<li>data/: Dataset of C/C++ projects (downloaded from public GitHub repositories) used to evaluate PHYSFRAME.</li>
<li>USER-GUIDE.txt: Helpful notes for user.</li>
</ul>

},
keywords = {Frame Consistency, Physical Frame of Reference, ROS, Static Analysis, Type Checking, z-score Mining}
}

@software{10.5281/zenodo.4968451,
author = {Houshmand, Farzin and Lesani, Mohsen and Vora, Keval},
title = {Artifact for article: "Grafs: Declarative Graph Analytics"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4968451},
abstract = {
    <p>Grafs is a synthesizer that automatically generates graph analytics code for five graph processing frameworks: Ligra [Shun and Blelloch 2013], GridGraph [Zhu et al.&nbsp;2015], PowerGraph [Gonzalez et al.&nbsp;2012], Gemini [Zhu et al. 2016], and GraphIt [Zhang et al.&nbsp;2018]. The package already contains the runtime for the frameworks.</p>

},
keywords = {Fusion, Graph Analytics, Synthesis}
}

@software{10.5281/zenodo.4968705,
author = {Mathew, George and Stolee, Kathryn T.},
title = {Code and Data Repository for Article: Cross-Language Code Search using Static and Dynamic Analyses},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4968705},
abstract = {
    <p>Code repository with code for the COSAL tool which performs code search across Java and Python. COSAL uses static and dynamic similarity measures to identify similar code across languages. For static similarity, COSAL uses token based and AST based similarity while it uses Input-Output behavior of code for dynamic similarity.</p>

},
keywords = {code-to-code search, cross-language code search, dynamic analysis, non-dominated sorting, static analysis}
}

@software{10.5281/zenodo.4970239,
author = {B\"{o}hme, Marcel and Liyanage, Danushka and W\"{u}stholz, Valentin},
title = {Estimating Residual Risk in Greybox Fuzzing - Artifacts},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4970239},
abstract = {
    <p>We make publicly available the tool used to produce the data, the data used to validate the claims made in the paper, and the simulation+evaluation scripts to produce from the data the figures shown in the paper. In the context of our paper, we conducted several simulation studies and evaluated the performance of the classical and proposed estimators of residual risk in the presence of adaptive bias in greybox fuzzing.</p>
<p>The data for the empirical evaluation were generated through fuzzing campaigns with a modified version of LibFuzzer. In this experimental setup, we establish ground truth for discovery probability to evaluate estimator performance with respect to the ground truth.</p>
<p>The workbooks and source code for experimental setup are available at https://github.com/Adaptive-Bias/fse21_paper270.</p>

},
keywords = {estimation, fuzzing, probability, software testing, statistics}
}

@software{10.5281/zenodo.4975033,
author = {Biswas, Sumon and Rajan, Hridesh},
title = {Replication Package for "Fair Preprocessing: Towards Understanding Compositional Fairness of Data Transformers in Machine Learning Pipeline"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4975033},
abstract = {
    <p>The artifact contains the benchmark, source code and data used in our ESEC/FSE 2021 paper on “Fair Preprocessing”. The benchmark can be used by other researchers and practitioners to evaluate the fairness of real-world machine learning (ML) pipelines collected from Kaggle. In addition, we released our implementation of the novel metrics proposed to measure component level fairness in the pipelines. The artifact also contains five popular datasets used in fairness research.</p>

},
keywords = {fairness, machine learning, models, pipeline, preprocessing}
}

@software{10.5281/zenodo.4988150,
author = {Kellogg, Martin and Shadab, Narges and Sridharan, Manu and Ernst, Michael D.},
title = {Artifact for "Lightweight and Modular Resource Leak Verification"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4988150},
abstract = {
    <p>This upload is a docker image containing the artifact accompanying our ESEC/FSE’21 paper “Lightweight and Modular Resource Leak Verification”.</p>
<p>To run the image,</p>
<p>0.) Install Docker following the directions at [https://www.docker.com/get-started] for your OS, if it is not already installed. We have tested the artifact with Docker Desktop on MacOS, but it should work for other operating systems.</p>
<p>1.) Unzip the provided Docker image. <code>gunzip -c path/to/resource-leak-checker.tar.gz &gt; resource-leak-checker.tar</code></p>
<p>2.) Load it into Docker. <code>docker load &lt; resource-leak-checker.tar</code></p>
<p>3.) Run the image. This should open a bash shell, at the home directory of user <code>fse</code>. <code>docker run -it msridhar/rlc:latest</code></p>
<p>Instructions for how to run the paper’s experiments are inside the container in the <code>object-construction-checker/fse-2021/README.md</code> file in the <code>fse</code> user’s home directory.</p>

},
keywords = {accumulation analysis, Pluggable type systems, resource leaks, static analysis, type- state analysis}
}

@software{10.5281/zenodo.5005829,
author = {Watanabe, Yasunari and Gopinathan, Kiran and P\^{\i}rlea, George and Polikarpova, Nadia and Sergey, Ilya},
title = {Certified SuSLik (ICFP 2021 Artifact): Code and Benchmarks},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5005829},
abstract = {
    <p>Artifact accompanying the the paper “Certifying the Synthesis of Heap-Manipulating Programs”, published in proceedings of ICFP 2021.</p>

},
keywords = {Mechanized Proofs, Program Synthesis, Proof Assistants, Separation Logic}
}

@software{10.5281/zenodo.5035645,
author = {Koparkar, Chaitanya and Rainey, Mike and Vollmer, Michael and Kulkarni, Milind and Newton, Ryan R.},
title = {Artifact for "Efficient Tree-Traversals: Reconciling Parallelism and Dense Data Representations"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5035645},
abstract = {
    <p>The artifact for our paper is the Gibbon compiler. Where the paper makes a distinction between “Parallel Gibbon” and “Sequential Gibbon”, here we will enable parallel execution by passing in command-line flags to the compiler, as the work presented in our paper was in fact an extension of work on the Gibbon project, but this was obscured by the double-blind requirement.</p>
<p>Besides the compiler, this artifact includes the benchmarks presented in the paper, and some scripts to run them on your machine.</p>

},
keywords = {compilers, data representation, parallelism}
}

@software{10.5281/zenodo.5037493,
author = {Rocha, Pedro and Caires, Lu\'{\i}s},
title = {Propositions-as-Types and Shared State (Artifact)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5037493},
abstract = {
    <p>This is the companion artifact for the <em>Propositions-as-Types and Shared State</em> (submission #97).</p>
<p>The artifact consists of a proof-of-concept type-checker and an interpreter for the language described in the paper. The interpreter is a fully (fine grain) concurrent runtime system, using the java threads library.</p>
<p>The artifact is distributed as a Debian QEmu image that bundles the source code, all its dependencies, the code examples from the paper and many other additional code examples and tests.</p>

},
keywords = {Propositions-as-Types, Session Types, Shared State}
}

@software{10.5281/zenodo.5043233,
author = {Yanovski, Joshua and Dang, Hoang-Hai and Jung, Ralf and Dreyer, Derek},
title = {GhostCell: Separating Permissions from Data in Rust (Artifact)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5043233},
abstract = {
    <p>This contains a snapshot of the GhostCell development. More updated information can be found at http://plv.mpi-sws.org/rustbelt/ghostcell/.</p>
<p>PAPER ABSTRACT</p>
<p>The Rust language offers a promising approach to safe systems programming based on the principle of aliasing XOR mutability: a value may be either aliased or mutable, but not both at the same time. However, to implement pointer-based data structures with internal sharing, such as graphs or doubly-linked lists, we need to be able to mutate aliased state. To support such data structures, Rust provides a number of APIs that offer so-called interior mutability: the ability to mutate data via method calls on a shared reference. Unfortunately, the existing APIs sacrifice flexibility, concurrent access, and/or performance, in exchange for safety.</p>
<p>In this paper, we propose a new Rust API called GhostCell which avoids such sacrifices by separating permissions from data: it enables the user to safely synchronize access to a collection of data via a single permission. GhostCell repurposes an old trick from typed functional programming: branded types (as exemplified by Haskell’s ST monad), which combine phantom types and rank-2 polymorphism to simulate a lightweight form of state-dependent types. We have formally proven the soundness of GhostCell by adapting and extending RustBelt, a semantic soundness proof for a representative subset of Rust, mechanized in Coq.</p>

},
keywords = {Coq, Iris, Rust, RustBelt}
}

@software{10.5281/zenodo.5054898,
author = {Birkedal, Lars and Dinsdale-Young, Thomas and Gu\'{e}neau, Arma\"{e}l and Jaber, Guilhem and Svendsen, Kasper and Tzevelekos, Nikos},
title = {Theorems for Free from Separation Logic Specifications: ICFP'21 artifact},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5054898},
abstract = {
    <p>This artifact contains the Coq formalization associated with the paper “Theorems for Free from Separation Logic Specifications”. It provides both a zip archive containing the source files (free-theorems-sl-archive.zip) and a QEmu VM image (VM.zip) which has been setup with the required dependencies and the source files, and can be used to run Coq to check the proof scripts.</p>

},
keywords = {coq, iris, linearizability, separation logic}
}

@software{10.5281/zenodo.5060213,
author = {Stucki, Sandro and Giarrusso, Paolo G.},
title = {A Theory of Higher-Order Subtyping with Type Intervals — Agda Formalization},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5060213},
abstract = {
    <p>This artifact contains the mathematical proofs for the associated paper, formalized in the Agda proof assistant, both as a source archive, and as a virtual machine image containing the necessary dependencies to check the proofs.</p>

},
keywords = {Agda, bounded polymorphism, bounded type operators, dependent kinds, hereditary substitution, higher-kinded types, Scala, singleton kinds, subtyping, type intervals, type safety}
}

@software{10.5281/zenodo.5064045,
author = {M\'{e}vel, Glen and Jourdan, Jacques-Henri},
title = {Formal Verification of a Concurrent Bounded Queue in a Weak Memory Model — proof artifact},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5064045},
abstract = {
    <p>This is the artifact that accompanies the paper “Formal Verification of a Concurrent Bounded Queue in a Weak Memory Model“, published at the ICFP 2021 conference.</p>
<p>The artifact consists in a set of Coq proof scripts. A plain source code archive is provided, as well as a virtual machine in which all dependencies are already installed and the project already compiled.</p>
<p>This project is developped in this git repository, which also contains the paper: https://gitlab.inria.fr/gmevel/cosmo</p>

},
keywords = {concurrency, concurrent queue, Coq, program verification, separation logic, weak memory}
}

@software{10.5281/zenodo.5081240,
author = {Zhang, Minjian and Mathur, Umang and Viswanathan, Mahesh},
title = {Replication of checking LTL[F,G,X] on compressed traces in polynomial time},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5081240},
abstract = {
    <p>The artifact contains all tools to reproduce the experiment result of the corresponding paper, which includes the algorithm introduced, manually encoded automata, graphs and formal descriptions of tested properties, and the compressed, uncompressed traces.</p>

},
keywords = {Model checking, software engineering, verification}
}

@software{10.5281/zenodo.5084000,
author = {Song, Dowon and Lee, Woosuk and Oh, Hakjoo},
title = {Replication Package for Article: Context-Aware and Data-Driven Feedback Generation for Programming Assignments},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5084000},
abstract = {
    <p>It is an artifact to reproduce the experimental results of the paper “Context-Aware and Data-Driven Feedback Generation for Programming Assignments”. The artifact contains the codes, benchmarks, and python scripts to reproduce the results easily.</p>
<p>The detailed description (e.g., Install, Usage) of the tool is available on the public repository: https://github.com/kupl/LearnML</p>

},
keywords = {Program Repair, Program Synthesis}
}

@software{10.5281/zenodo.5084364,
author = {An, Gabin and Yoo, Shin},
title = {Replication Package for Article: Reducing the Search Space of Bug Inducing Commits using Failure Coverage},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5084364},
abstract = {
    <p>This artifact contains a replication package accompanying the paper “Reducing the Search Space of Bug Inducing Commits using Failure Coverage”. It contains the full experimental results and provides a docker environment in which one can easily replicate the whole experiment described in the paper. The detailed guide to replication is provided in the artifact’s README.md file. It also provides a script for analyzing the experimental results to support the reproduction of all result figures in the paper.</p>

},
keywords = {Bug Inducing Commit, Code Coverage, Software Debugging, Test Coverage}
}

@software{10.5281/zenodo.5084655,
author = {Kuznetsov, Konstantin and Fu, Chen and Gao, Song and Jansen, David N. and Zhang, Lijun and Zeller, Andreas},
title = {Frontmatter dataset},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5084655},
abstract = {
    <p>This artifact represents the Frontmatter data set containing UI models (UI hierarchy and API calls) for about 160,000 Android applications, which was obtained with help of Frontmatter tool – a static analysis framework to automatically mine both user interface models and behavior of Android apps at a large scale with high precision. For apps that could not be processed the reason is given. The applications were downloaded from the AndroZoo repository.</p>

},
keywords = {Android, App mining, app stores, static analysis, user interfaces}
}

@software{10.5281/zenodo.5086293,
author = {Pei, Kexin and Guan, Jonas and Broughton, Matthew and Chen, Zhongtian and Yao, Songchen and Williams-King, David and Ummadisetty, Vikas and Yang, Junfeng and Ray, Baishakhi and Jana, Suman},
title = {Code for Article: StateFormer: Fine-Grained Type Recovery from Binaries using Generative State Modeling},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5086293},
abstract = {
    <p>StateFormer is a tool that aims to recover source-level type information from stripped binary executable based on transfer learning. Inspired by how human analyzer reason about the program, we propose a pretraining task called Generative State Modeling (GSM) to teach an ML model assembly code operational semantics, and then transfer the learned knowledge for type inference. See our paper for details.</p>

},
keywords = {Machine Learning for Program Analysis, Reverse Engineering, Transfer Learning, Type Inference}
}

@software{10.5281/zenodo.5088948,
author = {Hu, Yang and Wang, Wenxi and Hunger, Casen and Wood, Riley and Khurshid, Sarfraz and Tiwari, Mohit},
title = {Software tools for the paper - ACHyb: A Hybrid Analysis Approach to Detect Kernel Access Control Vulnerabilities},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5088948},
abstract = {
    <p>The artifact includes four software tools developed in our work: 1) a cve analysis tool to conduct our KACV study 2) a static analysis tool to detect potentially vulnerable paths, 3) a clustering-base seed distillation tool to generate high-quality seed programs, and 4) a kernel fuzzer to reduce false positives of the potential paths reported our static analysis tool. For each tool, we document setup procedures and usage, and provide the corresponding datasets.</p>

},
keywords = {Access Control, Operating System, Program Analysis}
}

@software{10.5281/zenodo.5089077,
author = {Park, Joonyoung and Park, Jihyeok and Youn, Dongjun and Ryu, Sukyoung},
title = {Accelerating JavaScript Static Analysis via Dynamic Shortcuts (Artifact Evaluation)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5089077},
abstract = {
    <p>We present dynamic shortcuts, a new technique to flexibly switch between abstract and concrete execution during JavaScript static analysis in a sound way. SAFEDS is the actual instance of dynamic shortcuts (DS) based on Jalangi2 in order to accelerate the static analyzer SAFE. It can significantly improve the analysis performance and precision by using highly-optimized commercial JavaScript engines (V8 in Node.js in our setting) and lessen the modeling efforts for opaque code. We apply our artifact for the Reusable badge and Artifacts Available badge. Our artifact provides the reproducible experimental environment, the full results of the experiments presented in the paper, and the commands of SAFEDS to analyze a new input program. A user can reproduce the experiments presented in the paper that is the comparison of analysis performances of SAFE and SAFEDS on Lodash4 tests. There are script files to juxtapose experimental results for each RQs with numbers in the paper. The README file on the root directory describes the above in detail. This package is forked from SAFE and imports Jalangi2 as a git submodule. The license of this package is under the BSD license. We added the option “ds” to the original SAFE to trigger dynamic shortcuts. When the option is turned on, SAFEDS communicates with the Node.js server in the dynamic-shortcut directory and the server runs Jalangi2 for dynamic analysis of functions in the target program on the concrete engine. The requirements of SAFEDS are inherited from SAFE and Jalangi2 and specified in the REQUIREMENTS file. The INSTALL file will guide to initialize the submodule, SAFE, and Jalangi2.</p>

},
keywords = {dynamic analysis, dynamic shortcut, JavaScript, sealed execution, static analysis}
}

@software{10.5281/zenodo.5089521,
author = {Zhu, Qihao and Sun, Zeyu and Xiao, Yuan-an and Zhang, Wenjie and Yuan, Kang and Xiong, Yingfei and Zhang, Lu},
title = {A Replication of "A Syntax-Guided Edit Decoder for Neural Program Repair"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5089521},
abstract = {
    <p>A PyTorch Implementation of “A Syntax-Guided Edits Decoder for Neural Program Repair”</p>

},
keywords = {Neural Network, Program Repair}
}

@software{10.5281/zenodo.5090536,
author = {Wang, Dinghua and Li, Shuqing and Xiao, Guanping and Liu, Yepang and Sui, Yulei},
title = {UAV bugs dataset and taxonomy},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5090536},
abstract = {
    <p>In our paper, we conducted a large-scale empirical study to characterize UAV-specific bugs in two open-source UAV platforms, namely PX4 and Ardupilot. We identified 168 UAV-specific bugs from 569 collected real bugs on GitHub. By analyzing these bugs (including bug reports, patches, and project development history), we proposed a taxonomy of UAV-specific bugs and summarized five challenges for detecting and fixing bugs in UAV systems. We believe that this study can facilitate future research and the development of UAV systems. Both UAV developers and users can receive useful guidance from our study.</p>
<p>The link to our replication package is：https://doi.org/10.5281/zenodo.4898868</p>
<p>This data set contains 569 real-world bugs, 168 UAV-specific bugs, and their taxonomy. Our replication package consists of two maim folders：bugSet and bugTaxonomy.</p>

},
keywords = {Bug, Taxonomy, UAV}
}

@software{10.5281/zenodo.5091384,
author = {He, Hao and He, Runzhi and Gu, Haiqiao and Zhou, Minghui},
title = {Replication Package for ESEC/FSE 2021 Paper "A Large-Scale Empirical Study of Java Library Migrations: Prevalence, Trends, and Rationales"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5091384},
abstract = {
    <p>This is the replication package for our ESEC/FSE 2021 paper A Large-Scale Empirical Study on Java Library Migrations: Prevalence, Trends, and Rationales. It can be used to replicate all three research questions in the paper using our preprocessed and manually labeled data. Please refer to this GitHub repository (https://github.com/hehao98/LibraryMigration) or the git repository archive (gitrepo.zip) in this package for detailed documentation about how to use this replication package.</p>
<p>It consists of the following files:</p>
<p>cache.zip: This file contains some most important datasets used in this paper, including the GitHub repositories and Maven libraries used, the set of all dependency changes, and the migration graph. Data related to thematic analysis can be found in the git repository. dbdata.tar.xz: This file contains the raw MongoDB data folder that will be used if you choose to install the required environment using Docker. dbdump.zip: This file contains the MongoDB data dump which will be used if you choose to manually install the required environment. gitrepo.zip: A git repository archive for the scripts, notebooks, and spreadsheets we used for this paper. Note that this archive may be somewhat older than the GitHub repository (https://github.com/hehao98/LibraryMigration). We recommend referring to the latest version at GitHub and only resort to this archive if the GitHub repository becomes unavailable in the unforeseeable future. We hope the provided scripts and dataset can be used to facilitate further research.</p>

},
keywords = {empirical software engineering, evolution and maintenance, library migration, mining software repositories}
}

@software{10.5281/zenodo.5091634,
author = {Zhang, Mingxue and Meng, Wei},
title = {zhangmx1997/fse21-jsisolate-artifact: JSIsolate version 1.1.0},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5091634},
abstract = {
    <p>The artefact contains the implementation of JSIsolate, as well as our analysis scripts. Detailed description can be found in the README file. Please refer to the supplementary material for the pre-built version of JSIsolate and the dataset we collected.</p>

},
keywords = {JavaScript isolation, JSIsolate}
}

@software{10.5281/zenodo.5092307,
author = {Rahaman, Sydur and Neamtiu, Iulian and Yin, Xin},
title = {Replication package for article: Algebraic-Datatype Taint Tracking, with Applications to Understanding Android Identifier Leaks},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5092307},
abstract = {
    <p>Given a list of sources, this TaintTracker tool produces algebric leak signatures of the sources and also categorize the leak as third party or own code leak.</p>
<p>CFG-Generator.jar (extension of Amandroid) will generate CFG (Control Flow Graph) given an apk</p>
<p>App_Wise_Signature.py will create the leak signature given the CFG file as text input</p>

},
keywords = {android, fingerprinting, identifier leak, mobile security, static analysis, taint analysis}
}

@software{10.5281/zenodo.5092777,
author = {Li, Song and Kang, Mingqing and Hou, Jianwei and Cao, Yinzhi},
title = {ObjLupAnsys},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5092777},
abstract = {
    <p>ObjLupAnsys is a tool to detect prototype pollution vulnerabilities in Node.js packages. This project is written in Python and JavaScript.</p>

},
keywords = {ESEC, FSE, NodeJS, ObjLupAnsys, prototype pollution, Vulnerability}
}

@software{10.5281/zenodo.5094851,
author = {Chowdhary, Sangeeta and Nagarakatte, Santosh},
title = {PFPSanitizer - A Parallel Shadow Execution Tool for Debugging Numerical Errors},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5094851},
abstract = {
    <p>This is the artifact for the FSE 2021 paper - Parallel Shadow Execution to Accelerate the Debugging of Numerical Errors appearing at FSE 2021. This artifact provides the link to the source code and step-by-step instructions to reproduce the performance graphs and case study from the accepted paper. We also provide the test harness to evaluate the correctness of our tool. In this artifact, we provide the scripts and instructions required to execute the different parts of the experiment automatically.</p>

},
keywords = {FPSanitizer, numerical errors, parallel execution, PFPSanitizer}
}

@software{10.5281/zenodo.5103655,
author = {Paraskevopoulou, Zoe and Li, John M. and Appel, Andrew W.},
title = {Source code and Proof Mechanization for the Article: Compositional Optimizations for CertiCoq},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5103655},
abstract = {
    <p>The source code of the CertiCoq compiler, containing the formally verified λANF pipeline, which is presented in this article</p>

},
keywords = {compilers, compositional compiler correctness, Coq, formal verification, logical relations}
}

@software{10.5281/zenodo.5109043,
author = {Shen, Qingchao and Ma, Haoyang and Chen, Junjie and Tian, Yongqiang and Cheung, Shing-Chi and Chen, Xiang},
title = {Replication Package for Article: "A Comprehensive Study of Deep Learning Compiler Bugs"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5109043},
abstract = {
    <p>This artifact has two components: the labeled dataset in our empirical study and our bug detection tool TVMFuzz. Folder named dataset includes the basic information of 603 bugs collected from GitHub by authors. Folder name TVMfuzz is a tool designed by us to fuzz the TVM, one of the most widely-used deep learning compilers. More details can be seen in README.md or https://github.com/ShenQingchao/DLCstudy</p>

},
keywords = {DL Compiler Bugs, TVMFuzz}
}

@software{10.5281/zenodo.5109338,
author = {Wang, Bo and Baluta, Teodora and Kolluri, Aashish and Saxena, Prateek},
title = {SynGuar: Guaranteeing Generalization in Programming by Example (Artifact)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5109338},
abstract = {
    <p>This is the artifact accompanying the paper SynGuar: Guaranteeing Generalization in Programming by Example accepted by the conference ESEC/FSE 2021. It is a framework for PBE synthesizers that guarantees to achieve low generalization error with high probability. It contains a tool named SynGuar that dynamically calculates how many additional examples suffice to theoretically guarantee generalization. It also contains two string program synthesizers StrPROSE and StrSTUN to show how SynGuar can be used in well-known program synthesis approaches such as the PROSE framework and STUN (synthesis through unification).</p>

},
keywords = {Program Synthesis, Programming by Example}
}

@software{10.5281/zenodo.5109867,
author = {Bittner, Paul Maximilian and Schulthei\ss{}, Alexander and Th\"{u}m, Thomas and Kehrer, Timo and Young, Jeffrey M. and Linsbauer, Lukas},
title = {Library and Demo for Article: Feature Trace Recording},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5109867},
abstract = {
    <p>The artefact mainly consists of a library written in the Haskell language that implements feature trace recording. The library is accompanied with a demo application that uses the library to reproduce our motivating example (Alice and Bob using feature trace recording in Section 2 in our paper) as well as examples of the edit patterns we used to evaluate feature trace recording (Section 5).</p>

},
keywords = {clone-and-own, feature location, feature traceability, software evolution, software product lines, variability mining}
}

@software{10.5281/zenodo.5110878,
author = {Winkler, Jordan and Agarwal, Abhimanyu and Tung, Caleb and Ugalde, Dario Rios and Jung, Young Jin and Davis, James C.},
title = {Replication Package for A Replication of ‘DeepBugs: A Learning Approach to Name-based Bug Detection’},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5110878},
abstract = {
    <p>Replication process, source code, and longer technical report for this paper.</p>

},
keywords = {deep learnining, Defect detection, machine learning, replication}
}

@software{10.5281/zenodo.5111183,
author = {Wang, Xiao and Xiao, Lu and Yu, Tingting and Woepse, Anne and Wong, Sunny},
title = {JMocker: An Automatic Refactoring Framework for ReplacingTest-Production Inheritance by Mocking Mechanism},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5111183},
abstract = {
    <p>JMocker is an Eclipse plugin for automatically identifying and refactoring the usage of inheritance for mocking by using Mockito-a well received mocking framework. The refactoring performed by JMocker can improve the quality of the unit test cases in various aspects, including improving the cohesion/concise, readability/understandability, and maintainability of unit test cases.</p>

},
keywords = {Software Refactoring, Software Testing}
}

@software{10.5281/zenodo.5111494,
author = {Bhandari, Guru and Naseer, Amara and Moonen, Leon},
title = {CVEfixes: Automated Collection of Vulnerabilities and Their Fixes from Open-Source Software},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5111494},
abstract = {
    <p>CVEfixes is a comprehensive vulnerability dataset that is automatically collected and curated from Common Vulnerabilities and Exposures (CVE) records in the public U.S. National Vulnerability Database (NVD). The goal is to support data-driven security research based on source code and source code metrics related to fixes for CVEs in the NVD by providing detailed information at different interlinked levels of abstraction, such as the commit-, file-, and method level, as well as the repository- and CVE level.</p>
<p>This repository includes the code to replicate the data collection. The complete process has been documented in the paper “CVEfixes: Automated Collection of Vulnerabilities and Their Fixes from Open-Source Software”, published at PROMISE 2021.</p>

},
keywords = {dataset, security vulnerabilities, software repository mining, source code repair, vulnerability classification, vulnerability prediction}
}

@software{10.5281/zenodo.5111541,
author = {Zhang, Wuqi and Wei, Lili and Li, Shuqing and Liu, Yepang and Cheung, Shing-Chi},
title = {Implementation of the Detection Tool: \DH{}Archer: Detecting On-Chain-Off-Chain Synchronization Bugs in Decentralized Applications},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5111541},
abstract = {
    <p>undefinedArcher is an automated testing framework aiming to test on-chain-off-chain synchronization bugs in decentralized applications (DApps). A detailed introduction to undefinedArcher can be found in the README.md file inside the artifact.</p>

},
keywords = {dapp, ethereum, testing, testing-framework, testing-tools}
}

@software{10.5281/zenodo.5111654,
author = {Shen, Bo and Zhang, Wei and K\"{a}stner, Christian and Zhao, Haiyan and Wei, Zhao and Liang, Guangtai and Jin, Zhi},
title = {Artifact for Article: SmartCommit: A Graph-Based Interactive Assistant for Activity-Oriented Commits},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5111654},
abstract = {
    <p>This artifact is the core algorithm of SmartCommit—an assistant tool to lead and help developers follow the best practice of cohesive commits, which is advocated by many companies (like Google and Facebook) and open source communities (like Git and Angular). A cohesive commit should specifically focus on a development or maintenance activity, such as feature addition, bugfix or refactoring. Cohesive commits form a clear change history that facilitates software maintenance and team collaboration. To help the developer make cohesive commits, SmartCommit can suggest a decomposition (groups of related and self-contained code changes) to the code changes, and allows the developer to interactively adjust the suggested decomposition, until it reaches a state that the developer feels reasonable to submit code change groups as commits.</p>

},
keywords = {changes decomposition, code commit, collaboration in software development, revision control system}
}

@software{10.5281/zenodo.5112878,
author = {Lukes, Dylan and Sarracino, John and Coleman, Cora and Peleg, Hila and Lerner, Sorin and Polikarpova, Nadia},
title = {Replication package for FSE '21, Synthesis of Web Layouts from Examples},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5112878},
abstract = {
    <p>Contains all code, experiments, and data, as well as instructions for installation, usage and replication of our experiments.</p>
<p>This package contains:</p>
<p>In ./implementation:</p>
<ul>
<li>mockdown, Our main tool, written in Python.</li>
<li>mockdown-client, A JavaScript client for mockdown, intended for use in writing benchmarks, or integrating mockdown into web applications. Used by auto-mock.</li>
<li>auto-mock (placed in implementation/web), Evaluation for the web backend (RQ1-RQ3).</li>
<li>inferui-eval (placed in implementation/android), Evaluation for the Android backend (RQ4).</li>
<li>flightlessbird.js, A fork of the kiwi.js constraint solver, with some bug fixes and changes to facilitate adding multiple constraints at once. Used by mockdown-client.</li>
</ul>
<p>In ./layouts, there is a variety of JSON files. These correspond to our scraped websites (input data).</p>
<p>In ./experiments/, there is the data and scripts for our experiments:</p>
<ul>
<li>overall, CSV files and Excel spreadsheets for our RQ1 trials.</li>
<li>noise, CSV files and plotting scripts for our RQ2 trials. There are two subfolders, 3/ and 10/ which correspond to the 3 and 10 training examples.</li>
<li>scaling, a CSV file, Excel spreadsheet, and helper python script for RQ3.</li>
<li>android, a CSV file for RQ4.</li>
</ul>

},
keywords = {cassowary, constraint-based layout, constraints, layout, linear constraints, program synthesis, synthesis}
}

@software{10.6084/m9.figshare.13712827.v2,
author = {Hort, Max and Zhang, Jie M. and Sarro, Federica and Harman, Mark},
title = {Replication package for article: Fairea: A Model Behaviour Mutation Approach to Benchmarking Bias Mitigation Methods},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.13712827.v2},
abstract = {
    <p>This on-line appendix is supplementary to the paper entitled “Fairea: A Model Behaviour Mutation Approach to Benchmarking Bias Mitigation Methods”, which has been accepted at FSE’21. It contains the data used in the study, raw results, Python code for the proposed approach, and scripts to replicate our experiments.</p>

},
keywords = {software fairness}
}

@software{10.6084/m9.figshare.14724453.v4,
author = {Trabish, David and Itzhaky, Shachar and Rinetzky, Noam},
title = {Replication package for the paper: A Bounded Symbolic-Size Model for Symbolic Execution},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.14724453.v4},
abstract = {
    <p>The package contains: - Source code for our tool (including all the required compiled binaries) - Benchmarks used in the experiments - Scripts for running the experiments</p>

},
keywords = {Symbolic Execution}
}

@software{10.1145/3462302,
author = {Pitchanathan, Arjun and Ulmann, Christian and Weber, Michel and Hoefler, Torsten and Grosser, Tobias},
title = {Replication Package for Article: FPL: Fast Presburger Arithmetic through Transprecision},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462302},
abstract = {
    <p>A Docker image with the necessary toolchains, data, sources and scripts to reproduce the main results of the FPL paper. Includes a benchmark for Presburger arithmetic as used in polyhedral compilation.</p>

},
keywords = {Integer Sets, Polyhedral Compilation, Presburger Arithmetic, Transprecision}
}

@software{10.5281/zenodo.5090141,
author = {Dura, Alexandru and Reichenbach, Christoph and S\"{o}derberg, Emma},
title = {Replication Package for Article: 'JavaDL: Automatically Incrementalizing Java Bug Pattern Detection'},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5090141},
abstract = {
    <p>The artifact contains the implementation of the JavaDL language and the evaluation setup that reproduces the claims regarding: - the precision of the JavaDL analyses relative to state-of-the-practice tools; - the performance comparison between JavaDL and state-of-the-practice tools.</p>

},
keywords = {Datalog, Software Bugs, Static Analysis Frameworks, Syntactic Patterns}
}

@software{10.5281/zenodo.5091711,
author = {Roth, Ori},
title = {Treetop: A Context-Free Fluent API Generator for C#},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5091711},
abstract = {
    <p>Treetop is a proof-of-concept C# fluent API generator for context-free protocols. Treetop accepts a context-free grammar, specifying an API protocol or a domain-specific language, and embeds it in C# as a fluent API. The resulting API enforces the grammar at compile-time: A fluent API chain may compile if and only if it encodes a word derived from the grammar.</p>

},
keywords = {context-free grammars, domain-specific languages, fluent API, nominal subtyping with variance}
}

@software{10.5281/zenodo.5093839,
author = {Herklotz, Yann and Pollard, James D. and Ramanathan, Nadesh and Wickerson, John},
title = {Vericert},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5093839},
abstract = {
    <p>A formally verified high-level synthesis (HLS) tool written in Coq, building on top of CompCert. The implementation and proofs are described in the paper “Formal Verification of High-Level Synthesis”.</p>

},
keywords = {C, CompCert, Coq, high-level synthesis, Verilog}
}

@software{10.5281/zenodo.5130646,
author = {Zhou, Zhe and Dickerson, Robert and Delaware, Benjamin and Jagannathan, Suresh},
title = {OOPSLA2021 Artifact: Data-Driven Abductive Inference of Library Specifications},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5130646},
abstract = {
    <p>OOPSLA2021 Artifact: Data-Driven Abductive Inference of Library Specifications</p>

},
keywords = {data-driven inference, oopsla, specifications, verification}
}

@software{10.5281/zenodo.5139390,
author = {Park, Jiwon and Winterer, Dominik and Zhang, Chengyu and Su, Zhendong},
title = {OOPSLA 2021 Artifact for "Generative Type-Aware Mutation for Testing SMT Solvers"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5139390},
abstract = {
    <p>Software artifact for the paper Generative Type-Aware Mutation for Testing SMT Solvers, in a VirtualBox image. The artifact is realized as a single VirtualBox image of three main components: (1) yinyang, the tool which we created and extended, and in which we integrated TypeFuzz. TypeFuzz realizes generative type-aware mutation to find all reported bugs in the paper, (2) A database with statistics on the bugs and Coverage data.</p>

},
keywords = {SMT solving
Fuzzing
Formal methods}
}

@software{10.5281/zenodo.5141479,
author = {Phipps-Costin, Luna and Anderson, Carolyn Jane and Greenberg, Michael and Guha, Arjun},
title = {TypeWhich},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5141479},
abstract = {
    <p>See Zenodo for a description of the artifact.</p>

},
keywords = {typed, untyped}
}

@software{10.5281/zenodo.5394235,
author = {Goel, Aviral and Je\v{c}men, Jan and Krynski, Sebasti\'{a}n and Fl\"{u}ckiger, Olivier and Vitek, Jan},
title = {Replication Package for Article: "Promises Are Made to Be Broken: Migrating R to Strict Semantics"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5394235},
abstract = {
    <p>The artifact is a ZIP file containing code that analyzes R packages to migrate them from lazy to strict semantics. Details can be found in the README.pdf file accompanying the artifact.</p>

},
keywords = {Code Migration, Corpus Analysis, Delayed Or Lazy Evaluation, Empirical Study, R Language}
}

@software{10.5281/zenodo.5400508,
author = {Malewski, Stefan and Greenberg, Michael and Tanter, \'{E}ric},
title = {Gradually Structured Data: Typechecker and Interpreter},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5400508},
abstract = {
    <p>GSD is an interpreter for a gradually typed language with Gradually Structured Data.</p>
<p>It’s main features are the following: - It can typecheck and evaluate programs with different levels of datatype definitions. From no definitions at all (for dynamic programs) to fully defined static programs, and the levels in between those two extremes. - It works with three different matching strategies: sound, exact and complete.</p>

},
keywords = {algebraic datatypes, gradual typing, semi-structured data}
}

@software{10.5281/zenodo.5411667,
author = {Chaliasos, Stefanos and Sotiropoulos, Thodoris and Drosos, Georgios-Petros and Mitropoulos, Charalambos and Mitropoulos, Dimitris and Spinellis, Diomidis},
title = {Replication Package for Article: "Well-Typed Programs Can Go Wrong: A Study of Typing-Related Bugs in JVM Compilers"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5411667},
abstract = {
    <p>The purpose of this artifact is (1) to reproduce the results presented in the OOPSLA 2021 paper titled “Well-Typed Programs Can Go Wrong: A Study of Typing-Related Bugs in JVM Compilers”, and (2) to document the dataset and the proposed categorization in order to facilitate further research. Specifically, the artifact has the following structure:</p>
<ul>
<li><p><code>scripts/</code>: This is the directory that contains the scripts needed to reproduce the results, the figures, and the tables presented in the paper.</p></li>
<li><p><code>scripts/fetch/</code>: This is the directory that contains the scripts needed to construct the dataset of typing-related bugs as described in Section 2.1 of the main paper.</p></li>
<li><p><code>data/</code>: This is the “pre-baked” dataset of the 320 typing-related bugs under study.</p></li>
</ul>

},
keywords = {bug, compiler, Groovy, Java, Kotlin, Scala, static typing, study, testing}
}

@software{10.5281/zenodo.5415230,
author = {Goel, Aviral and Donat-Bouillud, Pierre and K\v{r}ikava, Filip and Kirsch, Christoph M. and Vitek, Jan},
title = {Replication Package for Article: "What We Eval in the Shadows: A Large-Scale Study of Eval in R Programs"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5415230},
abstract = {
    <p>The artifact is a ZIP file containing code that performs dynamic analysis of R programs to study the use of eval. The insights yielded by this analysis are reported in the OOPSLA’21 paper - What We Eval in the Shadows: A Large-Scale Study of Eval in R Programs. The details can be found in the README.pdf file accompanying the artifact.</p>

},
keywords = {Dynamic Analysis, Empirical Studies, Eval, R, Scripting Languages}
}

@software{10.5281/zenodo.5415274,
author = {Br\"{a}m, Christian and Eilers, Marco and M\"{u}ller, Peter and Sierra, Robin and Summers, Alexander J.},
title = {Artifact of the paper "Rich Specifications for Ethereum Smart Contract Verification"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5415274},
abstract = {
    <p>This is the artifact accompanying the OOPSLA 2021 paper “Rich Specifications for Ethereum Smart Contract Verification”.</p>
<p>The artifact comes in the form of a VirtualBox VM image (2vyper-artifact.ova) and contains the paper’s implementation in the tool 2vyper as well as the benchmarks used in the evaluation. Instructions for running the VM image and using the artifact can be found in the README.</p>

},
keywords = {Ethereum, resources, smart contracts, software verification, specification}
}

@software{10.5281/zenodo.5421762,
author = {Ishimwe, Didier and Nguyen, KimHao and Nguyen, ThanhVu},
title = {Software Artifact for the OOPSLA'21 Paper Titled "Dynaplex: Analyzing Program Complexity using Dynamically Inferred Recurrence Relations"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5421762},
abstract = {
    <p>This artifact contains an implementation of the dynaplex algorithm and benchmark programs, as described in the paper: <em>Dynaplex: Analyzing Program Complexity using Dynamically Inferred Recurrence Relations</em>.</p>
<p>The development and experiment environment is provided as a single Docker image at <code>unsatx/dynaplex:oopsla21</code>. In addition to the image a <code>Dockerfile</code> as well as a zip containing the github repository are also provided as alternative source of the artifact. We recommend using the provided Docker image as it is self-contained with all the dependencies installed. A guide to set up and use this artifact from the docker image is provided in file <code>dynaplex.pdf</code>.</p>

},
keywords = {complexity analysis, dynamic analysis, invariants, recurrence relations}
}

@software{10.5281/zenodo.5424844,
author = {Brown, Michael D. and Pruett, Matthew and Bigelow, Robert and Mururu, Girish and Pande, Santosh},
title = {Artifact Package for Article: Not So Fast: Understanding and Mitigating Negative Impacts of Compiler Optimizations on Code Reuse Gadget Sets},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5424844},
abstract = {
    <p>Virtual Machine containing technical artifacts referenced in the article. Includes dataset of over 1000 binaries, recompiler passes, and evaluation tool (GSA).</p>

},
keywords = {binary recompilation, code reuse attacks, code reuse gadgets, compiler, optimization, recompiler, return-oriented programming, ROP}
}

@software{10.5281/zenodo.5442253,
author = {Emre, Mehmet and Schroeder, Ryan and Dewey, Kyle and Hardekopf, Ben},
title = {Artifact for "Translating C to Safer Rust"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5442253},
abstract = {
    <p>The purpose of the artifact is to reproduce the data presented in the paper. The artifact contains our prototype for the method presented in the paper along with evaluation tools and scripts. It can be used to reproduce the data in all tables except the performance data. It contains instructions for how to produce the data used for Figure 1, but the artifact does not generate the figure automatically (the user needs to use a spreadsheet or plotting program to create the figure from the data).</p>

},
keywords = {Automatic Translation, C, Empirical Study, Memory-Safety, Rust}
}

@software{10.5281/zenodo.5449078,
author = {Kazerounian, Milod and Foster, Jeffrey S. and Min, Bonan},
title = {Replication Package for Paper "SimTyper: Sound Type Inference for Ruby using Type Equality Prediction"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5449078},
abstract = {
    <p>This artifact can be used to reproduce the results presented in the paper “SimTyper: Sound Type Inference for Ruby using Type Equality Prediction.” It includes the type inference system SimTyper, and the eight programs which it is run on to produce results.</p>

},
keywords = {dynamic languages, machine learning, ruby, type inference}
}

@software{10.5281/zenodo.5459013,
author = {Ferdowsifard, Kasra and Barke, Shraddha and Peleg, Hila and Lerner, Sorin and Polikarpova, Nadia},
title = {VM Image containing software for: LooPy: Interactive Program Synthesis with Control Structures},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5459013},
abstract = {
    <p>This artifact is a VM image intended to be used with VirtualBox, which contains the source code and setup for building/running Loopy, including scripts for running the benchmarks and the GUI.</p>

},
keywords = {Live Programming, Program Synthesis, Programming by Example}
}

@software{10.5281/zenodo.5459312,
author = {Nandi, Chandrakana and Willsey, Max and Zhu, Amy and Wang, Yisu Remy and Saiki, Brett and Anderson, Adam and Schulz, Adriana and Grossman, Dan and Tatlock, Zachary},
title = {Artifact for article: &nbsp;Rewrite Rule Inference Using Equality Saturation},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5459312},
abstract = {
    <p>This is the artifact for our paper “Rewrite Rule Inference Using Equality Saturation”. In our paper, we presented a framework, Ruler, that uses equality saturation to automatically infer small, expressive rulesets for a domain, given an interpreter. The artifact reproduces the following quantitative evaluations from the paper:</p>
<ul>
<li><p>Comparing with CVC4 (Section 4): We show that Ruler can infer smaller, powerful rulesets faster by comparing the rules inferred for bool, bv4, and bv32 with varying expression sizes (2, 3). The results are in Table 1.</p></li>
<li><p>Integrating with Herbie (Section 5): We show that Ruler’s rules can be used to replace human-written rules by comparing the Herbie tool’s results in fours different configurations: <code>None</code>, <code>Herbie</code>, <code>Ruler</code>, <code>Both</code>. The results are in Figure 7.</p></li>
<li><p>Search Parameter Analysis (Section 6.1): We profiled Ruler’s search algorithm to measure how much time is spent in each phase. Figure 8 shows the results for bv4, bv32, and rationals domains. We also compared different variations of <code>choose_eqs</code> by varying n in Figure 5, Line 3, whose default value is infinity. The results are shown in Figure 9a for bv4, bv32, and rationals. Importantly, we measure both running time and the number of rules learned. We also measured running time, number of rules learned, and number of e-classes in the egraph with and without invoking <code>run_rewrites</code> (Figure 4, Line 9) to study its effect. The results are shown in Figure 9b for bv4, bv32, and rationals.</p></li>
<li><p>Validation Analysis (Section 6.2): We compared different rule validation methods for bv4, bv32, and rationals. The results are shown in Table 2.</p></li>
</ul>

},
keywords = {e-graphs, equality saturation, program synthesis, rewrite rules}
}

@software{10.5281/zenodo.5468873,
author = {Iorga, Dan and Donaldson, Alastair F. and Sorensen, Tyler and Wickerson, John},
title = {The semantics of Shared Memory in Intel CPU/FPGA},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5468873},
abstract = {
    <p>The aim of this artefact is to demonstrate the claims made in the paper “The Semantics of Shared Memory in Intel CPU/FPGA Systems”.</p>
<p>This manual is divided into two parts:&nbsp;Getting Started Guide&nbsp;which should be finished in 30 minutes and a section where we will provide the&nbsp;Step by Step Instructions&nbsp;by which the paper instructions can be reproduced.</p>

},
keywords = {Core Cache Interface (CCI-P), CPU/FPGA, memory model}
}

@software{10.5281/zenodo.5475211,
author = {Bartha, S\'{a}ndor and Cheney, James and Belle, Vaishak},
title = {Case studies for the paper: "One Down, 699 to Go: or, Synthesising Compositional Desugarings".},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5475211},
abstract = {
    <p>Case studies to synthesise compositional translations (desugarings), based on opaque implementations of source and target languages. The description of the case studies and its results are reported in the paper: “One Down, 699 to Go: or, Synthesising Compositional Desugarings”, S\'{a}ndor Bartha, James Cheney, and Vaishak Belle, OOPSLA 2021</p>

},
keywords = {Haskell, Program synthesis, Semantics of programming languages}
}

@software{10.5281/zenodo.5476274,
author = {Honor\'{e}, Wolf and Kim, Jieung and Shin, Ji-Yong and Shao, Zhong},
title = {Artifact for "Much ADO about Failures: A Fault-Aware Model for Compositional Verification of Strongly Consistent Distributed Systems"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5476274},
abstract = {
    <p>This artifact includes the Coq source files for the Advert distributed system verification framework as well as the examples from the paper, a C implementation of multi-Paxos verified with CCAL, and the C source code for the multi-Paxos, Chain Replication, and Two-Phase Commit protocols used for the performance evaluations. Source files are included in artifact.tgz. See the README for build instructions.</p>

},
keywords = {Coq, distributed systems, formal verification, proof assistants}
}

@software{10.5281/zenodo.5482251,
author = {Xu, Haoran and Kjolstad, Fredrik},
title = {Artifact for Paper "Copy-and-Patch Compilation: A fast compilation algorithm for high-level languages and bytecode"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5482251},
abstract = {
    <p>This is the artifact corresponding to paper</p>
<pre><code>Copy-and-Patch Compilation: A fast compilation algorithm for high-level languages and bytecode</code></pre>
<p>to be published in OOPSLA 2021.</p>
<p>This artifact is judged by the Artifact Evaluation Committee as functional and reusable.</p>
<p>List of Files</p>
<pre><code> 'instruction.pdf' contains all instructions on how to use this artifact.
 'artifact_vm_image.ova' is the Virtual Box VM image containing the artifact.
 'artifact_vm_image.ova.md5sum' is the MD5 checksum for file 'artifact_vm_image.ova'.
 'draft_paper.pdf' is the paper referred to by 'instruction.pdf'. It is NOT the camera-ready version of the paper:  for camera-ready version, please check the OOPSLA 2021 publication website. This draft version is included only for consistency of this artifact.
 'LICENSE.txt' is the license of this artifact.</code></pre>
<p>How to Use this Artifact</p>
<p>Please refer to ‘instruction.pdf’ for all instructions on how to use this artifact.</p>

},
keywords = {Artifact}
}

@software{10.5281/zenodo.5482557,
author = {Wolff, Fabian and B\'{\i}l\'{y}, Aurel and Matheja, Christoph and M\"{u}ller, Peter and Summers, Alexander J.},
title = {Modular Specification and Verification of Closures in Rust (artefact)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5482557},
abstract = {
    <p>This is the artefact accompanying our OOPSLA 2021 publication, “Modular Specification and Verification of Closures in Rust”. Please refer to the OOPSLA publication and the contained README file for more information.</p>

},
keywords = {closures, higher-order functions, Rust, software verification}
}

@software{10.5281/zenodo.5483138,
author = {Lanzinger, Florian and Weigl, Alexander and Ulbrich, Mattias and Dietl, Werner},
title = {Property Checker -- Scalability and Precision by Combining Expressive Type Systems and Deductive Verification},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5483138},
abstract = {
    <p>The Property Checker is a checker developed using the Checker Framework for Java. The Checker Framework allows programmers to leverage Java annotations to create pluggable Java type systems. Unlike other checkers in the CF, the Property Checker allows users to specify their own type qualifiers and qualifier hierarchies using a simple definition language.</p>
<p>If the Property Checker is not able to completely prove a program’s correctness, it outputs a JML translation, in which all property qualifiers are translated into specification clauses in the Java Modeling Language (JML). This translation can be given to a deductive verification tool like KeY or OpenJML to prove the parts of the program which the checker was not able to prove. This approach combines the scalability and easy-of-use of pluggable type system with the power of deductive verification.</p>
<p>This artifact includes the Property Checker itself and the JML deductive verification tools KeY and OpenJML. The example project in the directory property-checker-tutorial illustrates how the Property Checker can be run on your own projects; see that project’s readme for details. See this file for information on how to run KeY and OpenJML. In addition, there are some premade bash scripts to help you re-run the evaluation described in the paper; see the artifact documentation for more details.</p>

},
keywords = {Object-oriented languages, Program specification, Program verification, Type systems}
}

@software{10.5281/zenodo.5484436,
author = {Popescu, Natalie and Xu, Ziyang and Apostolakis, Sotiris and August, David I. and Levy, Amit},
title = {Artifact for 'Safer at Any Speed: Automatic Context-Aware Safety Enhancement for Rust'},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5484436},
abstract = {
    <p>This artifact is responsible for reproducing the experiments in the article “Safer at Any Speed: Automatic Context-Aware Safety Enhancement for Rust”. We populate a docker image with the open-source libraries, applications, and application-specific data that we eventually use for running experiments, as well as a driver and supporting scripts that instantiates each experiment. The experiments help support the claims we make in the paper.</p>

},
keywords = {bounds checks, Rust, safety-performance trade-off}
}

@software{10.5281/zenodo.5491895,
author = {Tan, Tian and Li, Yue and Ma, Xiaoxing and Xu, Chang and Smaragdakis, Yannis},
title = {Making Pointer Analysis More Precise by Unleashing the Power of Selective Context Sensitivity (Artifact)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5491895},
abstract = {
    <p>This artifact is provided to reproduce the results of research questions (RQ1 and RQ2) in Section 6 of our companion paper. The artifact contains Baton (our tool, as well as Collection, Zipper-e and Scaler which are used by Baton), Doop (a state-of-the-art pointer analysis framework for Java), and the Java programs and the library used in our evaluation.</p>

},
keywords = {Alias Analysis, Context Sensitivity, Java, Pointer Analysis}
}

@software{10.5281/zenodo.5493554,
author = {Yan, Pengbo and Murray, Toby},
title = {SecRSL: Security Separation Logic for C11 Release-Acquire Concurrency - Coq Formalisation},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5493554},
abstract = {
    <p>Formalisation, soundness proof, and example applications of SecRSL: Security Relaxed Separation Logic, a logic for reasoning about information flow security of programs in the Release-Acquire fragment of C11.</p>
<p>Includes the Coq sources (for Coq version 8.8.1) as well as a Ubuntu Linux virtual machine in which the theories and the required Coq version are already installed.</p>
<p>See README for instructions; LICENSE for licensing information.</p>
<p>This artifact accompanies the paper: Pengbo Yan and Toby Murray, “SecRSL: Security Separation Logic for C11 Release-Acquire Concurrency”, OOPSLA 2021</p>

},
keywords = {Axiomatic Semantics, Information-flow Security, Separation Logic, Weak Memory Consistency}
}

@software{10.5281/zenodo.5494504,
author = {Yamaguchi, Masaomi and Matsuda, Kazutaka and David, Cristina and Wang, Meng},
title = {Synbit: Synthesizing Bidirectional Programs using Unidirectional Sketches (Implementation)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5494504},
abstract = {
    <p>This is the artifact of a paper “Synbit: Synthesizing Bidirectional Programs using Unidirectional Sketches”. This artifact includes the implementation of Synbit and scripts for reproducing the experiments in the paper.</p>

},
keywords = {Bidirectional Transformation, Program Synthesis}
}

@software{10.5281/zenodo.5494813,
author = {Smaragdakis, Yannis and Grech, Neville and Lagouvardos, Sifis and Triantafyllou, Konstantinos and Tsatiris, Ilias},
title = {Symbolic Value-Flow Static Analysis: Deep, Precise, Complete Modeling of Ethereum Smart Contracts (Artifact)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5494813},
abstract = {
    <p>This artifact can be used to support all claims made in the evaluation section of the corresponding paper. In particular it can be used to reproduce the results of the Controlled Evaluation Section of the paper (Section 7). These examples require running 3 analysis tools: our proposed Symvalic analysis, Manticore, and Mythril on two sets of smart contracts.</p>

},
keywords = {ethereum, EVM, static analysis, symbolic execution}
}

@software{10.5281/zenodo.5496104,
author = {Patel, Nisarg and Krishna, Siddharth and Shasha, Dennis and Wies, Thomas},
title = {Replication Package for Article: Verifying Concurrent Multicopy Search Structures},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5496104},
abstract = {
    <p>Artifact for OOPSLA’21 paper: Verifying Concurrent Multicopy Search Structures</p>
<p>The artifact is packaged as a VirtualBox Image based on Ubuntu 20.04.2. The login is <code>templates:templates</code>.</p>
<p>This artifact relies on two tools: Iris (a high-order concurrent separation logic built on top of Coq) and GRASShopper (a program verification tool). The artifact is packaged with these software preinstalled and the necessary files precompiled.</p>
<p>See README for further information on how to use the artifact. See LICENSE for the license-related information.</p>

},
keywords = {concurrent data structures, flow framework, log-structured merge trees, logic and verification, separation logic, shared memory algorithms, template-based verification, theory of computation}
}

@software{10.5281/zenodo.5496483,
author = {Lahav, Ori and Namakonov, Egor and Oberhauser, Jonas and Podkopaev, Anton and Vafeiadis, Viktor},
title = {Making Weak Memory Models Fair: OOPSLA 2021 artifact},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5496483},
abstract = {
    <p>This artifact provides the supplementary Coq development for the Making Weak Memory Models Fair paper from OOPSLA’21: source code and VirtualBox image.</p>

},
keywords = {concurrency, fairness, software verification, weak memory models}
}

@software{10.5281/zenodo.5497628,
author = {Fu, Weili and Krause, Fabian and Thiemann, Peter},
title = {Artifact for Label Dependent Lambda Calculus and Gradual Typing},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5497628},
abstract = {
    <p>This artifact contains two parts corresponding to our claim at the end of section 1 in the paper “Label Dependent Lambda Calculus and Gradual Typing” appearing in OOPSLA 2021.</p>
<ol type="1">
<li>An implementation of the type checker for LDLC corresponding to section 3.2 from the paper and its gradual extension for GLDLC described in section 5.1. It does <em>not</em> contain the translation described in section 5.2.</li>
<li>A formalization of the cast calculus CCLDLC (a proper extension of LDLC) described in section 4 and an implementation of the progress proof of theorem 4.6 in Agda.</li>
</ol>

},
keywords = {dependent types, gradual types, subtyping}
}

@software{10.5281/zenodo.5497756,
author = {Soethout, Tim and van der Storm, Tijs and Vinju, Jurgen J.},
title = {TimSoethout/cbc-artifacts: Artifacts for AGERE'21 paper "Contract-Based Return-Value Commutativity: Safely exploiting contract-based commutativity for faster serializable transactions"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5497756},
abstract = {
    <h2 id="artifacts-accompanying-paper-contract-based-return-value-commutativity-safely-exploiting-contract-based-commutativity-for-faster-serializable-transactions">Artifacts accompanying paper: Contract-Based Return-Value Commutativity: Safely exploiting contract-based commutativity for faster serializable transactions</h2>
<h3 id="tla-models">TLA+ models</h3>
<p>Containing:</p>
<ul>
<li>RV-SER</li>
<li>LoCA with CBC/SCBC</li>
<li>2PL/2PC</li>
</ul>
<p>Please see <code>Readme.adoc</code> in the <code>tla</code> directory for more specifics.</p>
<h3 id="smt-static-cbc">SMT Static CBC</h3>
<p>In the <code>SCBC</code> folder you find multiple Rascal modules. The <code>rebel-cbc</code> module contains the SCBC checks using SMT solver Z3.</p>
<p>Tested/Run with:</p>
<ul>
<li>Rascal Version: 0.18.2 (https://update.rascal-mpl.org/stable)</li>
<li>Z3 version 4.8.8 - 64 bit</li>
</ul>
<h4 id="overview">Overview</h4>
<p>The Rascal source code can be run using Eclipse with the Rascal plugin.</p>
<p>This folder contains an Eclipse workspace containing all the modules required to run the Analysis.</p>
<pre><code>rebel-core: Rebel DSL core
rebel-eclipse: Rebel DSL tooling to use in Eclipse
rebel-cbc: The analysis tool
smtlib2: Grammar and tools to output SMTLIB constraints</code></pre>
<h4 id="run-the-cbc-analysis">Run the CBC analysis</h4>
<p>In order to run this, you require Eclipse (https://www.eclipse.org/) and Z3 (https://github.com/Z3Prover/z3/wiki). Z3 can be installed on Mac OSX via homebrew (brew cask install z3).</p>
<p>To reproduce the results from the paper, do the following steps:</p>
<pre><code>Open all projects in the `SCBC` folder in Eclipse.

Open the Rascal REPL in Eclipse by right clicking on source file: |project://rebel-cbc/src/cbc/tests/CbcTests.rsc| and selecting Run as &gt; Rascal Application.

After loading type/copy: `analyse(verySimple, scoRetvalAndPostStateAssert, scoRetvalAndPostStateAssert);`. The tool will return the SCBC table as done in the paper.</code></pre>

},
keywords = {Rascal, TLA+}
}

@software{10.5281/zenodo.5497862,
author = {Karachalias, Georgios and Koprivec, Filip and Pretnar, Matija and Schrijvers, Tom},
title = {Compiler and replication of results: "Efficient Compilation of Algebraic Effect Handlers"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5497862},
abstract = {
    <p>Artifact consists of Dockerfile, instructions document and compressed docker image. The docker image includes Eff compiler presented in the paper, benchmark files and a helper scripts to run the benchmarks and produce both human readable benchmark outputs and data used to generate plots in the paper. Full instructions on building and use are available in the documentation in pdf or markdown format.</p>

},
keywords = {Algebraic effects, Compilers, Eff, Focus on specific PL, Handlers, Transformations, Types}
}

@software{10.5281/zenodo.5499720,
author = {Ji, Ruyi and Xia, Jingtao and Xiong, Yingfei and Hu, Zhenjiang},
title = {Artifact for OOPSLA'21: Generalizable Synthesis Through Unification},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5499720},
abstract = {
    <p>Artifact for OOPSLA’21: Generalizable Synthesis Through Unification</p>

},
keywords = {generalizability, programming by example}
}

@software{10.5281/zenodo.5500548,
author = {Pelenitsyn, Artem and Belyakova, Julia and Chung, Benjamin and Tate, Ross and Vitek, Jan},
title = {Type Stability in Julia: Avoiding Performance Pathologies in JIT Compilation (Artifact)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5500548},
abstract = {
    <p>This artifact aims to give exact directions on how to reproduce experiments reported in Section 5 (Empirical Study) of the Type Stability in Julia paper presented at OOPSLA ’21; in particular: Tables 1 and 2, Figure 11.</p>
<p>The artifact consists of a number of scripts in Bash and Julia and have instructional comments inside. We submit the Git history of the project: the submitted version lives on the artifact branch. The same repository is available on Github (prl-julia/julia-type-stability).</p>

},
keywords = {compilation, dynamic languages, method dispatch, type inference}
}

@software{10.5281/zenodo.5501522,
author = {Sorensen, Tyler and Salvador, Lucas F. and Raval, Harmit and Evrard, Hugues and Wickerson, John and Martonosi, Margaret and Donaldson, Alastair F.},
title = {Artifact for "Specifying and Testing GPU Workgroup Progress Models" (OOPSLA 2021)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5501522},
abstract = {
    <p>A collection of software and data from the OOPSLA 2021 paper: Specifying and Testing GPU Workgroup Progress Models. It is provided as a docker container with as many pre-installed dependencies as possible.</p>
<p>Software includes: formal specifications for the CADP model checker; formal specifications for synthesizing progress litmus tests; a compiler from xml litmus tests to a variety of GPU backends, including Metal, CUDA, and Vulkan.</p>
<p>Data includes all of the test cases found after running the test case synthesis for 5 weeks. It includes running the progress litmus tests in 3 different configurations across 8 different GPUs. It also includes the results of running the progress litmus tests under various formal semi-fair models in the CADP model checker.</p>

},
keywords = {forward progress, GPGPU, model checking, test case synthesis}
}

@software{10.5281/zenodo.5501650,
author = {Jaber, Nouraldin and Wagner, Christopher and Jacobs, Swen and Kulkarni, Milind and Samanta, Roopsha},
title = {QuickSilver},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5501650},
abstract = {
    <p>This artifact contains a VirtualBox VM that can be used to replicate the results in “QuickSilver: Modeling and Parameterized Verification for Distributed Agreement-Based Systems”. It includes the source code of the QuickSilver tool.</p>

},
keywords = {modular verification., parameterized verification, QuickSilver}
}

@software{10.5281/zenodo.5502210,
author = {Gokhale, Satyajit and Turcotte, Alexi and Tip, Frank},
title = {Automatic Migration from Synchronous to Asynchronous JavaScript APIs (Artifact)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5502210},
abstract = {
    <p>This artifact contains information on setting up and evaluating the results for Desynchronizer, a tool for automatic refactoring of Synchronous Javascript API to their Asynchronous equivalents. The entire source code for the tool is also included.</p>

},
keywords = {async/await, JavaScript, promises, refactoring, static analysis}
}

@software{10.5281/zenodo.5502310,
author = {Moreira, Ang\'{e}lica Aparecida and Ottoni, Guilherme and Quint\~{a}o Pereira, Fernando Magno},
title = {OOPSLA Artifact of paper VESPA: Static Profiling for Binary Optimization},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5502310},
abstract = {
    <p>This artifact contains the VESPA tool as described in the paper, as well as scripts to reproduce the experiments mentioned in each of the research questions. Everything is packaged in a Docker image. Be aware that we have observed that database management systems and their benchmarks do not work properly inside a docker container, thus you may have not see the same behaviour for performance improvements, but you should observe the same behaviour for correlation and I-Cache misses that you read in the paper.</p>

},
keywords = {Compiler, Optimization, Prediction, Profiling}
}

@software{10.5281/zenodo.5504155,
author = {Paraskevopoulou, Zoe and Grover, Anvay},
title = {Accompanying Coq Development for the OOPLSA'21 Paper: Compiling With Continuations, Correctly.},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5504155},
abstract = {
    <p>This artifact is the source code of the CertiCoq project, part of which is the proved correct continuation-passing style transformation covered in the OOPSLA’21 paper “Compiling With Continuations Correctly”.</p>

},
keywords = {continuation-passing style, Coq, formal verification, logical relations, simulation relations, verified compilation}
}

@software{10.5281/zenodo.5504159,
author = {Atkinson, Eric and Baudart, Guillaume and Mandel, Louis and Yuan, Charles and Carbin, Michael},
title = {Statically Bounded-Memory Delayed Sampling for Probabilistic Streams},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5504159},
abstract = {
    <p>This artifact accompanies the paper “Statically Bounded-Memory Delayed Sampling for Probabilistic Streams” from OOPSLA 2021. It contains the code of the implementation and benchmarks, as well as a virtual machine that can be used to run the implementation.</p>

},
keywords = {Probabilistic programming, program analysis, reactive programming, semantics, streaming inference}
}

@software{10.5281/zenodo.5504362,
author = {Verbruggen, Gust and Le, Vu and Gulwani, Sumit},
title = {Replication Package for Article: "Semantic programming by example with pre-trained models"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5504362},
abstract = {
    <p>This archive contains the code for our paper “Semantic programming by example with pre-trained models”. It contains the code and data required to execute the experiments, as well as cached GPT-3 output in case no key is available.</p>

},
keywords = {flashfill, gpt-3, programming by example}
}

@software{10.5281/zenodo.5507442,
author = {Barbar, Mohamad and Sui, Yulei},
title = {Compacting Points-To Sets through Object Clustering (Artifact)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5507442},
abstract = {
    <p>Artifact packaged as a Docker image for reproducing the evaluation of “Compacting Points-To Sets Through Object Clustering” by Mohamad Barbar and Yulei Sui published at OOPSLA ’21.</p>

},
keywords = {bit-vectors, hierarchical clustering., points-to sets, staged points-to analysis}
}

@software{10.5281/zenodo.5510036,
author = {De Porre, Kevin and Ferreira, Carla and Pregui\c{c}a, Nuno and Gonzalez Boix, Elisa},
title = {Artifact for: ECROs: Building Global Scale Systems from Sequential Code},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5510036},
abstract = {
    <p>Complete software artifact for our submission “ECROs: Building Global Scale Systems from Sequential Code” by De Porre K., Ferreira C., Pregui\c{c}a N., and Gonzalez Boix E. at OOPSLA 2021. This version contains the complete artifact, i.e.&nbsp;the scripts to reproduce the benchmarks and the portfolio of ECROs.</p>

},
keywords = {data structures, eventual consistency, replication}
}

@software{10.5281/zenodo.5518181,
author = {Muehlboeck, Fabian and Tate, Ross},
title = {Transitioning from Structural to Nominal Code with Efficient Gradual Typing: Artifact},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5518181},
abstract = {
    <p>This is the software artifact for the OOPSLA 2021 paper “Transitioning from Structural to Nominal Code with Efficient Gradual Typing”.</p>
<p>It contains the source code for MonNom, the setup to reproduce all benchmark results shown in the paper, and the data for the plots presented in the paper. The artifact is a virtual machine where everything is already compiled and set up to run the benchmarks. For up-to-date source code, please check https://github.com/fabianmuehlboeck/monnom/tree/release/oopsla21 . The password for the user of the virtual machine is “monnom”. The artifact was packaged with Oracle VirtualBox 6.1.22 .</p>

},
keywords = {Gradual Typing, MonNom}
}

@software{10.5281/zenodo.5519606,
author = {He, Paul and Westbrook, Eddy and Carmer, Brent and Phifer, Chris and Robert, Valentin and Smeltzer, Karl and \c{S}tef\u{a}nescu, Andrei and Tomb, Aaron and Wick, Adam and Yacavone, Matthew and Zdancewic, Steve},
title = {Artifact: A Type System for Extracting Functional Specifications from Memory-Safe Imperative Programs},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5519606},
abstract = {
    <p>The artifact is a docker image which contains the Coq formalization of the metatheory presented in the paper, as well as the source code for the Heapster tool described in the paper. The example code that the Heapster tool is included along with the source code.</p>

},
keywords = {memory safety, pointers, Specification extraction, type systems}
}

@software{10.5281/zenodo.5530883,
author = {Biswas, Ranadeep and Kakwani, Diptanshu and Vedurada, Jyothi and Enea, Constantin and Lal, Akash},
title = {Replication Package for Article: MonkeyDB: Effectively Testing Correctness under Weak Isolation Levels},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5530883},
abstract = {
    <p>The artifact includes an implementation of the tool reported in the paper and the benchmark used for the experimental evaluation.</p>

},
keywords = {Applications of Storage Systems, Testing, Transactional Databases, Weak Isolation Levels}
}

@software{10.1145/3476480,
author = {Frachtenberg, Eitan and Kaner, Rhody},
title = {Implementation of the article "Representation of Women in High-Performance Computing Conferences"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3476480},
abstract = {
    <p>These files represent all the raw and processed data, as well as the code to process it, to analyze some of the top systems conferences during 2017. Each subdirectory holds its own README.md file to describe the files in it.</p>
}
}

@software{10.1145/3476484,
author = {Ding, Caiwen and Gaihre, Anil and Li, Lingda and Li, Sherry and Liu, Hang and Song, Shuaiwen Leon and Weitze, Scott and Zheng, Da},
title = {Implementation of the article "Dr. Top-k: delegate-centric Top-k on GPUs"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3476484},
abstract = {
    
}
}

@software{10.1145/3476485,
author = {Arafa, Yehia and Arafa, Yehia and Badawy, Abdel-Hameed A. and Barai, Atanu and Chennupati, Gopinath and ELWazir, Ammar Mohamed Amin Ahmed and Eidenbenz, Stephan and Eker, Ali and Santhi, Nandakishore},
title = {Implementation of the article "Hybrid, scalable, trace-driven performance modeling of GPGPUs"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3476485},
abstract = {
    <p>PPT-GPU is a scalable and flexible framework to predict the performance of GPUs running general purpose workloads. PPT-GPU can use the virtual (PTX) or the native (SASS) ISAs without sacrificing accuracy, ease of use, or portability. The tool is currently focused on NVIDIA GPUs. We plan to extend our approach to model other vendors' GPUs such as AMD and Intel.</p>
}
}

@software{10.1145/3476481,
author = {Guo, Shengjian and Li, Guanpeng and Rahman, Md Hasanur and Shamji, Aabid},
title = {Implementation of the article "PEPPA-X: finding program test inputs to bound silent data corruption vulnerability in HPC applications"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3476481},
abstract = {
    <p>Peppa-X can efficiently finds a test input that can
              estimate the bound of program SDC(silent data corruption) resiliency. Generally with
              strawman method it takes days even month to find the input
              that provides the highest SDC probablilty with manually doing fault injection to every single input
              and check their SDC probabilty. But Peppa-X leverages genetic algorithm, along with our dynamic
              analysis technique described in the paper to guide the search towards the input which exercises the
              relatively much higher SDC probability among all other inputs. That means it can find the input that
              exercises the most vulnerable part of the program.</p>
}
}

@software{10.1145/3476482,
author = {Adelman, Menachem and Anderson, Cristina and Avancha, Sasikanth and Breuer, Alexander and Bruestle, Jeremy and Chaudhary, Narendra and Georganas, Evangelos and Heinecke, Alexander and Kalamkar, Dhiraj D. and Kundu, Abhisek and Kutnick, Denise and Laub, Frank and Md, Vasimuddin and Misra, Sanchit and Mohanty, Ramanarayan and Mohanty, Ramanarayan and Pabst, Hans and Ziv, Barukh},
title = {Implementation of the article "Tensor processing primitives: a programming abstraction for efficiency and portability in deep learning workloads"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3476482},
abstract = {
    <p>LIBXSMM is a library for specialized dense and sparse matrix operations as well as for deep learning primitives such as small convolutions. The library is targeting Intel Architecture with <span>Intel&nbsp;SSE</span>, <span>Intel&nbsp;AVX</span>, <span>Intel&nbsp;AVX2</span>, <span>Intel&nbsp;AVX‑512</span> (with VNNI and Bfloat16), and <span>Intel&nbsp;AMX</span> (Advanced Matrix Extensions) supported by future Intel processor code-named Sapphire Rapids. Code generation is mainly based on <span>Just‑In‑Time (JIT)</span> code specialization for compiler-independent performance (matrix multiplications, matrix transpose/copy, sparse functionality, and deep learning). LIBXSMM is suitable for "build once and deploy everywhere", i.e., no special target flags are needed to exploit the available performance. Supported GEMM datatypes are: `FP64`, `FP32`, `bfloat16`, `int16`, and `int8`.</p>
}
}

@software{10.1145/3476483,
author = {Ahmed, Nesreen and Avancha, Sasikanth and Georganas, Evangelos and Heinecke, Alexander and Kalamkar, Dhiraj D. and Ma, Guixiang and Md, Vasimuddin and Misra, Sanchit and Mohanty, Ramanarayan},
title = {Implementation of the article "DistGNN: scalable distributed training for large-scale graph neural networks"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3476483},
abstract = {
    <p>DGL is an easy-to-use, high performance and scalable Python package for deep learning on graphs. DGL is framework agnostic, meaning if a deep graph model is a component of an end-to-end application, the rest of the logics can be implemented in any major frameworks, such as PyTorch, Apache MXNet or TensorFlow.</p>
}
}

@software{10.5281/zenodo.3881644,
author = {Li, Kun and Yuan, Liang and Yue, Yue and Zhang, Yunquan},
title = {Implementation of the article "Reducing Redundancy in Data Organization and Arithmetic Calculation for Stencil Computations"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3881644},
abstract = {
    <p></p><p>First Release.</p><p></p>
}
}

@software{10.5281/zenodo.4094667,
author = {Balaprakash, Prasanna and Egele, Romain and Egele, Romain and Guyon, Isabelle and Liu, Zhengying and Stevens, Rick and Vishwanath, Venkatram and Xia, Fangfang},
title = {Implementation of the article "AgEBO-Tabular: Joint Neural Architecture and Hyperparameter Search with Autotuned Data-Parallel Training for Tabular Data full strip note"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4094667},
abstract = {
    <p></p><p>A release for the creation of a DOI on Zeno.</p><p></p>
}
}

@software{10.5281/zenodo.4836022,
author = {Ashkboos, Saleh and De Sensi, Daniele and Di Girolamo, Salvatore and Hoefler, Torsten and Li, Shigang},
title = {Implementation of the article "Flare: Flexible In-Network Allreduce"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4836022},
abstract = {
    <p></p><p>SC21 Artifact</p><p></p>
}
}

@software{10.5281/zenodo.4884852,
author = {Amvrosiadis, George and Cranor, Chuck and Ganger, Greg and Gibson, Garth and Grider, Gary and Settlemyer, Brad and Zheng, Qing},
title = {Implementation of the article "DeltaFS: A Scalable No-Ground-Truth Filesystem For Massively-Parallel Computing"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4884852},
abstract = {
    <p></p><p>First release.</p><p></p>
}
}

@software{10.5281/zenodo.4895203,
author = {Chard, Kyle and Foster, Ian and Huang, Lei and Huang, Qi and Pauloski, J. Gregory and Venkataraman, Shivaram and Zhang, Zhao},
title = {Implementation of the article "KAISA: An Adaptive Second-order Optimizer Framework for Deep Neural Networks"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4895203},
abstract = {
    <p>BERT for Distributed PyTorch + AMP Training</p>
}
}

@software{10.5281/zenodo.4897500,
author = {Chen, Hanhua and Jin, Hai and Tan, Jei and Wang, Yonghui},
title = {Implementation of the article "Whale: Efficient One-to-Many Data Partitioning in RDMA-assisted Distributed Stream Processing Systems"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4897500},
abstract = {
    <p></p><p>Describe the steps for running benchmarks in more detail</p><p></p>
}
}

@software{10.5281/zenodo.4899910,
author = {Ananthan, Shreyas and Li, Ruipeng and Mullowney, Paul and Mullowney, Paul and Rood, Jon and Sharma, Ashesh and Sprague, Michael and Thomas, Stephen and Willians, Alan},
title = {Implementation of the article "Preparing an Incompressible-Flow Fluid Dynamics Code for Exascale-Class Wind Energy Simulations"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4899910},
abstract = {
    <p></p><p>This release of Nalu-Wind can make use of an optimized Hypre GPU device assembly algorithm (<a href="https://doi.org/10.5281/zenodo.4899892">https://doi.org/10.5281/zenodo.4899892</a>).</p>
<p>Nalu-Wind can be built using the exawind-builder project (<a href="https://exawind.github.io/exawind-builder/">https://exawind.github.io/exawind-builder/</a>)</p>
<p>The following example, reg_tests/test_files/ablNeutralNGPHypreSegregated/ablNeutralNGPHypreSegregated.yaml, can be modified to use the optimized device assembly algorithm by setting:
  simple_hypre_matrix_assemble: yes
in the solver blocks</p><p></p>
}
}

@software{10.5281/zenodo.5003901,
author = {Ding, Xiaoning and Foster, Ian and Guo, Yanfei and Kurc, Tahsin and Shu, Tong and Wozniak, Justin},
title = {Implementation of the article "Bootstrapping In-situ Workflow Auto-Tuning via Combining Performance Models of Component Applications full strip note"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5003901},
abstract = {
    <p></p><p>This is the first release.</p><p></p>
}
}

@software{10.5281/zenodo.5092219,
author = {Chen, Wei and Cheng, Liangfeng and Feng, Dan and Hu, Yuchong and Ke, Zhaokang and Wang, Weichun and Xu, Jia and Yao, Qiaori},
title = {Implementation of the article "LogECMem: Coupling Erasure-Coded In-Memory Key-Value Stores with Parity Logging"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5092219},
abstract = {
    <p>No description provided.</p>
}
}

@software{10.5281/zenodo.5116412,
author = {Hu, Qinghao and Sun, Peng and Wen, Yonggang and Yan, Shengen and Zhang, Tianwei},
title = {Implementation of the article "Characterization and Prediction of Deep Learning Workloads in Large-Scale GPU Datacenters"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5116412},
abstract = {
    <p></p><p>HeliosArtifact</p><p></p>
}
}

@software{10.5281/zenodo.5136675,
author = {Chen, Zhaodong and Ding, Yufei and Liu, Liu and Qu, Zheng and Xie, Yuan},
title = {Implementation of the article "Efficient Tensor Core-based GPU Kernels for Structured Sparsity under Reduced Precision"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5136675},
abstract = {
    <p></p><p>This is the artifact of our paper "Efficient Tensor Core-Based GPU Kernels for Structured Sparsity under Reduced Precision" accepted in SC21</p><p></p>
}
}

@software{10.5281/zenodo.5144378,
author = {Ding, Yufei and Feng, Boyuan and Feng, Boyuan and Geng, Tong and Li, Ang and WANG, YUKE},
title = {Implementation of the article "APNN-TC: Accelerating Arbitrary Precision Neural Networks on Ampere GPU Tensor Cores"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5144378},
abstract = {
    <p></p><p>This is the source code for the SC'21 paper:&nbsp;<strong>APNN-TC: Accelerating Arbitrary Precision Neural Networks on Ampere GPU Tensor Cores</strong></p>

<p>&nbsp;</p>

<p>&nbsp;</p>

<p>&nbsp;</p><p></p>
}
}

@software{10.5281/zenodo.5144438,
author = {Aluru, Srinivas and Aluru, Maneesha R. and Chockalingam, Sriram P. and Srivastava, Ankit},
title = {Implementation of the article "Parallel Construction of Module Networks"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5144438},
abstract = {
    <p></p><p>This release adds more details on reproducing the results in the publication.</p><p></p>
}
}

@software{10.5281/zenodo.5144709,
author = {Li, Kenli and Lin, Shengle and Tsai, Qinyun and Wang, Haotian and Yang, Wangdong},
title = {Implementation of the article "STM-Multifrontal QR: Streaming Task Mapping Multifrontal QR Factorization Empowered by GCN"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5144709},
abstract = {
    <p></p><p>This is the first release version of Streaming Task Map Multifrontal QR Factorization Empowered by GCN.</p><p></p>
}
}

@software{10.5281/zenodo.5144874,
author = {Fahringer, Thomas and Knorr, Fabian and Thoman, Peter},
title = {Implementation of the article "ndzip-gpu: Efficient Lossless Compression of Scientific Floating-Point Data on GPUs"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5144874},
abstract = {
    <p></p><p>As accepted by the SC'21 artifact evaluation committee.</p><p></p>
}
}

@software{10.5281/zenodo.5147569,
author = {Li, Keqiu and Li, Yiming and Yang, Yanan and Zhao, Laiping and Zhou, Xian},
title = {Implementation of the article "Understanding, Predicting and Scheduling Serverless Workloads under Partial Interference"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5147569},
abstract = {
    <p></p><p>Update README.md</p><p></p>
}
}

@software{10.5281/zenodo.5147573,
author = {Churavy, Valentin and Doerfert, Johannes and H\"{u}ckelheim, Jan and Moses, William S. and Narayanan, Sri Hari Krishna and Paehler, Ludger and Schanen, Michel},
title = {Implementation of the article "Reverse-Mode Automatic Differentiation and Optimization of GPU Kernels via Enzyme full strip note"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5147573},
abstract = {
    <p>This repo contains the benchmarks for Enzyme on GPU's</p>
}
}

@software{10.5281/zenodo.5148715,
author = {Kung, H. T. and Natesh, Vikas and Sabot, Andrew},
title = {Implementation of the article "CAKE: Matrix Multiplication Using Constant-Bandwidth Blocks"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5148715},
abstract = {
    <p></p><p>First release for Zenodo archiving</p><p></p>
}
}

@software{10.5281/zenodo.5148797,
author = {Alabandi, Ghadeer and Burtscher, Martin and Rusnak, Lucas and Te\v{s}i\'{c}, Jelena},
title = {Implementation of the article "Discovering and Balancing Fundamental Cycles in Large Signed Graphs"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5148797},
abstract = {
    <p></p><p>First release for reviewers.</p><p></p>
}
}

@software{10.5281/zenodo.5148930,
author = {Allen, Tyler and Ge, Rong},
title = {Implementation of the article "In-Depth Analyses of Unified Virtual Memory System for GPU Accelerated Computing"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5148930},
abstract = {
    <p></p><p>Artifact appendix item for SC2021.</p><p></p>
}
}

@software{10.5281/zenodo.5151491,
author = {Cao, Hang and Li, Kun and Lu, Pengqi and Yuan, Liang and Yue, Yue and Zhang, Yunquan},
title = {Implementation of the article "Temporal Vectorization for Stencils"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5151491},
abstract = {
    <p></p><p>first release</p><p></p>
}
}

@software{10.5281/zenodo.5152741,
author = {Manzano, Joseph and Ranganath, Kiran and Song, Shuaiwen Leon and Suetterlein, Joshua and Wong, Daniel},
title = {Implementation of the article "MAPA: Multi-Accelerator Pattern Allocation Policy for Multi-Tenant GPU Servers"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5152741},
abstract = {
    <p>No description provided.</p>
}
}

@software{10.5281/zenodo.5154114,
author = {Halappanavar, Mahantesh and Khan, Arif and Serra, Edoardo and Rajam, Aravind Sukumaran and Xiang, Lizhi},
title = {Implementation of the article "cuTS: Scaling Subgraph Isomorphism on Distributed Multi-GPU Systems Using Trie Based Data Structure"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5154114},
abstract = {
    <p></p><p>This repository contains the code for the "cuTS: Scaling Subgraph Isomorphism on Distributed Multi-GPU Systems Using Trie Based Data Structure" framework. The cuTS framework is an efficient subgraph isomorphism solver for GPUs.</p><p></p>
}
}

@software{10.5281/zenodo.5155509,
author = {Ben-Nun, Tal and Calotoiu, Alexandru and De Matteis, Tiziano and Hoefler, Torsten and Lavarini, Luca and Schneider, Timo and Ziogas, Alexandos Nikolaos and de Fine Licht, Johannes},
title = {Implementation of the article "Productivity, Portability, Performance: Data-Centric Python"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5155509},
abstract = {
    <p></p><p>Artifact of SC'21 Paper "Productivity, Portability, Performance: Data-Centric Python".</p>

<p>The artifact can also be cloned from&nbsp;<a href="https://spclgitlab.ethz.ch/tim0s/ddace-lite-sc21">https://spclgitlab.ethz.ch/tim0s/ddace-lite-sc21</a></p><p></p>
}
}

@software{10.5281/zenodo.5155769,
author = {He, Ligang and He, Bingsheng and Jin, Hai and Liao, Xiaofei and Liu, Haikun and Zhang, Yu and Zhao, Jin},
title = {Implementation of the article "LCCG: A Locality-Centric Hardware Accelerator for High Throughput of Concurrent Graph Processing"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5155769},
abstract = {
    <p></p><p>This paper presents a locality-centric programmable accelerator LCCG, which can fundamentally address the challenge of the irregular accesses of the CGP jobs so as to achieve higher throughput for the execution of these jobs. By regularizing the graph traversals of the CGP jobs and fully consolidating the storage and accesses of the graph data, LCCG can minimize the data access cost for the execution of the CGP jobs and also achieve higher utilization of the cores. On a simulated 64-core processor, the experimental results show that LCCG improves the throughput of the state-of-the-<br>
art software system by up to 23.9 times with only 0.5\% extra area cost. In the future, we will research how to integrate some existing hardware techniques into LCCG to get better performance, and also research how to avoid the leaking of some private information of the jobs for the LCCG.</p><p></p>
}
}

@software{10.5281/zenodo.5156431,
author = {Hsu, Kuan-Chieh and Tseng, Hung-Wei},
title = {Implementation of the article "Accelerating Applications using Edge Tensor Processing Units"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5156431},
abstract = {
    <p></p><p>Alpha version of GPETPU Release</p><p></p>
}
}

@software{10.5281/zenodo.5156596,
author = {He, Yuxiong and Rajbhandari, Samyam and Rasley, Jeff and Ruwase, Olatunji and Smith, Shaden},
title = {Implementation of the article "ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5156596},
abstract = {
    <p></p><p>DeepSpeed is a deep learning optimization library that makes distributed training easy, efficient, and effective. This repo contains the code used in the paper <a href="https://arxiv.org/abs/2104.07857">[2104.07857] ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning (arxiv.org)</a>.</p><p></p>
}
}

@software{10.5281/zenodo.5158988,
author = {Bader, Michael and Bastian, Peter and Rannabauer, Leonhard and Reinarz, Anne and Scheichl, Rob and Seelinger, Linus},
title = {Implementation of the article "High Performance Uncertainty Quantification with Parallelized Multilevel Markov Chain Monte Carlo"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5158988},
abstract = {
    <p></p><p>This bundle contains:</p>

<ul>
	<li>MIT UQ library commit: https://doi.org/10.5281/zenodo.5109563</li>
	<li>MUQ interface for ExaHyPE: https://doi.org/10.5281/zenodo.4678165</li>
	<li>ExaHyPE tsunami model: https://doi.org/10.5281/zenodo.4678163</li>
	<li>DUNE Interface for MUQ and Poisson model</li>
	<li>ExaHyPE simulation results used in the paper in hdf5 format</li>
</ul><p></p>
}
}

@software{10.5281/zenodo.5159333,
title = {Implementation of the article "3D Acoustic-Elastic Coupling with Gravity: The Dynamics of the 2018 Palu, Sulawesi Earthquake and Tsunami"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5159333},
abstract = {
    <p></p><p>This repository contains the supplementary files for our SC21 submission: "3D Acoustic-Elastic Coupling with Gravity: The Dynamics of the 2018 Palu, Sulawesi Earthquake and Tsunami".</p>

<p>It contains the input data for all simulations. For more details, please refer to the included README.md files.</p>

<p>&nbsp;</p>

<p>The directory "seissol-sc21-revision-source-code" contains the version of SeisSol that we used.</p>

<p>&nbsp;</p><p></p>
}
}

@software{10.5281/zenodo.5162688,
title = {Implementation of the article "Hardware-supported Remote Persistence for Distributed Persistent Memory"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5162688},
abstract = {
    <p></p><p>No description provided.</p><p></p>
}
}

@software{10.5281/zenodo.5163624,
author = {Brinkmann, Andr\'{e} and Cortes, Toni and Klopp, David and Moti, Nafiseh and R\"{u}ckert, Ulrich and Salkhordeh, Reza and Schimmelpfennig, Frederic},
title = {Implementation of the article "Simurgh: A Fully Decentralized and Secure NVMM User Space File System"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5163624},
abstract = {
    <p>No description provided.</p>
}
}

@software{10.5281/zenodo.5163851,
author = {Ali-Eldin, Ahmed and Shenoy, Prashant and Wang, Bin},
title = {Implementation of the article "The Hidden cost of the Edge: A Performance Comparison ofEdge and Cloud Latencies"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5163851},
abstract = {
    <p></p><p>This is the image dataset used in our paper The Hidden Cost of the Edge: A Performance Comparison of Edge and Cloud Latencies (to appear in SC21). In our experiments it's used as the workload of a deep neural network (DNN) image classification application.</p><p></p>
}
}

@software{10.5281/zenodo.5164277,
author = {Arifuzzaman, Md and Arslan, Engin},
title = {Implementation of the article "Online Optimization of File Transfers in High-Speed Networks"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5164277},
abstract = {
    <p></p><p>Combined FTP and GridFTP Repositories.</p><p></p>
}
}

@software{10.5281/zenodo.5164404,
author = {Aiken, Alex and Bauer, Michael and Lee, Wonchan and McCormick, Patrick S. and Papadakis, Manolis and Slaughter, Elliott and Soi, Rupanshu and Treichler, Sean},
title = {Implementation of the article "Index Launches: Scalable, Flexible Representation of Parallel Task Groups"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5164404},
abstract = {
    <p></p><p>This is the software artifact for "Index Launches: Scalable, Flexible Representation of Parallel Task Groups", published in SC'21. A copy of this artifact is also archived under the tag <a href="https://github.com/StanfordLegion/legion/blob/papers/index-launch-sc21/language/sc21_scripts/README.md">papers/index-launch-sc21</a> in the original GitHub repository.</p>

<p>To use this software artifact, unpack it and refer to the instructions under language/sc21_scripts/README.md.</p><p></p>
}
}

@software{10.5281/zenodo.5164666,
author = {Campanoni, Simone and Cuevas, Michael and Dinda, Peter and Hale, Kyle and Homerding, Brian and Huang, Zhen and Liu, Conghao and Ma, Jiacheng and Nelson, Aaron and Wang, Wenyi},
title = {Implementation of the article "Paths to OpenMP in the Kernel"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5164666},
abstract = {
    <p></p><p>Detailed Description For Replication, Software for Nautilus/RTK, Nautilus/PIK, Nautilus/CCK, Linux/AutoMP, and Comparable Linux/OpenMP Results</p><p></p>
}
}

@software{10.5281/zenodo.5165333,
author = {Awan, Muaaz Gul and Buluc, Aydin and Deslippe, Jack and Ding, Nan and Egan, Rob and Hofmeyr, Steven and Oliker, Leonid and Yelick, Katherine},
title = {Implementation of the article "Accelerating large scale de novo metagenome assembly using GPUs"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5165333},
abstract = {
    <p></p><p>We used the version of MetaHipMer2 available at: <a href="https://bitbucket.org/berkeleylab/mhm2/src/master/">https://bitbucket.org/berkeleylab/mhm2/src/master/</a> and integrated our GPU local assembly module in it. This release contains the GPU accelerated version of MetaHipMer2 that has been discussed and presented in the SC21 submission. If you are looking to reproduce the results as shown in the SC21 submission please use this repo and if you are a user looking to use the most recent and stable release of MetaHipMer2 please go to the link mentioned above.</p><p></p>
}
}

@software{10.5281/zenodo.5165762,
author = {Chen, Hongzheng and Shen, Minghua},
title = {Implementation of the article "Krill: A Compiler and Runtime System for Concurrent Graph Processing"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5165762},
abstract = {
    <p></p><p>Krill is an efficient graph system for processing concurrent graph jobs, which consists of a high-level compiler and a runtime system. Property buffer and its compiler are provided to easily manage the property data. The runtime system is equipped with graph kernel fusion that greatly reduces the number of memory accesses.</p><p></p>
}
}

@software{10.5281/zenodo.5166929,
author = {Ben-Nun, Tal and B\"{o}hringer, Roman and Dryden, Nikoli and Hoefler, Torsten},
title = {Implementation of the article "Clairvoyant Prefetching for Distributed Machine Learning I/O"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5166929},
abstract = {
    <p></p><p>Software used in the submission of "Clairvoyant Prefetching for Distributed Machine Learning I/O" by Dryden et al., to appear at Supercomputing 2021. For up-to-date versions, visit&nbsp;<a href="https://github.com/spcl/NoPFS">https://github.com/spcl/NoPFS</a>.</p><p></p>
}
}

@software{10.5281/zenodo.5167006,
author = {Uezato, Yuya},
title = {Implementation of the article "Accelerating XOR-based Erasure Coding using Program Optimization Techniques"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5167006},
abstract = {
    <p>No description provided.</p>
}
}

@software{10.5281/zenodo.5167629,
author = {Bhalachandra, Sridutt and Gupta, Akshat and Kumar, Vivek and Kumar, Sunil},
title = {Implementation of the article "Cuttlefish: Library for Achieving Energy Efficiency in Multicore Parallel Programs"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5167629},
abstract = {
    <p></p><p>This artifact is the software implementation of the paper titled "Cuttlefish: Library for Achieving Energy Efficiency in Multicore Parallel Programs" published at the SC '21 conference. Cuttlefish is a programming model oblivious C/C++ library for achieving energy efficiency in multicore parallel programs running over Intel processors. An online profiler periodically profiles model-specific registers to discover a running application’s memory access pattern. Using a combination of DVFS and UFS, Cuttlefish then dynamically adapts the processor’s core and uncore frequencies, thereby improving its energy efficiency.</p><p></p>
}
}

@software{10.5281/zenodo.5167980,
author = {Diffenderfer, James D. and Georgakoudis, Giorgis and Laguna, Ignacio and Menon, Harshitha and Osei-Kuffuor, Daniel and Parasyris, Konstantinos and Schordan, Markus},
title = {Implementation of the article "HPAC: Evaluating Approximate Computing Techniques on HPC OpenMP Applications."},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5167980},
abstract = {
    <p></p><p>This is a baseline implementation of the approximate programming model called HPAC. HPAC extends Clang/LLVM. HPAC supports two approximation techniques perforation and memoization. Perforation supports subclasses of the technique that define the pattern of the perforated loops. Memoization supports two sub-classes of approximate memoization, namely input (iACT), and output (TAF) memorization. Each sub-class can be further parameterized to fine-tune the behavior of the technique. Finally, the release contains a set of scripts that facilitate exploration of the approximation design space and identify opportunities for approximations.</p><p></p>
}
}

@software{10.5281/zenodo.5168027,
author = {Ben-Nun, Tal and Besta, Maciej and Gaillard, Andr\'{e} and Hoefler, Torsten and Kabic, Marko and Kozhevnikov, Anton and Kwasniewski, Grzegorz and Saethre, Jens Eirik and Schneider, Timo and VandeVondele, Joost and Ziogas, Alexandos Nikolaos},
title = {Implementation of the article "On the Parallel I/O Optimality of Linear Algebra Kernels: Near-Optimal Matrix Factorizations"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5168027},
abstract = {
    <p></p><p>The first release of the library for distributed, communication-optimal LU and Cholesky factorization algorithms, with the appendix and the results from the paper.</p><p></p>
}
}

@software{10.5281/zenodo.5168093,
author = {Biersdorff, Scott and Daley, Christopher and Gayatri, Rahulkumar and Ozen, Guray and Southwell, Annemarie and Toepfer, Craig and Wright, Nicholas J.},
title = {Implementation of the article "Non-Recurring Engineering (NRE) Best Practices: A Case Study with the NERSC/NVIDIA OpenMP Contract"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5168093},
abstract = {
    <p></p><p>DOI=<a href="https://doi.org/10.1145/3458817.3476213">https://doi.org/10.1145/3458817.3476213</a></p><p></p>
}
}

@software{10.5281/zenodo.5168313,
author = {Fernando, Milinda Shayamal and Ganapathysubramanian, Baskar and Gao, Boshun and Hsu, Ming-Chen and Ishii, Masado and Krishnamurthy, Adarsh and Saurabh, Kumar and Sundar, Hari},
title = {Implementation of the article "Scalable adaptive PDE solvers in arbitrary domains"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5168313},
abstract = {
    <p></p><p>Framework to generate mesh for complex geometries</p><p></p>
}
}

@software{10.5281/zenodo.5168471,
author = {Huang, Jian and Snir, Marc and Sun, Jinghan},
title = {Implementation of the article "Pinpointing Crash-Consistency Bugs in the HPC I/O Stack: A Cross-Layer Approach"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5168471},
abstract = {
    <p>No description provided.</p>
}
}

@software{10.5281/zenodo.5168853,
author = {Byna, Suren and Chen, Yong and Lee, Sangkeun and Sim, Hyogi and Sim, Hyogi and Vazhkudai, Sudharshan S. and Vazhkudai, Sudharshan and Zhang, Wei},
title = {Implementation of the article "Exploiting User Activeness for Data Retention in HPC Systems"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5168853},
abstract = {
    <p></p><p>Updated description on the relevant scripts in <code>bin</code> directory.</p>
<p>Also remove some irrelevant internal files from <code>bin</code>.</p><p></p>
}
}

@software{10.5281/zenodo.5171429,
author = {Enright Jerger, Natalie and Gratz, Paul and Krishna, Tushar and Parasar, Mayank and San Miguel, Joshua},
title = {Implementation of the article "SEEC: Stochastic Escape Express Channel"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5171429},
abstract = {
    <p>artifacteval eval repo for sc2021</p>
}
}

@software{10.5281/zenodo.5171833,
author = {Chen, Youxu and Li, Cheng and Shao, Xinyang and Wang, Yiduo and Xu, Yinlong and Yan, Feng},
title = {Implementation of the article "Lunule: An Agile and Judicious Metadata Load Balancer for CephFS"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5171833},
abstract = {
    <p></p><p>SC21 Lunule Artifact Version with dependencies installation instructions updated.</p><p></p>
}
}

@software{10.5281/zenodo.5176097,
author = {Chen, Quan and Cui, Weihao and Guo, Minyi and Leng, Jingwen and Li, Chao and Zhao, Han and Zhao, Jieru and Zheng, Ningxin},
title = {Implementation of the article "Enable Simultaneous DNN Services Based on Deterministic Operator Overlap and Precise Latency Prediction"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5176097},
abstract = {
    <p>No description provided.</p>
}
}

@software{10.5281/zenodo.5176507,
author = {Allalen, Momme and Bergbauer, Maximilian and Fehn, Niklas and Geitner, Carolin and Kronbichler, Martin and Munch, Peter and Schulz, Martin and Wall, Wolfgang A. and Wichmann, Karl-Robert},
title = {Implementation of the article "A Next-Generation Discontinuous Galerkin Fluid Dynamics Solver with Application to High-Resolution Lung Airflow Simulations"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5176507},
abstract = {
    <p></p><p>ExaDG is a software project written in C++ using state-of-the-art programming techniques. The software targets the numerical solution of partial differential equations (PDE) in the field of computational fluid dynamics (CFD).</p>

<p>This code specifies the specific version of the underlying <a href="https://www.dealii.org">deal.II library</a> hosted on <a href="https://github.com/dealii/dealii">https://github.com/dealii/dealii</a> and ExaDG hosted on <a href="https://github.com/exadg/exadg">https://github.com/exadg/exadg</a>. This release is specifically created to document the version of ExaDG and deal.II used in the particular set of experiments of the paper "A Next-Generation Discontinuous Galerkin Fluid Dynamics Solver with Application to High-Resolution Lung Airflow Simulations" by M. Kronbichler, N. Fehn, P. Munch, M. Bergbauer, K.-R. Wichmann, C. Geitner, M. Allalen, M. Schulz, W.-A. Wall, SC-21, 2021. Please do not cite this as a general source for ExaDG, deal.II, or any of its dependencies. Instead, refer to the ExaDG and deal.II repositories for details.</p>

<p>The attached file install.sh includes a script with installation on common Linux-based HPC architectures.</p><p></p>
}
}

@software{10.5281/zenodo.5181820,
author = {Bernauer, Julie and Casper, Jared and Catanzaro, Bryan and Kashinkunti, Prethvi and Korthikanti, Vijay Anand and LeGresley, Patrick and Narayanan, Deepak and Patwary, Mostofa and Phanishayee, Amar and Shoeybi, Mohammad and Vainbrand, Dmitri and Zaharia, Matei},
title = {Implementation of the article "Efficient Large-Scale Language Model Training on GPU Clusters"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5181820},
abstract = {
    <p>Ongoing research training transformer language models at scale, including: BERT \&amp; GPT-2</p>
}
}

@software{10.5281/zenodo.5201457,
author = {Dong, Dezun and Fang, Jianbin and Su, Xing and Wang, Zheng and Yang, Weiling},
title = {Implementation of the article "LibShalom: Optimizing Small and Irregular-shaped Matrix Multiplications on ARMv8 Multi-Cores"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5201457},
abstract = {
    <p>No description provided.</p>
}
}

@software{10.5281/zenodo.5203181,
author = {Chen, Dexun and Cui, Lizhen and Duan, Xiaohui and Fu, Haohuan and Gao, Ping and Guo, Jiaxu and Li, Guohui and Liu, Weiguo and Liu, Xin and Ma, Ming and Meng, Xiangxu and Song, Zhenya and Wang, Jin and Xue, Wei and Yang, Guangwen and Zhang, Wusheng},
title = {Implementation of the article "LMFF: Efficient and Scalable Layered Materials Force Field on Heterogeneous Many-Core Processors"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5203181},
abstract = {
    <p></p><p>LAMMPS is one of the most popular Molecular Dynamic (MD) packages and is widely used in the field of physics, chemistry and materials simulation. Layered Materials Force Field (LMFF) is our expansion of the LAMMPS potential function based on the Tersoff potential and inter-layer potential (ILP) in LAMMPS. LMFF is designed to study layered materials such as graphene and boron hexanitride. It is universal and does not depend on any platform.</p><p></p>
}
}

@software{10.5281/zenodo.5203281,
author = {Li, Tianxi and Lu, Xiaoyi and Shi, Haiyang and Shi, Haiyang},
title = {Implementation of the article "HatRPC: Hint-Accelerated Thrift RPC over RDMA"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5203281},
abstract = {
    <p></p><p>Artifact for&nbsp;HatRPC: Hint-Accelerated Thrift RPC over RDMA</p><p></p>
}
}

@software{10.5281/zenodo.5204819,
author = {Arumugam, Kamesh and Paterno, Marc and Ranjan, Desh and Sakiotis, Ioannis and Sakiotis, Ioannis and Terzic, Balsa and Zubair, Mohammad},
title = {Implementation of the article "PAGANI: A Parallel Adaptive GPU Algorithm for Numerical Integration full strip note"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5204819},
abstract = {
    <p></p><p>This markdown file provides links to artifacts associated with the PAGANI integrator.</p><p></p>
}
}

@software{10.5281/zenodo.5206960,
author = {Krishnamoorthy, Sriram and Li, Ang},
title = {Implementation of the article "SV-Sim: Scalable PGAS-based State Vector Simulation of Quantum Circuits"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5206960},
abstract = {
    <p></p><p>This is a release for DOI generation for SC-21 publication.</p><p></p>
}
}

@software{10.5281/zenodo.5236852,
author = {Brandt, Jim and Costa, Emily and Patel, Tirthak and Schwaller, Benjamin and Tiwari, Devesh},
title = {Implementation of the article "Systematically Inferring I/O Performance Variability by Examining Repetitive Job Behavior"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5236852},
abstract = {
    <p></p><p>Fixed an input parameter error</p><p></p>
}
}

@software{10.5281/zenodo.5262865,
author = {Roy, Rohan Basu and Gadepally, Vijay and Gettings, Karen and Li, Baolin and Patel, Tirthak and Tiwari, Devesh},
title = {Implementation of the article "Ribbon: Cost-Effective and QoS-Aware Deep Learning Model Inference using a Diverse Pool of Cloud Computing Instances"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5262865},
abstract = {
    <p></p><p>Renamed SIMBO to Ribbon</p><p></p>
}
}

@software{10.5281/zenodo.5513082,
author = {Bian, Zhengda and Bian, Zhengda and Li, Shenggui and Wang, Wei and You, Yang},
title = {Implementation of the article "Online Evolutionary Batch Size Orchestration for Scheduling Deep Learning Workloads in GPU Clusters"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5513082},
abstract = {
    <p>No description provided.</p>
}
}

@software{10.6084/m9.figshare.14396099,
author = {Canon, Richard Shane and Priedhorsky, Reid and Randles, Timothy and Younge, Andrew},
title = {Implementation of the article "Minimizing privilege for building HPC containers"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.14396099},
abstract = {
    <p></p>
}
}

@software{10.5281/zenodo.5531242,
author = {Jouneaux, Gwendal and Barais, Olivier and Combemale, Benoit and Mussbacher, Gunter},
title = {SEALS: A Framework for Building Self-Adaptive Virtual Machines},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5531242},
abstract = {
    <p>In this artifact, we provide the implementation of the three SEALS-based Self-Adaptive Virtual Machines and the three handcrafted Self-Adaptive Virtual Machines (HTML, RobLANG and MiniJava).</p>
<p>This artifact provides a Maven-based build for the artifact as well as scripts to reproduce the benchmarking experiment and the lines of code count. Additionally, we provide a Jupyter notebook to analyze the results of the benchmarking experiments.</p>

},
keywords = {framework, self-adaptation, software language}
}

@software{10.5281/zenodo.5534113,
author = {Verano Merino, Mauricio and Beckmann, Tom and van der Storm, Tijs and Hirschfeld, Robert and Vinju, Jurgen J.},
title = {Skogi},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5534113},
abstract = {
    <p>S/Kogi is an extension of Kog that implements some simplification rules of context-free grammars as described in the SLE paper Getting Grammars into Shape for Block-based Editors. This tool allows users to derive block-based environments from a context-free grammar specification. S/Kogi uses on Google Blockly for rendering block-based environments, and Squeak/Smalltalk</p>

},
keywords = {app inventor, blockly, grammars, kogi, language workbench, rascal, scratch, smalltalk, snap}
}

@software{10.5281/zenodo.5544353,
author = {Hlad, Nicolas and Lemoine, B\'{e}r\'{e}nice and Huchard, Marianne and Seriai, Abdelhak-Djamel},
title = {Original Data and AOC-Poset from Article: Leveraging Relational Concept Analysis for Automated Feature Location in Software Product Lines},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5544353},
abstract = {
    <p>This file contains the data we use to perform the experiment described in our article. This data can be reused to verify the results of our extraction algorithms.</p>
<p>The content of the folder is described in a README</p>

},
keywords = {Case Studies, experiment, feature location, formal context, formal context analysis}
}

@software{10.5281/zenodo.5572916,
author = {Leroy, Dorian and Lelandais, Beno\^{\i}t and Oudot, Marie-Pierre and Combemale, Benoit},
title = {Artifact for Article: Monilogging for Executabel DSLs},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5572916},
abstract = {
    <p>The artifact is a Vagrant script building a VM that runs NabLab with MoniLog, allowing to instrument the execution of NabLab models with moniloggers. The resulting VM provides a NabLab workspace with 6 MoniLog specifications illustrating the different ways MoniLog can be used to perform logging and monitoring.</p>

},
keywords = {executable DSLs, logging, runtime monitoring}
}

@software{10.5281/zenodo.5573543,
author = {Yedidia, Zachary and Chong, Stephen},
title = {Artifact for Fast Incremental PEG Parsing},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5573543},
abstract = {
    <p>This artifact contains the source code for our GPeg incremental parser, the Flare syntax highlighting engine, an example text editor that uses both libraries, and our benchmarks and experiments from the paper, along with scripts to auto-generate the figures.</p>

},
keywords = {incremental parsing, packrat parsing, parsing expression grammars}
}

@software{10.6084/m9.figshare.16825933.v1,
author = {Farooq, Aamir and Zaytsev, Vadim},
title = {Supporting Code for Article "There Is More Than One Way to Zen Your Python"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.16825933.v1},
abstract = {
    <p>This archive contains the supporting code for the paper “There Is More Than One Way to Zen Your Python”. - catalogue_website_code/ contains the code for the website for our list of pythonic idioms. It can be viewed either by: - installing <code>docsify-cli</code> using: <code>npm i docsify-cli -g</code> and then running <code>docsify serve</code> in the <code>catalogue_website_code</code> folder. - using something like the Live Server extension for VSCode: https://marketplace.visualstudio.com/items?itemName=ritwickdey.LiveServer - deploying it to Github Pages - or visiting the live version of the website here: https://slimshadyiam.github.io/ZenYourPython/#/ - idiom_detection_code/ contains the code used to detect idioms in open source Python projects. A detailed setup guide and overview of the contents can be found in the README.md file in that directory, as well as the raw data collected from using the detection tool.</p>

},
keywords = {Python, pythonic idioms, pythonicity}
}

@software{10.1145/3506572,
author = {Ca\~{n}amares, Roc\'{\i}o and Castells, Pablo},
title = {Should I Follow the Crowd?: A Probabilistic Analysis of the Effectiveness of Popularity in Recommender Systems},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3506572},
abstract = {
    <p>The use of IR methodology in the evaluation of recommender systems has become common practice in recent years. IR metrics have been found however to be strongly biased towards rewarding algorithms that recommend popular items "the same bias that state of the art recommendation algorithms display. Recent research has confirmed and measured such biases, and proposed methods to avoid them. The fundamental question remains open though whether popularity is really a bias we should avoid or not; whether it could be a useful and reliable signal in recommendation, or it may be unfairly rewarded by the experimental biases. We address this question at a formal level by identifying and modeling the conditions that can determine the answer, in terms of dependencies between key random variables, involving item rating, discovery and relevance. We find conditions that guarantee popularity to be effective or quite the opposite, and for the measured metric values to reflect a true effectiveness, or qualitatively deviate from it. We exemplify and confirm the theoretical findings with empirical results. We build a crowdsourced dataset devoid of the usual biases displayed by common publicly available data, in which we illustrate contradictions between the accuracy that would be measured in a common biased offline experimental setting, and the actual accuracy that can be measured with unbiased observations.</p>

},
keywords = {accuracy, bias, collaborative filtering, evaluation, non-random missing data, popularity, recommender systems}
}

@software{10.1145/3506802,
author = {Draws, Tim Draws and Tintarev, Nava and Gadiraju, Ujwal and Bozzon, Alessandro and Timmermans, Benjamin},
title = {This Is Not What We Ordered: Exploring Why Biased Search Result Rankings Affect User Attitudes on Debated Topics},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3506802},
abstract = {
    In web search on debated topics, algorithmic and cognitive biases strongly influence how users consume and process information. Recent research has shown that this can lead to a search engine manipulation effect (SEME): when search result rankings are biased towards a particular viewpoint, users tend to adopt this favored viewpoint. To better understand the mechanisms underlying SEME, we present a pre-registered, 5 \texttimes{} 3 factorial user study investigating whether order effects (i.e., users adopting the viewpoint pertaining to higher-ranked documents) can cause SEME. For five different debated topics, we evaluated attitude change after exposing participants with mild pre-existing attitudes to search results that were overall viewpoint-balanced but reflected one of three levels of algorithmic ranking bias. We found that attitude change did not differ across levels of ranking bias and did not vary based on individual user differences. Our results thus suggest that order effects may not be an underlying mechanism of SEME. Exploratory analyses lend support to the presence of exposure effects (i.e., users adopting the majority viewpoint among the results they examine) as a contributing factor to users’ attitude change. We discuss how our findings can inform the design of user bias mitigation strategies.
},
keywords = {HCI design and evaluation methods, Human-centered computing, Information systems, User studies, Web searching and information discovery}
}

@software{10.1145/3506803,
author = {Ghosh, Avijit and Dutt, Ritam and Wilson, Christo},
title = {When Fair Ranking Meets Uncertain Inference},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3506803},
abstract = {
    <p>Existing fair ranking systems, especially those designed to be demographically fair, assume that accurate demographic information about individuals is available to the ranking algorithm. In practice, however, this assumption may not hold --- in real-world contexts like ranking job applicants or credit seekers, social and legal barriers may prevent algorithm operators from collecting peoples' demographic information. In these cases, algorithm operators may attempt to infer peoples' demographics and then supply these inferences as inputs to the ranking algorithm. <br> In this study, we investigate how uncertainty and errors in demographic inference impact the fairness offered by fair ranking algorithms. Using simulations and three case studies with real datasets, we show how demographic inferences drawn from real systems can lead to unfair rankings. Our results suggest that developers should not use inferred demographic data as input to fair ranking algorithms, unless the inferences are extremely accurate.</p>

},
keywords = {algorithmic fairness, demographic inference, ethical ai, noisy protected attributes, ranking algorithms, uncertainty}
}

@software{10.1145/3506804,
author = {Hiep Tran, Khanh and Ghazimatin, Azin and Roy, Rishiraj Saha},
title = {Counterfactual Explanations for Neural Recommenders},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3506804},
abstract = {
    <p>While neural recommenders have become the state-of-the-art in recent years, the complexity of deep models still makes the generation of tangible explanations for end users a challenging problem. Existing methods are usually based on attention distributions over a variety of features, which are still questionable regarding their suitability as explanations, and rather unwieldy to grasp for an end user. Counterfactual explanations based on a small set of the user's own actions have been shown to be an acceptable solution to the tangibility problem. However, current work on such counterfactuals cannot be readily applied to neural models. In this work, we propose ACCENT, the first general framework for finding counterfactual explanations for neural recommenders. It extends recently-proposed influence functions for identifying training points most relevant to a recommendation, from a single to a pair of items, while deducing a counterfactual set in an iterative process. We use ACCENT to generate counterfactual explanations for two popular neural models, Neural Collaborative Filtering (NCF) and Relational Collaborative Filtering (RCF), and demonstrate its feasibility on a sample of the popular MovieLens 100K dataset.</p>

},
keywords = {Explanations, Influence functions, Recommendation Systems}
}

@software{10.1145/3506805,
author = {Kaiser, Magdalena and Roy, Rishiraj Saha and Weikum, Gerhard},
title = {Reinforcement Learning from Reformulations in Conversational Question Answering over Knowledge Graphs},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3506805},
abstract = {
    <p>The rise of personal assistants has made conversational question answering (ConvQA) a very popular mechanism for user-system interaction. State-of-the-art methods for ConvQA over knowledge graphs (KGs) can only learn from crisp question-answer pairs found in popular benchmarks. In reality, however, such training data is hard to come by: users would rarely mark answers explicitly as correct or wrong. In this work, we take a step towards a more natural learning paradigm - from noisy and implicit feedback via question reformulations. A reformulation is likely to be triggered by an incorrect system response, whereas a new follow-up question could be a positive signal on the previous turn's answer. We present a reinforcement learning model, termed CONQUER, that can learn from a conversational stream of questions and reformulations. CONQUER models the answering process as multiple agents walking in parallel on the KG, where the walks are determined by actions sampled using a policy network. This policy network takes the question along with the conversational context as inputs and is trained via noisy rewards obtained from the reformulation likelihood. To evaluate CONQUER, we create and release ConvRef, a benchmark with about 11k natural conversations containing around 205k reformulations. Experiments show that CONQUER successfully learns to answer conversational questions from noisy reward signals, significantly improving over a state-of-the-art baseline.</p>
},
keywords = {Explanations, Influence functions, Recommendation Systems}
}

@software{10.1145/3462303,
author = {Niu, Yue and Sterling, Jonathan and Grodin, Harrison and Harper, Robert},
title = {agda-calf},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462303},
abstract = {
    <p>The calf language is a cost-aware logical framework for studying quantitative aspects of (parallel) functional programs. agda-calf is the implementation of calf in the Agda proof assistant and comes bundled with the calf mechanization of various case studies.</p>

},
keywords = {algorithm analysis, amortized analysis, behavioral verification, cost models, equational reasoning, intensional property, mechanized proof, modal type theory, noninterference, parallel algorithms, phase distinction, proof assistants, recurrence relations}
}

@software{10.1145/3462304,
author = {Ciccone, Luca and Padovani, Luca},
title = {FairCheck},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462304},
abstract = {
    <p>FairCheck is a proof-of-concept implementation of the type system described in the paper Fair Termination of Binary Sessions in the proceedings of POPL 2022. FairCheck parses a distributed program modeled in a session-oriented variant of the π-calculus and verifies that: (1) There exists a typing derivation for each definition in the program using the algorithmic version of the type system; (2) Each process definition is action bounded, namely there exists a finite branch leading to termination; (3) Each process definition is session bounded, namely the number of sessions the process needs to create in order to terminate is bounded; (4) Each process definition is cast bounded, namely the number of casts the process needs to perform in order to terminate is bounded.</p>

},
keywords = {deadlock-freedom, fairness, liveness-checker, pi-calculus, session-types, type-checker}
}

@software{10.1145/3462305,
author = {Hou (Favonia), Kuen-Bang and Wang, Zhuyang},
title = {Replication Package for Article: Logarithm and Program Testing},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462305},
abstract = {
    <p>This artifact contains the our Haskell implementation and experiments on it for the article Logarithm and Program Testing. It contains the following components: 1. README.txt: instructions to build and run the experiments and evaluate claims in the article. 2. polycheck-qc: our library with the QuickCheck backend. 3. polycheck-sc: our library with the SmallCheck backend. 4. polycheck-qc-draw: scripts for the distribution figures. 5. Dockerfile, Dockerfile-draw: Dockerfiles to reproduce the results.</p>

},
keywords = {Haskell, property-based testing}
}

@software{10.1145/3462306,
author = {Castagna, Giuseppe and Laurent, Micka\"{e}l and Nguy\~{\^e}n, Kim and Lutze, Matthew},
title = {Prototype Typechecker for the Article 'On Type-Cases, Union Elimination, and Occurrence Typing'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462306},
abstract = {
    <p>The artifact is the prototype of the typechecker used to provide experimental results in the article ‘On Type-Cases, Union Elimination, and Occurrence Typing’. It features an implementation of the inference algorithm presented in the paper (as well as several extensions documented in the supplementary appendix).</p>

},
keywords = {Intersection Types, Occurrence Typing, Set-Theoretic Types, Type Inference., Type-Checking, Union Types}
}

@software{10.1145/3462307,
author = {Eichholz, Matthias and Campbell, Eric Hayden and Krebs, Matthias and Foster, Nate and Mezini, Mira},
title = {Software Artifact for Paper: Dependently-Typed Data Plane Programming},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462307},
abstract = {
    <p>This artifact contains the source code for the prototype implementation of the Pi4 type checker.</p>

},
keywords = {data plane programming, dependent types, P4, type checker}
}

@software{10.1145/3462308,
author = {M\"{u}ller, Mark Niklas and Makarchuk, Gleb and Singh, Gagandeep and P\"{u}schel, Markus and Vechev, Martin},
title = {Artifact for article: PRIMA: General and Precise Neural Network Certification via Scalable Convex Hull Approximations},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462308},
abstract = {
    <p>Codebase for the ERAN verification framework including the verifier PRIMA (domains “refinepoly” or “refinegpupoly”) and scripts to reproduce the results reported in “PRIMA: General and Precise Neural Network Certification via Scalable Convex Hull Approximations”.</p>

},
keywords = {Abstract Interpretation, Convexity, Polyhedra, Robustness}
}

@software{10.1145/3462309,
author = {Chen, Taolue and Flores-Lamas, Alejandro and Hague, Matthew and Han, Zhilei and Hu, Denghang and Kan, Shuanglong and Lin, Anthony W. and R\"{u}mmer, Philipp and Wu, Zhilin},
title = {String solver and benchmarks from 'Solving String Constraints with Regex-Dependent Functions through Transducers with Priorities and Variables'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462309},
abstract = {
    <p>Experiments in the article ‘Solving String Constraints with Regex-Dependent Functions through Transducers with Priorities and Variables’ were done using a version of the OSTRICH SMT solver, extended with support for PSSTs and the string functions described in the article. The artifact contains binaries (as Java bytecode) and sources (Scala) of this extended solver, in directory ostrich/, as well as benchmarks used in the evaluation.</p>

},
keywords = {String solving
SMT solver
Regular expressions}
}

@software{10.1145/3462311,
author = {Zhang, Yihong and Wang, Yisu Remy and Willsey, Max and Tatlock, Zachary},
title = {Artifact for "Relational E-matching"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462311},
abstract = {
    <p>https://github.com/yihozhang/relational-ematching-benchmark/commit/584156fe84b3862c862da6b3ee15320e8c8a7cf1</p>
<p>This is the artifact for the POPL 2022 paper “Relational E-matching”. A copy can be found on arXiv.</p>
<p>The paper introduces a new way to solve the e-matching problem using techniques from relational databases. In particular, our implementation uses an algorithm called generic join. The evaluation compares our approach (referred to in the paper and here as GJ) with a traditional e-matching algorithm (referred to as EM).</p>
<p>This artifact aims to reproduce Figure 9 and Table 1.</p>

},
keywords = {e-graphs, e-matching, generic join, relational database}
}

@software{10.1145/3462312,
author = {Raad, Azalea and Maranget, Luc and Vafeiadis, Viktor},
title = {X86_64 Memory Type Tests.},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462312},
abstract = {
    <p>This set of web pages explores the effect of X86_64 memory types on memory model. This is companion material to our article “Extending Intel-x86 Consistency and Persistency: Formalising the Semantics of Intel-x86 Memory Types and Non-Temporal Stores” by A. Raad, L. Maranget, V. Vafeiadis.</p>
<p>A dedicated section “Reproduce some experiments” describes two experiments to be performed on a Linux system: reproducing our main experiment and running our tests on hardware. This will demonstrate tools from the herdtools7 toolbox at work.</p>

},
keywords = {memory model, programming language semantics, shared memory concurrency., X86_64}
}

@software{10.1145/3462313,
author = {Miltner, Anders and Nu\~{n}ez, Adrian Trejo and Brendel, Ana and Chaudhuri, Swarat and Dillig, Isil},
title = {Replication Package for Artifact: Bottom-Up Synthesis of Recursive Functional Programs using Angelic Execution},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462313},
abstract = {
    <p>This archive contains the code and benchmarks for the paper Bottom-Up Synthesis of Recursive Functional Programs using Angelic Execution.</p>
<p>Instructions for installation and build, instructions for reproduction of the results, and a description of the structure of the repository, are all available in the file $/README.pdf.</p>

},
keywords = {finite tree automata, functional programming, program synthesis, recursion}
}

@software{10.5281/zenodo.5549765,
author = {Madiot, Jean-Marie and Pottier, Fran\c{c}ois},
title = {A Separation Logic for Heap Space under Garbage Collection - Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5549765},
abstract = {
    <p>This is the artifact corresponding to the article entitled A Separation Logic for Heap Space under Garbage Collection, and its associated documentation.</p>

},
keywords = {live data, program verification, separation logic, tracing garbage collection}
}

@software{10.5281/zenodo.5550765,
author = {Kokologiannakis, Michalis and Marmanis, Iason and Gladstein, Vladimir and Vafeiadis, Viktor},
title = {Replication Package for "Truly Stateless, Optimal Dynamic Partial Order Reduction"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5550765},
abstract = {
    <p>We consider our paper’s artifact to be the included version of TruSt, as well as the results we got by running the various tools on our benchmarks set. We stress that the results obtained for the same benchmarks by TruSt in the future might differ, as the tool will evolve.</p>
<p>We have made TruSt publicly available as part of GenMC: https://github.com/MPI-SWS/genmc. For any bugs, comments, or feedback regarding TruSt, please do not hesitate to contact us.</p>

},
keywords = {Dynamic Partial Order Reduction, Model Checking, Weak Memory Models}
}

@software{10.5281/zenodo.5553753,
author = {Wang, Yuting and Zhang, Ling and Shao, Zhong and Koenig, J\'{e}r\'{e}mie},
title = {Artifact: Verified Compilation of C Programs with a Nominal Memory Model},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5553753},
abstract = {
    <p>This is the artifact for the POPL 2022 paper “Verified Compilation of C Programs with a Nominal Memory Model”.</p>
<p>The artifact is a VM image in .ova format. We have tested the VM in VirtualBox 6.1.26 running on a host linux machine with 64-bit Ubuntu LTS 20.04. The source code can be found in the directory ‘/home/authors/nominal-compcert-popl22-artifact’. Follow the ‘READM.md’ file to evaluate the artifact. You can also open the README file with Firefox browser for improved readability.</p>
<p>If you prefer to compile from the source code on your local machine (Linux or Mac), please find the source code at the following address:</p>
<p>https://github.com/SJTU-PLV/nominal-compcert-popl22-artifact</p>
<p>The prerequisites are the same as for CompCert. You need to setup Coq 8.12, install necessary software (e.g., menhir), and run the configuration and make files in each directory as follows:</p>
<p>./configure x86_64-linux make</p>
<p>See CompCert’s user manual for more details.</p>

},
keywords = {Memory Models, Nominal Techniques, Verified Compilation}
}

@software{10.5281/zenodo.5553759,
author = {Li, Yuanbo and Satya, Kris and Zhang, Qirun},
title = {Implementation for "Efficient Algorithms for Dynamic Bidirected Dyck-Reachability"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5553759},
abstract = {
    <p>The artifact includes the implementation for the algorithm proposed in the paper “Efficient Algorithms for Dynamic Bidirected Dyck-Reachability”. It also include the necessary componenet of DDlog Data solver for the evaluation.</p>
<p>The artifact contains two main parts: The DynDyck implementation and the DDlog tool. We implement the dynamic Dyck-reachability algorithm for bidirected graphs in the directory <code>/root/popl_2022/dynamic</code>. The <code>/root/popl_2022/ddlog</code> directory contains the DDlog tool. The <code>/root/popl_2022/benchmark</code> directory contains the two benchmarks evaluated in our experiments.</p>

},
keywords = {bidirected graphs, Dyck-reachability, Dynamic graph algorithms, incremental analysis}
}

@software{10.5281/zenodo.5568850,
author = {Blanvillain, Olivier and Brachth\"{a}user, Jonathan Immanuel and Kjaer, Maxime and Odersky, Martin},
title = {Type-Level Programming with Match Types Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5568850},
abstract = {
    <p>This VM contains everything necessary to run the supplementary material of the “Type-Level Programming with Match Types” paper. To run this VM in VirtualBox:</p>
<ol type="1">
<li>Install Oracle VM VirtualBox (see instructions: Downloads – Oracle VM VirtualBox)</li>
<li>Click on the .ova file to import it into VirtualBox</li>
<li>Start the VM, then open the README.md file on the desktop for further instructions</li>
</ol>

},
keywords = {Match Types, Scala}
}

@software{10.5281/zenodo.5576388,
author = {Yuan, Charles and McNally, Christopher and Carbin, Michael},
title = {Artifact for Article: Twist: Sound Reasoning for Purity and Entanglement in Quantum Programs},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5576388},
abstract = {
    <p>This artifact supports the POPL’22 paper “Twist: Sound Reasoning for Purity and Entanglement in Quantum Programs” by Charles Yuan, Chris McNally, and Michael Carbin.</p>
<p>The artifact contains necessary materials to reproduce the evaluation of the paper, including sources of the interpreter for the Twist language, benchmark programs, and scripts to execute the evaluation.</p>

},
keywords = {entanglement, purity, quantum programming, type systems}
}

@software{10.5281/zenodo.5576679,
author = {Lim, Jay P. and Nagarakatte, Santosh},
title = {RLIBM-ALL: One Polynomial Approximation to Produce Correctly Rounded Results of an Elementary Function for Multiple Representations and Rounding Modes},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5576679},
abstract = {
    <p>We present the artifact for the accepted paper, One Polynomial Approximation to Produce Correctly Rounded Results of an Elementary Function for Multiple Representations and Rounding Modes. We describe the list of claims made by the paper, the installation instructions, and evaluation instructions. To ease the installation effort, we provide a docker image with all required softwares installed already. Additionally, we provide complete instructions to manually install the artifact on Ubuntu 20.04.</p>

},
keywords = {Correctly Rounded Elementary Functions, RLIBM, RLIBM-ALL, Round-to-odd}
}

@software{10.5281/zenodo.5586354,
author = {Hirsch, Andrew K. and Garg, Deepak},
title = {Coq Code for 'Pirouette: Higher-Order Typed Functional Choreographies'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5586354},
abstract = {
    <p>Coq code describing Pirouette, a higher-order typed functional choreography language. Contains code for all constructions in the paper along with formal proofs of every theorem in the paper. Pirouette is defined with reference to a local language, which can be given as a module.</p>

},
keywords = {choreographies, concurrent programming, coq, formal proofs, Functional languages}
}

@software{10.5281/zenodo.5598485,
author = {Tan, Bryan and Mariano, Benjamin and Lahiri, Shuvendu K. and Dillig, Isil and Feng, Yu},
title = {Replication Package for for SolType: Refinement Types for Arithmetic Overflow in Solidity},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5598485},
abstract = {
    <p>A collection of scripts and benchmarks for (partially) reproducing the results of the SolType evaluation.</p>

},
keywords = {automated verification, integer overflow, refinement type inference, smart contracts}
}

@software{10.5281/zenodo.5604551,
author = {Liu, Amanda and Bernstein, Gilbert Louis and Chlipala, Adam and Ragan-Kelley, Jonathan},
title = {Verified Scheduling Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5604551},
abstract = {
    <p>This artifact contains a virtual machine containing the source code and dependencies for building our Coq framework and running the tests and benchmarks as described in our accompanying paper. It also includes a README containing documentation and instructions for building and running components of this artifact.</p>

},
keywords = {Coq, formal verification, Halide, image processing, optimization, proof assistants}
}

@software{10.5281/zenodo.5628699,
author = {Ikebuchi, Mirai and Erbsen, Andres and Chlipala, Adam},
title = {Code Artifact for Certifying Derivation of State Machines from Coroutines},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5628699},
abstract = {
    <p>This artifact is for the paper “Certifying Derivation of State Machines from Coroutines” to appear at POPL 2022.</p>
<p>The code tarball includes our Coq development, the TLS case study, and supporting infrastructure for running extracted code using dependencies implemented in Haskell. The Virtual machine image also contains all dependencies for development and evaluation.</p>

},
keywords = {coroutines, cryptographic protocols, interaction trees, nested state machines, program derivation, proof assistants}
}

@software{10.5281/zenodo.5652106,
author = {Ye, Qianchuan and Delaware, Benjamin},
title = {Oblivious Algebraic Data Types: POPL22 Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5652106},
abstract = {
    <p>This artifact holds the Coq formalization of Oblivious Algebraic Data Types, a language for writing secure computation with recursive data types whose structures are protected. More specifically, it formalizes the two core calculi, λOADT and λOADT✚, from the POPL22 paper Oblivious Algebraic Data Types, and proves their soundness and obliviousness.</p>
<p>This artifact contains 3 files:</p>
<ul>
<li><p>oadt-pure-popl22.zip: λOADT formalization. It is a snapshot of tag pure-popl22 (commit b34546f).</p></li>
<li><p>oadt-tape-popl22.zip: λOADT✚ formalization. It is a snapshot of tag tape-popl22 (commit 32d8fc4).</p></li>
<li><p>oadt-popl22.ova: virtual machine image.</p></li>
</ul>

},
keywords = {algebraic data types, coq, dependent types, multiparty computation, oblivious computation}
}

@software{10.5281/zenodo.5652640,
author = {Jeon, Minseok and Oh, Hakjoo},
title = {Return of CFA: Call-Site Sensitivity Can Be Superior to Object Sensitivity Even for Object-Oriented Programs},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5652640},
abstract = {
    <p>This artifact aims to reproduce the results in Table 2~6, which experimentally show that call-site sensitivity is more precise than existing state-of-the-art object sensitivities. POPL_2022_paper586.ova is a bootable VirtualBox image with all of the necessary libraries installed. ArtifactManual.pdf provides instructions to check whether the artifact is installed correctly (Section 1). Section 2 presents how to reproduce the results in our paper. Section 3 illustrates how to analyze other programs with our artifact and how to analyze a program with a user-defined tunneling abstraction.</p>

},
keywords = {Context sensitivity, Machine learning for program analysis, Pointer analysis}
}

@software{10.5281/zenodo.5655530,
author = {Heunen, Chris and Kaarsgaard, Robin},
title = {Artifact for 'Quantum Information Effects'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5655530},
abstract = {
    <p>This is an implementation of the languages UPi, UPi_a, and UPi^chi_a and all related constructions, described in the paper Quantum Information Effects by Chris Heunen and Robin Kaarsgaard.</p>
<p>This artifact contains the implementation of the constructions and translations relating to UPi, UPi_a, and UPi^chi_a. These languages are implemented as eDSLs in (heavily extended Glasgow) Haskell. They have been tested to work with the GHC Haskell compilation system version 8.10.1 on macOS 11.6 Big Sur, as well as 8.6.5 on Ubuntu 20.04.</p>
<p>Though Haskell supports arrows via the Arrow type class, the implementation in Haskell only permits arrows over Haskell functions (i.e., over the type a -&gt; b) rather than over an arbitrary Category instance. For this reason, though the and constructions are arrows, they cannot be implemented as such. Instead, we have chosen to name the arrow combinators with suggestive but non-conflicting names, such as arr’, first’, left’, and so forth.</p>
<p>The code is structured as follows:</p>
<p>UPiBase.hs: Contains the data type declaration for UPi combinators. UPi.hs: Implementation of all (derived) UPi combinators, including the quantum gates described in Section 3.2. UPiaBase.hs: Contains the data type declaration for UPi_a combinators, as well as the declaration of the type classes Cloneable and Inhabited used to define the clone and inhab combinators respectively. Since all UPi_a types have a Cloneable instance, the Cloneable constraint is trivial (but Haskell doesn’t know that). UPia.hs: Contains the implementation of all (derived) combinators of UPi_a, as described in Section 3.3. UPichiaBase.hs: Contains the data type declaration for UPi^chi_a combinators, as well as the declaration of the Discardable type class used to handle projections. Again, all UPi^chi_a types have Discardable instances, so the constraint is trivial, but Haskell doesn’t know that. UPichia.hs: Contains the implementation of all (derived) combinators relating to UPi^chi_a, see Section 3.4. QFC.hs: Contains the translation from quantum flow charts to UPi^chi_a as described in Section 6.2.</p>

},
keywords = {arrows, information effects, quantum computing, reversible computing}
}

@software{10.5281/zenodo.5662349,
author = {Lepigre, Rodolphe and Sammler, Michael and Memarian, Kayvan and Krebbers, Robbert and Dreyer, Derek and Sewell, Peter},
title = {Artifact and Appendix of "VIP: Verifying Real-World C Idioms with Integer-Pointer Casts"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5662349},
abstract = {
    <p>This is the artifact for the POPL’22 paper “VIP: Verifying Real-World C Idioms with Integer-Pointer Casts”. It contains an extended version of the RefinedC and Cerberus tools with the presented VIP memory model, as well as examples, evaluation data, and the technical appendix for the paper.</p>

},
keywords = {C programming language, Coq, Iris, memory model, pointer provenance, proof automation, separation logic}
}

@software{10.5281/zenodo.5662717,
author = {Loehr, Devon and Walker, David},
title = {POPL22 Pipe AEC Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5662717},
abstract = {
    <p>This artifact contains a copy of the source code for the Lucid executable, as of POPL22’s AEC evaluation period. It also contains a vagrant box with the necessary tools to build the executable, as well as instructions for running the artifact and a link to the github repo containing the most up-to-date source code. Full instructions are contained in the README file included with the artifact.</p>

},
keywords = {Network programming languages, P4, PISA, type and effect systems}
}

@software{10.5281/zenodo.5662934,
author = {Porncharoenwase, Sorawee and Nelson, Luke and Wang, Xi and Torlak, Emina},
title = {"A formal foundation for symbolic evaluation with merging" Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5662934},
abstract = {
    <p>The artifact contains: - mechanization of our symbolic semantics and proof of its correctness - a reference interpreter named Leanette, which is proven correct. - solver-aided differential testing setup to test that Leanette agrees with Rosette 4 (https://github.com/emina/rosette), a new Rosette system that implements the symbolic semantics with an optimized symbolic factory - tools that test performance and compare interface of Rosette 4 vs Rosette 3 (the previous Rosette system)</p>

},
keywords = {state merging, symbolic evaluation}
}

@software{10.5281/zenodo.5667545,
author = {G\"{a}her, Lennard and Sammler, Michael and Spies, Simon and Jung, Ralf and Dang, Hoang-Hai and Krebbers, Robbert and Kang, Jeehoon and Dreyer, Derek},
title = {Coq development and technical documentation for "Simuliris: A Separation Logic Framework for Verifying Concurrent Program Optimizations"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5667545},
abstract = {
    <p>This is the artifact for the paper “Simuliris: A Separation Logic Framework for Verifying Concurrent Program Optimizations”. It contains the Coq mechanization of Simuliris, in particular the logic, its soundness proof, and the examples described in the paper. The artifact contains the Simuliris development both in a VM image with pre-built sources and as a .zip source archive. In addition, the technical appendix is included.</p>

},
keywords = {Coq, data races, Iris, program optimizations, separation logic}
}

@software{10.5281/zenodo.5668206,
author = {Fiore, Marcelo and Szamozvancev, Dmitrij},
title = {Source code repository for article: Formal Metatheory of Second-Order Abstract Syntax},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5668206},
abstract = {
    <p>GitHub repository for the Agda source of the language-formalisation framework. Includes the formalisation of the abstract metatheory along with initiality proofs, the Python code generation script, and a wide range of examples.</p>

},
keywords = {abstract syntax, Agda, category theory, language formalisation}
}

@software{10.5281/zenodo.5668357,
author = {Pujet, Lo\"{\i}c and Tabareau, Nicolas},
title = {A Logical Relation for Setoid Type Theory in Agda},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5668357},
abstract = {
    <h2 id="a-logical-relation-for-setoid-type-theory-in-agda">A Logical Relation for Setoid Type Theory in Agda</h2>
<p>This is a formalized proof of the decidability of conversion for an extension of Martin L\"{o}f type theory with an equality satisfying UIP, function extensionality, and propositional extensionality.</p>
<p>The source code can be browsed in HTML <a href="https://htmlpreview.github.io/?https://github.com/CoqHott/logrel-mltt/blob/setoid-universes-hierarchy/html/README.html">here</a>.</p>
<p>The companion paper can be found <a href="https://hal.inria.fr/hal-03367052">here</a></p>
<h4 id="setoid-type-theory">Setoid Type Theory</h4>
<p>The type theory under scrutiny is a simplified version of TT<sup>obs</sup>, as described in the companion paper. It features: - A hierarchy of universes for proof-relevant types, and one for proof-irrelevant types, - dependent products, with domain and codomain in any universe, - dependent pairs with proof-irrelevant domain and codomain (“existential types”), - proof-irrelevant identity types and type casting along equalities in the universes, - natural numbers and a proof-irrelevant empty type. However, it is subject to the following restrictions: - The universe hierarchies are restricted to two levels, - no general inductive types, - no equality types \`{a} la Swan, - no quotient types.</p>
<p>The interested reader is invited to consult either the companion paper or the formalized definitions for a more detailed account of TT<sup>obs</sup>.</p>
<h4 id="structure-of-the-proof">Structure of the proof</h4>
<p>The raw, untyped syntax is defined inductively, followed by an inductive definition of the typing derivations of TT<sup>obs</sup>.</p>
<p>The proof then relies on Agda’s implementation of induction-recursion to define a logical relation that characterizes the computational behaviour of the typing judgments. Some basic properties of this logical relation are then established, in order to prove the <em>fundamental lemma</em>, which states that any derivable judgement satisfies the logical relation.</p>
<p>Once the fundamental lemma has been proven, it entails several fundamental properties of the type theory, such as the termination of the weak-head reduction strategy, the canonicity of the integers, typing inversion results, etc.</p>
<p>This first part lays the foundation necessary to the definition of an algorithmic equality relation on types and terms. We can prove that this algorithmic equality is decidable, and, using the fundamental lemma, that it coincides with the judgmental equality. It follows that the judgmental equality of terms and types is decidable.</p>
<p>A more detailed, but still high-level overview of the proof is provided in the companion paper.</p>
<h4 id="files">Files</h4>
<p>A more detailed description of the role of each file can be found in README.agda</p>
<h4 id="dependencies">Dependencies</h4>
<p>This project is written in Agda. It has been tested to be working with Agda version 2.6.3.</p>
<h4 id="warning">Warning</h4>
<p>The reader who wishes to type-check the entire proof should be warned that the files Defintion/LogicalRelations/Substitution/Introductions/Cast.agda and Conversion/Decidable.agda may be quite resource-intensive (Type-checking the latter seems to take at least 10 min on a higher-end laptop).</p>

},
keywords = {Agda, Logical Relations, Type Theory}
}

@software{10.5281/zenodo.5668384,
author = {Perera, Roly and Nguyen, Minh and Petricek, Tomas and Wang, Meng},
title = {Implementation for article: Linked Visualisations via Galois Dependencies},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5668384},
abstract = {
    <p>Proof-of-concept implementation of data-linked visualisations.</p>

},
keywords = {data visualisation, dependency analysis, program slicing, provenance}
}

@software{10.5281/zenodo.5671746,
author = {Choudhury, Vikraman and Karwowski, Jacek and Sabry, Amr},
title = {Artifact for Symmetries in Reversible Programming},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5671746},
abstract = {
    <p>This artifact contains the accompanying formalisation for the POPL’22 paper “Symmetries in Reversible Programming: From Symmetric Rig Groupoids to Reversible Programming Languages”.</p>
<p>The purpose of this artifact is to:</p>
<ul>
<li><p>Provide a partial formalisation of the semantics presented in the paper and related results.</p></li>
<li><p>Show applications of the semantics, using a collection of examples showing normalisation-by-evaluation, synthesis, and equivalence of reversible circuits written in the Pi language.</p></li>
</ul>

},
keywords = {categorical semantics, computational group theory, denotational semantics, homotopy type theory, reversible computing, reversible programming languages}
}

@software{10.5281/zenodo.5675056,
author = {Jeffrey, Alan and Riely, James and Batty, Mark and Cooksey, Simon and Kaysin, Ilya and Podkopaev, Anton},
title = {Formalization in Coq. The Leaky Semicolon: Compositional Semantic Dependencies for Relaxed-Memory Concurrency},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5675056},
abstract = {
    <p>This artifact contains Coq code supplementing the paper Leaky Semicolon: Compositional Semantic Dependencies for Relaxed-Memory Concurrency.</p>

},
keywords = {Coq, weak memory models}
}

@software{10.5281/zenodo.5675249,
author = {Jacobs, Jules and Balzer, Stephanie and Krebbers, Robbert},
title = {Connectivity Graphs: A Method for Proving Deadlock Freedom Based on Separation Logic (Artifact)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5675249},
abstract = {
    <p>The artifact for the paper “Connectivity Graphs: A Method for Proving Deadlock Freedom Based on Separation Logic”. It contains the Coq sources for the connectivity graph framework and a mechanisation of the deadlock freedom property of a binary session typed lambda calculus. The file readme.pdf contains a full description.</p>

},
keywords = {Coq, deadlock freedom, formal proof, graphs., mechanised proof, separation logic, Session types}
}

@software{10.5281/zenodo.5676412,
author = {K, Hari Govind V and Shoham, Sharon and Gurfinkel, Arie},
title = {Replication Instructions for paper: CHCs modulo ADTs and RF},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5676412},
abstract = {
    <p>The artifact contains instructions to replicate results from the paper titled Constrained Horn Clauses modulo Algebraic Data Types and Recursive Functions. It also contains links to the source code, a docker image will all necessary executables, and benchmarks.</p>

},
keywords = {Algebraic Data Types, Formal verification, Model Checking, Recursive Functions}
}

@software{10.5281/zenodo.5703081,
author = {Padon, Oded and Wilcox, James R. and Koenig, Jason R. and McMillan, Kenneth L. and Aiken, Alex},
title = {Artifact for POPL 2022 Paper: Induction Duality: Primal-Dual Search for Invariants},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5703081},
abstract = {
    <p>The artifact is provided as a virtual machine, and includes input files (benchmarks) and results (log files) for all experiments reported in the paper. The VM also includes a version of mypyvy that matches the one used in the paper for the experiments of primal-dual Houdini and UPDR.</p>
<p>For more details, see induction-duality-popl-2022-artifact.txt.</p>

},
keywords = {counterexample-guided abstraction refinement, Houdini, IC3, induction duality, invariant inference, primal-dual Houdini, property directed reachability}
}

@software{10.5281/zenodo.5707114,
author = {Kjelstr\o{}m, Adam Husted and Pavlogiannis, Andreas},
title = {Replication package for article: The Decidability and Complexity of Interleaved Bidirected Dyck Reachability},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5707114},
abstract = {
    <p>Paper: The Decidability and Complexity of Interleaved Bidirected Dyck Reachability, POPL’22</p>
<p>Artifact Outline - In the above paper, we present an algorithm for solving interleaved, bidirected <span class="math inline"><em>D</em><sub>1</sub> ⊙ <em>D</em><sub>1</sub></span> reachability in <span class="math inline"><em>O</em>(<em>n</em><sup>3</sup><em>α</em>(<em>n</em>))</span>, where a is the inverse Ackermann function. We have implemented this algorithm along with techniques for pre-processing and simplifying input graphs and run it on Dacapo Benchmarks.</p>
<p>We also present an algorithm for solving interleaved, bidirected <span class="math inline"><em>D</em><sub>1</sub> ⊙ <em>D</em><sub><em>k</em></sub></span> reachability in <span class="math inline"><em>O</em>(<em>n</em><sup>2</sup><em>α</em>(<em>n</em>))</span> with <span class="math inline"><em>O</em>(<em>n</em>)</span> bounded counters. We have also implemented this algorithm along with pre-processing and simplification and run it on Dacapo Benchmarks.</p>
<p>We have implemented the algorithms in C++.</p>

},
keywords = {bidirected graphs, CFL/Dyck reachability, complexity, static analysis}
}

@software{10.1145/3462314,
author = {Yang, Yanan and Zhao, Laiping and Li, Yiming and Zhang, Huanyu and Li, Jie and Zhao, Mingyang and Chen, Xingzhen and Li, Keqiu},
title = {Replication package for INFless},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462314},
abstract = {
    <p>The artifact includes the source code and scripts of INFless system, which is a native serverless platform for high throughput DNN inference.</p>

},
keywords = {DNN inference, serverless platform}
}

@software{10.1145/3462316,
author = {Gorjiara, Hamed and Xu, Guoqing Harry and Demsky, Brian},
title = {Replication Package for Article: Yashme: Detecting Persistency Races},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462316},
abstract = {
    <p>This artifact contains a vagrant repository that downloads and compiles the source code for Yashme, its companion compiler pass, and benchmarks. The artifact enables users to reproduce the bugs that are found by Yashme in PMDK, Memcached, and Redis, and RECIPE as well as the performance results to compare Yashme with Jaaru, the underlying model checker.</p>

},
keywords = {CCEH, Compiler, FastFair, Memcached, Persistency Race, PMDK, RECIPE, Redis, Software Verification, Yashme}
}

@software{10.1145/3462317,
author = {Du, Dong and Liu, Qingyuan and Jiang, Xueqiang and Xia, Yubin and Zang, Binyu and Chen, Haibo},
title = {Artifact for Paper: Serverless Computing on Heterogeneous Computers},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462317},
abstract = {
    <p>The artifact is the main repo for paper, Serverless Computing on Heterogeneous Computers. It contains the instructions to build and run the experiments, and the top directory of the project.</p>

},
keywords = {heterogeneous architecture, operating system, Serverless computing, smart computers}
}

@software{10.1145/3462318,
author = {Suchy, Brian and Ghosh, Souradip and Kersnar, Drew and Chai, Siyuan and Huang, Zhen and Nelson, Aaron and Cuevas, Michael and Bernat, Alex and Chaudhary, Gaurav and Hardavellas, Nikos and Campanoni, Simone and Dinda, Peter},
title = {Source Kernel for Conference Paper:},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462318},
abstract = {
    <p>Nautilus is an example of an Aerokernel, a very thin kernel-layer exposed (much like Unikernel) directly to a runtime system and/or application. An Aerokernel does not, by default, have a user-mode! There are several reasons for this, simplicity and performance among the most important. Furthermore, there are no heavy-weight processes—only threads, all of which share an address space. Therefore, Nautilus is also an example of a single address-space OS (SASOS). The runtime can implement user-mode features or address space isolation if this is required for its execution model.</p>
<p>This version of Nautilus has been modified to accommodate running with a CARAT address space abstraction (CARAT CAKE). CARAT CAKE is an extension of work found in PLDI ’20 with the paper describing this work appearing in ASPLOS ’22.</p>
<p>The concept of CARAT CAKE is to replace paging with a system that can operate using only physical addresses. Doing this enables the underlying system to have significant energy savings as well as allow new performance minded optimizations in both the micro-architecture and in software.</p>

},
keywords = {compiler, kernel, nautilus, operating system, paging, virtual memory}
}

@software{10.5281/zenodo.5733989,
author = {Zheng, Zhen and Yang, Xuanda and Zhao, Pengzhan and Long, Guoping and Zhu, Kai and Zhu, Feiwen and Zhao, Wenyi and Liu, Xiaoyong and Yang, Jun and Zhai, Jidong and Song, Shuaiwen Leon and Lin, Wei},
title = {ASPLOS22 Artifact - AStitch Machine Learning Optimizing Compiler},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5733989},
abstract = {
    <p>The artifact contains the necessary software components to validate the main results in AStitch paper. We provide a docker image to ease the environment setup. The docker image contains the compiled binary of AStitch, scripts to evaluate the inference and training performance, and scripts to draw the figures. It requires a Linux system with NVIDIA driver (capable to run CUDA 10.0) running on a NVIDIA V100 GPU equipped x86_64 machine to create the docker container. After launching the docker container, people can run one script to collect all performance numbers. It requires some manual finishing to fill the performance numbers into several python scripts to draw the most important figures in the paper, showing the speedup of AStitch and breakdown information.</p>

},
keywords = {Compiler Optimization, Kernel Fusion, Machine Learning System, Memory-intensive Computation}
}

@software{10.5281/zenodo.5735634,
author = {Zhao, Mark and Gao, Mingyu and Kozyrakis, Christos},
title = {Artifact for Article: ShEF: Shielded Enclaves for Cloud FPGAs},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5735634},
abstract = {
    <p>In our artifact, we provide the entirety of the ShEF source code, including the Shield and implementations of the Secure Boot and Remote Attestation protocols. Our artifacts also include a number of reference benchmarks that we use to evaluate ShEF. We provide instructions on how to build, run, and evaluate Shield benchmarks on AWS F1 instances. Our archival and GitHub repository also provides a README containing more details on using ShEF.</p>

},
keywords = {cloud computing, enclaves, FPGAs, reconfigurable computing, trusted execution}
}

@software{10.5281/zenodo.5746392,
author = {Guo, Zhiyuan and Shan, Yizhou and Luo, Xuhao and Huang, Yutong and Zhang, Yiying},
title = {Replication Package for Article: Clio: A Hardware-Software Co-Designed Disaggregated Memory System},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5746392},
abstract = {
    <p>This artifact provides the source code of Clio, a hardware software co-designed disaggregated memory system. The Clio artifact has a C-based host-side library, a C-based ARM SoC management path, and a SpinalHDL-based FPGA data path along with a set of comprehensive FPGA building scripts. The artifact suite also has a set of microbenchmark examples and ported applications</p>

},
keywords = {FPGA, Hardware Software Co-design, Resource Disaggregation, Virtual Memory}
}

@software{10.5281/zenodo.5746505,
author = {Zhang, Haotian and Ren, Mengfei and Lei, Yu and Ming, Jiang},
title = {uTrimmer: Security Hardening of MIPS Embedded Systems via Static Binary Debloating for Shared Libraries},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5746505},
abstract = {
    <p>This abstract is used to evaluate performance of our debloating framework uTrimmer on SPEC CPU2017, MIPS firmware applications, and a real MIPS embedded application. uTrimmer is built on top of angr to identify and wipe out unused basic blocks from shared libraries’ binary code in MIPS firmware applications. For a given MIPS binary program and its dependent shared libraries, uTrimmer can export a debated shared libraries of the program. uTrimmer itself does not need additional software to work. However, to evaluate the debloating result, It requires IDA pro for function boundary detection and QEMU to emulate execution environment for programs under the test. The required execution scripts to reproduce the experiment results are provided in the VM image.</p>
<p>We performed several experiments to evaluate uTrimmer’s performance. The first experiment evaluates debloating capability of uTrimmer on SPEC CPU2017 and real firmware applications. The result is shown in Table 3 on page 10. The second experiment compares uTrimmer with the static linker about the debloating efficiency, which is shown in Table 4 on page 10. The third experiment demonstrates uTrimmer’s ability to reduce ROP gadgets on SPEC 2017 and firmware applications. We show the execution results in Table 5 on page 10. We also conducted an experiment on real firmware to evaluate uTrimmer’s performance, shown in Table 6 on page 12.</p>

},
keywords = {embeded system, shared library debloating, static binary analysis}
}

@software{10.5281/zenodo.5746945,
author = {Gonzalez-Guerrero, Patricia and Bautista, Meriam Gay and Lyles, Darren and Michelogiannakis, George},
title = {Artifacts for article: Temporal and SFQ Pulse-Streams Encoding for Area-Efficient Superconducting Accelerators},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5746945},
abstract = {
    <p>This artifact contains WRSPICE circuit netlists and Octave scripts that implement key circuits and analysis in our article. In the “library” folder you can find netlists for cells and building blocks that we use in our designs. In directory “spice_netlist” you can find WRSPICE netlists for some of our key circuits that we propose in the article. Directory “octave” contains scripts for error and other design space exploration that we perform in our article. Finally, directory “perl” contains auxiliary scripts. You can find more info in the README.md file.</p>

},
keywords = {FIR, Josephson junctions, netlist, processing elements, superconducting digital, WRSPICE}
}

@software{10.5281/zenodo.5747666,
author = {Kannan, Tejas and Hoffmann, Henry},
title = {Replication Package for Article: Protecting Adaptive Sampling from Information Leakage on Low-Power Sensors},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5747666},
abstract = {
    <p>This artifact provides an implementation of Adaptive Group Encoding (AGE). AGE is a framework that protects adaptive sampling procedures on low-power sensors from leaking information through the size of batched messages. The system works by encoding all measurement batches as fixed-length messages, thereby breaking the relationship between the message size and the adaptive policy’s collection rate. This repository implements AGE both in a simulated environment and on a microcontroller (MCU). The simulator, written in Python, represents the sensor and server as individual processes. These components communicate using a local (encrypted) socket, and the simulator tracks the sensor’s energy consumption using traces from a TI MSP430 MCU. The hardware setting executes AGE on a TI MSP430 FR5994. The MCU transmits measurement batches to a separate server over a Bluetooth link. These experimental settings confirm AGE’s ability to maintain the low error of adaptive sampling while preventing information leakage and incurring negligible energy overhead. The repository https://github.com/tejaskannan/adaptive-group-encoding contains all the code for this work.</p>

},
keywords = {Adaptive Sampling, Data Privacy, Embedded Systems, Lossy Data Encoding}
}

@software{10.5281/zenodo.5748202,
author = {Chen, Yanju and Liu, Junrui and Feng, Yu and Bodik, Rastislav},
title = {Tree Traversal Synthesis Using Domain-Specific Symbolic Compilation},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5748202},
abstract = {
    <p>Tree Traversal Synthesis Using Domain-Specific Symbolic Compilation - Artifact for ASPLOS 2022 Submission</p>

},
keywords = {program synthesis, symbolic compilation, tree traversal}
}

@software{10.5281/zenodo.5748274,
author = {Pismenny, Boris and Liss, Liran and Morrison, Adam and Tsafrir, Dan},
title = {Artifact for 'The Benefits of General-Purpose On-NIC Memory'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5748274},
abstract = {
    <p>This repository contains scripts for ASPLOS’22 artifact evaluation of the The Benefits of General-Purpose on-NIC Memory paper by Boris Pismenny, Liran Liss, Adam Morrison, and Dan Tsafrir.</p>

},
keywords = {NFV acceleration, NIC memory, nicmem}
}

@software{10.5281/zenodo.5748410,
author = {Zhang, Qian and Wang, Jiyuan and Xu, Guoqing Harry and Kim, Miryung},
title = {Artifact for Article: HeteroGen: Transpiling C to Heterogeneous HLS Code with Automated Test Generation and Program Repair},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5748410},
abstract = {
    <p>This artifact includes an error study, a fuzzing-based test generation tool, and an automated code edit tool for error removal.</p>

},
keywords = {heterogeneous applications, program repair, test generation}
}

@software{10.5281/zenodo.5748606,
author = {Deutsch, Peter W. and Yang, Yuheng and Bourgeat, Thomas and Drean, Jules and Emer, Joel S. and Yan, Mengjia},
title = {Gem5/Rosette Simulation Packages for DAGguise},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5748606},
abstract = {
    <p>Our artifact comprises of two distinct parts: a unified gem5 / DRAMSim2 model (for performance evaluation), and a Rosette model (for security verification). The unified gem5/DRAMSim2 model is able to evaluate the performance of DAGguise and FS-BTA against an insecure baseline. We use gem5’s OoO core to perform baseline measurements, profile candidate rDAGs, and report final performance numbers. We also include the sample victim programs (DocDist and DNA) as described in the paper, in addition to an rDAG generation tool, and plotting scripts for Figures 7 and 9. The Rosette model symbolically executes the DAGguise system and verifies the Security Property with K-Induction as described in Section 5 of the paper.</p>

},
keywords = {dagguise, dramsim2, gem5, rosette}
}

@software{10.5281/zenodo.5748667,
author = {Roy, Rohan Basu and Patel, Tirthak and Tiwari, Devesh},
title = {IceBreaker: Warming Serverless Functions Better with Heterogeneity},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5748667},
abstract = {
    <p>IceBreaker is technique that reduces the service time and keep-alive cost of serverless functions, which are executed on a heterogeneous system consisting of costly and cheaper nodes. IceBreaker’s design consists of two major components: (1) Function Invocation Prediction Scheme (FIP), and (2) Placement Decision Maker (PDM). The FIP uses a Fourier transform based approach to determine the invocation concurrency of a function. The PDM decides where to warm up a serverless function: on a high-end server, or on a low- end server, or no warm up at all. This decision is made based upon an utility score which is calculated by considering several factors like probability of function invocation, speedup of a function on a high-end server, etc. Our artifact packages the scripts for setting up and invoking IceBreaker. It also contains the data obtained in our experimentation.</p>

},
keywords = {Cloud Computing, Cold Start, Heterogeneous Hardware, Keep-alive Cost, Serverless Computing}
}

@software{10.5281/zenodo.5780204,
author = {Li, Gushu and Wu, Anbang and Shi, Yunong and Javadi-Abhari, Ali and Ding, Yufei and Xie, Yuan},
title = {Artifact for Article: Paulihedral: A Generalized Block-Wise Compiler Optimization Framework for Quantum Simulation Kernels},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5780204},
abstract = {
    <p>See appendix for artifact description</p>

},
keywords = {compiler, quantum computing, quantum simulation}
}

@software{10.5281/zenodo.5785310,
author = {Wang, Bangyan and Deng, Lei and Sun, Fei and Dai, Guohao and Liu, Liu and Wang, Yu and Xie, Yuan},
title = {Replication package for paper "A One-for-All and $O(V\log(V))$-Cost Solution for Parallel Merge Style Operations on Sorted Key-Value Arrays"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5785310},
abstract = {
    <p>It contains the necessary source code to reproduce the result in paper “A One-for-All and <span class="math inline"><em>O</em>(<em>V</em>log (<em>V</em>))</span>-Cost Solution for Parallel Merge Style Operations on Sorted Key-Value Arrays”. It contains:</p>
<ol type="1">
<li>A modified GCC compiler that support the new SIMD primitives</li>
<li>A modified Gem5 simulator that support the new SIMD primitives</li>
<li>A collection of kernels written in C++ that use the new SIMD primitives. It should be compiled using the modified GCC.</li>
<li>A dockerfile to help you setup the environement.</li>
</ol>

},
keywords = {GCC, Gem5, Graph, Join, Key-value array, Merge sort, SIMD, Sparse linear algebra, SpGEMM}
}

@software{10.5281/zenodo.5790730,
author = {Chen, Zhangyu and Hua, Yu and Zhang, Yongle and Ding, Luochangqi},
title = {Replication Package for Article: Efficiently Detecting Concurrency Bugs in Persistent Memory Programs},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5790730},
abstract = {
    <p>This is the finalized artifact of PMRace, a debugging tool for PM concurrency bugs. The artifact is maintained at <a href="https://github.com/yhuacode/pmrace-vagrant">GitHub</a> and developed by Zhangyu and Luochangqi.</p>

},
keywords = {Concurrency, Crash Consistency, Debugging, Persistent Memory, Testing}
}

@software{10.5281/zenodo.5792458,
author = {Zhao, Shixiong and Li, Fanxin and Chen, Xusheng and Shen, Tianxiang and Chen, Li and Wang, Sen and Zhang, Nicholas and Li, Cheng and Cui, Heming},
title = {Replication Package for Article: NASPipe: High Performance and Reproducible Pipeline Parallel Supernet Training via Causal Synchronous Parallelism},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5792458},
abstract = {
    <p>The artifact provides the availability, functionality, and key reproducible results of the paper (NASPipe: High Performance and Reproducible Pipeline Parallel Supernet Training via Causal Synchronous Parallelism): a causal parallel training execution framework. The artifact requires a host with at least 100GB CPU RAM and 4 Nvidia GPUs, and each GPU requires at least 11GB memory. The runtime environment is installed by docker with a few command lines. The experiments contain a throughput evaluation and reproducible training evaluation. The artifact provides one-click shell scripts to conduct the experiments.</p>

},
keywords = {Distributed Training, Neural Architecture Search, Pipeline training}
}

@software{10.5281/zenodo.5796083,
author = {Zhou, Keren and Hao, Yueming and Mellor-Crummey, John and Meng, Xiaozhu and Liu, Xu},
title = {Replication Package for Article: ValueExpert, Exploring Value Patterns in GPU-Accelerated Applications},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5796083},
abstract = {
    <p>Our artifact includes ValueExpert and benchmark code in this paper, along with instructions to use benchmarks to generate results for Figure 2, Figure 6, and Table 3 on NVIDIA A100 and RTX 2080 Ti GPUs. The speedup and overhead of each benchmark are averaged among 10 runs.</p>
<p>We provide a docker image with pre-installed prerequisites to simplify the experiment workflow. Users can also use a script to install all software from scratch.</p>

},
keywords = {GPU profilers, GPUs, Profiling Tools, Value Analysis, Value Patterns}
}

@software{10.5281/zenodo.5799180,
author = {Zhao, Zirui Neil and Ji, Houxiang and Morrison, Adam and Marinov, Darko and Torrellas, Josep},
title = {Pinned Loads: Taming Speculative Loads in Secure Processors},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5799180},
abstract = {
    <p>Our artifact provides a complete gem5 implementation of Pinned Loads, along with scripts to evaluate Pinned Loads’ performance on SPEC17, PARSEC, and SPLASH2X benchmark suites. We further provide access to a server with SPEC17 SimPoint checkpoints, PARSEC&amp;SPLASH2X checkpoints and disk images that allow a recreation of all the evaluation figures of the paper. Finally, we open sourced our implementation and scripts on GitHub.</p>

},
keywords = {Cache coherence protocol, Memory consistency, Processor design, Speculative execution defense}
}

@software{10.5281/zenodo.5802292,
author = {Cock, David and Ramdas, Abishek and Schwyn, Daniel and Giardino, Michael and Turowski, Adam and He, Zhenhao and Hossle, Nora and Korolija, Dario and Licciardello, Melissa and Martsenko, Kristina and Achermann, Reto and Alonso, Gustavo and Roscoe, Timothy},
title = {The Enzian Research Computer; Altium Design Sources},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5802292},
abstract = {
    <p>CAD design sources for the computer</p>

},
keywords = {cache coherence., FPGAs, heterogeneous systems}
}

@software{10.5281/zenodo.5826357,
author = {Yang, Boyuan and Chen, Ruirong and Huang, Kai and Yang, Jun and Gao, Wei},
title = {Replication package of paper: Eavesdropping User Credentials via GPU Side Channels on Smartphones},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5826357},
abstract = {
    <p>This repository contains artifacts of the paper Eavesdropping User Credentials via GPU Side Channels on Smartphones. It contains 1) the source codes of smartphone app and backend server program that are needed to launch the eavesdropping attack; 2）the mobile user apps that are listed as the victims of this attack; 3) the automated scripts that operate the attacking programs for replicating the experiment results reported in the paper.</p>

},
keywords = {Input Eavesdropping, Mobile GPU, Performance Counters, Side Channel, Smartphones}
}

@software{10.5281/zenodo.5830832,
author = {Miano, Sebastiano and Sanaee, Alireza and Risso, Fulvio and R\'{e}tv\'{a}ri, G\'{a}bor and Antichi, Gianni},
title = {Morpheus: Domain Specific Run Time Optimization for Software Data Planes - Artifact for ASPLOS'22},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5830832},
abstract = {
    <p>This is the artifact for the “Morpheus: Domain Specific Run Time Optimization for Software Data Planes” paper published at ASPLOS’22. This artifact contains the source code, the experimental workflow, and additional information to 1) compile and build Morpheus, 2) install the software dependencies and setup the testbed to run all the experiments, 3) the scripts that can be used to perform some of the experiments presented in the paper, and 4) the scripts to generate the plots based on the obtained results.</p>

},
keywords = {Data Plane Compilation, DPDK, eBPF, LLVM, XDP}
}

@software{10.5281/zenodo.5831327,
author = {Nikolaev, Ruslan and Nadeem, Hassan and Stone, Cathlyn and Ravindran, Binoy},
title = {Adelie: Continuous Address Space Layout Re-randomization for Linux Drivers - Artifact for ASPLOS'22},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5831327},
abstract = {
    <p>Artifact for ASPLOS’22 paper “Adelie: Continuous Address Space Layout Re-randomization for Linux Drivers”. The artifact contains source code, benchmark scripts, and preinstalled VM images that should be used with VirtualBox. The server VM image is in Adelie.zip, and the client (load generator) VM image is in Client.zip. Please see README.txt for more information. Please also see the licensing terms in LICENSE.</p>

},
keywords = {ASLR, PIC, ROP}
}

@software{10.5281/zenodo.5838527,
author = {Patel, Tirthak and Younis, Ed and Iancu, Costin and de Jong, Wibe and Tiwari, Devesh},
title = {QUEST (ASPLOS'22) Code and Data},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5838527},
abstract = {
    <p>This appendix describes the code and data artifacts related to QUEST. The artifacts are open-source at https://doi.org/10.5281/zenodo.5747894. They include the input files for the executed benchmarks, the code for partitioning, synthesis, dual annealing, and simulation, as well as a docker image set up with the code. Please see the following sections for more details, especially the Experiment Workflow section to read in detail about how the artifact directories and code files are organized.</p>

},
keywords = {Quantum Circuit Approximation, Quantum Circuit Synthesis, Quantum Computing}
}

@software{10.5281/zenodo.5842408,
author = {Mathur, Umang and Pavlogiannis, Andreas and Tun\c{c}, H\"{u}nkar Can and Viswanathan, Mahesh},
title = {Replication Package for Article: A Tree Clock Data Structure for Causal Orderings in Concurrent Executions},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5842408},
abstract = {
    <p>This artifact contains all the source codes and experimental data for replicating our evaluation in the paper. We implemented the analyses programs as part of the tool Rapid. The provided experimental data contains all the 153 trace logs used in our evaluation. In our artifact we also provide Python scripts that fully automate the process of replicating our evaluation.</p>

},
keywords = {concurrency, dynamic analyses, happens-before, vector clocks}
}

@software{10.5281/zenodo.5846419,
author = {Ahmad, Hammad and Huang, Yu and Weimer, Westley},
title = {CirFix: Automatically Repairing Defects in Hardware Design Code (Artifact)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5846419},
abstract = {
    <p>We provide the public repository for CirFix, both on Zenodo and GitHub. The artifact includes instructions for installing and running CirFix, as well as scripts and instructions used to reproduce core results from our paper.</p>
<p>Please contact Hammad Ahmad (hammada@umich.edu) if you have any questions.</p>

},
keywords = {automated program repair, hardware bugs, hardware designs, HDL benchmark}
}

@software{10.5281/zenodo.5847956,
author = {Pandey, Shweta and Kamath, Aditya K and Basu, Arkaprava},
title = {Replication Package for Article: GPM: Leveraging Persistent Memory from a GPU},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5847956},
abstract = {
    <p>GPM is a system which allows a GPU to leverage Persistent Memory and enables writing highly performant recoverable GPU applications. The repository contains the source of our benchmark suite: GPMBench and a CUDA library: LibGPM. GPMBench comprises of 9 benchmarks categorized as transactional, native and checkpointing. LibGPM contains the source of our CUDA library which provides a user-friendly interface for GPU-accelerated recoverable applications. More details about the work can be found in our paper ASPLOS’22 paper: Leveraging Persistent Memory from a GPU. The artifact also allows a user to reproduce some of the key results published in the paper.</p>

},
keywords = {GPU, Persistent Memory}
}

@software{10.5281/zenodo.5848404,
author = {Bandara, Thilini Kaushalya and Wijerathne, Dhananjaya and Mitra, Tulika and Peh, Li-Shiuan},
title = {REVAMP: A Systematic Framework for Heterogeneous CGRA Realization},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5848404},
abstract = {
    <p>REVAMP artifact includes the complete framework comprising the heterogeneous architecture generator, heterogeneous CGRA mapper, parameterized RTL and scripts for power, area calculation. We elaborate on the REVAMP tool flow with an example of generating a pareto-optimal heterogeneous CGRA from a 4x4 homogeneous CGRA targeting five application kernels.</p>

},
keywords = {CGRA design space exploration, Coarse Grained Reconfigurable Arrays (CGRAs), Heterogeneous CGRAs}
}

@software{10.5281/zenodo.5848986,
author = {Theodoridis, Theodoros and Grosser, Tobias and Su, Zhendong},
title = {ASPLOS 2022 Artifact for "Understanding and Exploiting Optimal Function Inlining"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5848986},
abstract = {
    <p>The artifact contains the code and dataset we used for our experiments, as well as scripts to generate the numbers, figures, and tables of our evaluation. Specifically, it includes (a) the LLVM-IR files we used both for exhaustive search and autotuning (b) a modified LLVM that we use for exhaustive search and autotuning; (c) scripts to run exhaustive search and autotuning; (d) the expected outputs; (e) scripts to generate the tables and figures of our paper; (f) scripts to perform exhaustive search and autotuning only on smaller callgraphs and to validate the results against the provided ones. Everything is packaged and pre-built as a docker image. A standard X86 Linux machine running docker is necessary to evaluate this artifact.</p>

},
keywords = {autotuning, compiler optimization, optimal inlining, program size}
}

@software{10.5281/zenodo.5855030,
author = {Ma, Jiacheng and Zuo, Gefei and Loughlin, Kevin and Zhang, Haoyang and Quinn, Andrew and Kasikci, Baris},
title = {Replication Package for Paper: Debugging in the Brave New World of Reconfigurable Hardware},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5855030},
abstract = {
    <p>20 hardware bugs and the debugging tools mentioned in the paper “Debugging in the Brave New World of Reconfigurable Hardware”.</p>

},
keywords = {Bug Study, Debugging, FPGA, Reconfigurable Hardware}
}

@software{10.5281/zenodo.5856289,
author = {Erd\H{o}s, M\'{a}rton and Ainsworth, Sam and Jones, Timothy M.},
title = {Research data supporting "MineSweeper: a "clean sweep" for drop-in use-after-free prevention"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5856289},
abstract = {
    <p>This artifact contains our MineSweeper implementation, an allocator extension implemented on top of JeMalloc to mitigate use-after-free attacks, together with scripts to evaluate its running time and memory overheads on the SPEC CPU2006 benchmarks. The base implementation itself and a minimally modified JeMalloc memory allocator are fetched from their own repositories, compiled, and dynamically loaded in the SPEC config scripts. The dynamically linked libraries can be used to evaluate SPEC CPU2006 overheads using our scripts (benchmarks not included), or they can be loaded to protect a pre-compiled program from use-after-reallocate and double-free exploits.</p>

},
keywords = {programming language security, temporal safety, use-after-free}
}

@software{10.5281/zenodo.5863686,
author = {Asmussen, Nils and Haas, Sebastian and Weinhold, Carsten and Miemietz, Till and Roitzsch, Michael},
title = {ASPLOS'22 artifact for Efficient and Scalable Core Multiplexing with M³v},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5863686},
abstract = {
    <p>This is the artifact for the ASPLOS’22 paper “Efficient and Scalable Core Multiplexing with M³v”. The archive contains the source code of the software part, including the modified Linux kernel we compared M³v against, and all scripts to run the benchmarks. The archive also contains the FPGA bitfiles for the hardware platform.</p>

},
keywords = {communications management, operating systems, operating-systems security, process management, tiled architecture}
}

@software{10.5281/zenodo.5865606,
author = {Oleksenko, Oleksii and Fetzer, Christof and K\"{o}pf, Boris and Silberstein, Mark},
title = {Replication Package for Article: Revizor - Testing Black-Box CPUs against Speculation Contracts},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5865606},
abstract = {
    <p>The artifact includes the source code of Revizor, a set of scripts for reproducing the results, and a description of how to use them. They help to reproduce the contract violations described in the paper and validate the claimed fuzzing speed.</p>

},
keywords = {contracts, spectre, Speculation, testing}
}

@software{10.5281/zenodo.5870184,
author = {Theodoridis, Theodoros and Rigger, Manuel and Su, Zhendong},
title = {ASPLOS 2022 Artifact for "Finding Missed Optimizations through the Lens of Dead Code Elimination"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5870184},
abstract = {
    <p>The artifact contains the code and dataset we used for our experiments, as well as scripts to generate the numbers and tables of our evaluation. Specifically, it includes (a) the corpus of randomly generated programs that we used in Section 4’s evaluation; (b)scripts for generating a new corpus and validating the existing one; (c) our LLVM-based optimization marker instrumenter; (d) scripts for generating the missed optimization statistics presented in Section 4; (e) the full list of submitted bug reports with links to the respective compiler bug trackers; (f) end-to-end examples that led to bug reports. Everything is packaged and pre-built as a docker image. A standard X86 Linux machine running docker is necessary to evaluate this artifact.</p>

},
keywords = {compilers, missed optimizations, testing}
}

@software{10.5281/zenodo.5874548,
author = {Cheng, Xiang and Devecsery, David},
title = {Artifact for: Creating Concise and Efficient Dynamic Analyses with ALDA},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5874548},
abstract = {
    <p>This artifact description contains information about the complete workflow required to set up and reproduce experiments in ALDA. We describe how the software can be obtained and the build process as well as necessary preprocessing steps to generate the test program and baseline. All the programs and benchmarks are publicly available except for the SPEC 2006 benchmark. In addition, we provide a VM with all the programs and input data pre-pared and as well as instructions on how to build such a VM.</p>

},
keywords = {compiler optimization, domain specific language, dynamic analysis}
}

@software{10.5281/zenodo.5893373,
author = {Liu, Ziheng and Xia, Shihao and Liang, Yu and Song, Linhai and Hu, Hong},
title = {Replication Package for Article: Who Goes First? Detecting Go Concurrency Bugs via Message Reordering},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5893373},
abstract = {
    <p>The source code of GFuzz, an effective bug detector for Golang.</p>

},
keywords = {bug, concurrent, fuzzing, golang}
}

@software{10.5281/zenodo.5900766,
author = {Li, Zijun and Liu, Yushi and Guo, Linsong and Chen, Quan and Cheng, Jiagan and Zheng, Wenli and Guo, Minyi},
title = {Artifact for Article: FaaSFlow: Enable Efficient Workflow Execution for Function-as-a-Service},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5900766},
abstract = {
    <p>FaaSFlow is a serverless workflow engine that enables efficient workflow execution in 2 ways: a worker-side workflow schedule pattern to reduce scheduling overhead, and an adaptive storage library to use local memory to transfer data between functions on the same node.</p>

},
keywords = {FaaS, graph partition, master-worker, serverless workflows}
}

@software{10.5281/zenodo.5902507,
author = {Lefeuvre, Hugo and B\u{a}doiu, Vlad-Andrei and Jung, Alexander and Teodorescu, Stefan Lucian and Rauch, Sebastian and Huici, Felipe and Raiciu, Costin and Olivier, Pierre},
title = {FlexOS: Towards Flexible OS Isolation},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5902507},
abstract = {
    <p>This artifact contains the source code of FlexOS, the proof of-concept of our flexible isolation approach presented at ASPLOS’22 (“FlexOS: Towards Flexible OS Isolation”), along with all scripts necessary to reproduce the paper’s measurements and plots. The goal of this artifact is to allow readers to reproduce the paper’s results, and build new research on top of FlexOS.</p>
<p>Abstract of the paper:</p>
<p>At design time, modern operating systems are locked in a specific safety and isolation strategy that mixes one or more hardware/software protection mechanisms (e.g.&nbsp;user/kernel separation); revisiting these choices after deployment requires a major refactoring effort. This rigid approach shows its limits given the wide variety of modern applications’ safety/performance requirements, when new hardware isolation mechanisms are rolled out, or when existing ones break.</p>
<p>We present FlexOS, a novel OS allowing users to easily specialize the safety and isolation strategy of an OS at compilation/deployment time instead of design time. This modular LibOS is composed of fine-grained components that can be isolated via a range of hardware protection mechanisms with various data sharing strategies and additional software hardening. The OS ships with an exploration technique helping the user navigate the vast safety/performance design space it unlocks. We implement a prototype of the system and demonstrate, for several applications (Redis/Nginx/SQLite), FlexOS’ vast configuration space as well as the efficiency of the exploration technique: we evaluate 80 FlexOS configurations for Redis and show how that space can be probabilistically subset to the 5 safest ones under a given performance budget. We also show that, under equivalent configurations, FlexOS performs similarly or better than several baselines/competitors.</p>

},
keywords = {compartmentalization, isolation, operating system, operating system security}
}

@software{10.5281/zenodo.5942213,
author = {Saileshwar, Gururaj and Wang, Bolin and Qureshi, Moinuddin and Nair, Prashant J.},
title = {Randomized Row-Swap: Mitigating Row Hammer by Breaking Spatial Correlation between Aggressor and Victim Rows},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5942213},
abstract = {
    <p>This artifact presents the code and methodology to simulate Randomized Row-Swap (RRS), our defense against Rowhammer attacks. We provide the C code for the implementation of RRS which is encapsulated within the USIMM, a memory system simulator. The RRS structures and operations are implemented within the memory controller module in our artifact. We provide scripts to compile our simulator, and run the baseline and RRS. We also provide scripts to parse the results and collate the performance results.</p>

},
keywords = {DRAM, Fault-Injection Attacks, Memory System, Row Hammer}
}

@software{10.6084/m9.figshare.17097524.v1,
author = {Swamy, Tushar and Rucker, Alexander and Shahbaz, Muhammad and Gaur, Ishan and Olukotun, Kunle},
title = {Reproduction Package for Article 'Taurus: A Data Plane Architecture for Per-Packet ML '},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.17097524.v1},
abstract = {
    <p>Taurus MapReduce Block in FPGA: This repository contains the source code and instructions for building an FPGA-based implementation of the Taurus’s MapReduce block. For more details, please read our Taurus: A Data Plane Architecture for Per-Packet ML paper (appearing in ASPLOS ’22).</p>
<p>Taurus Anomaly-Detection Application: In this repository, we share the source code for the anomaly-detection application (AD) presented in our Taurus: A Data Plane Architecture for Per-Packet ML paper (to appear in ASPLOS ’22). We also provide details on what is needed to replicate the end-to-end testbed used for evaluating the AD application.</p>

},
keywords = {Anomaly Detection, FPGA, MapReduce, P4, Per-packet ML, Self-driving Networks, Spatial}
}

@software{10.6084/m9.figshare.18480953.v3,
author = {Jangda, Abhinav and Huang, Jun and Liu, Guodong and Sabet, Amir Hossein Nodehi and Maleki, Saeed and Miao, Youshan and Musuvathi, Madanlal and Mytkowicz, Todd and Saarikivi, Olli},
title = {CoCoNet: Co-optimizing Computation and Communication for Distributed Neural Networks},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.18480953.v3},
abstract = {
    <p>CoCoNet is a domain specific language for expressing and optimizing distributed machine learning workloads. This artifact contains the CoCoNet implementation and our benchmark infrastructure.</p>

},
keywords = {CUDA, Distributed Machine Learning, MPI, NCCL}
}

@software{10.5281/zenodo.5982794,
author = {Groce, Alex and van Tonder, Rijnard and Kalburgi, Goutamkumar Tulajappa and Le Goues, Claire},
title = {Making No-Fuss Compiler Fuzzing Effective: CC 2022 Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5982794},
abstract = {
    <p>This is the artifact for the paper “Making No-Fuss Compiler Fuzzing Effective” by Alex Groce, Rijnard van Tonder, Goutamkumar Tulajappa Kalburg, and Claire Le Goues, for the 2022 International Conference on Compiler Construction.</p>

},
keywords = {fuzzing mutation compilers}
}

@software{10.5281/zenodo.5988606,
author = {Peduri, Anurudh and Bhat, Siddharth and Grosser, Tobias},
title = {QSSA: An SSA-based IR for Quantum Computing - Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5988606},
abstract = {
    <p>This is the artifact for our CC’22 paper “QSSA: An SSA-based IR for Quantum Computing”. It consists of a docker image containing full source code of our compiler, benchmarks and scripts for reproducing main experiments of the paper. We supply instructions on how to run the artifact evaluation in the appendix of our paper.</p>

},
keywords = {compilers, intermediate representations, optimization, quantum circuits, SSA}
}

@software{10.5281/zenodo.6313660,
author = {Wang, Huanting and Tang, Zhanyong and Zhang, Cheng and Zhao, Jiaqi and Cummins, Chris and Leather, Hugh and Wang, Zheng},
title = {Reproduction Package for Article 'Automating Reinforcement Learning Architecture Design for Code Optimization'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6313660},
abstract = {
    <p>The research artifact enables the reproduction of the main results of the paper. It provides instructions to download and run a preconfigured Docker image to reproduce the results and customize the experiments.</p>

},
keywords = {code optimization, Compiler optimization, reinforcement learning}
}

@software{10.5281/zenodo.6330043,
author = {Xu, Yufan and Raje, Saurabh and Rountev, Atanas and Sabin, Gerald and Sukumaran-Rajam, Aravind and Sadayappan, P.},
title = {Reproduction package for "Training of Deep Learning Pipelines on Memory-Constrained GPUs via Segmented Fused-Tiled Execution"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6330043},
abstract = {
    <p>The artifact contains all the scripts and data required to reproduce the experimental results in the CC 2022 paper titled “ Training of Deep Learning Pipelines on Memory-Constrained GPUs via Segmented Fused-Tiled Execution”. The git repository contains: 1)The SFT source code; 2)The scripts to measure execution time of default PyTorch, PyTorch checkpoint, and SFT; 3)Raw data that we used to plot Fig. 8 (for comparison).</p>

},
keywords = {Checkpointing, DNN, Fusion, GPU, Large image training, Memory-constrained execution, Tiling}
}

@software{10.5281/zenodo.6330172,
author = {Sahebolamri, Arash and Gilray, Thomas and Micinski, Kristopher},
title = {Ascent},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6330172},
abstract = {
    <p>Source code of Ascent, a logic programming language (similar to Datalog) embedded in Rust via macros.</p>

},
keywords = {Datalog, Logic Programming, Program Analysis, Rust}
}

@software{10.5281/zenodo.6337971,
author = {Ryu, Jaehun and Park, Eunhyeok and Sung, Hyojin},
title = {One-Shot Tuner for Deep Learning Compilers (Artifact)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6337971},
abstract = {
    <p>Our artifact includes an implementation of the One-Shot Tuner predictor model and a variant of the TVM compiler modified to use One-Shot Tuner. We provide a fully trained One-Shot Tuner predictor model, along with model source codes, training data samples obtained using PGS and EBS methods, and scripts to use the data to re-train the model. For the compiler, we provide binaries and source codes for the TVM compiler modified to use the trained One-Shot Tuner predictor model for a single iteration of search and validation in place of its AutoTVM-based auto-tuning process. This will allow evaluation and reproduction of our results on the NVIDIA GPU and Intel CPU systems described in the paper.</p>

},
keywords = {autotuning, deep neural networks, optimizing compilers, performance models}
}

@software{10.5281/zenodo.6345727,
author = {Gerard, Blake and Grosser, Tobias and Kong, Martin},
title = {BlakeGerard/qrane-artifact:},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6345727},
abstract = {
    <p>This artifact contains a version of our proposed tool, Qrane, along with all of the data and scripts needed to run each experiment in the paper. The artifact is presented as a public GitHub repository. It also comes with a Dockerfile to load the repository onto a Docker image with all dependencies installed, if the user wishes to take that route. Within the repository, you will find a README with instructions to run the one wrapper script that will automatically run all experiments. The wrapper script will invoke Qrane on the provided datasets used in the paper, and dump all intermediate files to a specified directory. It will then generate similar plots to those found in the Experiment and Supplemental sections of the paper (with some variation from machine thread-usage and optional tweaking of Qrane flags, if desired).</p>

},
keywords = {delinearization, polyhedral model, quantum affine computing., quantum assembly}
}

@software{10.6084/m9.figshare.19249817.v1,
author = {Mogers, Naums and Li, Lu and Radu, Valentin and Dubach, Christophe},
title = {Artifact for the paper "Mapping Parallelism in a Functional IR through Constraint Satisfaction"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.19249817.v1},
abstract = {
    <p>This artifact contains the parallel code generator Lift which is described in the CC 2022 paper “Mapping Parallelism in a Functional IR through Constraint Satisfaction”. Furthermore, this artifact contains the Docker image, scripts and best-found convolution kernels required to reproduce the performance and search efficiency results presented in the paper. To validate the results, build Lift, run the best-found VGG-16 convolution kernels on a Mali GPU board, and, finally use the plotting script to reproduce the results from Figure 4 in the paper. We also provide scripts to perform time-intensive parallel mapping space exploration and discover the best parallelizations for each layer of VGG-16 for a given Mali GPU board, as well as measure exploration duration to reproduce Figure 5 in the paper.</p>

},
keywords = {code generation, convolution, mobile GPU, parallelism}
}

@software{10.5281/zenodo.6335690,
author = {Chow, Ka-Ho and Deshpande, Umesh and Seshadri, Sangeetha and Liu, Ling},
title = {Implementation of the article "DeepRest: Deep Resource Estimation for Interactive Microservices"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6335690},
abstract = {
    <p>Deep Learning for API-aware Resource Estimation</p>
}
}

@software{10.5281/zenodo.6335844,
author = {Shen, Weihai and khanna, Ansh and Angel, Sebastian and Sen, Siddhartha and Mu, Shuai},
title = {Implementation of the article "Rolis: a software approach to efficiently replicating multi-core transactions"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6335844},
abstract = {
    <p></p><p>Artifact appendix item for Eurosys22'</p><p></p>
}
}

@software{10.5281/zenodo.6336004,
author = {Li, Ning and Jiang, Hong and Che, Hao and Wang, Zhijun and NGUYEN, MINH},
title = {Implementation of the article "Improving Scalability of Database Systems by Reshaping User Parallel I/O"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6336004},
abstract = {
    <p></p><p>AppleS aims to improve database scalability by delivering the right amount and pattern of user parallel I/O requests to the database system under excessive user parallelism, aligning with the concurrency supported by the database and its underlying I/O stack. In doing so, AppleS improves user-level I/O performance in terms of user-level I/O fairness, throughput and latency stability. Implemented as a user-space module based on system call interception, AppleS is compatible with and portable to different types/versions of databases, different versions of OS kernels and their resource management tools, e.g., Cgroups.</p><p></p>
}
}

@software{10.5281/zenodo.6336103,
author = {Kuo, Hsuan-Chi and Chen, Kai-Hsun and Lu, Yicheng and Williams, Dan and Mohan, Sibin and Xu, Tianyin},
title = {Implementation of the article "Verified Programs Can Party: Optimizing Kernel Extensions via Post-Verification In-Kernel Merging"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6336103},
abstract = {
    <p>No description provided.</p>
}
}

@software{10.5281/zenodo.6336196,
author = {Lu, Ziyi and Cao, Qiang and Jiang, Hong and Wang, Shucheng},
title = {Implementation of the article "p2KVS: a Portable 2-Dimensional Parallelizing Framework to Improve Scalability of Key-value Stores on SSDs"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6336196},
abstract = {
    <p>p2KVS: a Portable Parallelizing Scheduler to Speed Up LSM-tree Based KV Stores on High-performance SSDs</p>
}
}

@software{10.5281/zenodo.6336200,
author = {Zhou, Xia and Li, Jiaqi and Zhang, Wenlong and Zhou, Yajin and Shen, Wenbo and Ren, Kui},
title = {Implementation of the article "OPEC: Operation-based Security Isolation for Bare-metal Embedded Systems"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6336200},
abstract = {
    <p></p><p>Keep consistent with zhouxzju/opec:v1.3</p><p></p>
}
}

@software{10.5281/zenodo.6336301,
author = {Kirth, Paul and Dickerson, Mitchel and Crane, Stephen and Larsen, Per and Dabrowski, Adrian and Gens, David and Na, Yeoul and Volckaert, Stijn and Franz, Michael},
title = {Implementation of the article "PKRU-Safe: Automatically Locking Down the Heap Between Safe and Unsafe Languages"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6336301},
abstract = {
    <p></p><p>Public release v1.0.0 of PKRU-Safe for EuroSys22.</p><p></p>
}
}

@software{10.5281/zenodo.6337102,
author = {Thalheim, Joerg and Okelmann, Peter and Unnibhavi, Harshavardhan and Gouicem, Redha and Bhatotia, Pramod},
title = {Implementation of the article "VMSH: Hypervisor-agnostic Guest Overlays for VMs"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6337102},
abstract = {
    <p></p><p>Source code of VMSH</p><p></p>
}
}

@software{10.5281/zenodo.6337790,
author = {Baranawal, Animesh and Simmhan, Yogesh},
title = {Implementation of the article "Optimizing the Interval-centric Distributed Computing Model for Temporal Graph Algorithms"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6337790},
abstract = {
    <p></p><p>This version was used for artifact evaluation of the paper "Optimizing the Interval-centric Distributed Computing Model for Temporal Graph Algorithms" to appear in Eurosys 2022.</p><p></p>
}
}

@software{10.5281/zenodo.6338745,
author = {Bozdoaan, Kartal Kaan and Stavrakakis, Dimitrios and Issa, Shady and Bhatotia, Pramod},
title = {Implementation of the article "SafePM: A Sanitizer for Persistent Memory"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6338745},
abstract = {
    <p></p><p>SafePM: Memory Safety for Persistent Memory --- Artifact Evaluation</p><p></p>
}
}

@software{10.5281/zenodo.6342303,
author = {Xiang, Lingfeng and Zhao, Xingsheng and Rao, Jia and Jiang, Song and Jiang, Hong},
title = {Implementation of the article "Characterizing the Performance of Intel Optane Persistent Memory -- A Close Look at its On-DIMM Buffering"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6342303},
abstract = {
    <p></p><p>Submitted version for EuroSys 2022 artifact evaluation</p><p></p>
}
}

@software{10.5281/zenodo.6344032,
author = {Stathakopoulou, Chrysoula and Pavlovic, Matej and Vukolic, Marko and Stathakopoulou, Chrysoula},
title = {Implementation of the article "State Machine Replication Scalability Made Simple"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6344032},
abstract = {
    <p></p><p>This is the research prototype of the ISS state machine replication protocol.
It was used to obtain the performance results published at EuroSys 2022.
Authors: @matejpavlovic @stchrysa</p><p></p>
}
}

@software{10.5281/zenodo.6344960,
author = {Lawall, Julia and Pandya, Himadri and Lozi, Jean-Pierre and Lepers, Baptiste and Zwaenepoel, Willy and Muller, Gilles},
title = {Implementation of the article "OS Scheduling with Nest: Keeping Tasks Close Together on Warm Cores"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6344960},
abstract = {
    <p></p><p>Nest is a scheduling policy built on the Linux kernel that is designed according to the principles of core reuse and keeping cores warm.&nbsp; This artifact contains instructions and tools necessary to replicate the experiments found in this paper.</p><p></p>
}
}

@software{10.5281/zenodo.6345303,
author = {Jiao, Yizheng and Porter, Don and Patel, Sagar and Zeller, Luke and Bennet, Rory and Bender, Michael and Condict, Michael and Conway, Alex and Farach-Colton, Martin and GE, XIONGZI and Jannen, William and Johnson, Rob and Yuan, Jun and Bertron, Simon and Mukherjee, Nirjhar},
title = {Implementation of the article "BetrFS: A Compleat File System for Commodity SSDs"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6345303},
abstract = {
    <p></p><p>Versions of scripts used to recreate the results from "BetrFS: A Compleat File System for Commodity SSDs".</p><p></p>
}
}

@software{10.5281/zenodo.6345350,
author = {Gog, Ionel and Kalra, Sukrit and Schafhalter, Peter and Gonzalez, Joseph and Stoica, Ion},
title = {Implementation of the article "D3: A Dynamic Deadline-Driven Approach for Building Autonomous Vehicles"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6345350},
abstract = {
    <p></p><p>Scripts to reproduce experiments and graphs from the <code>D3: A Dynamic Deadline-Driven Approach for Building Autonomous Vehicles</code> paper accepted at <code>EuroSys 2022</code>.</p><p></p>
}
}

@software{10.5281/zenodo.6345713,
author = {Chen, Chen and Zhong, Wenshao and Wu, Xingbo and Wu, Xingbo},
title = {Implementation of the article "Building an Efficient Key-Value Store in a Flexible Address Space"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6345713},
abstract = {
    <p></p><p>This is the Digital Object Identifier (DOI) page for persistently indexing the source code and artifact of FlexTree, FlexSpace and FlexDB. Their latest version could be found in the following GitHub repositories:</p>

<p>https://github.com/flexible-address-space/flexspace<br>
https://github.com/flexible-address-space/eurosys22-artifact</p><p></p>
}
}

@software{10.5281/zenodo.6345733,
author = {Xu, Ran and Lee, Jayoung and Wang, Pengcheng and Bagchi, Saurabh and Li, Yin and Chaterji, Somali},
title = {Implementation of the article "LiteReconfig: Cost and Content Aware Reconfiguration of Video Object Detection Systems for Mobile GPUs"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6345733},
abstract = {
    <p></p><p>The source code for the LiteReconfig paper at EuroSys 2022. Thanks to @StarsThu2016 @starpic414 @ChulanZhang for their contributions to this release.</p><p></p>
}
}

@software{10.5281/zenodo.6345869,
author = {Oh, Hyungjun and Lee, Junyeol and Seo, Jiwon},
title = {Implementation of the article "Out-Of-Order BackProp: An Effective Scheduling Technique for Deep Learning"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6345869},
abstract = {
    <p>No description provided.</p>
}
}

@software{10.5281/zenodo.6347456,
author = {Yang, Jianbang and Tang, Dahai and Song, Xiaoniu and Wang, Lei and Yin, Qiang and Chen, Rong and Yu, Wenyuan and Zhou, Jingren},
title = {Implementation of the article "GNNLab: A Factored System for Sample-based GNN Training over GPUs"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6347456},
abstract = {
    <p>FGNN's artifact evaluation (EuroSys 2022)</p>
}
}

@software{10.5281/zenodo.6347736,
author = {Asyabi, Esmail and Wang, Yuanli and Liagouris, John and Kalavri, Vasiliki and Bestavros, Azer},
title = {Implementation of the article "A New Benchmark Harness for Systematic and Robust Evaluation of Streaming State Stores"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6347736},
abstract = {
    <p></p><p>No description provided.</p><p></p>
}
}

@software{10.5281/zenodo.6348174,
author = {Mehrab, A K M Fazla and Nikolaev, Ruslan and Ravindran, Binoy},
title = {Implementation of the article "Kite: Lightweight Critical Service Domains full strip note"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6348174},
abstract = {
    <p></p><p>Artifact for EuroSys'22 paper "Kite: Lightweight Critical Service Domains". Please see kite/README.md in Kite.zip for more information.&nbsp;Please also see the licensing terms in LICENSE.</p><p></p>
}
}

@software{10.5281/zenodo.6349594,
author = {Vardoulakis, Michalis and Saloustros, Giorgos and Gonzalez-Farez, Pilar and Bilas, Angelos},
title = {Implementation of the article "Tebis: Index Shipping for Efficient Replication in LSM Key-Value Stores"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6349594},
abstract = {
    <p></p><p>Key-value (KV) stores based on LSM tree have become a foundational layer in the storage stack of datacenters and cloud services. Current approaches for achieving reliability and availability favor reducing network traffic and send to replicas only new KV pairs. As a result, they perform costly compactions to reorganize data in both the primary and backup nodes, which increases device I/O traffic and CPU overhead, and eventually hurts overall system performance. In this paper we describe Tebis, an efficient LSM-based KV store that reduces I/O amplification and CPU overhead for maintaining the replica index. We use a primary-backup replication scheme that performs compactions only on the primary nodes and sends pre-built indexes to backup nodes, avoiding all compactions in backup nodes. Our approach includes an efficient mechanism to deal with pointer translation across nodes in the pre-built region index. Our results show that Tebis reduces pressure on backup nodes compared to performing full compactions: Throughput is increased by 1.1 − 1.48\texttimes{}, CPU efficiency is increased by 1.06 − 1.54\texttimes{}, and I/O amplification is reduced by 1.13 − 1.81\texttimes{}, without increasing server to server network traffic excessively (by up to 1.09 − 1.82\texttimes{}).</p><p></p>
}
}

@software{10.5281/zenodo.6349596,
author = {Khandelwal, Anurag and Tang, Yupeng and Agarwal, Rachit and Akella, Aditya and Stoica, Ion and Akella, Aditya},
title = {Implementation of the article "Jiffy: Statistical Multiplexing for Disaggregated Memory full strip note"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6349596},
abstract = {
    <p></p><p>Artifact appendix item for Eurosys 2022.</p><p></p>
}
}

@software{10.5281/zenodo.6350453,
author = {Wanninger, Nicholas and Hale, Kyle and Bowden, Joshua},
title = {Implementation of the article "Isolating at the Hardware Limit with Virtines"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6350453},
abstract = {
    <p></p><p>Wasp: micro-hypervisor that enables lightweight, isolated virtines</p><p></p>
}
}

@software{10.5281/zenodo.6353717,
author = {Danezis, George and Kokoris-Kogias, Eleftherios and Sonnino, Alberto and Spiegelman, Alexander and Sonnino, Alberto},
title = {Implementation of the article "Narwhal and Tusk: A DAG-based Mempool and Efficient BFT Consensus"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6353717},
abstract = {
    <p></p><p>No changes, just a release to link with Zenodo</p><p></p>
}
}

@software{10.5281/zenodo.6354775,
author = {Hajkazemi, Mohammad Hossein and Aschenbrenner, Vojtech and Abdi, Mania and Kaynar, Emine Ugur and Mossayebzadeh, Amin and Krieger, Orran and Desnoyers, Peter},
title = {Implementation of the article "Beating the I/O bottleneck: A case for log-structured virtual disks"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6354775},
abstract = {
    <p>DIS: blockDevice over Immutable Storage</p>
}
}

@software{10.5281/zenodo.6359660,
author = {Athlur, Sanjith and Saran, Nitika and Sivathanu, Muthian and Ramjee, Ramachandran and Kwatra, Nipun and Athlur, Sanjith},
title = {Implementation of the article "Varuna: Scalable, Low-cost Training of Massive Deep Learning Models"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6359660},
abstract = {
    <p></p><p>&nbsp;</p>

<p><em>Varuna</em>&nbsp;is a tool for efficient training of large DNN models on commodity GPUs and networking. It implements a combination of pipeline parallelism and data parallelism in PyTorch, and enables training on a changing set of resources smoothly.</p><p></p>
}
}

@software{10.5281/zenodo.6360235,
author = {Vinck, Jonas and Abrath, Bert and Coppens, Bart and Voulimeneas, Alexios and De Sutter, Bjorn and Volckaert, Stijn},
title = {Implementation of the article "Sharing is Caring: Secure and Efficient Shared Memory Support for MVEEs"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6360235},
abstract = {
    <p></p><p>Artifact available in eurosys2022-artifact/.</p><p></p>
}
}

@software{10.5281/zenodo.6360540,
author = {Iqbal, Md Shahriar and Krishna, Rahul and Javidian, Mohammad Ali and Ray, Baishakhi and Jamshidi, Pooyan},
title = {Implementation of the article "Unicorn: Reasoning about Configurable System Performance through the lens of Causality"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6360540},
abstract = {
    <p>Debugging Cross Stack Performance Faults using Causal Inference</p>
}
}

@software{10.5281/zenodo.6360833,
author = {Ao, Lixiang and Porter, George and Voelker, Geoffrey M.},
title = {Implementation of the article "FaaSnap: FaaS Made Fast Using Snapshot-based VMs"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6360833},
abstract = {
    <p>No description provided.</p>
}
}

@software{10.5281/zenodo.6374411,
author = {Saxena, Divyanshu and Ji, Tao and Singhvi, Arjun and Khalid, Junaid and Akella, Aditya},
title = {Implementation of the article "Memory Deduplication for Serverless Computing with Medes"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6374411},
abstract = {
    <p></p><p>Implementation sufficing the details and optimizations included in the paper presented at EuroSys'22</p><p></p>
}
}

@software{10.5281/zenodo.5821862,
author = {Georges, A\"{\i}na Linn and Trieu, Alix and Birkedal, Lars},
title = {Le Temps des Cerises: Efficient Temporal Stack Safety on Capability Machines using Directed Capabilities (Artifact)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5821862},
abstract = {
    <p>This the artifact accompanying the article “Le Temps des Cerises: Efficient Temporal Stack Safety on Capability Machines using Directed Capabilities”.</p>
<p>The artifact contains the Coq proofs accompanying the paper. These proofs are built using the Iris framework.</p>
<p>These proofs are available either as a .tar.gz archive, which can then be checked and compiled following the instructions in the README within, or as a virtual machine image for VirtualBox containing the already compiled Coq proofs. The VM does not require any password and has emacs with Proof General already installed to browse the proofs.</p>
<p>html/index.html provides a description of the files and how they correspond to statements in the paper. (You need to run make html first if compiling by yourself).</p>

},
keywords = {capability machines, CHERI, compilation, Coq, full abstraction, Iris, logical relations, separation logic}
}

@software{10.5281/zenodo.5834281,
author = {Paltenghi, Matteo and Pradel, Michael},
title = {Reproduction Package for "Bugs in Quantum Computing Platforms: An Empirical Study"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5834281},
abstract = {
    <p>It contains the bugs inspected in the study together with the minimized bug-fixing commits and a jupyter notebook to reproduce the result of the analysis.</p>

},
keywords = {braket, bug patterns, bug study, c# bugs, c++ bugs, circ, commit, dwave-system, empirical study, github, mitiq, open source quantum platforms, open source software, openql, oss, pennylane, projectq, pyquil, python bugs, q#, qalcs, qdk, qiskit, qiskit-aer, qiskit-ignis, qiskit-terra, quantum bug, quantum computing, quantum computing platforms, quantum programming languages, quantum programs, quantum software, quantum-specific bugs, software bug, software engineering, strawberryfields, tequila, xacc}
}

@software{10.5281/zenodo.6329773,
author = {Jacobs, Koen and Devriese, Dominique and Timany, Amin},
title = {Artifact OOPSLA22 - Purity of an ST Monad - Full Abstraction by Semantically Typed Back-Translation},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6329773},
abstract = {
    <p>Coq formalization of the results presented in the paper.</p>

},
keywords = {Coq, full abstraction, Iris, semantic typing, ST}
}

@software{10.5281/zenodo.6341551,
author = {Labrada, Elizabeth and Toro, Mat\'{\i}as and Tanter, \'{E}ric and Devriese, Dominique},
title = {Plausible Sealing for Gradual Parametricity: Supporting Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6341551},
abstract = {
    <p>This is the artifact accompanying the paper “Plausible Sealing for Gradual Parametricity”, to be published at OOPSLA 2022.</p>
<p>Graduality and parametricity have proven to be extremely challenging notions to bring together. Intuitively, enforcing parametricity gradually requires possibly sealing values in order to detect violations of uniform behavior. Toro et al.&nbsp;(2019) argue that the two notions are incompatible in the context of System F, where sealing is transparently driven by potentially imprecise type information, while New et al.&nbsp;(2020) reconcile both properties at the cost of abandoning the syntax of System F and requiring user-provided sealing annotations, which are not subject to graduality guarantees. Furthermore, all current proposals rely on a global form of dynamic sealing in order to enforce parametric behavior at runtime, which weakens parametric reasoning and breaks equivalences in the static language. Based on the observation that the tension between graduality and parametricity comes from the early commitment to seal values based on type information, we propose plausible sealing as a new intermediate language mechanism that allows postponing such decisions to runtime. We propose an intermediate language for gradual parametricity, Funky, which supports plausible sealing in a simplified setting where polymorphism is restricted to instantiations with base and variable types. We prove that Funky satisfies both parametricity and graduality, mechanizing key lemmas in Agda. Additionally, we avoid global dynamic sealing and instead propose a novel lexically-scoped form of sealing realized using a representation of evidence inspired by the category of spans. As a consequence, Funky satisfies a standard formulation of parametricity that does not break System F equivalences. In order to show the practicality of plausible sealing, we describe a translation from Funk, a source language without explicit sealing, to Funky, that takes care of inserting plausible sealing forms. We establish graduality of Funk, subject to a restriction on type applications, and explain the source-level parametric reasoning it supports. Finally, we provide an interactive prototype along with illustrative examples both novel and from the literature.</p>

},
keywords = {gradual parametricity
plausible sealing
parametricity
gradual typing}
}

@software{10.5281/zenodo.6342311,
author = {Le, Quang Loc and Raad, Azalea and Villard, Jules and Berdine, Josh and Dreyer, Derek and O'Hearn, Peter W.},
title = {Artifact and Appendix of "Finding Real Bugs in Big Programs with Incorrectness Logic"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6342311},
abstract = {
    <p>This is the artifact for the OOPSLA’22 paper “Finding Real Bugs in Big Programs with Incorrectness Logic”. It contains the scripts reproducing the results and proofs of the paper.</p>

},
keywords = {bug catching, compositionality, incorrectness logic, incorrectness proving}
}

@software{10.5281/zenodo.6342476,
author = {Lesani, Mohsen and Xia, Li-yao and Kaseorg, Anders and Bell, Christian J. and Chlipala, Adam and Pierce, Benjamin C. and Zdancewic, Steve},
title = {Coq formalization of C4: Verified Transactional Objects},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6342476},
abstract = {
    <p>A framework for Verified Transactional Objects in Coq.</p>
<ul>
<li>Formalization of concurrent objects, linearizability, strict serializability, and associated proof techniques.</li>
<li>Verified linearizable concurrent hash map</li>
<li>Verified strictly serializable TML</li>
<li>Verified strictly serializable transaction-predicated map</li>
</ul>

},
keywords = {concurrency, coq, formal verification, library}
}

@software{10.5281/zenodo.6366579,
author = {Benzaken, V\'{e}ronique and Contejean, \'{E}velyne and Hachmaoui, Mohammed Houssem and Keller, Chantal and Mandel, Louis and Shinnar, Avraham and Sim\'{e}on, J\'{e}r\^{o}me},
title = {Translating Canonical SQL to Imperative Code in Coq Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6366579},
abstract = {
    <p>This artifact is associated to the paper <code>Translating Canonical SQL to Imperative Code in Coq</code> by V\'{e}ronique Benzaken, \'{E}velyne Contejean, Mohammed Houssem Hachmaoui, Chantal Keller, Louis Mandel, Avraham Shinnar, and J\'{e}r\^{o}me Sim\'{e}on published at OOPSLA 2022. It supports the following claims: - a new formal translation of SQLcoq to NRAe, - a new formal translation of NRAe to Imp, - a complete compiler for a large subset of SQL to JavaScript.</p>
<p>The artifact contains: - <code>dbcert.tar.gz</code> the docker image of the containing the installed artifact, - <code>oopsla22.pdf</code> the OOPSLA 2022 paper with appendix, - <code>dbcert-0.1.0</code> the source of the compiler, - <code>dbcert-0.1.0-no-float</code> the source of the compiler without support for floating point numbers (that does not requires axioms).</p>

},
keywords = {Coq, Formal proof, JavaScript, Query compiler, Semantics preserving compiler, SQL}
}

@software{10.5281/zenodo.6367565,
author = {Pelsmaeker, Daniel A. A. and van Antwerpen, Hendrik and Poulsen, Casper Bach and Visser, Eelco},
title = {Artifact for "Language-Parametric Static Semantic Code Completion"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6367565},
abstract = {
    <p>This is the artifact submitted alongside our OOPSLA’22 paper “Language-Parametric Static Semantic Code Completion”. The artifact contains a VirtualBox image and guide that were evaluated, and the relevant source and benchmark/test files.</p>

},
keywords = {code completion, semantics, Spoofax, Statix}
}

@software{10.5281/zenodo.6370152,
author = {Dyer, Tristan and Nelson, Tim and Fisler, Kathi and Krishnamurthi, Shriram},
title = {Applying Cognitive Principles to Model-Finding Output: The Positive Value of Negative Information (artifact)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6370152},
abstract = {
    <p>This artifact includes an experimental model-finder that demonstrates the “2+1-” visualization mode from the paper. Additionally, working versions of all user interfaces used in the studies are included, as well as the raw and anonymized data for all participants in the quantitative studies and the anonymized audio transcripts for participants in the qualitative studies. In-depth instructions for how to access and use the included items are included in the artifact README.</p>

},
keywords = {Alloy, cognitive science, formal methods, Human-centered computing, model finding, user studies}
}

@software{10.5281/zenodo.6371291,
author = {Liu, Jiawei and Wei, Yuxiang and Yang, Sen and Deng, Yinlin and Zhang, Lingming},
title = {Coverage-Guided Tensor Compiler Fuzzing with Joint IR-Pass Mutation},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6371291},
abstract = {
    <p>This artifact is for the paper “Coverage-Guided Tensor Compiler Fuzzing with Joint IR-Pass Mutation” accepted by OOPSLA’22. It contains the original experimental statistics presented in the paper and source code to reproduce it with guidance.</p>

},
keywords = {fuzzing, machine learning system, tensor compiler}
}

@software{10.5281/zenodo.6372033,
author = {Li, Jialin and Lattuada, Andrea and Zhou, Yi and Cameron, Jonathan and Howell, Jon and Parno, Bryan and Hawblitzel, Chris},
title = {Linear VeriBetrKV Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6372033},
abstract = {
    <p>This artifact includes the VeribetrKV-DF and VeriBetrKV-LT described in the case study of the paper. It also includes details for the formalization of Linear Dafny.</p>

},
keywords = {linear types, system verification}
}

@software{10.5281/zenodo.6372830,
author = {Brachth\"{a}user, Jonathan Immanuel and Schuster, Philipp and Lee, Edward and Boruch-Gruszecki, Aleksander},
title = {Artifact of the paper "Effects, Capabilities, and Boxes: From Scope-based Reasoning to Type-based Reasoning and Back"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6372830},
abstract = {
    <p>The artifact consists of two parts:</p>
<ol type="1">
<li>Coq proofs, proving soundness of the calculus System C.</li>
<li>A website featuring an implementation of System C with examples that can be typechecked, edited, and run.</li>
</ol>

},
keywords = {coq proofs, effect handlers, effect safety, type systems}
}

@software{10.5281/zenodo.6384379,
author = {Machiry, Aravind and Kastner, John and McCutchen, Matt and Eline, Aaron and Headley, Kyle and Hicks, Michael},
title = {Reproduction and Source Code for the paper "C to Checked C by 3C"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6384379},
abstract = {
    <p>This artifact contains all the necessary instructions and software to reproduce the results in the paper along with instructions to re-use/re-purpose the software.</p>

},
keywords = {C, Checked C, Rewriting, Type Inference}
}

@software{10.5281/zenodo.6390003,
author = {Cl\'{e}ment, Basile and Cohen, Albert},
title = {Reproduction Package for Article `End-to-End Translation Validation for the Halide Language`},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6390003},
abstract = {
    <p>This artifact contains a checking tool that allows to verify the correctness of affine implementations of affine Halide specifications, using the techniques described in the paper “End-to-End Translation Validation for the Halide language”. It also contains a patched version of the Halide compiler that generates prophetic annotations as described in the paper, and the examples used in the experiments, adapted from the official Halide benchmark suite.</p>
<p>The artifact is intended for the reproduction of the results in the paper, and to allow further experimentation with the techniques of the paper.</p>

},
keywords = {affine program, Halide, ocaml, tensor compiler, translation-validation, verification}
}

@software{10.48420/17041502.v1,
author = {Stirling, Sean and Rocha, Rodrigo C. O. and Hazelwood, Kim and Leather, Hugh and O'Boyle, Michael and Petoumenos, Pavlos},
title = {Artifact for F3M: Fast Focused Function Merging},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.48420/17041502.v1},
abstract = {
    <p>Evaluation Artifact for the CGO 2022 paper “F3M: Fast Focused Function Merging”.</p>
<p>This archive contains: 1) The scripts needed to setup the evaluation environment including pulling the Function Merging code and building it. 2) The scripts needed to reproduce the experiments in the paper. 3) Pre-compiled LLVM IR bitcode files on which we evaluate function merging.</p>

},
keywords = {code-size reduction, compiler optimization, function merging, LLVM}
}

@software{10.5281/zenodo.5703630,
author = {Vishwanathan, Harishankar and Shachnai, Matan and Narayana, Srinivas and Nagarakatte, Santosh},
title = {Artifact for submission "Sound, Precise, and Fast Abstract Interpretation with Tristate Numbers"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5703630},
abstract = {
    <p>In this artifact, we provide instructions to reproduce and validate the following claims in the paper.</p>
<ol type="1">
<li><p>Verification of tnum operations using the Z3 SMT solver</p></li>
<li><p>Precision improvements in our tnum multiplication algorithm compared to the Linux kernel’s tnum multiplication.</p></li>
<li><p>Performance improvements in our tnum multiplication algorithm compared to Linux kernel’s tnum multiplication.</p></li>
<li><p>Precision of tnum multiplication compared to the Linux kernel’s tnum multiplication as a function of increasing bitwidth of input tnums.</p></li>
</ol>

},
keywords = {Abstract domains, eBPF, Kernel extensions, Program verification, Static
analysis}
}

@software{10.5281/zenodo.5710526,
author = {Kallwies, Hannes and Leucker, Martin and Scheffel, Torben and Schmitz, Malte and Thoma, Daniel},
title = {Artifact (Docker Image) for paper "Aggregate Update Problem for Multi-Clocked Dataflow Languages"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5710526},
abstract = {
    <p>The artifact contains a TeSSLa to Scala compiler with the optimization described in the paper “Aggregate Update Problem for Multi-Clocked Dataflow Languages” and the benchmarks from the paper. The artifact is packaged as a Docker image for x86 64 Bit architectures. It provides shell scripts to compile and execute the synthetic as well as the real-world benchmarks described in the paper. The artifact further contains the source code of the implemented compiler phase and additional examples.</p>

},
keywords = {Aggregate Update Problem, Compiler Optimization, Dataflow Languages}
}

@software{10.5281/zenodo.5784251,
author = {Cummins, Chris and Wasti, Bram and Guo, Jiadong and Cui, Brandon and Ansel, Jason and Gomez, Sahir and Jain, Somya and Liu, Jia and Teytaud, Olivier and Steiner, Benoit and Tian, Yuandong and Leather, Hugh},
title = {CompilerGym Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5784251},
abstract = {
    <p>This is a supporting code artifact for the publication: “CompilerGym: Robust, Performant Compiler Optimization Environments for AI Research”. This is a snapshot of the CompilerGym repository, created at the time of publication.</p>
<p>For the most up-to-date release of CompilerGym, see GitHub: https://github.com/facebookresearch/CompilerGym.</p>
<p>For further information on CompilerGym, see our documentation site: https://compilergym.ai/.</p>

},
keywords = {compiler optimization, machine learning, reinforcement learning}
}

@software{10.5281/zenodo.5784768,
author = {Saumya, Charitha and Sundararajah, Kirshanthan and Kulkarni, Milind},
title = {Replication Package for Article: DARM: Control-Flow Melding for SIMT Thread Divergence Reduction},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5784768},
abstract = {
    <p>This artifact provides the source code that implements DARM, a compiler optimization technique for reducing SIMT thread divergence by control-flow melding. Our approach is implemented on top of the ROCm LLVM compiler. We also provide a benchmark suite to evaluate the effectiveness of our technique. This benchmark suite consists of well-known open-source GPGPU applications and optimized reference implementations of certain GPGPU applications. We provide a README file that describes how to build DARM and perform the experimental evaluation described in the initial version of our paper.</p>

},
keywords = {Compiler Optimizations, Control-Flow Divergence, GPGPUs}
}

@software{10.5281/zenodo.5785485,
author = {Tian, Linan and Shi, Yangyang and Chen, Liwei and Yang, Yanqi and Shi, Gang},
title = {Gadgets Splicing: Dynamic Binary Transformation for Precise Rewriting (CGO 2022 Artifact)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5785485},
abstract = {
    <p>This document describes the artifact for paper “Gadgets Splicing: Dynamic Binary Transformation for Precise Rewriting” at CGO 2022. The artifact is in the form of a virtual machine running Ubuntu 18.04. It contains all software dependencies and compiled GRIN rewriter, benchmark binaries and scripts. You can directly run the scripts for reproducing main experiments.</p>

},
keywords = {Binary analysis, Binary rewriting, Dynamic execution, Static analysis}
}

@software{10.5281/zenodo.5785832,
author = {Park, Sunghyun and Latifi, Salar and Park, Yongjun and Behroozi, Armand and Jeon, Byungsoo and Mahlke, Scott},
title = {SRTuner: Effective Compiler Optimization Customization by Exposing Synergistic Relations},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5785832},
abstract = {
    <p>SRTuner is a tuning strategy that searches for the best possible optimization setting for the given run-time environment. Within the tuning budget, SRTuner endeavors to expose important inter-relatonship between optimizations and leverage them to focus on the promising search subspace. To allow fast integration, SRTuner is built in the form of python library that provides tuning primitives. Users can build a standalone tuning framework with these primitives or adopt them into the existing tuning framework as a new tuning method. Latest version of SRTuner is available at: https://github.com/sunggg/SRTuner</p>

},
keywords = {autotuner, compiler, optimization}
}

@software{10.5281/zenodo.5786074,
author = {Bhat, Siddharth and Grosser, Tobias},
title = {Lambda the Ultimate SSA: Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5786074},
abstract = {
    <p>This is the artifact in the form of a docker image for our CGO’22 paper “Lambda the ultimate SSA”. It contains full source code of our compiler, benchmarks and scripts for reproducing main experiments of the paper. We supply instructions on how to run the artifact evaluation in the appendix of our paper.</p>

},
keywords = {compilers, functional programming}
}

@software{10.5281/zenodo.5787482,
author = {Wang, Xudong and Xu, Xuezheng and Li, Qingan and Yuan, Mengting and Xue, Jingling},
title = {Artifact for Article: Recovering Container Class Types in C++ Binaries},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5787482},
abstract = {
    <p>The artifact provides all non-proprietary components of TIARA.</p>

},
keywords = {Binary Code Analysis, Containers, Template Classes, Type Inference}
}

@software{10.5281/zenodo.5788478,
author = {Kurhe, Vaibhav Kiran and Karia, Pratik and Gupta, Shubhani and Rose, Abhishek and Bansal, Sorav},
title = {Artifact for "Automatic Generation of Debug Headers through BlackBox Equivalence Checking"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5788478},
abstract = {
    <p>The artifact contains source code for our tool, along with shell scripts and a dockerfile to install it inside a docker container. It also contains the output files from an equivalence checker (the .proof files) that are taken as input by our tool, along with the source and object files for TSVC benchmarking suite compiled with three different compilers – gcc, clang/llvm and icc. It can be used to reproduce the experimental results in Tables 2 and 3 of our CGO’22 paper – <strong>Automatic Generation of Debug Headers through BlackBox Equivalence Checking</strong>.</p>

},
keywords = {Compiler Optimizations, Debug Headers, Equivalence Checking}
}

@software{10.5281/zenodo.5788581,
author = {Brahmakshatriya, Ajay and Amarasinghe, Saman},
title = {Replication Package for the paper 'GraphIt to CUDA Compiler in 2021 LOC: A Case for High-Performance DSL Implementation via Staging with BuilDSL'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5788581},
abstract = {
    <p>The artifact contains the source code and the evaluation scripts for the evaluations in the paper. The attached README has step-by-step instructions to clone, build and run BuilDSL. The README also has steps on how to obtain the dataset, build the comparison framework GraphIt and run the experiments that compare the performance of the generated code on 9 datasets and 5 applications.</p>
<p>The second part of the README provides step-by-step instructions to write a new DSL with BuilDSL for matrix multiplication and implement a simple analysis on top of it before generating CPU and GPU code.</p>

},
keywords = {code generation, data-flow analysis, domain-specific languages, meta-programming, multi-stage programming}
}

@software{10.5281/zenodo.5789242,
author = {Li, Ao and Zheng, Bojian and Pekhimenko, Gennady and Long, Fan},
title = {Replication Packet for Article: Automatic Horizontal Fusion for GPU Kernels},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5789242},
abstract = {
    <p>This replication package provides the source code for article: Automatic Horizontal Fusion for GPU Kernels.</p>

},
keywords = {CUDA, GPU, Kernel Fusion, LLVM}
}

@software{10.5281/zenodo.5789400,
author = {Matni, Angelo and Deiana, Enrico Armenio and Su, Yian and Gross, Lukas and Ghosh, Souradip and Apostolakis, Sotiris and Xu, Ziyang and Tan, Zujun and Chaturvedi, Ishita and Homerding, Brian and McMichen, Tommy and August, David I. and Campanoni, Simone},
title = {Replication Package For Article: NOELLE Offers Empowering LLVM Extensions},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5789400},
abstract = {
    <p>This artifact generates three sets of results.</p>
<p>MINIMAL: Data that supports the version of the paper that was submitted in September. This experiment does not include HELIX and DSWP, which both take a significant amount of time to transform each benchmark.</p>
<p>SUBMISSION: HELIX and DSWP are included.</p>
<p>FINAL: New results that were not included in the submitted version of the paper (extra 5 days). Also, HELIX and DSWP are included in this experiment.</p>

},
keywords = {automatic parallelization, dependence analysis, loop invariant analysis}
}

@software{10.5281/zenodo.5791919,
author = {Huber, Joseph and Cornelius, Melanie and Georgakoudis, Giorgis and Tian, Shilei and Monslave Diaz, Jose M and Dinel, Kuter and Chapman, Barbara and Doerfert, Johannes},
title = {Replication Package for Article: Efficient Execution of OpenMP on GPUs},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5791919},
abstract = {
    <p>Our artifact provides the benchmarks used to evaluate the inter-procedural OpenMP optimizations implemented for this work. These benchmarks were evaluated using LLVM 12.0.1 as the baseline against a development branch of LLVM containing our changes with CUDA version 11.0. All but one of these patches have landed upstream, so any build of LLVM containing the commit hash 29a3e3dd7bed should be sufficient for general testing. Evaluation was done on a single Nvidia V100 GPU node, only kernel time was considered for benchmarking to measure the impact of our optimizations on the GPU.</p>

},
keywords = {GPU, LLVM, Offloading, OpenMP, Optimization}
}

@software{10.5281/zenodo.5792202,
author = {Rivera, Joao and Franchetti, Franz and P\"{u}schel, Markus},
title = {Artifact: A Compiler for Sound Floating-Point using Affine Arithmetic},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5792202},
abstract = {
    <p>The artifact is in the form of a virtual machine running Ubuntu 20.04. It contains source code of SafeGen, benchmarks and scripts for reproducing main experiments of the paper.</p>

},
keywords = {affine arithmetic, floating-point arithmetic, guaranteed computations, source-to-source compiler}
}

@software{10.5281/zenodo.5866935,
author = {Vesely, Jan and Pothukuchi, Raghavendra Pradyumna and Joshi, Ketaki and Gupta, Samyak and Cohen, Jonathan D. and Bhattacharjee, Abhishek},
title = {Distill: Domain-Specific Compilation for Cognitive Models Evaluation Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5866935},
abstract = {
    <p>This artifact contains an image with the environments and experiments presented in: “Distill: Domain-Specific Compilation for Cognitive Models” [CGO’22, Seoul, South Korea].</p>
<p>This artifact is based on an older version of PsyNeuLink (April 2021), and no longer represents the latest version. For up-to-date information on PsyNeuLink, as well as any support with developing cognitive models please visit https://github.com/PrincetonUniversity/PsyNeuLink.</p>

},
keywords = {cognitive models, Domain-specific compilation, human brain, JIT compilers, LLVM, PsyNeuLink, Python.}
}

@software{10.6084/m9.figshare.17048447.v1,
author = {Olabi, Mhd Ghaith and Luna, Juan G\'{o}mez and Mutlu, Onur and Hwu, Wen-mei and El Hajj, Izzat},
title = {A Compiler Framework for Optimizing Dynamic Parallelism on GPUs},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.17048447.v1},
abstract = {
    <p>Our artifact is a compiler implemented within Clang for optimizing applications that use dynamic parallelism. Since building the compiler requires building Clang/LLVM which can be time and resource consuming, we provide pre-built binaries in a Docker image, along with the required dependences and the benchmarks/datasets on which the compiler has been evaluated. Reviewers can use these binaries to transform the CUDA code with our optimizations, then compile and run the code on a CUDA-capable GPU. Scripts are provided to automate this process.</p>

},
keywords = {compiler, CUDA kernel, GPU computing}
}

@software{10.6084/m9.figshare.17263274.v1,
author = {Rocha, Rodrigo C. O. and Petoumenos, Pavlos and Franke, Bj\"{o}rn and Bhatotia, Pramod and O'Boyle, Michael},
title = {Replication Package for Article, "Loop Rolling for Code Size Reduction"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.17263274.v1},
abstract = {
    <p>Artifact for the CGO 2022 paper titled: “Loop Rolling for Code Size Reduction”.</p>

},
keywords = {Code Size Reduction, Compiler, Compiler Optimization, LLVM, Loop Optimization}
}

@software{10.5281/zenodo.6326451,
author = {Zagieboylo, Drew and Sherk, Charles and Suh, Gookwon Edward and Myers, Andrew C.},
title = {Reproduction Package for 'PDL: A High-Level Hardware Design Language for Pipelined Processors'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6326451},
abstract = {
    <p>A Docker container which can be used to recreate the results from the PLDI ’22 paper, PDL: A High-Level Hardware Design Language for Pipelined Processors.</p>
<p>This includes:</p>
<ul>
<li>The source code of the PDL compiler and its test suite</li>
<li>A simulator for the baseline Chisel processor used in our evaluation</li>
<li>The PDL programs describing the RISC-V architectures described in our evaluation</li>
<li>A build system to generate the CPI results reported in the paper for the above architectures</li>
</ul>

},
keywords = {Computer Architecture, Language Design}
}

@software{10.5281/zenodo.6326513,
author = {Greenberg, Michael and Beckett, Ryan and Campbell, Eric},
title = {Implementation of the KMT framework in OCaml},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6326513},
abstract = {
    <p>Kleene algebra modulo theories (KMT) is a framework for deriving concrete Kleene algebras with tests (KATs)—an algebraic framework for While-like programs with decidable program equivalence.</p>
<p>More plainly: KMT is a framework for building simple programming languages with structured control (if, while, etc.) where we can algorithmically decide whether or not two programs are equivalent. You can use equivalence to verify programs. If a is a nice property to have after running your program, then if p;a == p, you know that p satisfies a. Kleene algebra with tests subsumes Hoare logic: if a;p;~b == 0 then all runs starting from a either diverge or end with b, i.e., that equation corresponds to the partial correctness specification {a} p {b}. While prior work on KAT often focuses on abstract properties, we write programs over theories that assign concrete meanings to primitive tests and actions.</p>
<p>In addition to providing an OCaml library for defining KMTs over your own theories, we offer a command-line tool for testing equivalence in a variety of pre-defined theories.</p>

},
keywords = {algebraic models, functors, kleene algebra, modules, program equivalence, tracing semantics, verification}
}

@software{10.5281/zenodo.6327186,
author = {Jones, Eddie and Ong, C.-H. Luke and Ramsay, Steven},
title = {CycleQ},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6327186},
abstract = {
    <p>CycleQ is an efficient basis for automatic equation reasoning with cyclic proofs, rather than traditional induction, that is aimed at verifying the behaviour of functional programs. Specifically, the tool is implemented as a plugin for GHC.</p>

},
keywords = {cyclic proofs, equational reasoning, program verification}
}

@software{10.5281/zenodo.6327595,
author = {Tang, Shizhi and Zhai, Jidong and Wang, Haojie and Jiang, Lin and Zheng, Liyan and Yuan, Zhenhao and Zhang, Chen},
title = {Artifact: FreeTensor: A Free-form DSL with Holistic Optimizations for Irregular Tensor Programs},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6327595},
abstract = {
    <p>Artifact for PLDI ’22 paper “FreeTensor: A Free-form DSL with Holistic Optimizations for Irregular Tensor Programs”. The tensor compiler described in the paper is included, and the performance number can be reproduced.</p>

},
keywords = {DSL, optimizing compilers, tensor computing}
}

@software{10.5281/zenodo.6327882,
author = {Crichton, Will and Patrignani, Marco and Agrawala, Maneesh and Hanrahan, Pat},
title = {Artifact for "Modular Information Flow through Ownership"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6327882},
abstract = {
    <p>This is a Docker image that contains the codebase and evaluation scripts for our PLDI 2022 paper “Modular Information Flow Through Ownership”.</p>

},
keywords = {information flow, modular program analysis, rust}
}

@software{10.5281/zenodo.6329754,
author = {Farzan, Azadeh and Lette, Danya and Nicolet, Victor},
title = {Software Artifact for "Recursion Synthesis with Unrealizability Witnesses" Paper},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6329754},
abstract = {
    <p>This software artifact is provided to support the experimental claims made in the PLDI’22 paper <em>Recursion Synthesis with Unrealizability Witnesses</em>. All the results given in the paper are reproducible modulo experimental error. The artifact also contains a reusable version of Synduce, the tool implementing the synthesis algorithms presented in the paper.</p>

},
keywords = {Abstraction, Functional Programming, Invariants, Program Synthesis, Recursion, Unrealizability}
}

@software{10.5281/zenodo.6330157,
author = {Woodruff, Jackson and Armengol-Estap\'{e}, Jordi and Ainsworth, Sam and O'Boyle, Michael F. P.},
title = {Reproducing package for Bind the Gap: Compiling Software to Hardware FFT Accelerators},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6330157},
abstract = {
    <p>#FACC Artifact Evaluation</p>
<p>This set of instructions is split into several sections. First, we cover the generic build process. We then cover steps required to reproduce each figure. The main directory is FACC. Other sub-directories should be used as refered to in the README.</p>

},
keywords = {Compiler, FFT, Hardware Accelerator}
}

@software{10.5281/zenodo.6330164,
author = {Chabbi, Milind and Ramanathan, Murali Krishna},
title = {Data race examples},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6330164},
abstract = {
    <p>Examples of the data races discussed in the PLDI 22 paper titled “A Real World Study of Data Races in Golang”</p>

},
keywords = {data races, dynamic analysis, golang}
}

@software{10.5281/zenodo.6330174,
author = {Milano, Mae and Turcotti, Joshua and Myers, Andrew C.},
title = {A Flexible Type System for Fearless Concurrency: Accompanying Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6330174},
abstract = {
    <p>An implementation of a type-checker (with efficient proof search/inference) for the language described in the PLDI 2022 paper “A Flexible Type System for Fearless Concurrency,” available with DOI 10.1145/3519939.3523443 at the The ACM DL in June of 2022. Includes an accompanying virtual machine, with all dependencies installed, capable of building the type checker.</p>

},
keywords = {aliasing, compiler, concurrency, coq, linear types, ocaml, regions, type systems}
}

@software{10.5281/zenodo.6330208,
author = {Briggs, Ian and Panchekha, Pavel},
title = {OpTuner Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6330208},
abstract = {
    <p>Instructions and a virtual machine image to verify the claims in the paper “Choosing Math Function Implementations for Speed and Accuracy”</p>

},
keywords = {accuracy, floating point, ILP, optimization}
}

@software{10.5281/zenodo.6330232,
author = {Zhou, Xiangyu and Bodik, Rastislav and Cheung, Alvin and Wang, Chenglong},
title = {Reproduction Package for Synthesizing Analytical SQL Queries from Computation Demonstration},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6330232},
abstract = {
    <p>In this artifact, we included implementations of an analytical query synthesizer that uses enumerative synthesis algorithm and provenance abstraction for pruning the search space. In addition, we included the implementation of baselines synthesizers that use value abstraction, and type abstraction for experiments. Running the experimental scripts reproduces graph results in Synthesizing Analytical SQL Queries from Computation Demonstration. We also included 80 real-world benchmarks on solving analytical SQL problems with synthesizer.</p>

},
keywords = {Program Synthesis, Query by Demonstration}
}

@software{10.5281/zenodo.6330461,
author = {Choi, Wonhyuk and Finkbeiner, Bernd and Piskac, Ruzica and Santolucito, Mark},
title = {Artifact Package for "Can Reactive Synthesis and Syntax-Guided Synthesis Be Friends?"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6330461},
abstract = {
    <p>Instructions to download and run the tool temos, the artifact for the paper “Can Reactive Synthesis and Syntax-Guided Synthesis Be Friends?”</p>

},
keywords = {Program Synthesis, Reactive Synthesis, Syntax-Guided Synthesis}
}

@software{10.5281/zenodo.6330573,
author = {Verbeek, Freek and Bockenek, Joshua and Fu, Zhoulai and Ravindran, Binoy},
title = {Artifact for Article `Formally Verified Lifting of C-compiled x86-64 Binaries'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6330573},
abstract = {
    <p>This artifact accompanies the PLDI’22 article `Formally Verified Lifting of C-compiled x86-64 Binaries’. It can be used to disassemble x86-64 binaries and export proofs of correctness to the Isabelle/HOL theorem prover.</p>

},
keywords = {binary verification, disassembly, formal methods}
}

@software{10.5281/zenodo.6330707,
author = {Tao, Runzhou and Shi, Yunong and Yao, Jianan and Li, Xupeng and Javadi-Abhari, Ali and Cross, Andrew W. and Chong, Frederic T. and Gu, Ronghui},
title = {Artifact for PLDI 2022 paper Giallar: Push-button Verification for the Qiskit Quantum Compiler},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6330707},
abstract = {
    <p>The artifact contains the docker image file needed to reproduce the results presented in the paper.</p>

},
keywords = {automated verification, compiler verification, quantum computing}
}

@software{10.5281/zenodo.6330740,
author = {Pit-Claudel, Cl\'{e}ment and Philipoom, Jade and Jamner, Dustin and Erbsen, Andres and Chlipala, Adam},
title = {Artifact for "Relational Compilation for Performance-Critical Applications"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6330740},
abstract = {
    <p>A virtual machine submitted to PLDI 2022’s artifact evaluation committee.</p>

},
keywords = {compilation, theorem proving, verification}
}

@software{10.5281/zenodo.6351111,
author = {Guo, Zheng and Cao, David and Tjong, Davin and Yang, Jean and Schlesinger, Cole and Polikarpova, Nadia},
title = {Reproduction package of "Type-Directed Program Synthesis for RESTful APIs"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6351111},
abstract = {
    <p>This package includes a VMware virtual machine to reproduce results reported in the paper “Type-Directed Program Synthesis for RESTful APIs”.</p>

},
keywords = {Program Synthesis, RESTful API, Type Inference}
}

@software{10.5281/zenodo.6354482,
author = {Doenges, Ryan and Kapp\'{e}, Tobias and Sarracino, John and Foster, Nate and Morrisett, Greg},
title = {Leapfrog: Certified Equivalence for Protocol Parsers},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6354482},
abstract = {
    <p>This is the artifact accompanying the paper “Leapfrog: Certified Equivalence for Protocol Parsers”, to appear at PLDI 2022. See the README.md file for more details and installation instructions.</p>

},
keywords = {automata, certified parsers, Coq, equivalence, foundational verification, network protocol parsers, P4}
}

@software{10.5281/zenodo.6366190,
author = {Fehr, Mathieu and Niu, Jeff and Riddle, River and Amini, Mehdi and Su, Zhendong and Grosser, Tobias},
title = {IRDL: An IR Definition Language for SSA Compilers - PLDI 2022 Artifact Evaluation},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6366190},
abstract = {
    <p>The artifact provides: * A python tool to extract an IRDL representation of the 28 dialects available in MLIR. Each dialect can be extracted in two variants: (1) contains constraints that can currently be enforced by our IRDL implementation, (2) contains additional IRDL constraints that demonstate the full expressiveness of IRDL. The reader can manually inspect the IRDL file of each dialect to get a visual impression of the IRDL files for typical MLIR dialects. * Scripts to reproduce all plots (except Figure 3) from the evaluation section of the paper. In particular, Figure 3 is not reproduced * An implementation of the key language constructs of IRDL for MLIR, which can be registered at runtime and supports the following constructs: * Definition of dialects * Operations with operands, results, and constraint variables * Types * The following type constraints: <code>Any</code>, <code>AnyOf</code>, equality constraint, base constraint, parametric constraint</p>

},
keywords = {Compilers, Intermediate Representation, MLIR}
}

@software{10.5281/zenodo.6366296,
author = {Ahrens, Willow and Kjolstad, Fredrik and Amarasinghe, Saman},
title = {Autoscheduling for Sparse Tensor Algebra with an Asymptotic Cost Model (The Artifact)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6366296},
abstract = {
    <p>An artifact to replicate the results of “Autoscheduling for Sparse Tensor Algebra with an Asymptotic Cost Model”, Willow Ahrens, Fredrik Kjolstad, and Saman Amarasinghe. PLDI 2022.</p>

},
keywords = {Asymptotic Analysis, Automatic Scheduling, Compilers, Conjunctive Query Containment, Query Optimization, Sparse Tensors}
}

@software{10.5281/zenodo.6374369,
author = {Dang, Hoang-Hai and Jung, Jaehwang and Choi, Jaemin and Nguyen, Duc-Than and Mansky, William and Kang, Jeehoon and Dreyer, Derek},
title = {Compass: Strong and Compositional Library Specifications in Relaxed Memory Separation Logic (Artifact)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6374369},
abstract = {
    <p>This contains a snapshot of the Compass development.</p>
<p>More updated information can be found at https://plv.mpi-sws.org/compass/.</p>

},
keywords = {C11, Coq, Iris, Linearizabliity, Logical Atomicity, Relaxed Memory, Separation Logic}
}

@software{10.5281/zenodo.6392272,
author = {Chen, Yishen and Mendis, Charith and Amarasinghe, Saman},
title = {Reproduction Package for "All You Need Is Superword-Level Parallelism: Systematic Control-Flow Vectorization with SLP"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6392272},
abstract = {
    <p>Artifact to reproduce the result in the paper.</p>

},
keywords = {Compiler, Optimization, SIMD, Vectorization}
}

@software{10.5281/zenodo.6394618,
author = {Fl\"{u}ckiger, Olivier and Je\v{c}men, Jan and Krynski, Sebasti\'{a}n and Vitek, Jan},
title = {Artifact of "Deoptless: Speculation with Dispatched On-Stack Replacement and Specialized Continuations"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6394618},
abstract = {
    <p>This is the artifact to accompany our PLDI 2022 submission on “Deoptless: Speculation with Dispatched On-Stack Replacement and Specialized Continuations”. The artifact consists of a virtual machine for the R language, called \v{R}, a suite of benchmarks written in R, as well as R scripts to plot the results.</p>

},
keywords = {virtual machine}
}

@software{10.5281/zenodo.6395059,
author = {Gorjiara, Hamed and Luo, Weiyu and Lee, Alex and Xu, Guoqing Harry and Demsky, Brian},
title = {Replication Package for Article: Checking Robustness to Weak Persistency Models},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6395059},
abstract = {
    <p>This artifact contains a vagrant repository that downloads and compiles the source code for PSan(a plugin for Jaaru), its companion compiler pass, and benchmarks. The artifact enables users to reproduce the bugs that are found by PSan in PMDK and RECIPE (Table 2} in Evaluation Section) as well as comparing bug-finding capabilities and performance of PSan with Jaaru, a persistent memory model checker (Table 3 in the Evaluation Section). To simplify the evaluation process, we created an instance of VM that includes all the source code and corresponding binary files. This VM is fully set up and it is available on this artifact repository. This artifact also provides a guideline on how to setup the VM and use it to reproduce PSan’s evaluation results.</p>

},
keywords = {Crash Consistency Bugs, Jaaru, Persistency Bugs, Persistent Memory Model Checker, PMDK, PSan, RECIPE, Robustness Violations}
}

@software{10.5281/zenodo.6402134,
author = {Honor\'{e}, Wolf and Shin, Ji-Yong and Kim, Jieung and Shao, Zhong},
title = {Artifact For "Adore: Atomic Distributed Objects with Certified Reconfiguration"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6402134},
abstract = {
    <p>This is the Coq implementation of the Adore model, safety proof, and refinement described in the paper. It also includes an executable instantiation of the abstract model using OCaml extraction. Refer to the README for build instructions and additional details.</p>

},
keywords = {consensus protocols, Coq, distributed systems, formal verification, reconfiguration, refinement}
}

@software{10.5281/zenodo.6408463,
author = {Rocha, Rodrigo C. O. and Sprokholt, Dennis and Fink, Martin and Gouicem, Redha and Spink, Tom and Chakraborty, Soham and Bhatotia, Pramod},
title = {Lasagne: A Static Binary Translator for Weak Memory Model Architectures},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6408463},
abstract = {
    <p>Artifact for the paper titled “Lasagne: A Static Binary Translator for Weak Memory Model Architectures” published in the Conference on Programming Language Design and Implementation, 2022. It contains the automated proofs presented in the paper as well as the software for the Lasagne system and its evaluation.</p>

},
keywords = {LLVM, Memory Model, Static Binary Translation}
}

@software{10.5281/zenodo.6409577,
author = {Morelli, Canberk and Reineke, Jan},
title = {Replication Package for Warping Cache Simulation of Polyhedral Programs},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6409577},
abstract = {
    <p>This is the artifact of the conference paper “Warping Cache Simulation of Polyhedral Programs” at PLDI 2022.</p>
<p>The artifact structure is as follows: - <code>benchmark</code>: The <a href="https://web.cse.ohio-state.edu/~pouchet.2/software/polybench/">PolyBench</a> benchmark that is used in our experiments. - <code>data</code>: The data we obtained from our experiments (<code>data/existing</code>) which are presented in our paper as plots. The data that you will reproduce will also be available here (<code>data/reproduced</code>). - <code>haystack-artifact</code>: The <a href="https://dl.acm.org/do/10.1145/332599">artifact</a> provided by the related work <a href="https://dl.acm.org/doi/10.1145/3314221.3314606">HayStack</a>. - <code>plots</code>: The plots you will generate (<code>plots/from-existing-data</code> and <code>plots/from-reproduced-data</code>). - <code>scripts</code>: The scripts for repeating our experiments and generating our figures. - <code>warping-cache-simulation</code>: The source code of our cache simulation tool. - <code>d4-7.tar.gz</code>: DineroIV package, used only if the ftp server used in <code>haystack-artifact/Dockerfile</code> is down. - <code>Dockerfile</code>: File to build our Docker image, which will be used to repeat our experiments and generate our plots. - <code>README.md</code>: This file. We suggest using a “markdown capable” viewer to read the file. - <code>paper-submission-version.pdf</code>: The submission version of our accepted paper.</p>
<p>Please refer to the README.md for more information.</p>

},
keywords = {cache model, cache simulation, data independence, performance analysis, simulation}
}

@software{10.5281/zenodo.6410434,
author = {Chaliasos, Stefanos and Sotiropoulos, Thodoris and Spinellis, Diomidis and Gervais, Arthur and Livshits, Benjamin and Mitropoulos, Dimitris},
title = {Replication Package for Article: "Finding Typing Compiler Bugs"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6410434},
abstract = {
    <p>The purpose of this artifact is to reproduce the results presented in the PLDI 2022 paper titled “Finding Typing Compiler Bugs”. The artifact contains the instructions, tool, and scripts to re-run the evaluation described in the paper. The artifact has the following structure:</p>
<ul>
<li>scripts/: This directory contains the scripts needed to re-run the experiments presented in our paper.</li>
<li>data/: This is the directory that contains the precomputed results of our evaluation.</li>
<li>database/bug_schema.sql: This is the database schema that contains the bugs discovered by our approach.</li>
<li>database/bugdb.sqlite3: This is the sqlite3 database file corresponding to our bug database.</li>
<li>database/bugs.json: This JSON file contains the bugs of database/bugdb.sqlite.</li>
<li>hephaestus/: Contains the source code of the tool (provided as a git submodule) used for testing the compilers of Java, Kotlin, and Groovy. The name of our tool is Hephaestus.</li>
<li>installation_scripts/: Contains helper scripts used to install all dependencies (e.g., compiler versions from SDKMAN).</li>
<li>figures/: This directory will be used to save figure 8 of the paper.</li>
<li>Dockerfile: The Dockerfile used to create a Docker image of our artifact. This image contains all data and dependencies.</li>
</ul>

},
keywords = {compiler bugs, compiler testing, Groovy, Java, Kotlin, static typing}
}

@software{10.5281/zenodo.6412048,
author = {Guria, Sankha Narayan and Vazou, Niki and Guarnieri, Marco and Parker, James},
title = {Replication package for "ANOSY: Approximated Knowledge Synthesis with Refinement Types for Declassification"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6412048},
abstract = {
    <p>The artifact is a Docker image that contains all of the source code, benchmarks, and experiment harnesses used in the development of the paper (set-up and ready to run). The README contains instructions to reproduce results from the paper, as well as pointers for how to use, extend or modify the tool and benchmarks.</p>

},
keywords = {knowledge-based privacy, program synthesis, program verification, refinement types}
}

@software{10.5281/zenodo.6413018,
author = {Kortbeek, Vito and Ghosh, Souradip and Hester, Josiah and Campanoni, Simone and Pawe\l{}czak, Przemys\l{}aw},
title = {WARio: Efficient Code Generation for Intermittent Computing - PLDI 2022 Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6413018},
abstract = {
    <p>This is the PLDI 2022 artifact for WARio, a compiler-support runtime for intermittently-powered platforms with non-volatile main memory.</p>
<p>This artifact is separated into three downloadable objects: * docker.zip, which holds all the Dockerfiles and prebuilt Docker containers. * code.zip, which holds all the source code (also available at: https://github.com/TUDSSL/WARio) * README.md, a markdown file containing more details about this artifact and how to evaluate it properly.</p>
<p>The docker containers can go through all the steps required to reproduce WARio, from building WARio and its dependencies to generating the figures and tables presented in the paper (and more).</p>
<p>For more information, please download the README.md file in this artifact.</p>
<p>Accompanying GitHub repository: https://github.com/TUDSSL/WARio</p>
<p>Supporting grants: NWO: P15-06 NSF: CNS-1850496, CNS-2145584, CCF-1908488, CNS-1763743</p>

},
keywords = {ARM, battery-free, compiler-support, embedded, intermittent computing, mixed-memory architecture, non-volatile memory, PLDI}
}

@software{10.5281/zenodo.6413290,
author = {Cho, Minki and Lee, Sung-Hwan and Lee, Dongjae and Hur, Chung-Kil and Lahav, Ori},
title = {Coq Development for the article `Sequential Reasoning for Optimizing Compilers Under Weak Memory Concurrency`},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6413290},
abstract = {
    <p>This artifact contains Coq development of the promising semantics model extended with non-atomic accesses, the SEQ model and its soundness theorem, and the certified optimizer.</p>

},
keywords = {Compiler Optimizations, Operational Semantics, Relaxed Memory Concurrency}
}

@software{10.5281/zenodo.6413814,
author = {\v{Z}ikeli\'{c}, undefinedor\dj{}e and Chang, Bor-Yuh Evan and Bolignano, Pauline and Raimondi, Franco},
title = {Differential Cost Analysis with Simultaneous Potentials and Anti-potentials (Artifact)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6413814},
abstract = {
    <p>The artifact contains a prototype tool for differential cost analysis of numerical C programs with polynomial arithmetic and possibly with non-determinism. Given two programs together with their input sets, the tool computes an upper bound on the maximal difference in cost usage between the two programs on any initial variable valuation that is contained in both input sets. Cost may take both positive and negative values, and we assume that each program has a special variable “cost” that is initialized to 0 and that is updated whenever cost is incurred in the program. It could be used to track program runtime, memory usage, the number of object allocations, or any other program property of interest that could be tracked by a program variable.</p>
<p>The artifact is provided both as a docker image and as a zip of all source files. The reason for providing both is that, in our experimental evaluation, we use Gurobi for linear programming (LP) which is licensed and is free only for academic use. Thus, we cannot install Gurobi in our docker image but replace it with the GLPK solver. GLPK allows reproducing our experimental results with slightly longer runtimes (details are provided in README). To reproduce our reported experimental results with Gurobi, one needs to build the tool from source files and instructions for doing so are provided in README.</p>

},
keywords = {Cost analysis, Differential cost analysis, Potential functions, Relational reasoning}
}

@software{10.5281/zenodo.6414469,
author = {Grewal, Karuna and D'Antoni, Loris and Hsu, Justin},
title = {Reproduction Package for Article "P4BID: Information Flow Control in P4"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6414469},
abstract = {
    <p>The artifact contains the main Readme.txt describing how to reproduce the evaluation presented in the paper using the baseline original P4c compiler and its IFC extension.</p>

},
keywords = {IFC, P4}
}

@software{10.5281/zenodo.6414787,
author = {Mulder, Ike and Krebbers, Robbert and Geuvers, Herman},
title = {Artifact and Appendix of 'Diaframe: Automated Verification of Fine-Grained Concurrent Programs in Iris'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6414787},
abstract = {
    <p>This is the artifact for the PLDI ‘22 paper ’Diaframe: Automated Verification of Fine-Grained Concurrent Programs in Iris’. It contains the Diaframe source code, a VM containing a compiled version of this source code, the appendix for the paper, and instructions for evaluation.</p>

},
keywords = {Coq, fine-grained concurrency, Iris, proof automation, Separation logic}
}

@software{10.5281/zenodo.6416420,
author = {Paraskevopoulou, Zoe and Eline, Aaron and Lampropoulos, Leonidas},
title = {Artifact for Computing Correctly with Inductive Relations},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6416420},
abstract = {
    <p>VM containing ready-to-build experiments for the paper.</p>

},
keywords = {Coq, Inductive relations, QuickChick}
}

@software{10.5281/zenodo.6416442,
author = {Christensen, Michael and Tzimpragos, Georgios and Kringen, Harlan and Volk, Jennifer and Sherwood, Timothy and Hardekopf, Ben},
title = {Reproduction Package for Article "PyLSE: A Pulse-Transfer Level Language for Superconductor Electronics"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6416442},
abstract = {
    <p>PyLSE is a Python-embedded pulse-transfer level language for the design and simulation of superconductor electronics (SCE). The purpose of PyLSE is to make it easier to create precise and composable models of the basic SCE cells (i.e.&nbsp;gates), use these models to create larger systems, quickly get up and running in the built-in simulation framework, and finally prove various properties about these cells and systems using a state-of-the-art model checker. This artifact will show you how to do so, as well as show you how to get the results in the tables and figures found in the evaluation section of our paper.</p>

},
keywords = {hardware description language, superconductor electronics, timed automata}
}

@software{10.5281/zenodo.6416483,
author = {O'Connor, Liam and Wickstr\"{o}m, Oskar},
title = {Reproduction Package for 'Quickstrom: Property-based acceptance testing with LTL specifications'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6416483},
abstract = {
    <p>This artifact contains the software, source code, and experimental results for the paper ‘Quickstrom: Property-based acceptance testing with LTL specifications’ at PLDI 2022. See README.TXT for more details.</p>

},
keywords = {programming, property-based testing, results, software, web applications}
}

@software{10.5281/zenodo.6417959,
author = {Sammler, Michael and Hammond, Angus and Lepigre, Rodolphe and Campbell, Brian and Pichon-Pharabod, Jean and Dreyer, Derek and Garg, Deepak and Sewell, Peter},
title = {Artifact for "Islaris: Verification of Machine Code Against Authoritative ISA Semantics"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6417959},
abstract = {
    <p>This is the artifact for the PLDI’22 paper “Islaris: Verification of Machine Code Against Authoritative ISA Semantics”. It contains the Coq development for the paper.</p>

},
keywords = {Arm, assembly, Coq, Iris, Isla, proof automation, RISC-V, Sail, separation logic, verification}
}

@software{10.5281/zenodo.6419124,
author = {Ikarashi, Yuka and Bernstein, Gilbert Louis and Reinking, Alex and Genc, Hasan and Ragan-Kelley, Jonathan},
title = {Exocompilation for Productive Programming of Hardware Accelerators},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6419124},
abstract = {
    <p>This artifact consists of a Docker image capable of reproducing our AVX-512 benchmarks on compatible hardware (e.g.&nbsp;Skylake-X or Tiger Lake). To use the latest Exo system for practical development, we refer readers to our GitHub repository at: https://github.com/ChezJrk/exo and our Python package at: https://pypi.org/project/exo-lang/</p>

},
keywords = {Code optimization, Computer architecture, High performance computing, Language design}
}

@software{10.5281/zenodo.6450309,
author = {Farzan, Azadeh and Klumpp, Dominik and Podelski, Andreas},
title = {Artifact for PLDI'22 paper "Sound Sequentialization for Concurrent Program Verification"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6450309},
abstract = {
    <p>This artifact for the PLDI’22 paper “Sound Sequentialization for Concurrent Program Verification” consists of a docker image that contains source code for the evaluated verifiers, compiled binaries of the verifiers, benchmark programs to compare the verifiers, and the raw evaluation results that form the basis for the discussion in the paper.</p>

},
keywords = {Concurrency, Partial Order Reduction, Sequentialization}
}

@software{10.5281/zenodo.6460021,
author = {Bendrissou, Bachir and Gopinath, Rahul and Zeller, Andreas},
title = {Reproduction package for “Synthesizing Input Grammars”: A Replication Study},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6460021},
abstract = {
    <p>This is a virtual box image that contains all experiments necessary to reproduce the results of the paper “Synthesizing Input Grammars”: A Replication Study.</p>

},
keywords = {glade, grammar mining, replication}
}

@software{10.5281/zenodo.6466911,
author = {Dhulipala, Laxman and Blelloch, Guy E. and Gu, Yan and Sun, Yihan},
title = {CPAM (Compressed Parallel Augmented Maps), an implementation of "PaC-Trees: Supporting Parallel and Compressed Purely-Functional Collections"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6466911},
abstract = {
    <p>CPAM (Compressed Parallel Augmented Maps) is a parallel C++ library providing an implementation of the PaC-tree data structure, which is used to provide an interface for augmented maps that supports blocking of the nodes and applying user-defined compression schemes on the underlying data. CPAM’s interface is an extension of the interface from the PAM (Parallel Augmented Maps) library. CPAM is designed for maintaining ordered map data structures on potentially large and compressed datasets while efficiently answering queries (e.g., range queries) and performing dynamic updates on the data.</p>
<p>In the experiments, we use the interface in four examples: an inverted index, interval-queries, 2d range-queries, and graph processing. This artifact provides a self-contained docker image, includes examples and scripts for running the main experiments reported in the paper. It has also been designed to make it easy to try many other scenarios (e.g., different sizes, different datasets, different numbers of cores, and other operations described in the paper, but not reported in the experiments).</p>
<p>More details, examples, and discussion can be found in our paper.</p>

},
keywords = {parallel data structures, purely-functional data structures, space-efficient data structures}
}

@software{10.5281/zenodo.6468999,
author = {Anderson, Daniel and Blelloch, Guy E. and Wei, Yuanhao},
title = {Artifact for "Turning Manual Concurrent Memory Reclamation into Automatic Reference Counting"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6468999},
abstract = {
    <p>This artifact contains our code and experiments as they were at the time of <strong>submission</strong>, and hence, at the time that they were validated by the artifact evaluation comittee. The latest version of our code can always be obtained from <a href="https://github.com/cmuparlay/concurrent_deferred_rc">here</a>. If you wish to build on our code for your own research, we highly recommend obtaining the latest version.</p>
<p>Note that this artifact does not contain the commercial <a href="https://www.stdthread.co.uk/">just::threads</a> library, which we compare with in Figure 13 of our paper, due to copyright. This artifact is still able to plot Figure 13, but without the line for just::threads.</p>

},
keywords = {automatic memory reclamation, concurrency, lock-free, smart pointers}
}

@software{10.5281/zenodo.6470820,
author = {Beutner, Raven and Ong, C.-H. Luke and Zaiser, Fabian},
title = {Artifact for: Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming (PLDI 2022)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6470820},
abstract = {
    <p>This is the artifact for “Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming” (PLDI 2022). It contains the implementation of the GuBPI tool, which can compute Guaranteed Bounds for Posterior Inference. It also includes the benchmarks from the paper and scripts to reproduce the reported data. For convenience, Docker images are also provided to allow for quick experimentation.</p>

},
keywords = {abstract interpretation, Bayesian inference, interval arithmetic, operational semantics, probabilistic programming, symbolic execution, type system, verification}
}

@software{10.5281/zenodo.6501665,
author = {Matsushita, Yusuke and Denis, Xavier and Jourdan, Jacques-Henri and Dreyer, Derek},
title = {RustHornBelt: A Semantic Foundation for Functional Verification of Rust Programs with Unsafe Code, Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6501665},
abstract = {
    <p>It is the artifact for the PLDI 2022 paper “RustHornBelt: A Semantic Foundation for Functional Verification of Rust Programs with Unsafe Code”. It contains the Coq mechanization of RustHornBelt’s type-spec system and its semantic soundness proof, as well as the benchmarks that evaluate RustHornBelt’s specs using a semi-automated Rust verifier Creusot.</p>

},
keywords = {Coq mechanization, Iris, Rust, semi-automated verification, separation logic, Why3}
}

@software{10.5281/zenodo.6501899,
author = {Zhao, Wenyu and Blackburn, Stephen M. and McKinley, Kathryn S.},
title = {[PLDI'22 Artifact] #132 Low-Latency, High-Throughput Garbage Collection},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6501899},
abstract = {
    <p>Artifact for PLDI 2022 paper: Low-Latency, High-Throughput Garbage Collection</p>
<p>Please check https://github.com/wenyuzhao/lxr-pldi-2022-artifact/blob/main/README.md for instructions on building and evaluating the artifact.</p>
<p>Please refer to https://github.com/wenyuzhao/mmtk-core/tree/lxr for the latest implementation.</p>

},
keywords = {Garbage collection, Reference counting}
}

@software{10.5281/zenodo.6503045,
author = {Zha, Junpeng and Liang, Hongjin and Feng, Xinyu},
title = {Artifact of "Verifying Optimizations of Concurrent Programs in the Promising Semantics"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6503045},
abstract = {
    <p>This is the artifact of PLDI22-paper984 “Verifying Optimizations of Concurrent Programs in the Promising Semantics”. We package our artifact (mechanized proof of the verification framework introduced in our paper in the Coq) in the virtual machine VirtualBox-6.1.32 as <code>pldi22-paper984.ova</code>. Detailed descriptions of the artifact can be found in the README.txt.</p>

},
keywords = {Code optimizations, Concurrency, Coq, Verification, Weak memory models}
}

@software{10.5281/zenodo.6503142,
author = {Chen, Yanju and Yan, Xifeng and Feng, Yu},
title = {Research Artifact for PLDI'22 Paper: Visualization Question Answering Using Introspective Program Synthesis},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6503142},
abstract = {
    <p>Research Artifact for PLDI’22 Paper: Visualization Question Answering Using Introspective Program Synthesis</p>

},
keywords = {Machine Learning, Program Synthesis}
}

@software{10.5281/zenodo.6508992,
author = {Xu, Mingkuan and Li, Zikun and Padon, Oded and Lin, Sina and Pointing, Jessica and Hirth, Auguste and Ma, Henry and Palsberg, Jens and Aiken, Alex and Acar, Umut A. and Jia, Zhihao},
title = {Artifact for PLDI 2022 Paper: Quartz: Superoptimization of Quantum Circuits},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6508992},
abstract = {
    <p>Quartz is a quantum circuit optimizer that automatically generates and verifies circuit transformations for an arbitrary quantum gate set. To optimize an input quantum circuit, Quartz uses these auto-generated circuit transformations to construct a search space of functionally equivalent quantum circuits. Quartz uses a cost-based search algorithm to explore the space and discovers highly optimized quantum circuits.</p>
<p>Quartz is open-source and developed on GitHub: https://github.com/quantum-compiler/quartz.</p>
<p>This artifact supports the PLDI 2022 paper about Quartz, and contains the implementation and scripts used to obtain the results reported in the paper. See also the extended version of the paper at https://arxiv.org/abs/2204.09033.</p>

},
keywords = {quantum computing, superoptimization}
}

@software{10.5281/zenodo.6509997,
author = {Aanjaneya, Mridul and Lim, Jay P. and Nagarakatte, Santosh},
title = {Artifact for Progressive Polynomial Approximations for Fast Correctly Rounded Math Libraries},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6509997},
abstract = {
    <p>We present the artifact for the paper, “Progressive Polynomial Approximations for Fast Correctly Rounded Math Libraries.” We describe the list of claims made by the paper, evaluation instructions, and instructions on how to use RLIBM-PROG. To ease the installation effort, we provide a docker image with all but one required softwares installed already (with instructions on how to build the remaining required software in the docker image). Additionally, we provide complete instructions to manually install the artifact on Ubuntu 20.04.</p>

},
keywords = {Correct rounded elementary functions, progressive polynomials, RLIBM, RLIBM-PROG}
}

@software{10.5281/zenodo.6512301,
author = {Ma, Haoran and Liu, Shi and Wang, Chenxi and Qiao, Yifan and Bond, Michael D. and Blackburn, Stephen M. and Kim, Miryung and Xu, Guoqing Harry},
title = {Mako -- A Low-Pause, High-Throughput Evacuating Collector for Memory-Disaggregated Datacenters},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6512301},
abstract = {
    <p>Mako contains the following three components:</p>
<ul>
<li>the Linux kernel with functionalities required by Mako - kernel</li>
<li>the CPU-server Java Virtual Machine - Mako-CPU</li>
<li>the Memory-server Java Virtual Machine - Mako-Memory</li>
</ul>

},
keywords = {Disaggregation, Garbage Collection}
}

@software{10.5281/zenodo.6514315,
author = {Greenman, Ben},
title = {Deep and Shallow Types for Gradual Languages},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6514315},
abstract = {
    <p>Data, analysis scripts, and source code.</p>

},
keywords = {complete monitoring, gradual typing, migratory typing, type enforcement strategies}
}

@software{10.1145/3462319,
author = {Baudart, Guillaume and Mandel, Louis and Tekin, Reyyan},
title = {Reproduction package for article JAX Based Parallel Inference for Reactive Probabilistic Programming},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462319},
abstract = {
    <p>This artifact supports the LCTES 2022 article <strong>JAX Based Parallel Inference for Reactive Probabilistic Programming</strong>. It contains:</p>
<ul>
<li><code>zelus</code>: a modified version of the <a href="https://zelus.di.ens.fr">Zelus</a> compiler with a new JAX backend</li>
<li><code>probzelus</code>: the original <a href="https://github.com/IBM/probzelus">ProbZelus</a> runtime for OCaml</li>
<li><code>zlax</code>: the new ProbZelus runtime for JAX</li>
<li><code>examples</code>: several examples of ProbZelus programs</li>
<li><code>zlax-benchmarks</code>: the benchmarks to compare the OCaml and JAX runtimes based on the original <a href="https://github.com/IBM/probzelus">ProbZelus benchmark</a></li>
<li><code>lctes22-zlax.pdf</code>: the <a href="https://pldi22.sigplan.org/track/LCTES-2022">LCTES 2022</a> paper.</li>
<li><code>lctes22-zlax-image.tar.gz</code>: the saved <a href="https://www.docker.com">Docker</a> image with everything installed.</li>
</ul>

},
keywords = {Compilation, Parallel Computing, Probabilistic Programming, Reactive Programming, Streaming Inference}
}

@software{10.1145/3462320,
author = {Schlaak, Christof and Juang, Tzung-Han and Dubach, Christophe},
title = {Reproducton Package for Article "Optimizing Data Reshaping Operations in Functional IRs for High-Level Synthesis"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462320},
abstract = {
    <p>This artifact fully covers all the experiments in section 4 of the LCTES 2022 paper “Optimizing Data Reshaping Operations in Functional IRs for High-Level Synthesis”. Starting from high-level expressions as described in sections 4.1 and 4.2 for tiled matrix multiplication and 2D convolution, the compiler automatically generates an optimized hardware design based on VHDL files. On the FPGA server, a bitstream for an FPGA is synthesised from these generated design files. Then the design is run on a real FPGA to get all the performance numbers and resource usages of Table 2 and Table 3.</p>

},
keywords = {compilers, functional IR, High-level synthesis, rewrite rules}
}

@software{10.1145/3462321,
author = {Schneider, Klaus and Bhagyanath, Anoop and Roob, Julius},
title = {Reproduction Package for Paper "Code Generation Criteria for Buffered Exposed Datapath Architectures from Dataflow Graphs "},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462321},
abstract = {
    <p>The software can be used to reproduce the computations described in the corresponding paper and also to perform computations with modified or completely different examples. In general, one can derive via a SAT solver a move code program for a BED architecture either from a sequential program or a dataflow graph derived from it.</p>

},
keywords = {code generation, dataflow graphs, exposed data- path architectures, linear graph layouts, queue layouts}
}

@software{10.5281/zenodo.6385800,
author = {Dolby, Julian and Tsay, Jason and Hirzel, Martin},
title = {Replication kit for "Automatically Debugging AutoML Pipelines Using Maro: ML Automated Remediation Oracle"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6385800},
abstract = {
    <p>This archive contains our tool, data, and experimental results used for the evaluation for our MAPS 2022 paper entitled “Automatically Debugging AutoML Pipelines Using Maro: ML Automated Remediation Oracle.”</p>

},
keywords = {AI Debugging, Automated Debugging, Automated Remediation, AutoML}
}

@software{10.5281/zenodo.6598647,
author = {Liu, Fengyun and Prokopec, Aleksandar},
title = {Artifact for paper implicit state machines LCTES 2022},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6598647},
abstract = {
    <p>This is the artefact for the paper “implicit state machines” at LCTES 2022.</p>
<p>Note that DSL is an old version and thus deprecated. We are working on a newer version with a better design.</p>

},
keywords = {digital design, DSL, implicit state machine}
}

@software{10.5281/zenodo.6605099,
author = {Wang, Tianyu and Shen, Zhaoyan and Shao, Zili},
title = {Reproduction package of "Co-mining: A Processing-in-Memory Assisted Framework for Memory-Intensive PoW Acceleration"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6605099},
abstract = {
    <p>A simple simulator that can simulate hashrate for different NVIDIA graphic cards with GDDR6 or HBM-PIM. Content: /configs: All the configurations of different graphic cards. /build: The trace file and result analysis scripts. /src: Main logic of the simulator.</p>

},
keywords = {GPU-PIM simulator}
}

@software{10.5281/zenodo.6607837,
author = {Chen, Zizhan and Shang, Siqi and Wu, Qihong and Xue, Jin and Shen, Zhaoyan and Shao, Zili},
title = {AE Package for "An Old Friend Is Better Than Two New Ones: Dual-Screen Android"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6607837},
abstract = {
    <p>The artifact is for “An Old Friend Is Better Than Two New Ones: Dual-Screen Android”. App_List.pdf contains the Corpus-L application list.</p>
<p>Modifications/ folder contains the modified files.</p>
<p>Scripts/ folder contains the scripts.</p>
<p>Expected_outputs/ folder contains the expected outputs.</p>
<p>Link to the demo Videos: https://mycuhk-my.sharepoint.com/:f:/g/personal/1155107934_link_cuhk_edu_hk/EmUhtXbQ5I5EqrmK66yOrDQBS7948nAc2ye-JFsBp5xd5w?e=bbP3gw</p>
<p>AE_Addition/ contains the python scripts to generate the experimental results.</p>

},
keywords = {display energy optimization, Embedded system, mobile system}
}

@software{10.5281/zenodo.6630188,
author = {Rabin, Md Rafiqul Islam and Hussain, Aftab and Alipour, Mohammad Amin},
title = {Artifact for Article (CI-DD-PERSES): Syntax-Guided Program Reduction for Understanding Neural Code Intelligence Models},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6630188},
abstract = {
    <p>This artifact contains the prediction-preserving program reduction code and the experimental reduced data using the DD and Perses algorithms for our paper ‘Syntax-Guided Program Reduction for Understanding Neural Code Intelligence Models’ accepted at MAPS’22. For extracting key features in the model’s prediction, we integrate the Perses \&amp; DD simplification algorithms with the CI model as a black-box framework into SIVAND-Perses and SIVAND-DD, respectively. The main insight is that, by reducing some input programs of a target label, we can better understand what key input features a CI model learns from the training dataset.</p>

},
keywords = {Feature Engineering, Interpretability, Neural Models of Source Code, Program Reduction, Transparency}
}

@software{10.5281/zenodo.5734090,
author = {Ngo, Chanh-Duc and Pastore, Fabrizio and Briand, Lionel C.},
title = {Reproduction package for "Automated, Cost-effective, and Update-driven App Testing" paper},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5734090},
abstract = {
    <p>This repository contains the replicability package for the evaluation conducted in the paper “Chanh Duc Ngo, Fabrizio Pastore, and Lionel Briand. 2021. Automated, Cost-effective, and Update-driven App Testing. ACM Trans. Softw. Eng. Methodol. Just Accepted (November 2021). https://dl.acm.org/doi/10.1145/3502297”. The most recent version of the tool can also be found at https://github.com/SNTSVV/ATUA</p>

},
keywords = {Android Testing, Model-based Testing, Regression Testing, Upgrade Testing}
}

@software{10.5281/zenodo.6480633,
author = {Lu, Yifei and Pan, Minxue and Pei, Yu and Li, Xuandong},
title = {The reproduction package for 'Detecting Resource Utilization Bugs Induced by Variant Lifecycles in Android'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6480633},
abstract = {
    <p>VALA is a static analyzer to detect resource utilization bugs in Android applications induced by variant lifecycles. The VALA artifact has three components: (1) the executable jar file with configuration files in the folder ‘bin’; (2) the benchmark including 35 apps and all the experiment results in the folder ‘BenchmarkAndResults’; (3) a ‘README.md’ and demonstration video to teacher users how to use VALA and reproduce the experiment. With the three components, users can easily reproduce the experiment and get the results claimed in our paper ‘Detecting Resource Utilization Bugs Induced by Variant Lifecycles in Android’ within around 10 minutes. If provided with APK files of other Android apps as input, VALA can also detect the resource utilization bugs induced by variant lifecycles in the apps.</p>

},
keywords = {Android applications, resource utilization bugs, static analysis, variant lifecycles}
}

@software{10.5281/zenodo.6481927,
author = {Wang, Tao and Zhang, Kangkang and Chen, Wei and Dou, Wensheng and Zhu, Jiaxin and Wei, Jun and Huang, Tao},
title = {Dataset for ISSTA'22 Understanding Device Integration Bugs in Smart Home System},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6481927},
abstract = {
    <p>This is the dataset for the ISSTA`22 submission “Understanding Device Integration Bugs in Smart Home System”. It contains 330 device integration bugs collected from the most popular open source SmartHome system, i.e., Home Assistant.</p>

},
keywords = {Home Assistant, integration bug, smart home system}
}

@software{10.5281/zenodo.6508469,
author = {Pang, Qi and Yuan, Yuanyuan and Wang, Shuai},
title = {Reproduction package for article "MDPFuzz: Testing Models Solving Markov Decision Processes"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6508469},
abstract = {
    <p>Official implementation of ISSTA 2022 paper: MDPFuzz: Testing Models Solving Markov Decision Processes.</p>

},
keywords = {Deep learning testing, Markov decision procedure}
}

@software{10.5281/zenodo.6515687,
author = {Lipp, Stephan and Banescu, Sebastian and Pretschner, Alexander},
title = {Artifacts for the ISSTA 2022 Paper: An Empirical Study on the Effectiveness of Static C Code Analyzers for Vulnerability Detection},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6515687},
abstract = {
    <p>This artifact contains the evaluation script and the corresponding data of the ISSTA’22 paper “An Empirical Study on the Effectiveness of Static C Code Analyzers for Vulnerability Detection”. It can be used to replicate the evaluation results as well as to perform further analyses on the effectiveness of static code analyzers.</p>

},
keywords = {empirical study, static code analysis, vulnerability detection}
}

@software{10.5281/zenodo.6516024,
author = {Zhong, Ziyuan and Hu, Zhisheng and Guo, Shengjian and Zhang, Xinyang and Zhong, Zhenyu and Ray, Baishakhi},
title = {AIasd/FusED},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6516024},
abstract = {
    <p>MIT License</p>
<p>Copyright (c) 2022 Ziyuan Zhong</p>
<p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p>
<p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p>
<p>THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>

},
keywords = {advanced driving assistance system, causal analysis, multi-sensor fusion, software testing}
}

@software{10.5281/zenodo.6516441,
author = {Liu, Pei and Zhao, Yanjie and Cai, Haipeng and Fazzini, Mattia and Grundy, John and Li, Li},
title = {Reproduction Packages for "Automatically Detecting API-induced Compatibility Issues in Android Apps: A Comparative Analysis (Replicability Study)"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6516441},
abstract = {
    <p>This artefact provides the experimental datasets and results presented in our paper.</p>

},
keywords = {Android, API, Compatibility Issues, Fragmentation}
}

@software{10.5281/zenodo.6517515,
author = {Chen, Weimin and Sun, Zihan and Wang, Haoyu and Luo, Xiapu and Cai, Haipeng and Wu, Lei},
title = {WASAI: Uncovering Vulnerabilities in Wasm Smart Contracts},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6517515},
abstract = {
    <p>WASAI is a concolic fuzzer for identifying vulnerabilities in Wasm smart contracts, taking EOSIO as the mainly Wasm favored blockchain. The source code is uploaded to 10.5281/zenodo.6517515.</p>

},
keywords = {concolic fuzzing, dynamic software analysis, smart contracts}
}

@software{10.5281/zenodo.6519572,
author = {Li, Yu and Chen, Muxi and Xu, Qiang},
title = {Reproduction package for article "HybridRepair: Towards Annotation-Efficient Repair for Deep Learning Models"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6519572},
abstract = {
    <p>This is an implementation of our paper “HybridRepair: Towards Annotation-Efficient Repair for Deep Learning Models”.HybridRepair is a holistic approach that combines the use of a small amount of labelled data and a large amount of unlabeled data for model repair, based on the observation that model repair requires sufficient local training data density. This artifact contains all the experiment codes in the paper.</p>

},
keywords = {deep neural networks, model repairing, model testing, semi-supervised learning}
}

@software{10.5281/zenodo.6520942,
author = {Weiss, Michael and Tonella, Paolo},
title = {Reproduction Package for Paper `Simple Techniques Work Surprisingly Well for Neural Network Test Prioritization and Active Learning (Replicability Study)`},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6520942},
abstract = {
    <p>This is the reproduction package of the paper Simple Techniques Work Surprisingly Well for Neural Network Test Prioritization and Active Learning by M.Weiss and P.Tonella, published at ISSTA 2022.</p>
<p>For uses other than reproduction, we also extracted three standalone, general-purpose artifacts: - fashion-mnist-c dataset (Github: https://github.com/testingautomated-usi/fashion-mnist-c) - text corruptor (Github: https://github.com/testingautomated-usi/corrupted-text) - tip implementations (Github: https://github.com/testingautomated-usi/dnn-tip)</p>

},
keywords = {neural networks, Test prioritization, uncertainty quantification}
}

@software{10.5281/zenodo.6529828,
author = {Andronidis, Anastasios and Cadar, Cristian},
title = {Artefact for SnapFuzz: High-Throughput Fuzzing of Network Applications},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6529828},
abstract = {
    <p>This is the artefact submitted for the SnapFuzz: High-Throughput Fuzzing of Network Applications paper. The artefact includes a README file with full details on how to run and reproduce our results.</p>
<p>A latest version can always be found in: https://github.com/srg-imperial/SnapFuzz-artefact</p>

},
keywords = {afl, aflnet, artefact, binary rewriting, fuzzing, snapfuzz}
}

@software{10.5281/zenodo.6530839,
author = {Kapugama, Charaka Geethal and Pham, Van-Thuan and Aleti, Aldeida and B\"{o}hme, Marcel},
title = {Grammar2Fix:Human-in-the-Loop Oracle Learning for Semantic Bugs in String Processing Programs},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6530839},
abstract = {
    <p>GRAMMAR2FIX is an active oracle learning technique for programs processing string inputs. Given a single failing input of a bug, it learns a grammar describing the pattern of all the failing inputs of the bug, interacting with a bug oracle systematically. GRAMMAR2FIX returns this grammar as a collection of Deterministic Finite Automata(DFA), and the grammar can serve as an automated test oracle for the bug. GRAMMAR2FIX also produces a test suite in grammar learning, which can be used as a repair test suite in Automated Program Repair.</p>

},
keywords = {Automated Test Oracle, Grammar Inference, Software Debugging}
}

@software{10.5281/zenodo.6534062,
author = {Ghaleb, Asem and Rubin, Julia and Pattabiraman, Karthik},
title = {Reproduction Package for Article 'eTainter: Detecting Gas-Related Vulnerabilities in Smart Contracts'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6534062},
abstract = {
    <p>The execution of smart contracts on the Ethereum blockchain consumes gas paid for by users submitting contracts’ invocation requests. A contract execution proceeds as long as the users dedicate enough gas for execution and the total gas for the execution is under the block gas limit set by Ethereum. Otherwise, the contract execution halts, and changes made during execution get reverted. Unfortunately, smart contracts may contain code patterns that increase their execution gas cost, causing them to run out of gas. These patterns can be manipulated by malicious attackers to induce unwanted behavior in the targeted victim contracts, e.g., Denial-of-Service (DoS) attacks. We call these gas-related vulnerabilities. The paper proposes eTainter, a static analyzer for detecting gas-related vulnerabilities based on taint tracking in the bytecode of smart contracts.</p>
<p>In this artifact, we provide the implementation of the proposed approach and the scripts to reproduce results shown in the paper. Further, we provide 3 datasets we have used in our experiments, one of the datasets is annotated dataset.</p>

},
keywords = {Ethereum, security, Solidity, taint analysis}
}

@software{10.5281/zenodo.6534173,
author = {Rak-amnouykit, Ingkarat and Milanova, Ana and Baudart, Guillaume and Hirzel, Martin and Dolby, Julian},
title = {The Raise of Machine Learning Hyperparameter Constraints in Python Code (Artifact)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6534173},
abstract = {
    <p>The artifact for the paper “The Raise of Machine Learning Hyperparameter Constraints in Python Code”.</p>

},
keywords = {interprocedural analysis, machine learning libraries, Python}
}

@software{10.5281/zenodo.6534229,
author = {Lahiri, Sumit and Roy, Subhajit},
title = {Almost Correct Invariants: Synthesizing Inductive Invariants by Fuzzing Proofs},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6534229},
abstract = {
    <p>The artifact is a tar zip file containing the README along with install script to set the tool up and other assets which have been detailed in the README file.</p>

},
keywords = {fuzzing, inductive invariant synthesis, testing, verification}
}

@software{10.5281/zenodo.6534292,
author = {Liu, Ye and Li, Yi and Lin, Shang-Wei and Artho, Cyrille},
title = {Replication Data for: Finding Permission Bugs in Smart Contracts with Role Mining},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6534292},
abstract = {
    <p>Smart contracts deployed on permissionless blockchains, such as Ethereum, are accessible to any user in a trustless environment. Therefore, most smart contract applications implement access control policies to protect their valuable assets from unauthorized accesses. A difficulty in validating the conformance to such policies, i. e., whether the contract implementation adheres to the expected behaviors, is the lack of policy specifications. In this paper, we mine past transactions of a contract to recover a likely access control model, which can then be checked against various information flow policies and identify potential bugs related to user permissions. We implement our role mining and security policy validation in tool SPCon. The experimental evaluation on labeled smart contract role mining benchmark demonstrates that SPCon effectively mines more accurate user roles compared to the state-of-the-art role mining tools. Moreover, the experimental evaluation on real-world smart contract benchmark and access control CVEs indicates SPCon effectively detects potential permission bugs while having better scalability and lower false-positive rate compared to the state-of-the-art security tools, finding 11 previously unknown bugs and detecting six CVEs that no other tool can find.</p>

},
keywords = {access control, information flow policy, role mining, Smart contract}
}

@software{10.5281/zenodo.6534329,
author = {Li, Zhiming and Xie, Xiaofei and Li, Haoliang and Xu, Zhengzi and Li, Yi and Liu, Yang},
title = {Reproduction Package for Cross-Lingual Transfer Learning for Statistical Type Inference},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6534329},
abstract = {
    <p>The artifact contains data and code for the reproduction of Cross-Lingual Transfer Learning for Statistical Type Inference.</p>

},
keywords = {Deep Learning, Transfer Learning, Type Inference}
}

@software{10.5281/zenodo.6534525,
author = {Zhou, Hao and Wu, Shuohan and Luo, Xiapu and Wang, Ting and Zhou, Yajin and Zhang, Chao and Cai, Haipeng},
title = {Artifacts for "NCScope: Hardware-Assisted Analyzer for Native Code in Android Apps"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6534525},
abstract = {
    <p>The artifacts contains the code and dataset associated with the ISSTA’22 paper “NCScope: Hardware-Assisted Analyzer for Native Code in Android Apps”.</p>

},
keywords = {Android, App Analysis, Dynamic Analysis}
}

@software{10.5281/zenodo.6534554,
author = {Kim, Myeongsoo and Xin, Qi and Sinha, Saurabh and Orso, Alessandro},
title = {Reproduction Package for Article `Automated Test Generation for REST APIs: No Time to Rest Yet`},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6534554},
abstract = {
    <p>This artifact is for reproducing the results of the article <code>Automated Test Generation for REST APIs: No Time to Rest Yet.</code> It has an automated script to run the ten state-of-the-art REST API testing tools for 20 RESTful services. Users can analyze the result using the provided script.</p>

},
keywords = {Automated software testing, RESTful APIs}
}

@software{10.5281/zenodo.6534721,
author = {Zheng, Yingying and Dou, Wensheng and Wang, Yicheng and Qin, Zheng and Tang, Lei and Gao, Yu and Wang, Dong and Wang, Wei and Wei, Jun},
title = {ISSTA 22 Artifact for "Finding Bugs in Gremlin-Based Graph Database Systems via Randomized Differential Testing"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6534721},
abstract = {
    <p>Grand is a tool for finding logic bugs in Gremlin-Based Graph Database Systems (GDBs). We refer to logic bugs as those bugs that GDBs return an unexpected result (e.g., incorrect query result or unexpected error) without crashing the GDBs for a given query.</p>
<p>Grand operates in the following three phases: 1. Graph database generation: The goal of this phase is to generate a populated graph database for each target GDB. Specially, Grand first randomly generates the graph schema to define the types of vertices and edges. Then, the detailed vertices and edges can be randomly generated according to the generated graph schema. Finally, the generated database will be written into target GDBs. 2. Gremlin query generation: This phase is aimed to generate syntactically correct and valid Gremlin queries. We first construct a traversal model for Gremlin APIs, and then generate Gremlin queries based on the constructed traversal model. 3. Differential Testing: Grand executes the generated Gremlin queries and validates the query results by differential testing.</p>

},
keywords = {differential testing, Graph database systems, Gremlin}
}

@software{10.5281/zenodo.6534755,
author = {Yang, Shuaihao and Zeng, Zigang and Song, Wei},
title = {Reproduction package for Article `PermDroid: Automatically Testing Permission-Related Behaviour of Android Applications'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6534755},
abstract = {
    <p>We propose PermDroid, an automatic testing method and open-source tool to testing permission-related behavior of Android apps. For more information, please read the readme file in the zip file uploaded.</p>

},
keywords = {Android, dynamic permission model, permission combinations, software testing, static analysis}
}

@software{10.5281/zenodo.6534803,
author = {Huang, Pei and Yang, Yuting and Liu, Minghao and Jia, Fuqi and Ma, Feifei and Zhang, Jian},
title = {Reproduction Package for Article "ε-Weakened Robustness of Deep Neural Networks"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6534803},
abstract = {
    <p>The artifact is used for reproducing the experimental results in the article “ε-Weakened Robustness of Deep Neural Networks”, including the attack algorithm PGD, robustness enhancement algorithm FPP, ε-Weakened robustness evaluation and decision algorithms (EWRE and EWRD) for several neural networks (resnet18, densenet121, dpn92, regnetx_200, etc.)</p>

},
keywords = {adversarial attack, neural networks, robustness, testing}
}

@software{10.5281/zenodo.6535073,
author = {Guo, Wunan and Dong, Zhen and Shen, Liwei and Tian, Wei and Su, Ting and Peng, Xin},
title = {Reproduction Package for Article 'Detecting and Fixing Data Loss Issues in Android Apps'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6535073},
abstract = {
    <p>This tool(iFixDataloss) consists of three components: static analyzer, dynamic explorer and patch generator. It works as follows: In the first step, iFixDataloss uses the static analyzer to build an activity transition graph and get persistent data for the app under test; In the second step, iFixDataloss runs dynamic explorer to detect data loss issues in the app. The relevant data for the data loss issue is stored in a database. Lastly, iFixDataloss takes the source code of the app and the data obtained in the dynamic exploration to generate a patch.</p>

},
keywords = {dynamic analysis, mobile testing, patching}
}

@software{10.5281/zenodo.6535361,
author = {Zheng, Yaowen and Li, Yuekang and Zhang, Cen and Zhu, Hongsong and Liu, Yang and Sun, Limin},
title = {Reproduction Package for 'Efficient Greybox Fuzzing of Applications in Linux-Based IoT Devices via Enhanced User-Mode Emulation'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6535361},
abstract = {
    <p>To easily use our prototype, you can follow the README.md to run the docker images and perform the testing. Source code is also included in EQUAFL_code.zip, so that others can extend it for further research.</p>

},
keywords = {Enhanced User-mode Emulation, Greybox Fuzzing, Linux-based IoT Devices}
}

@software{10.5281/zenodo.6535525,
author = {Song, Xuezhi and Lin, Yun and Ng, Siang Hwee and Wu, Yijian and Peng, Xin and Dong, Jin Song and Mei, Hong},
title = {RegMiner: Towards Constructing Large Regression Dataset from Code Evolution History},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6535525},
abstract = {
    <p>Bug datasets lay significant empirical and experimental foundation for various SE/PL researches such as fault localization, software testing, and program repair. All well-known datasets are constructed manually, which inevitably limits their scalability, representativeness, and the support for the emerging data-driven research. In this work, we propose an approach to automate the process of harvesting replicable regression bugs from the code evolution history. We focus on regression bugs, as they (1) manifest how a bug is introduced and fixed (as non-regression bugs), (2) support regression bug analysis, and (3) incorporate a much stronger specification (i.e., the original passing version) than non-regression bug dataset for bug analysis. Technically, we address an information retrieval problem on code evolution history. Given a code repository, we search for regressions where a test can pass a regression-fixing commit, fail a regression-inducing commit, and pass a previous working commit. In this work, we address the challenges of (1) identifying potential regression-fixing commits from the code evolution history, (2) migrating the test and its code dependencies over the history, and (3) minimizing the compilation overhead during the regression search. We build our tool, RegMiner, which harvested 1035 regressions over 147 projects for 8 weeks, creating the largest replicable regression dataset within the shortest period, to the best of our knowledge. Our extensive experiments show that (1) RegMiner can construct the regression dataset with very high precision and acceptable recall, and (2) the constructed regression dataset is of high authenticity and diversity. We foresee that a continuously growing regression dataset opens many data-driven research opportunities in the SE/PL communities.</p>

},
keywords = {bug collection, mining code repository, regression bug}
}

@software{10.5281/zenodo.6535557,
author = {Zhang, Yuntong and Gao, Xiang and Duck, Gregory J. and Roychoudhury, Abhik},
title = {Reproduction Package for Article `Program Vulnerability Repair via Inductive Inference'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6535557},
abstract = {
    <p>Contains source code, experimental subjects, and instructions to reproduce main results for the article `Program Vulnerability Repair via Inductive Inference’.</p>

},
keywords = {Automated program repair, Inductive inference, Snapshot fuzzing}
}

@software{10.5281/zenodo.6539575,
author = {Busse, Frank and Gharat, Pritam and Cadar, Cristian and Donaldson, Alastair F.},
title = {Artefact for the ISSTA 2022 Paper: "Combining Static Analysis Error Traces with Dynamic Symbolic Execution (Experience Paper)"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6539575},
abstract = {
    <p>The artefact provides a Docker image that contains the source code and binaries of our instrumentation/bug injection tools and KLEE extension, all benchmarks with their bitcode files, scripts to reproduce our experiments, and the static analysis reports for investigated real-world applications.</p>

},
keywords = {Clang Static Analyzer, Infer, KLEE, software testing, static analysis, symbolic execution}
}

@software{10.5281/zenodo.6564504,
author = {Perretta, James and DeOrio, Andrew and Guha, Arjun and Bell, Jonathan},
title = {Artifact for "On the Use of Mutation Analysis For Evaluating Student Test Suite Quality"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6564504},
abstract = {
    <p>Contains data and analysis scripts accompanying the paper “On the Use of Mutation Analysis For Evaluating Student Test Suite Quality.”</p>

},
keywords = {mutation analysis, testing, testing education}
}

@software{10.5281/zenodo.6575363,
author = {An, Gabin and Yoo, Shin},
title = {Replication Package for Article: "FDG: A Precise Measurement of Fault Diagnosability Gain of Test Cases"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6575363},
abstract = {
    <p>This artifact contains a replication package for the paper “FDG: A Precise Measurement of Fault Diagnosability Gain of Test Cases”. It provides the scripts and documents to replicate the experiment described in the paper. The detailed guide to replication is provided in the artifact’s README.md file.</p>

},
keywords = {fault diagnosability, fault localisation, test augmentation, test generation}
}

@software{10.5281/zenodo.6579248,
author = {Kim, Geunwoo and Hong, Sanghyun and Franz, Michael and Song, Dokyung},
title = {XBA},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6579248},
abstract = {
    <p>XBA is a deep learning tool for generating platform-agnostic binary code embeddings. XBA applies Graph Convolutional Network (GCN) on the graph representation of binary which we call Binary Disassembly Graph (BDG). XBA can learn semantic matchings of binary code compiled for different platforms that are not included in the training dataset. It outperformed prior works in aligning binary code blocks for different platforms, which shows the embeddings generated by XBA indeed are useful in the cross binary analysis. XBA is implemented with Python v3.8 and Tensorflow v2.7.0.</p>

},
keywords = {Binary analysis, Cross-platform, Graph alignment}
}

@software{10.1145/3550215,
author = {Kelly, Terence},
title = {Source code for the article "Efficient Graph Search"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3550215},
abstract = {
    <p>The run.csh script compiles two random graph generators and two variants of the BFS implementation, then the script runs experiments. I recommend running the script twice: once to bring your computer up to normal operating temperature and a second time to gather performance results.  Some modern computers may throttle back CPU performance when intensive computations cause them to overheat, so we want to measure performance with the machine in a warm steady state rather than under cold-start conditions.</p>
}
}

@software{10.5281/zenodo.6651953,
author = {Nguyen, Minh and Perera, Roly and Wang, Meng and Wu, Nicolas},
title = {Reproduction Package for Article: Modular Probabilistic Models via Algebraic Effects},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6651953},
abstract = {
    <p>This is the artifact for the probabilistic programming language ProbFX as described in the paper “Modular Probabilistic Models via Algebraic Effects”.</p>
<p>It contains:</p>
<ol type="1">
<li><p>A preprint of the paper “Modular Probabilistic Models via Algebraic Effects”.</p></li>
<li><p>A virtual image prepared with an executable script for running and visualising the example programs shown in the paper (and more).</p></li>
<li><p>The documented source code for the language implementation and example programs.</p></li>
</ol>

},
keywords = {effect handlers, embedded domain-specific languages, functional programming, modularity, probabilistic programming}
}

@software{10.5281/zenodo.6668446,
author = {Koppel, James and Guo, Zheng and de Vries, Edsko and Solar-Lezama, Armando and Polikarpova, Nadia},
title = {Artifact for "Searching Entangled Program Spaces"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6668446},
abstract = {
    <p>This artifact is to reproduce results reported in the paper “Searching Entangled Program Spaces”. It includes a virtual machine in <code>ecta-artifact.tar</code> and the source code in <code>icfp-artifact-source-code.*</code>. Run the virtual machine with the script <code>start.sh</code> and there is a README file inside, which tells you how to run the commands and reproduce our figures.</p>

},
keywords = {synthesis, tree automata}
}

@software{10.5281/zenodo.6671887,
author = {Westrick, Sam and Arora, Jatin and Acar, Umut A.},
title = {Entanglement Detection With Near-Zero Cost: Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6671887},
abstract = {
    <p>This artifact provides code and scripts for reproducing the empirical evaluation in the paper “Entanglement Detection with Near-Zero Cost” at ICFP’22. Running these experiments requires access to a modern multi-core x86_64 machine. The experiments in the paper use up to 72 cores and 110GB RAM, but partial results can be obtained using a smaller machine. In particular, 8 cores and 8 GB RAM is sufficient for a small set of experiments. A full set of experiments requires 110 GB RAM and a decent number of cores (preferably at least 32 cores).</p>

},
keywords = {disentanglement, functional programming, memory management, parallelism}
}

@software{10.5281/zenodo.6672939,
author = {Ho, Son and Protzenko, Jonathan},
title = {Aeneas: Rust Verification by Functional Translation},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6672939},
abstract = {
    <p>We present Aeneas, a new verification toolchain for Rust programs based on a lightweight functional translation. We leverage Rust’s rich region-based type system to eliminate memory reasoning for a large class of Rust programs, as long as they do not rely on interior mutability or unsafe code. Doing so, we relieve the proof engineer of the burden of memory-based reasoning, allowing them to instead focus on functional properties of their code.</p>
<p>The first contribution of Aeneas is a new approach to borrows and controlled aliasing. We propose a pure, functional semantics for LLBC, a Low-Level Borrow Calculus that captures a large subset of Rust programs. Our semantics is value-based, meaning there is no notion of memory, addresses or pointer arithmetic. Our semantics is also ownership-centric, meaning that we enforce soundness of borrows via a semantic criterion based on loans rather than through a syntactic type-based lifetime discipline. We claim that our semantics captures the essence of the borrow mechanism rather than its current implementation in the Rust compiler.</p>
<p>The second contribution of Aeneas is a translation from LLBC to a pure lambda-calculus. This allows the user to reason about the original Rust program through the theorem prover of their choice, and fulfills our promise of enabling lightweight verification of Rust programs. To deal with the well-known technical difficulty of terminating a borrow, we rely on a novel approach, in which we approximate the borrow graph in the presence of function calls. This in turn allows us to perform the translation using a new technical device called backward functions.</p>
<p>We implement our toolchain in a mixture of Rust and OCaml; our chief case study is a low-level, resizing hash table, for which we prove functional correctness, the first such result in Rust. Our evaluation shows significant gains of verification productivity for the programmer. This paper therefore establishes a new point in the design space of Rust verification toolchains, one that aims to verify Rust programs simply, and at scale.</p>
<p>Rust goes to great lengths to enforce static control of aliasing; the proof engineer should not waste any time on memory reasoning when so much already comes “for free”!</p>

},
keywords = {program verification, rust}
}

@software{10.5281/zenodo.6678339,
author = {Li, Yao and Weirich, Stephanie},
title = {Program Adverbs and Tl\"{o}n Embeddings (Artifact)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6678339},
abstract = {
    <p>This artifact contains the Coq formalization of the paper Program Adverbs and Tl\"{o}n Embeddings. It contains a Coq implementation of all the key definitions, theorems and proofs, as well as examples described in the paper.</p>

},
keywords = {Coq, embedding, formal verification, mechanized reasoning, program adverbs}
}

@software{10.5281/zenodo.6684085,
author = {Ullrich, Sebastian and de Moura, Leonardo},
title = {Supplement of "'do' Unchained: Embracing Local Imperativity in a Purely Functional Language"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6684085},
abstract = {
    <p>This supplement consists of a Lean 4 package containing translation rules and example proofs of equivalence as described in the paper. Each extension is declared in a separate <code>.lean</code> file in the <code>Do</code> directory. <code>Do/Formal.lean</code> contains the formalization of the equivalence proof written in a literate style explaining more details not mentioned in the paper. Each Lean file comes with a corresponding <code>.html</code> file rendered using Alectryon that allows for exploring the file including type and goal information in any browser without installing Lean. The directory <code>gh-survey</code> contains simple scripts for aggregating the use of extended <code>do</code> notation from Lean projects on GitHub.</p>

},
keywords = {formal verification, Lean, macros}
}

