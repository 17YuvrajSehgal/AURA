@software{10.5281/zenodo.13365896,
author = {Riouak, Idriss and Fors, Niklas and \"{O}qvist, Jesper and Hedin, G\"{o}rel and Reichenbach, Christoph},
title = {Efficient Demand Evaluation of Fixed-Point Attributes Using Static Analysis (Artifact)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13365896},
abstract = {
    <p>This is the software artifact for the paper “Efficient Demand
Evaluation of Fixed-Point Attributes Using Static Analysis” published in
SLE 2024. This artifact supports the evaluation of a new demand-driven
algorithm for efficient circular Reference Attribute Grammar evaluation,
specifically designed to improve performance of higly circular
applications, e.g., dataflow analyses for Java. The artifact includes
all necessary tools, dependencies, benchmarks, and scripts to reproduce
the experiments presented in the corresponding paper. It provides a
Docker-based setup for easy deployment, as well as detailed instructions
for manual installation. The artifact allows users to explore and
validate the proposed algorithm’s performance improvements through
real-world case studies, demonstrating significant speedups in
dead-assignment and null-pointer dereference analyses compared to
existing algorithms. While the artifact does not require specific
hardware, reproducing the experiments as described in the paper may take
one to two days of computation time. The artifact has been tested on
Linux and macOS systems.</p>

},
keywords = {Attribute Grammars, Circular Attributes, Demand Analysis, Fixpoint Computations, Static Analysis}
}

@software{10.5281/zenodo.13643574,
author = {Gao, Cunyuan and Parreaux, Lionel},
title = {Implementation for Seamless Scope-Safe Metaprogramming through Polymorphic Subtype Inference (Short Paper)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13643574},
abstract = {
    <p>Our artifact implements the quasiquote syntax, type inference
algorithm, and code generation on the MLscript compiler. The artifact
consists of two parts:</p>
<ul>
<li>The main project is written in Scala and powered by sbt, which
includes the original MLscript compiler, our implementation, and
corresponding test cases for quasiquote;</li>
<li>The web demo allows users to compile and run general MLscript with
our quasiquote system programs directly in browsers and check type
inference and execution results.</li>
</ul>
<p>Our quasiquote system is implemented in the main project, on which
the web demo is based.</p>

},
keywords = {First-Class Polymorphism, Metaprogramming, MLscript, Type Inference}
}

@software{10.5281/zenodo.13741142,
author = {Miljak, Luka and Bach Poulsen, Casper and Corvino, Rosilde},
title = {Concrete Syntax Metapatterns - Artifact},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13741142},
abstract = {
    <p>Software artifact pertaining to the paper “Concrete Syntax
Metapatterns.” The artifact contains a Virtual Machine for running the
CSMP Kotlin library, examples, and performance tests described in the
Implementation/Evaluation and Discussion sections of the paper. The
artifact also contains the source code and instructions for running it
outside the VM.</p>

},
keywords = {black-box parsers, concrete syntax, metaprogramming, refactoring, restructuring}
}

@software{10.5281/zenodo.13801418,
author = {Zhang, Yilin and Dhawal, Omkar Dilip and Nandivada, V. Krishna and Chiba, Shigeru and Ugawa, Tomoharu},
title = {Artifact for Reducing Write Barrier Overheads for Orthogonal Persistence},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13801418},
abstract = {
    <p>This is the artifact for the paper “Reducing Write Barrier Overheads
for Orthogonal Persistence” accepted by the ACM SIGPLAN International
Conference on Software Language Engineering (SLE) 2024. The goal of this
artifact is to reproduce the experimentation shown in the paper.</p>

},
keywords = {Concurrency, Escape Analysis, Memory Management, Non-Volatile Memory, Orthogonal Persistence}
}

@software{10.5281/zenodo.13814132,
author = {Hu, Yuefeng and Ishibe, Hiromu and Dai, Feng and Yamazaki, Tetsuro and Chiba, Shigeru},
title = {Artifact - Bugfox: A Trace-based Analyzer for Localizing the Cause of Software Regression in JavaScript},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13814132},
abstract = {
    <p>All the programs and dataset to reproduce the evaluation presented in
the corresponding paper.</p>

},
keywords = {Code Transformation, Debugging, Regression, Runtime Tracing}
}

@software{10.5281/zenodo.13832238,
author = {Caylak, Gizem and Lund\'{e}n, Daniel and Senderov, Viktor and Broman, David},
title = {Reproduction package for Article “ Statically and Dynamically Delayed Sampling for Typed Probabilistic Programming Languages”},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13832238},
abstract = {
    <p>The artifact contains a Docker image (delayed.tar.gz) including
everything needed to run the benchmarks and produce the results
presented in the paper. The artifact also includes the Dockerfile used
to create the Docker image.</p>

},
keywords = {delayed, docker, Results, sampling}
}

@software{10.5281/zenodo.13851394,
author = {Huberdeau, Laurent and Hamel, Cassandre and Monnier, Stefan and Feeley, Marc},
title = {Pnut: A C Transpiler Targeting POSIX Shell},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13851394},
abstract = {
    <p>This is the artifact accompanying our paper “The Design of a
Self-Compiling C Transpiler Targeting POSIX Shell”, accepted for
presentation at the ACM SIGPLAN International Conference on Software
Language Engineering (SLE) 2024. For ease of evaluation, the artifact
includes a Docker image containing the project source code, the
dependencies and shells that can run the scripts produced by our
transpiler, and the scripts used to obtain the results presented in the
paper. Some code examples to demonstrate the usage of the transpiler are
also included.</p>

},
keywords = {Bootstrapping, Compiler, Reproducible Builds}
}

@software{10.5281/zenodo.12552491,
author = {Lin, Zhengyao and Gancher, Joshua and Parno, Bryan},
title = {FlowCert: Translation Validation for Asynchronous Dataflow Programs via Dynamic Fractional Permissions},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12552491},
abstract = {
    <p>Implementation of FlowCert and evaluation data packaged in a Docker
image.</p>

},
keywords = {Asynchronous Dataflow, Coarse-Grained Reconfigurable Arrays, Translation Validation}
}

@software{10.5281/zenodo.12604575,
author = {Le, Callista and Gopinathan, Kiran and Lee, Koon Wen and Gilbert, Seth and Sergey, Ilya},
title = {OBatcher: Implementation, Data Structures, and Experiments (OOPSLA'24 Artefact) Creators},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12604575},
abstract = {
    <p>This release snapshots the functionality of the submitted artefact
for the OBatcher framework and data structures described in the OOPSLA
24 paper “Concurrent Data Structures Made Easy”:</p>
<ul>
<li><p>Docker file with reproducible build environment</p></li>
<li><p>Readme with getting started and step-by-step
instructions</p></li>
<li><p>Source code and build files for OBatcher</p></li>
<li><p>Instantiation of the OBatcher framework in Rust</p></li>
<li><p>Benchmark code and scripts to reproduce the 33 graphs presented
in the paper</p></li>
</ul>

},
keywords = {batched data structures, batching, concurrency, OCaml, programming languages, Rust}
}

@software{10.5281/zenodo.12627576,
author = {Nagy, Shaan and Kim, Jinwoo and Reps, Thomas and D’Antoni, Loris},
title = {Wuldo Unrealizability Logic Proof Synthesizer},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12627576},
abstract = {
    <p>Automated verification of all members of a (potentially infinite) set
of programs has the potential to be useful in program synthesis, as well
as in verification of dynamically loaded code, concurrent code, and
language properties. Existing techniques for verification of sets of
programs are limited in scope and unable to create or use interpretable
or reusable information about sets of programs. The consequence is that
one cannot learn anything from one verification problem that can be used
in another. Unrealizability logic (UL), proposed by Kim et al.&nbsp;as the
first Hoare-style proof system to prove properties over sets of programs
(defined by a regular tree grammar), presents a theoretical framework
that can express and use reusable insight. In particular, UL features
nonterminal summaries—inductive facts that characterize recursive
nonterminals (analogous to procedure summaries in Hoare logic). In this
work, we design the first UL proof synthesis algorithm, implemented as
Wuldo. Specifically, we decouple the problem of deciding how to apply UL
rules from the problem of synthesizing/checking nonterminal summaries by
computing proof structure in a fully syntax-directed fashion. We show
that Wuldo, when provided nonterminal summaries, can express and prove
verification problems beyond the reach of existing tools, including
establishing how infinitely many programs behave on infinitely many
inputs. In some cases, Wuldo can even synthesize the necessary
nonterminal summaries. Moreover, Wuldo can reuse previously proven
nonterminal summaries across verification queries, making verification
1.96 times as fast as when summaries are instead proven from
scratch.</p>

},
keywords = {automated reasoning, infinite sets of programs, Unrealizability logic}
}

@software{10.5281/zenodo.12637589,
author = {Raad, Azalea and Vanegue, Julien and O’Hearn, Peter},
title = {Non Termination Proving At Scale: Artifact (Pulse Infinite)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12637589},
abstract = {
    <p>This package contains the Pulse-Infinite project source code
distributed as part of the Infer framework as of 7/6/24.</p>
<p>For the most recent version of Pulse-Infinite, please consult:
https://github.com/jvanegue/infer/</p>

},
keywords = {incorrectness, infer, logic, separation, termination}
}

@software{10.5281/zenodo.12654518,
author = {Torczon, Cassia and Su\'{a}rez Acevedo, Emmanuel and Agrawal, Shubh and Velez-Ginorio, Joey and Weirich, Stephanie},
title = {Artifact Associated with "Effects and Coeffects in Call-by-Push-Value"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12654518},
abstract = {
    <p>Coq mechanization of definitions and theorems</p>

},
keywords = {CBPV, Coeffects, Coq, Effects}
}

@software{10.5281/zenodo.12659527,
author = {Haselwarter, Philipp G. and Li, Kwing Hei and de Medeiros, Markus and Gregersen, Simon Oddershede and Aguirre, Alejandro and Tassarotti, Joseph and Birkedal, Lars},
title = {Tachis: Higher-Order Separation Logic with Credits for Expected Costs - Coq Artifact},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12659527},
abstract = {
    <p>Formalization of the results of the paper “Tachis: Higher-Order
Separation Logic with Credits for Expected Costs” in the Coq proof
assistant.</p>

},
keywords = {expected time complexity, probabilistic programs, resource analysis}
}

@software{10.5281/zenodo.12666682,
author = {Liew, Dennis and Cogumbreiro, Tiago and Lange, Julien},
title = {Sound and partially-complete static analysis of data-races in GPU programs (Artifact)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12666682},
abstract = {
    <p>An artifact with all the tools and datasets presented in Section 6,
and mechanized proofs of the theoretical results mentioned in Section
4.4.</p>

},
keywords = {data-race detection, GPU programming, static analysis, true positives}
}

@software{10.5281/zenodo.12668895,
author = {Drosos, Georgios-Petros and Sotiropoulos, Thodoris and Alexopoulos, Georgios and Mitropoulos, Dimitris and Su, Zhendong},
title = {Reproduction Package for Article: "When Your Infrastructure Is a Buggy Program: Understanding Faults in Infrastructure as Code Ecosystems},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12668895},
abstract = {
    <p>The purpose of this artifact is (1) to reproduce the results
presented in the OOPSLA 2024 paper titled “When Your Infrastructure Is a
Buggy Program: Understanding Faults in Infrastructure as Code
Ecosystems”, and (2) to document the dataset and the proposed
categorization in order to facilitate further research. Specifically,
the artifact has the following structure:</p>
<ul>
<li><code>scripts/</code>: This directory contains the scripts necessary
to replicate the findings, figures, and tables introduced in our
study.</li>
<li><code>scripts/fetch/</code>: This directory contains the scripts
required to assemble the dataset of IaC bugs as outlined in Section 3.1
of our study (i.e., this directory includes the code for our repository
collection gathering and bug collection stages).</li>
<li><code>data/</code>: This directory contains the initial bug dataset
of the data collection phase as well as the “pre-baked” dataset of the
360 IaC bugs under study.</li>
<li><code>figures/</code>: A directory which is going to store the
produced paper figures.</li>
<li><code>requirements.txt</code>: A textual file declaring the required
PyPI libraries to run our analysis.</li>
</ul>

},
keywords = {Ansible, bug, Chef, deployment, IaC, infrastructure as code, Puppet}
}

@software{10.5281/zenodo.12669479,
author = {Blinn, Andrew and Li, Xiang and Kim, June Hyung and Omar, Cyrus},
title = {Artifact for Statically Contextualizing Large Language Models with Typed Holes},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12669479},
abstract = {
    <p>Artifact for the paper ‘Artifact for Statically Contextualizing Large
Language Models with Typed Holes’, to be published at OOPSLA2024. The
artifact consists of raw data from the experiments, the testing harness
used, the source for the Hazel Editor and Langauge Server, and a copy of
the StarCoder2 LLM weights. The archive is password protected to prevent
the benchmark data set from being automatically scrapped; see the Zenodo
description for the password.</p>

},
keywords = {Large Language Models, Program Synthesis, Programming Languages, Types}
}

@software{10.5281/zenodo.12669572,
author = {Pham, Long and Wang, Di and Saad, Feras A. and Hoffmann, Jan},
title = {Artifact for Programmable MCMC with Soundly Composed Guide Programs},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12669572},
abstract = {
    <p>In probabilistic programming with a newly proposed coroutine-based
programmable inference framework, the user provides (i) a model
coroutine and (ii) a sequential composition of guide coroutines. The
model coroutine specifies a probabilistic model for Bayesian inference.
Meanwhile, the sequential composition of guide coroutines customizes the
Block Metropolis-Hastings (BMH) algorithm, where we successively run the
guide coroutines, each of which is followed by an MH acceptance routine.
Each guide coroutine only updates a subset (i.e., block) of random
variables. The model and guide coroutines communicate with one another
by message passing, and their communication protocols are described by
guide types.</p>
<p>This artifact is a program analysis tool for statically checking the
soundness of a probabilistic program in this coroutine-based framework.
The artifact offers three functionalities: - Type-equality checking:
check structural type equality of guide types. - Type inference: infer
guide types of model and guide coroutines (using the first functionality
for structural-type-equality checking) - Coverage checking: check
whether the support of sequentially composed guide coroutines coincides
with the support of a model coroutine.</p>

},
keywords = {Bayesian inference, context-free types, coroutines, probabilistic programming, type systems}
}

@software{10.5281/zenodo.12669638,
author = {Zhang, Chengyu and Su, Zhendong},
title = {SMT2Test: From SMT Formulas to Effective Test Cases},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12669638},
abstract = {
    <p>The main focus of this artifact is to help people 1) validate the
functionality of the bugfinding tool SMT2Test, 2) check the bug
triggering test cases reported in the paper, 3) reproduce the
performance evaluation. This artifact includes the implementation of
SMT2Test, bug-triggering test cases, seed formulas, and scripts for
reproducing the experiments.</p>

},
keywords = {program verification, SMT solving, software testing}
}

@software{10.5281/zenodo.12669773,
author = {Johnson, Keith J.C. and Krishnan, Rahul and Reps, Thomas and D’Antoni, Loris},
title = {Automating Pruning in Top-Down Enumeration for Program Synthesis Problems with Monotonic Semantics},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12669773},
abstract = {
    <p>This is the artifact submission for OOPSLA’24 (R2) submission #377:
Automating Pruning in Top-Down Enumeration for Program Synthesis
Problems with Monotonic Semantics</p>

},
keywords = {abstract interpretation, grammar flow analysis, program synthesis}
}

@software{10.5281/zenodo.12669929,
author = {Zhou, Litao and Wan, Qianyong and Oliveira, Bruno C. d. S.},
title = {Artifact for "Full Iso-Recursive Types"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12669929},
abstract = {
    <p>This artifact accompanies the OOPSLA’24 paper titled Full
Iso-recursive Types. It provides the Coq formalization of the proofs
discussed in the paper, including a pre-configured Docker image for easy
verification and the original source code for those who wish to build
the proofs manually. The artifact includes all necessary scripts, proof
files, and dependencies to reproduce the results presented in the paper,
with a focus on the formalization of iso-recursive types and their
extensions.</p>

},
keywords = {Coq, Mechanized Proof, Recursive types, Subtyping, Type system}
}

@software{10.5281/zenodo.12670476,
author = {Reitz, Antonin and Fromherz, Aymeric and Protzenko, Jonathan},
title = {Artifact for OOPSLA 2024 paper: StarMalloc: Verifying a Modern, Hardened Memory Allocator},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12670476},
abstract = {
    <p>This is the artifact for the OOPSLA 2024 paper: StarMalloc: Verifying
a Modern, Hardened Memory Allocator. It includes the F* sources for
StarMalloc, the generated C code, and the experimental setup to
reproduce experiments presented in the paper.</p>

},
keywords = {Formal Verification, Memory Allocators, Separation Logic}
}

@software{10.5281/zenodo.12670660,
author = {Wang, Qian and Jung, Ralf},
title = {Reproduction Image for Article 'Rustlantis: Randomized Differential Testing of the Rust Compiler'},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12670660},
abstract = {
    <p>Docker image to reproduce evaluations in OOPSLA 2024 paper
Rustlantis: Randomized Differential Testing of the Rust Compiler.</p>

},
keywords = {Compiler testing, Differential fuzzing, Rust}
}

@software{10.5281/zenodo.12671562,
author = {Dardinier, Thibault and Li, Anqi and M\"{u}ller, Peter},
title = {Hypra: A Deductive Program Verifier for Hyperproperties (artifact)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12671562},
abstract = {
    <p>This artifact consists of: - Our tool Hypra. - Our evaluation, with
instructions to replicate it. - An Isabelle/HOL proof of the soundness
of the novel loop rule described in section 4.2 (Theorem 1), as well as
Lemma 1.</p>
<p>The artifact is a VirtualBox VM image with Ubuntu 24.04 LTS that
contains our tool Hypra, all benchmarks used in our evaluation, Isabelle
2024, and our Isabelle/HOL formalization. It uses 8GB of RAM and two
cores by default.</p>

},
keywords = {automated reasoning, deductive verification, hyperproperties, incorrectness logic}
}

@software{10.5281/zenodo.12671619,
author = {Zhou, Chijin and Qian, Bingzhou and Go, Gwihwan and Zhang, Quan and Li, Shanshan and Jiang, Yu},
title = {PolyJuice: Detecting Mis-Compilation Bugs in Tensor Compilers with Equality Saturation Based Rewriting},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12671619},
abstract = {
    <p>This is the artifact for “PolyJuice: Detecting Mis-Compilation Bugs
in Tensor Compilers with Equality Saturation Based Rewriting”, published
in SPLASH/OOPSLA 2024. Reproducibility instructions can be found in the
“oopsla24-polyjuice-artifact.pdf” file.</p>

},
keywords = {Equality Saturation, Fuzzing, ML System, Tensor Compiler Testing}
}

@software{10.5281/zenodo.12775308,
author = {Schenck, Robert and Hinnerskov, Nikolaj Hey and Henriksen, Troels and Madsen, Magnus and Elsman, Martin},
title = {futhark-oopsla24},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12775308},
abstract = {
    <p>Artifact for the paper AUTOMAP: Inferring Rank-Polymorphic Function
Applications with Integer Linear Programming submitted to OOPSLA 24.</p>

},
keywords = {array programming, constraint-based type systems, data parallelism}
}

@software{10.5281/zenodo.12785373,
author = {Campbell, Eric Hayden and Hojjat, Hossein and Foster, Nate},
title = {Capisce Source Code for paper ``Computing Precise Control Interface Specifications''},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12785373},
abstract = {
    <h2 id="capisce">Capisce</h2>
<p>Capisce is described in the OOPSLA paper entitled <em>Computing
Precise Control Interface Specifications</em>.</p>
<p>The Capisce library comprises two key pieces:</p>
<ul>
<li><p>an OCAML library for writing down and specifying data plane
programs called <code>GPL</code>.</p>
<ul>
<li><p>Example programs can be seen in the
<code>capisce/programs</code>.</p></li>
<li><p>The core interface for writing programs can be found in
<code>capisce/lib/ASTs.ml</code>.</p></li>
</ul></li>
<li><p>an instrumentation algorithm to translate <code>GPL</code>
programs into programs in the guarded command language</p>
<ul>
<li>the instrumentation algorithm <code>GPL.encode_tables</code> van be
found in <code>capisce/lib/AST.ml</code></li>
</ul></li>
<li><p>an inference algorithm to infer control interface specifications
for data plane programs</p>
<ul>
<li>The core algorithm (<code>cegqe</code>) can be found in
<code>capisce/lib/Qe.ml</code>.</li>
</ul></li>
</ul>
<p>Here we list the claims in the paper and how they are supported by
the artifact:</p>
<ol type="1">
<li><p><em>Capisce compute control interface specifications for real
programs.</em> This artifact supports this via its survey of real world
programs that have been implemented in our library. We have provided
scripts to automatically generate the tex for Figures 5 and 6 from the
paper.</p></li>
<li><p><em>A small proportion of paths suffice to compute control
interface specifications for real programs</em>. This can be seen in the
final column of Figures 5 and 6, as well as qualitatively in Figure 7.
We have provided scripts to automatically generate the graphs in Figure
7.</p></li>
</ol>
<h3 id="hardware-dependencies">Hardware Dependencies</h3>
<p>We ran our experiments on an Ubuntu 22.04.4 server with the following
specs: - CPU: Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz - RAM: 0.5
TB</p>
<h3 id="getting-started">Getting started</h3>
<p>There are two ways to get started with Docker: using Docker, and
building from source. We have tested <code>Capisce</code> on Ubuntu
20.04 and 22.04. We recommend using docker to get started quickly.</p>
<p>Either way, the first step is to download the source code, by either
cloning the repository using git, or unpacking the downloaded .zip file.
Then change into the newly created directory. For instance:</p>
<pre><code>git clone https://github.com/cornell-netlab/capisce.git
cd capisce</code></pre>
<h4 id="docker">Docker</h4>
<p>The easiest way to get Capisce running is using Docker.</p>
<ul>
<li>First install Docker.</li>
<li>Finally, <code>build</code> and <code>run</code> the docker
image</li>
</ul>
<pre><code>docker build -t capisce .
docker run -it capisce</code></pre>
<p>Once this succeeds (it may take a while), you should be greeted with
a shell prompt similar to the following:</p>
<pre><code>opam@1497723f4b4d:~/capisce/capisce$</code></pre>
<p>Now to build Capisce, run <code>make</code>.</p>
<p>Verify your build by running <code>./capisce exp -help</code></p>
<h6 id="known-issue">Known Issue</h6>
<p>On M1 Macs there may be an issue regarding the a missing
<code>/lib64/ld-linux-x86-64.so.2</code> file. If you get such an error
try building with the flag <code>--platform linux/amd64</code></p>
<h4 id="installing-from-source">Installing from source</h4>
<p>Capiscelib is an ocaml library, so we first need to install
<code>opam</code>. Then, <code>switch</code> to the supported ocaml
compiler version</p>
<pre><code>opam switch create 4.14.0
eval $(opam env)</code></pre>
<p>Now install some basic ocaml tooling</p>
<pre><code>opam install dune
opam install menhir
opam install utop</code></pre>
<p>As well as a system dependency:</p>
<pre><code>sudo apt install libgmp-dev -y</code></pre>
<p>Now, change into the nested <code>capisce</code> directory
(i.e.&nbsp;<code>/path/to/repo/capisce/capisce</code>), and install the
dependencies in the <code>capisce.opam</code> file:</p>
<pre><code>opam install . --deps-only</code></pre>
<p>Now you should be ready to build <code>capisce</code> by running
<code>make</code></p>
<pre><code>make</code></pre>
<p>Verify your installation by running
<code>./capisce exp -help</code></p>
<h5 id="dependencies-for-processing-the-experimental-results">Dependencies
for processing the experimental results</h5>
<p>The experimental results are processed using some python scripts.
They have their own dependencies that need to be installed:</p>
<pre><code>sudo apt install python3 -y
sudo apt install python3-pip -y
pip3 install sigfig
pip3 install matplotlib
pip3 install ipython</code></pre>
<h4 id="hello-world-arp">Hello World: ARP</h4>
<p>Once you’ve installed <code>Capisce</code>, you can verify it works,
by computing a specification for the <code>arp</code> program, which can
be found in <code>programs/Arp.ml</code>.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># wd: capisce/capisce</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> ./survey_data_oopsla</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="ex">./capisce</span> exp arp <span class="at">-out</span> ./survey_data_oopsla <span class="at">-hv</span></span></code></pre></div>
<p><code>capisce</code> will spit out a collection of SMT formulae whose
conjunction corresponds to the control interface specification (spec)
that enforces there are no invalid header reads (<code>-hv</code>). It
should take about 5 seconds.</p>
<p>If the above command fails, with an error complaining about not being
able to find <code>../solvers/z3.4.8.13</code> or
<code>../solvers/princess</code>, you can specify the path to these
solvers (in the <code>solvers</code> directory) manually by using the
<code>-z3</code> and <code>-princess</code> flags. For instance:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="ex">./capisce</span> exp <span class="at">-name</span> arp <span class="at">-hv</span> <span class="at">-out</span> ./survey_data_oopsla <span class="at">-z3</span> /path/to/z3 <span class="at">-princess</span> /path/to/princess</span></code></pre></div>
<p>In the sequel we will omit the explicit paths flags, but they may
always be added if needed.</p>
<h3 id="step-by-step-instructions">Step By Step Instructions</h3>
<p>We’ve provided instructions for automatically exercising the
experiments using our scripts, and for running them manually.</p>
<h4 id="exercising-the-experiments">Exercising the Experiments</h4>
<p>Now you can run the experiments from the paper. These will take
several days. Note that because path selection is done by Z3, there may
be some variation in the precise numbers generated by this step.</p>
<ul>
<li><p><code>make survey</code> runs the experiments described in
Figures 5 and 6. The output can be seen in
<code>./survey_data_oopsla</code>. Running the experiments takes about 5
days of compute.</p></li>
<li><p><code>make survey-tex</code> generates the TeX for Figures 5 and
6. Note. Run this while <code>make survey</code> is running to see the
results computed so far.</p></li>
<li><p><code>make coverage</code> generates the graphs in Figure 7. This
will take 2-3 hours</p></li>
</ul>
<h4 id="running-experiments-one-by-one">Running Experiments
One-by-One</h4>
<p>To run the experiments individually, execute the following command
once for each pipeline:</p>
<pre><code>./capisce exp NAME -out ./survey_data_oopsla</code></pre>
<p>where <code>OUT</code> is the output directory in which you wish to
store the results, and <code>NAME</code> is the name of the example
program. The valid names can be seen by typing
<code>./capisce exp</code>.</p>
<p>Most of these will finish in minutes, but several will take nearly
two days. For more-precise timing expectations, consult Figures 5 and
6.</p>
<p>Once you’ve done this, you can generate Figures 5 and 6 using the
script <code>./scripts/survey-to-tex.py</code>.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span> ./scripts/survey-to-tex.py</span></code></pre></div>
<p>You may run this script after any number of examples have been run,
and you will get partial results. Those results that haven’t finished
running yet will be indicated by an infinity symbol in the “Result”
column.</p>
<p>To reproduce Figure 7, re-run the relevant programs with the
<code>-replay</code> flag. This will generate the additional data
required to generate Figure 7. The coverage analysis is slow, and may
take several hours. To generate the data run the following commands:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="ex">./capisce</span> exp arp <span class="at">-replay</span> <span class="at">-out</span> survey_data_oopsla <span class="at">-hv</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="ex">./capisce</span> exp heavy_hitter_2 <span class="at">-replay</span> <span class="at">-out</span> survey_data_oopsla <span class="at">-hv</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="ex">./capisce</span> exp heavy_hitter_1 <span class="at">-replay</span> <span class="at">-out</span> survey_data_oopsla <span class="at">-hv</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="ex">./capisce</span> exp flowlet <span class="at">-replay</span> <span class="at">-out</span> survey_data_oopsla <span class="at">-hv</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="ex">./capisce</span> exp 07-multiprotocol <span class="at">-replay</span> <span class="at">-out</span> survey_data_oopsla <span class="at">-hv</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="ex">./capisce</span> exp simple_nat <span class="at">-replay</span> <span class="at">-out</span> survey_data_oopsla <span class="at">-hv</span></span></code></pre></div>
<p>Then, to produce the graphs as seen in Figure 7, run the following
script:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span> scripts/graphs.py</span></code></pre></div>
<p>Running the script will output the relative paths to the pdfs it
generates.</p>
<h4 id="common-issues">Common Issues</h4>
<p>The Capisce repo ships with solver executables in the
<code>solvers</code> directory. It is common to have are issues with the
solvers—Capisce prints an inscrutable error message followed by
<code>(Failure "found false")</code>. For instance,</p>
<pre><code>Error: Cannot find or load the main class ap.CmdlMain
Cause: java.lang.ClassNotFoundException: ap.CmdlMain
Uncaught exception:

  (Failure "found false")</code></pre>
<p>If these occur, please install <a href="https://github.com/Z3Prover/z3">Z3</a> and <a href="http://www.philipp.ruemmer.org/princess.shtml">princess</a>. You
can either place the executables in capisce’s <code>solvers</code>
directory, or pass the locations of the executables to
<code>capisce</code> using the <code>-z3</code> and
<code>-princess</code> flags.</p>
<h3 id="reusability-guide">Reusability Guide</h3>
<p>Our artifact supports three key pieces for reusability.</p>
<ul>
<li><p>The pipeline specification IR <code>GPL</code>, which can be
found in <code>ASTs.GPL</code>. This AST can be used as a compiler
backend for related dataplane analysis tools like <code>petr4</code>,
<code>p4cub</code>, <code>p4k</code>, <code>p4-constraints</code>, or
<code>PI4</code>.</p></li>
<li><p>The compiler infrastructure for <code>GPL.t</code> allows for
programmers to easily extend the core set of primitives, in a way that
supports efficient reuse.</p></li>
<li><p>The Counterexample-guided inductive quantifier elimination
algorithm <code>QE.cegqe</code> is succinctly stated, and can be
reimplemented or adapted to as new algorithms are discovered.</p></li>
</ul>
<h4 id="tutorial">Tutorial</h4>
<p>Now that you’ve build <code>Capisce</code>, we’ll show you how it
works.</p>
<p>First run <code>dune utop</code>. This will load <code>Capisce</code>
into a REPL. Now, open the <code>Capisce</code> module:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>utop # <span class="kw">open</span> Capisce;;</span></code></pre></div>
<p>In this Hello-World tutorial, we’ll write a program in our IR
<code>GPL</code>, which represents the guarded pipeline language
described in the paper. Then we’ll write a specification that it must
satisfy. Finally, we’ll infer a ccontrol interface spec that will ensure
the assertion is satisfied.</p>
<h5 id="part-1-writing-a-program-in-gpl">Part 1: Writing a program in
GPL</h5>
<p>First, let open the Modules for the program syntax
(<code>GPL</code>), including Bitvector Expressions (<code>Expr</code>)
and Boolean Expressions (<code>BExpr</code>).</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>utop # <span class="kw">open</span> ASTs.GPL;; <span class="kw">open</span> Expr;; <span class="kw">open</span> BExpr;;</span></code></pre></div>
<p>We’ll now write a simple GPL program that uses a single forwarding
table to set a single 9-bit field <code>port</code> based on the value
of a 32-bit destination address <code>dst</code>. First, we can define
the variables <code>port</code>and <code>dst</code>:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>utop # <span class="kw">let</span> port = Var.make <span class="st">"port"</span> <span class="dv">9</span>;;</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="kw">val</span> port : Var.t = &lt;abstr&gt;</span></code></pre></div>
<div class="sourceCode" id="cb20"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>utop # <span class="kw">let</span> dst = Var.make <span class="st">"dst"</span> <span class="dv">32</span>;;</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="kw">val</span> dst : Var.t = &lt;abstr&gt;</span></code></pre></div>
<p>We’ll use these variables to construct our table. Lets see how we
might do that by inspecting the type of the constructor
<code>table</code>:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>utop # table;;</span></code></pre></div>
<p>should produce</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>- : <span class="dt">string</span> -&gt;</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    [&gt; `Exact <span class="kw">of</span> Var.t | `Maskable <span class="kw">of</span> Var.t | `MaskableDegen <span class="kw">of</span> Var.t ] <span class="dt">list</span> -&gt;</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    (Var.t <span class="dt">list</span> * Capiscelib.Primitives.Action.t <span class="dt">list</span>) <span class="dt">list</span> -&gt;</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    Pack.t</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>= &lt;<span class="kw">fun</span>&gt;</span></code></pre></div>
<p>This tells us that to construct a <code>table</code>, we need 3
arguments: a <code>string</code> name, a list variable keys tagged with
their matchkind (<code>Exact</code>, <code>Maskable</code>, and
<code>MaskableDegen</code>), then a list of
<code>Var.t list * Primitives.Action.t list</code>. Each pair
<code>(xs, as)</code> in this list corresponds to an anonymous function
where <code>xs</code> occur free in a list of primitive actions. This
list should be understood as sequential composition. Lets construct our
first action.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>utop # <span class="kw">let</span> nop : Var.t <span class="dt">list</span> * Primitives.Action.t <span class="dt">list</span> = [],[];;</span></code></pre></div>
<p>This action is the trivial action. It takes no arguments
<code>[],</code> and executes noactions <code>[]</code>.</p>
<p>Stepping it up a notch in complexity. We will define a action that
takes in a single argument, indicated by parameter <code>p</code>, and
assigns <code>p</code> to our previously-defined variable
<code>port</code>:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>utop # <span class="kw">let</span> setport =</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>     <span class="kw">let</span> p = Var.make <span class="st">"p"</span> <span class="dv">9</span> <span class="kw">in</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>     [p], Primitives.Action.[</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>          assign port (Expr.var p)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>     ];;</span></code></pre></div>
<p>The first line constructs the AST node for parameter <code>p</code>.
Then the <code>[p],</code> says that <code>p</code> is an argument for
the action, which is defined by the subsequent action list.</p>
<p>Now we can define a table, called <code>simpletable</code> that reads
the vpalue of <code>port</code>, and then either execute the
<code>setport</code> action with some parameter, or take no action.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>utop # <span class="kw">let</span> simpletable =</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>    table <span class="st">"simpletable"</span> [`Exact port] [setport; nop];;</span></code></pre></div>
<p>The <code>Exact</code> matchkind tells us that
<code>simpletable</code> must precisely read the bits of
<code>port</code>. Using <code>Maskable</code> corresponds unifies the
notions of <code>ternary</code>, <code>lpm</code> and
<code>optional</code>, all of which allow the the table to skip reading
that specific key. <code>MaskableDegen</code> is semantically equivalent
to <code>Exact</code>, but allows us to differentiate between truly
maskable match data and degenerate cases described in the paper</p>
<h5 id="part-2-writing-a-specification">Part 2: Writing a
Specification</h5>
<p>Now, as an example specification, we can exclude a specific port
value. Perhaps to indicate that this port value, say <code>47</code> is
disabled. So we never want to forward a packet out on port
<code>47</code>. We define a spec that ensures this as follows:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>utop # <span class="kw">let</span> port_not_47 =</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> prohibited = Expr.bvi <span class="dv">47</span> <span class="dv">9</span> <span class="kw">in</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>    BExpr.(not_ (eq_ (Expr.var port) prohibited));;</span></code></pre></div>
<p>Now we can use assertions to specify that our table must satisfy this
spec:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>utop # <span class="kw">let</span> program = sequence [</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    simpletable;</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    assert_ port_not_47</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>];;</span></code></pre></div>
<h5 id="part-3-inferring-a-spec">Part 3: Inferring A Spec</h5>
<p>Inferring the control interface spec for the table requires two
steps. First we encode the tables using the instrumentation strategy
described in the paper, and then we run our inference algorithm.</p>
<p>The encoding step eliminates tables, and converts a
<code>GPL.t</code> program into a <code>GCL.t</code> program.
<code>GCL</code> here stands for Dijkstra’s <em>guarded command
language</em>. We run this using the <code>GPL.encode_tables</code>
function:</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>utop # <span class="kw">let</span> gcl = ASTs.GPL.encode_tables program;;</span></code></pre></div>
<p>To see a pretty printed version of the table-free program, run the
following:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>utop # <span class="dt">Printf</span>.printf <span class="st">"\%s"</span> @@ ASTs.GCL.to_string gcl;;</span></code></pre></div>
<p>Now we can infer the specification for this program by running the
<code>CEGQE</code> algorithm:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>utop # <span class="kw">let</span> cis = Qe.cegqe gcl;;</span></code></pre></div>
<p>To pretty print the result in SMTLIB format, run the following
command:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>utop # <span class="dt">Printf</span>.printf <span class="st">"\%s"</span> @@ BExpr.to_smtlib cis;;</span></code></pre></div>
<p>The resulting specification has two conjucts. The first, shown below,
says that whenever the action is has index <code>0</code>, that is when
it corresponds to <code>setport</code>, the argument to
<code>setport</code> must not be <code>47</code>.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode lisp"><code class="sourceCode commonlisp"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>  (<span class="kw">not</span> (<span class="kw">and</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>          (<span class="op">=</span> _symb$simpletable$action$_$<span class="dv">0</span> (_ bv1 <span class="dv">1</span>))</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>          (<span class="op">=</span> _symb$simpletable$<span class="dv">1</span>$p$_$<span class="dv">0</span> (_ bv47 <span class="dv">9</span>))))</span></code></pre></div>
<p>The second conjunct, replicated below, says that whenever the action
is <code>setport</code>, the key that was matched by
<code>simpletable</code> must not be equal to <code>47</code>.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode lisp"><code class="sourceCode commonlisp"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>  (<span class="kw">not</span> (<span class="kw">and</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>          (<span class="op">=</span> _symb$simpletable$action$_$<span class="dv">0</span> (_ bv0 <span class="dv">1</span>))</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>          (<span class="op">=</span> _symb$simpletable$match_0$_$<span class="dv">0</span> (_ bv47 <span class="dv">9</span>))))</span></code></pre></div>
<h4 id="guarded-pipeline-language-gpl">Guarded Pipeline Language
<code>GPL</code></h4>
<p>Here we provide documentation of the core interface for writing
<code>GPL.t</code> programs.</p>
<p>The <code>GPL</code> module, defined in <code>ASTs.ml</code> defines
programs.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> t</span></code></pre></div>
<p>It has a type <code>t</code> that corresponds to <code>GPL</code>
programs themselves.</p>
<p>We can construct trivial programs</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="kw">val</span> skip : t</span></code></pre></div>
<p>Sequential compositions of programs;</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="kw">val</span> sequence : t <span class="dt">list</span> -&gt; t</span></code></pre></div>
<p>Nondeterministic choice between programs:</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="kw">val</span> choice : t <span class="dt">list</span> -&gt; ts</span></code></pre></div>
<p>We can also construct variable assignments</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="kw">val</span> assign_ : Var.t -&gt; Expr.t -&gt; t</span></code></pre></div>
<p>and the most important constuct, tables:</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="kw">val</span> table : <span class="dt">string</span> </span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>  -&gt; [&gt; `Exact <span class="kw">of</span> Var.t <span class="dt">list</span> | `Maskable <span class="kw">of</span> Var.t <span class="dt">list</span> | `MaskableDegen <span class="kw">of</span> Var.t ] <span class="dt">list</span> </span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>  -&gt; ( Var.t * Primtives.Action.t <span class="dt">list</span>) <span class="dt">list</span> -&gt; t</span></code></pre></div>
<p>As described above <code>table name keys actions</code> constructs a
table named <code>name</code> that chooses an action <code>a</code> in
<code>actions</code> by inspecting the variables in
<code>keys</code>.</p>
<p>More about <code>Primitives.Action</code> can be found in the next
section.</p>
<p>To specify desired behaviors we have two primitives,
<code>assume</code> and <code>assert</code>.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="kw">val</span> assume : BExpr.t -&gt; t</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="kw">val</span> assert_ : BExpr.t -&gt; t</span></code></pre></div>
<p>The <code>assume</code> primitive is angelic—if it can be satisfied
the program assumes it is. Conversely, <code>assert_</code> is
demonic—if it can ba falsified the program assumes it is.</p>
<h5 id="building-the-documentation">Building the Documentation</h5>
<p>The full documentation can be viewed using the following command. It
may prompt you to install <code>odoc</code>. Please do so using
<code>opam install odoc</code>.</p>
<pre><code>make doc -B</code></pre>
<p>This will open the documentation in your systems default web browser.
If you do not have a web browser installed the terminal
<code>xdg-open</code> command will fail. Feel free to browse the
documenation some other way. In the docker container the docs will be
opened in <code>w3m</code> (press <code>enter</code> to follow links and
<code>q</code> to quit).</p>
<p>The documentation for the core modules can be found by clicking on
<code>capisce</code> and then navigating to modules <code>Cmd</code>,
<code>ASTs</code>, and <code>Qe</code>.</p>
<h4 id="instrumentation-and-compiler">Instrumentation and Compiler</h4>
<p><code>GPL.t</code> is constructed using a functor
<code>Cmd.Make</code> that allows users to produce simple loop-free
imperative programs with demonic nondeterminism.</p>
<p><code>Cmd.Make</code> has a single module argument which must have
module type <code>Primitive</code> shown below:</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="kw">module</span> <span class="kw">type</span> Primitive = <span class="kw">sig</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">type</span> t [@@deriving quickcheck, eq, hash, sexp, <span class="dt">compare</span>]</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>  <span class="kw">val</span> assume : BExpr.t -&gt; t</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>  <span class="kw">val</span> assert_ : BExpr.t -&gt; t</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>  <span class="kw">val</span> contra : t -&gt; t -&gt; <span class="dt">bool</span></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>  <span class="kw">val</span> to_smtlib : t -&gt; <span class="dt">string</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>  <span class="kw">val</span> size : t -&gt; <span class="dt">int</span></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>  <span class="kw">val</span> vars : t -&gt; Var.t <span class="dt">list</span></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code></pre></div>
<p>The <code>assume</code> and <code>assert_</code> functions construct
assumptions and assertions as before; <code>contra</code> describes when
two assumptions and/or assertions are contradictory;
<code>to_smtlib</code> converts <code>t</code> into an string that uses
smtlib syntax for expressions and variables; <code>size</code> computes
the size of a primitive, and <code>vars</code> computes the variables
used in a primitive.</p>
<p>This structure is extremely extensible and facilitates easy reuse of
our code. The file <code>Primitives.ml</code> serves as a great tutorial
for how to build up a higherarchical set of Primitives. Then
<code>ASTs.ml</code> uses these Primtives to build a set of IRs and a
compiler pipeline between them. We summarize it here.</p>
<p>Our compiler pipeline starts with <code>GPL</code> and then uses
<code>encode_tables</code> to produce a <code>GCL</code> program. Then
passify produces a program in the passive form <code>Psv.t</code> as
defined in Section 3.4 of the paper. Then we use standard verification
generation technqiues to produce formulae in SMTLIB.</p>
<p>Each of these passes is a fundamentally a catamorphism over the core
structure of the programs, and eliminates a single primitive at a time:
<code>encode_tables</code> eliminates tables, and <code>passify</code>
eliminates assignments. This is captured in the types.</p>
<p>Starting from the bottom, <code>Psv.t = Cmd.Make(Passive).t</code>,
where <code>Passive.t</code> is either an <code>Assume</code> or an
<code>Assert</code>. Then <code>GCL = Cmd.Make(Active).t</code>, where
<code>Active.t</code> is either a <code>Passive.t</code> or an
<code>Assign</code>ment. Finally
<code>GPL = Cmd.Make(Pipeline).t</code>, where <code>Pipeline.t</code>
is either a <code>Table</code> or an <code>Active</code>. The
transformation functions <code>encode_tables</code> and
<code>passify</code> defined in <code>ASTs.ml</code> define this
clearly.</p>
<p>With this compiler infrastructure in place, it would be easy for
future researchers to extend our work with additional features. Just as
writing the compiler for <code>GPL</code> leverages the existing
compiler for <code>GCL</code>, futurue work could extend GPL add
primitives for multiple-assignment, hash functions, or stateful
operations. Simply by writing elimination passes, researchers could make
ready use of our existing verification generation and specification
inference code.</p>
<h4 id="specification-inference-and-modelling">Specification Inference
and Modelling</h4>
<p>The algorithm <code>Qe.ceqge</code> in the <code>Qe.ml</code> file is
straightfoward and easy to modify. The experimental setup defined in
<code>bin/Main.ml</code> supports swapping in different algorithms for
performing the inference, which will allow future researchers to
directly measure their improvements over CegQe.</p>

},
keywords = {deductive synthesis, programmable networks, quantifier elimination}
}

@software{10.5281/zenodo.13367665,
author = {Wu, Jifeng and Lemieux, Caroline},
title = {Reproduction Package for Article `QuAC: Quick Attribute-Centric Type Inference for Python`},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13367665},
abstract = {
    <p>This artifact supports the paper “QuAC: Quick Attribute-Centric Type
Inference for Python.” The artifact includes the code and data used to
generate the results presented in the paper. It aims to reproduce the
main scientific claims and facilitate future research by making the
software publicly available.</p>

},
keywords = {Gradual Typing, Python, Static Analysis, Type Inference}
}

@software{10.5281/zenodo.13370788,
author = {Kang, Chan Gu and Lee, Joonghoon and Oh, Hakjoo},
title = {Artifact for Paper "Statistical Testing of Quantum Programs via Fixed-Point Amplitude Amplification" in OOPSLA 2024},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13370788},
abstract = {
    <p>This is Zenodo repoistory for Software Artifact of Paper “Statistical
Testing of Quantum Programs via Fixed-Point Amplitude Amplification”
appeared in in OOPSLA 2024.</p>
<p>This repository contains a PDF file of artifact manual and runnable
software artifact. Running the artifact will give :</p>
<ul>
<li>Numerical calculation shown in the Examples in the paper</li>
<li>Validation of depth cost expression (appeared in Section 6 and 7 of
the paper)</li>
<li>Producing Speed-up plots in Case Study (appeared in Section 7 of the
paper)</li>
<li>Implementation of Testing Algorithms</li>
</ul>
<p>For the further details, see the attached artifact manual. For any
questions, contact changukang@korea.ac.kr. The artifact may be continued
through following github repo : https://github.com/kupl/FpaaTestArtifact
.</p>

},
keywords = {Quantum Computing, Quantum Programming, Testing, Verification}
}

@software{10.5281/zenodo.13370814,
author = {Tan, Jinhao and Oliveira, Bruno C. d. S.},
title = {A Case for First-Class Environments (Artifact)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13370814},
abstract = {
    <p>The artifact includes the Coq formalization of the paper “A Case for
First-Class Environments”.</p>

},
keywords = {First-class Environments, Mechanical Formalization, Semantics}
}

@software{10.5281/zenodo.13372573,
author = {Bembenek, Aaron and Greenberg, Michael and Chong, Stephen},
title = {Making Formulog Fast: An Argument for Unconventional Datalog Evaluation (OOPSLA'24 Artifact)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13372573},
abstract = {
    <p>Welcome to the artifact for the paper “Making Formulog Fast: An
Argument for Unconventional Datalog Evaluation” (OOPSLA’24) by Aaron
Bembenek, Michael Greenberg, and Stephen Chong. This artifact was
reviewed by the OOPSLA’24 Artifact Evaluation Committee. The artifact
includes: our extensions to Formulog and Souffl\'{e}; benchmarks and
experimental infrastructure; the data from our experiments and our data
analysis scripts; and documentation on how to build on top of our
software. To use the artifact, download the archive, extract it, and
follow the instructions in the README. If you just want to run Formulog,
you can get Formulog directly from the GitHub repo
(https://github.com/HarvardPL/formulog).</p>

},
keywords = {compilation, Datalog, Formulog, parallel evaluation, SMT solving}
}

@software{10.5281/zenodo.13376916,
author = {Bowman, William J.},
title = {A Low-Level Look at A-Normal Form (artifact)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13376916},
abstract = {
    <p>This artifact accompanies the paper A low-level look at A-normal form
(https://doi.org/10.1145/3689717). The <code>materials.tar.gz</code>
contain source files, documentation, Docker files, and assorted build
scripts. The file <code>oopsla2024-159-artifact-amd64.qcow2</code>
contains the same files, bundled as a QEMU VM image; instructions for
running it are in the gzip file.</p>

},
keywords = {A-normal form, Compilers, CPS, Intermediate Representation, Monadic Form, Normal Form, Normalization, Optimization}
}

@software{10.5281/zenodo.13377564,
author = {Jeon, Seungmin and Cho, Kyeongmin and Kang, Chan Gu and Lee, Janggun and Oh, Hakjoo and Kang, Jeehoon},
title = {Artifact for "Quantum Probabilistic Model Checking for Time-Bounded Properties"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13377564},
abstract = {
    <p>This is the artifact for OOPSLA 2024 paper: “Quantum Probabilistic
Model Checking for Time-Bounded Properties”.</p>
<p>This artifact includes the following files: - qpmc.zip: Contains the
implementation and evaluation program used to generate the results
presented in the paper. - qpmc-evaluation-results.zip: Includes the
output files generated by the evaluation program.</p>
<p>For detailed information about this artifact, please refer to the
README.md file within the qpmc.zip archive. The artifact also includes
the full paper with appendices (paper-full.pdf).</p>

},
keywords = {bounded reachability, probabilistic model checking, quantum computing}
}

@software{10.5281/zenodo.13380062,
author = {Craaijo, Jos and Verbeek, Freek and Ravindran, Binoy},
title = {Reproduction package (Docker container) for the OOPSLA 2024 article "libLISA: Instruction Discovery and Analysis on x86-64"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13380062},
abstract = {
    <p>These files accompany the OOPSLA 2024 paper ‘libLISA - Instruction
Discovery and Analysis on x86-64’.</p>
<p>This artifact consists of the following:</p>
<ul>
<li>The source code for libLISA, the tool presented in the paper.</li>
<li>The generated semantics for the five CPU architectures we
analyzed.</li>
<li>The source code for all additional tools that we used to generate
the data in Table 5, 6, 7, 8 and 9.</li>
</ul>
<p>This is all relevant source code and data necessary to reproduce all
results in the paper.</p>
<p>Please see the full guide in artifact-evaluation-guide.7z.</p>

},
keywords = {instruction enumeration, instruction semantics, synthesis}
}

@software{10.5281/zenodo.13380561,
author = {Hinrichsen, Jonas Kastberg and Jacobs, Jules and Krebbers, Robbert},
title = {Multris: Functional Verification of Multiparty Message Passing in Separation Logic - Coq Mechanization},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13380561},
abstract = {
    <p>Coq mechanization artifact for the OOPSLA’24 paper: “Multris:
Functional Verification of Multiparty Message Passing in Separation
Logic”.</p>
<p>See included README for more details.</p>

},
keywords = {Coq, Mechanization, Separation Logic}
}

@software{10.5281/zenodo.13381305,
author = {Root, Alexander J and Yan, Bobby and Liu, Peiming and Gyurgyik, Christophe and Bik, Aart J.C. and Kjolstad, Fredrik},
title = {Artifact for OOPSLA 2024 Paper: Compilation of Shape Operators on Sparse Arrays},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13381305},
abstract = {
    <p>This artifact contains the prototype Burrito compiler, all benchmarks
from the paper, and graphing scripts used to produce the figures in the
paper.</p>

},
keywords = {sparse array programming, sparse data structures, sparse iteration theory}
}

@software{10.5281/zenodo.13383121,
author = {Legoupil, Maxime and Rousseau, June and Georges, A\"{\i}na Linn and Pichon-Pharabod, Jean and Birkedal, Lars},
title = {Artifact and Appendix of 'Iris-MSWasm: elucidating and mechanising the security invariants of Memory-Safe WebAssembly'},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13383121},
abstract = {
    <p>This is the artifact and appendix of the OOPSLA ‘24 paper
’Iris-MSWasm: elucidating and mechanising the security invariants of
Memory-Safe WebAssembly’. The artifact contains the coq source code as
well as a readme.md file that explains how to build the project and
where to find the different parts of the paper. The appendix is a pdf
that contains figures that were elided in the paper for space
constraints.</p>

},
keywords = {Capabilities, Coq, Encapsulation, Logical Relation, Mechanised Proofs, Memory Safety, MSWasm, Wasm, WebAssembly}
}

@software{10.5281/zenodo.13383433,
author = {Simonnet, Julien and Lemerre, Matthieu and Sighireanu, Mihaela},
title = {Artifact for the paper 'A Dependent Nominal Physical Type System for the Static Analysis of Memory in Low Level Code'},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13383433},
abstract = {
    <p>The artifact includes the sources of the analyser Codex, the set of
benchmarks used in experiments, and the utilities (makefiles, scripts)
to reproduce the results presented in this paper.</p>

},
keywords = {Abstract interpretation, Dependent types, Spatial memory safety, Type checking, Typed C}
}

@software{10.5281/zenodo.13485897,
author = {Alvarez-Picallo, Mario and Freund, Teodoro and Ghica, Dan R. and Lindley, Sam},
title = {Effect Handlers for C via Coroutines - Artifact},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13485897},
abstract = {
    <p>Artifact for the library and benchmarks described in the Effect
Handlers for C via Coroutines paper published at OOPSLA 2024.</p>

},
keywords = {C, Coroutines, Effect Handlers}
}

@software{10.5281/zenodo.13487216,
author = {Venev, Hristo and Gehr, Timon and Dimitrov, Dimitar and Vechev, Martin},
title = {Artifact for "Modular Synthesis of Efficient Quantum Uncomputation"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13487216},
abstract = {
    <p>This archive contains the artifact for the paper “Modular Synthesis
of Efficient Quantum Uncomputation”. &nbsp;It can be used to reproduce the
results in Tables 1-3.</p>

},
keywords = {intermediate representations, quantum programming languages}
}

@software{10.5281/zenodo.13502454,
author = {Bittner, Paul Maximilian and Schulthei\ss{}, Alexander and Moosherr, Benjamin and Young, Jeffrey M. and Teixeira, Leopoldo and Walkingshaw, Eric and Ataei, Parisa and Th\"{u}m, Thomas},
title = {Vatras - Artifact for the Paper "On the Expressive Power of Languages for Static Variability"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13502454},
abstract = {
    <p>Vatras is an Agda library and formalizes all results in our
paper:</p>
<ul>
<li>All formal languages for static software variability presented in
our survey (<strong>Section 3 + Table 1</strong>) are formalized as
algebraic datatypes.</li>
<li>The library implements our formal framework for language
comparisons, including necessary data structures, theorems, and proofs
(<strong>Section 4</strong>).</li>
<li>This library contains all theorems and proofs to establish the map
of variability languages we find by comparing the languages from our
survey with our framework (<strong>Section 5</strong>).</li>
</ul>
<p>Additionally, our library comes with a small demo. When run in a
terminal, our demo will show a translation roundtrip, showcasing the
circle of compilers developed for identifying the map of variability
languages (Section 5).</p>

},
keywords = {expressive power, formalization, proofs, software product lines, software variability}
}

@software{10.5281/zenodo.13599952,
author = {Somers, Thomas and Krebbers, Robbert},
title = {Artifact of 'Verified Lock-Free Session Channels with Linking'},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13599952},
abstract = {
    <p>This artifact contains the Coq mechanization of the OOPSLA 2024
paper: ‘Verified Lock-Free Session Channels with Linking’. It contains
the source code, instructions for evaluating the artifact, and the
correspondence between the artifact and paper.</p>

},
keywords = {Coq, Iris, Message passing, separation logic, session types}
}

@software{10.5281/zenodo.13618225,
author = {Liu, Si and Gu, Long and Wei, Hengfeng and Basin, David},
title = {Artifact for "Plume: Efficient and Complete Black-Box Checking of Weak Isolation Levels"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13618225},
abstract = {
    <p>This artifact provides a Docker image that includes all the necessary
tools and experimental data used in the paper titled “Plume: Efficient
and Complete Black-Box Checking of Weak Isolation Levels.” The Docker
image ensures a fully configured environment to facilitate the
reproducibility of the results presented in the paper.</p>
<p>The Docker image includes:</p>
<ul>
<li>Comparison Tools: A suite of tools required for the
experiments.</li>
<li>Experimental Data: Complete datasets used in the experiments.</li>
<li>Reproduction Scripts: Scripts for reproducing the experimental
results.</li>
</ul>

},
keywords = {black-box testing, formal specification, weak isolation levels}
}

@software{10.5281/zenodo.13621222,
author = {Cheng, Luyu and Parreaux, Lionel},
title = {The Ultimate Conditional Syntax (Artifact)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13621222},
abstract = {
    <p>This is the artifact of OOPSLA paper titled <em>The Ultimate
Conditional Syntax</em>. The latest version of the artifact can be found
at <a href="https://github.com/hkust-taco/ucs" class="uri">https://github.com/hkust-taco/ucs</a>. A online web demo can
be found at <a href="https://ucs.mlscript.dev" class="uri">https://ucs.mlscript.dev</a>. A comprehensive manual of the
artifact is located at <code>manual/manual.pdf</code> in the
archive.</p>

},
keywords = {compiler, MLscript, pattern matching, semantics, syntax, transformation, web demo}
}

@software{10.5281/zenodo.13622515,
author = {Lobo-Vesga, Elisabet and Russo, Alejandro and Gaboardi, Marco and Corti\~{n}as, Carlos Tom\'{e}},
title = {Paper Artifact: Sensitivity by Parametricity},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13622515},
abstract = {
    <p>The official artifact accompanying the OOPSLA 2024 paper “Sensitivity
by Parametricity” for the Spar library. The paper explores the use of
parametricity to perform sensitivity analysis on user-defined functions,
additionally, it introduces a Haskell library called Spar that
implements this technique. Spar encodes value distances as type-level
naturals, proving the sensitivity of a function is reduced to
type-checking! This artifact is distributed as a Docker image where the
Spar library is built and ready to use. Instructions for building the
image are provided in README.</p>

},
keywords = {differential privacy, functional programming languages, Haskell, sensitivity}
}

@software{10.5281/zenodo.13624896,
author = {Goharshady, Amir Kafshdar and Lam, Chun Kit and Parreaux, Lionel},
title = {Fast and Optimal Extraction for Sparse Equality Graphs},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13624896},
abstract = {
    <p>This artifact contains the implementation of our optimal extraction
algorithm, as well as experiment with the cranelift (wasmtime)
compiler.</p>

},
keywords = {e-graphs, optimal extraction, treewidth}
}

@software{10.5281/zenodo.13625830,
author = {Yang, Ziteng and Shirako, Jun and Sarkar, Vivek},
title = {Artifact for "Fully Verified Instruction Scheduling"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13625830},
abstract = {
    <p>This is the artifact of our project in our paper Fully Verified
Instruction Scheduling: a lightweight and flexible approach.</p>
<p>The artifacts consists of two parts: mechanized proofs and
performance experiments. Evaluating the mechanized proofs only requires
software dependencies on Linux machine and the use of proof assistant
Coq. Evaluating the experiments requires an in-order Risc-V
hardware.</p>
<p>The documentations contains step-by-step building guides and a
detailed paper-to-artifact correspondence guide that matches every
lemma/theorems in our submitted paper with the mechanized proofs.</p>

},
keywords = {CompCert, Compiler Verification, Coq Proof Assistant, Instruction-level
Parallelism}
}

@software{10.5281/zenodo.13625874,
author = {Carnier, Denis and Pottier, Fran\c{c}ois and Keuchel, Steven},
title = {Type Inference Logics - Artifact},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13625874},
abstract = {
    <p>This artifact contains both sources and a prebuilt Docker image. The
sources file contains a <code>README.md</code> for navigating the source
code with instructions on how to get started. The image file contains a
Docker image compiled for AMD64 with all the necessary dependencies to
check the code with the Coq proof assistant and GHC.</p>

},
keywords = {elaboration, program verification, type inference}
}

@software{10.5281/zenodo.13626195,
author = {Nagar, Kartik and Sahoo, Anmol and Chowdhury, Romit Roy and Jagannathan, Suresh},
title = {Artifact - Automated Robustness Verification of Concurrent Data Structure Libraries Against Relaxed Memory Models},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13626195},
abstract = {
    <p>The artifact for our submission contains the implementation of the
tool (Robocop) and various library implementations tested for
robustness. Robocop is an executable program, written in Python, that
takes as input a library implementation in C and library specifications
in a text format. Internally, it parses the C code, performs the
necessary analysis to generate constraints and generates SMT calls to
Z3, to discharge whether the library is robust or not.</p>

},
keywords = {verification, weak-memory}
}

@software{10.5281/zenodo.13626469,
author = {Guan, Zhichao and Cao, Yiyuan and Yu, Tailai and Wang, Ziheng and Wang, Di and Hu, Zhenjiang},
title = {Artifact for OOPSLA'24: Semantics Lifting for Syntactic Sugar},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13626469},
abstract = {
    <p>Artifact for OOPSLA’24: Semantics Lifting for Syntactic Sugar. This
project will be maintained at
https://github.com/vbcpascal/Osazone-oopsla24.</p>

},
keywords = {Domain-specific Languages, Programming Language, Syntactic Sugar}
}

@software{10.5281/zenodo.13770453,
author = {Ma, Cong and Ge, Zhaoyi and Lee, Edward and Zhang, Yizhou},
title = {Lexical Effect Handlers, Directly (artifact)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13770453},
abstract = {
    <p>This is the artifact accompanying the paper
<code>Lexical Effect Handlers, Directly</code>.</p>

},
keywords = {Algebraic effects, compiler correctness, continuations, effect handlers, Lexa, Salt, stack switching}
}

@software{10.5281/zenodo.13825844,
author = {Saioc, Georgian-Vlad and Lange, Julien and M\o{}ller, Anders},
title = {Artifact Submission For "Automated Verification of Parametric Channel-Based Process Communication"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.13825844},
abstract = {
    <p>Public release of OOPSLA 2024 Ginger artifact. Includes a small set
of example program fragments. Experimental data used in the evaluation
section of the original paper is proprietary.</p>

},
keywords = {automated verification, Go, invariant discovery, message passing concurrency, partial deadlocks, static analysis}
}

@software{10.5281/zenodo.10890011,
author = {Helm, Dominik and Roth, Tobias and Keidel, Sven and Reif, Michael and Mezini, Mira},
title = {Unimocg: Modular Call-Graph Algorithms for Consistent Handling of Language Features - Companion Artifact},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10890011},
abstract = {
    <p>This is the artifact of the paper: Unimocg: Modular Call-Graph
Algorithms for Consistent Handling of Language Features published at
ISSTA 2024. Our paper proposes a modular architecture for call-graph
construction that decouples the computation of type information from
resolving calls.</p>
<p>Unimocg_Artifact.zip contains our artifact and results (excluding
computed call graphs because of their size). The evaluation is performed
in a docker container that can automatically be build from the files in
the artifact zip.</p>

},
keywords = {call graph, static analysis}
}

@software{10.5281/zenodo.12632401,
author = {Jiang, Zhihan and Liu, Jinyang and Huang, Junjie and Li, Yichen and Huo, Yintong and Gu, Jiazhen and Chen, Zhuangbin and Zhu, Jieming and Lyu, Michael R.},
title = {Reproduction Package for Article "A Large-Scale Evaluation for Log Parsing Techniques: How Far Are We?"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12632401},
abstract = {
    <p>This is the artifact of [ISSTA’24] “A Large-Scale Evaluation for Log
Parsing Techniques: How Far Are We?”</p>

},
keywords = {Benchmark, Log Analysis, Log Parsing}
}

@software{10.5281/zenodo.12668172,
author = {Wei, Haolai and Chen, Liwei and Zhang, Zhijie and Shi, Gang and Meng, Dan},
title = {Artifact of the ISSTA 2024 paper -- "Sleuth: A Switchable Dual-Mode Fuzzer to Investigate Bug Impacts Following a Single PoC"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12668172},
abstract = {
    <p>Sleuth is an open-source fuzzer for automatically discovering bug
impacts following a single PoC. It is based on LLVM and the fuzzing tool
AFL++. It employs SVF to construct the memory-relevant graph, and
utilizes this graph to guide Fuzzer to efficiently discover new bug
impacts.</p>
<p>The artifact contains a docker image and the source code with a
READEME file. The current version still has some cumbersome user
interactions. We will optimize this part in the future and release a
more stable version.</p>

},
keywords = {Bug impact, Fuzzing, Patch testing}
}

@software{10.5281/zenodo.12668777,
author = {Mazouni, Quentin and Spieker, Helge and Gotlieb, Arnaud and Acher, Mathieu},
title = {Policy Testing with MDPFuzz (Replicability Study)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12668777},
abstract = {
    <p>This is the artifact implementing our replicability study of the
policy testing method MDPFuzz. The artifact is hosted on Zenodo as well
as on GitHub. It contains all the source code for reproducing the
experiments of the paper. In particular, we provide detailed
instructions and a Dockerfile that can be used to build a Docker image
and run the artifact as a Docker container. We also release the Docker
image on Docker Hub.</p>

},
keywords = {Reinforcement Learning, Replicability, Software Testing}
}

@software{10.5281/zenodo.12669081,
author = {Saha, Antu and Song, Yang and Mahmud, Junayed and Zhou, Ying and Moran, Kevin and Chaparro, Oscar},
title = {Toward the Automated Localization of Buggy Mobile App UIs from Bug Descriptions},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12669081},
abstract = {
    <p>This is the replication package for the ISSTA’24 paper titled “Toward
the Automated Localization of Buggy Mobile App UIs from Bug
Descriptions”. Authors: Antu Saha, Yang Song, Junayed Mahmud, Ying Zhou,
Kevin Moran, and Oscar Chaparro</p>
<p>Please visit the latest version (currently v5) for the most updated
artifacts.</p>

},
keywords = {Bug Reports, Information Retrieval, Mobile Applications, UI Data}
}

@software{10.5281/zenodo.12669964,
author = {Zhang, Mengxiao and Tian, Yongqiang and Xu, Zhenyang and Dong, Yiwen and Tan, Shin Hwei and Sun, Chengnian},
title = {Artifact for "LPR: Large Language Models-Aided Program Reduction"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12669964},
abstract = {
    <p>This is the artifact for the paper “LPR: Large Language Models-Aided
Program Reduction”</p>

},
keywords = {compiler testing, debugging, LLM, program reduction}
}

@software{10.5281/zenodo.12670309,
author = {Cao, Shangtong and He, Ningyu and She, Xinyu and Zhang, Yixuan and Zhang, Mu and Wang, Haoyu},
title = {WASMaker: Differential Testing of WebAssembly Runtimes via Semantic-aware Binary Generation},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12670309},
abstract = {
    <p>WASMaker, a novel differential testing framework that can generate
complicated Wasm test cases by disassembling and assembling real-world
Wasm binaries, which can trigger hidden inconsistencies among Wasm
runtimes.</p>

},
keywords = {Differential Testing, WebAssembly}
}

@software{10.5281/zenodo.12670597,
author = {Nguyen, Huan and Priyadarshan, Soumyakant and Sekar, R.},
title = {Reproduction Package for the ISSTA 2024 Article 'Scalable, Sound and Accurate Jump Table Analysis'},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12670597},
abstract = {
    <p>This artifact contains our state-of-the-art jump table analyzer,
which is accepted for presentation at the ACM SIGSOFT International
Symposium on Software Testing and Analysis (ISSTA) 2024. We ship our
artifact as a VM that contains our source code and the scripts used to
obtain the results in the paper.</p>

},
keywords = {Binary Analysis, Program Analysis, Reverse Engineering, Static Analysis}
}

@software{10.5281/zenodo.12792159,
author = {He, Dongnan and Xie, Dongchen and Wang, Yujie and You, Wei and Liang, Bin and Huang, Jianjun and Shi, Wenchang and Zhang, Zhuo and Zhang, Xiangyu},
title = {Artifact for "Define-Use Guided Path Exploration for Better Forced Execution"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12792159},
abstract = {
    <p>This artifact contains supplementary material for the paper
“Define-Use Guided Path Exploration for Better Forced Execution”
(ISSTA’24). The artifact contains a docker image and a READEME file.</p>

},
keywords = {dynamic analysis, forced execution, path exploration}
}

@software{10.5281/zenodo.11233589,
author = {Bahr, Patrick and Hutton, Graham},
title = {Supplementary Material for "Beyond Trees: Calculating Graph-Based Compilers"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11233589},
abstract = {
    <p>This repository contains the supplementary material for the paper Beyond Trees: Calculating Graph-Based Compilers. The material includes Agda formalisations of all calculations in the paper. In addition, further examples and calculations are included as well.</p>

},
keywords = {graphs, higher-order abstract syntax, program calculation}
}

@software{10.5281/zenodo.11429428,
author = {Xue, Xu and Oliveira, Bruno C. d. S.},
title = {Contextual Typing (Artifact)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11429428},
abstract = {
    <p>The artifact includes the Agda formalisation of the paper “Contextual Typing”.</p>

},
keywords = {Bidirectional Typing, Type Inference}
}

@software{10.5281/zenodo.11470739,
author = {Michelland, S\'{e}bastien and Zakowski, Yannick and Gonnord, Laure},
title = {Replication package for article: Abstract Interpreters: a Monadic Approach to Modular Verification},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11470739},
abstract = {
    <p>This software package is a Docker image and tarball of a project about building abstract interpreters out of a monadic denotation of source languages. The Docker image contains the tools needed to check the project’s proof scripts, namely opam, the Coq proof assistant, and a few Coq libraries.</p>

},
keywords = {Abstract Interpretation, Coq, Formal Verification, Interaction Trees, Monadic Semantics}
}

@software{10.5281/zenodo.11470781,
author = {Mulleners, Niek and Jeuring, Johan and Heeren, Bastiaan},
title = {Example-Based Reasoning About the Realizability of Polymorphic Programs},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11470781},
abstract = {
    <p>This is the code accompanying the ICFP ’24 paper “Example-Based Reasoning About the Realizability of Polymorphic Programs”. It includes the source code, as well as a virtual image containing the same sources, but with all dependencies installed.</p>

},
keywords = {container functors, example propagation, parametricity, program synthesis, unrealizability}
}

@software{10.5281/zenodo.11481248,
author = {Gregersen, Simon Oddershede and Aguirre, Alejandro and Haselwarter, Philipp G. and Tassarotti, Joseph and Birkedal, Lars},
title = {Almost-Sure Termination by Guarded Refinement - Coq Artifact},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11481248},
abstract = {
    <p>This artifact contains the Coq development accompanying the ICFP 2024 submission “Almost-Sure Termination by Guarded Refinement”.</p>
<p>coq-caliper.tar.gz contains the Coq development which includes a README with instructions for installing dependencies and building the development. The archive also contains PAPER that maps definitions and results from the paper to its formalization.</p>
<p>docker-caliper.tar.gz contains a pre-built Docker image with dependencies and the Coq development already installed. Suggested commands for loading, rebuilding, and interacting with the image is shown below. The Docker image is built using the instructions found in Dockerfile. Note that building the Dockerfile requires coq-caliper.tar.gz to be available in the same folder.</p>

},
keywords = {almost-sure termination, coq, probabilistic coupling, separation logic}
}

@software{10.5281/zenodo.11489778,
author = {Aguirre, Alejandro and Haselwarter, Philipp G. and de Medeiros, Markus and Li, Kwing Hei and Gregersen, Simon Oddershede and Tassarotti, Joseph and Birkedal, Lars},
title = {Error Credits: Resourceful Reasoning about Error Bounds for Higher-Order Probabilistic Programs - Coq Artifact},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11489778},
abstract = {
    <p>This is the artifact of the Eris logic, highlighted in the ICFP 2024 submission “Error Credits: Resourceful Reasoning about Error Bounds for Higher-Order Probabilistic Programs”.</p>
<p>The logic is built using the Iris program logic framework and mechanized in the Coq proof assistant.</p>
<p>This project is built on top of the Clutch project.</p>

},
keywords = {almost-sure termination, Coq, error bounds, error credits, Iris}
}

@software{10.5281/zenodo.11491613,
author = {Carette, Jacques and Heunen, Chris and Kaarsgaard, Robin and Sabry, Amr},
title = {Software for "How to Bake a Quantum Pi"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11491613},
abstract = {
    <p>Agda source code and qemu VM for the implementation of the programming language described in the paper. Also contains runnable tests as well as some proofs reasoning with programs in QuantumPi.</p>

},
keywords = {quantum programming language, reversible computing, rig category, unitary quantum computing}
}

@software{10.5281/zenodo.11494317,
author = {De Santo, No\'{e} and Barri\`{e}re, Aur\`{e}le and Pit-Claudel, Cl\'{e}ment},
title = {Artifact for "A Coq Mechanization of JavaScript Regular Expression Semantics" at ICFP 2024},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11494317},
abstract = {
    <p>The artifact consists of a virtual machine with our Coq mechanization, our proof scripts, and our auxiliary code (fuzzer, tests), as well as scripts to recreate the virtual machine from scratch.</p>

},
keywords = {Coq, ECMAScript, Mechanization, Regex}
}

@software{10.5281/zenodo.11500453,
author = {Ho, Son and Fromherz, Aymeric and Protzenko, Jonathan},
title = {Artifact for: Sound Borrow-Checking for Rust via Symbolic Semantics},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11500453},
abstract = {
    <h2 id="paper-abstract">Paper Abstract</h2>
<p>The Rust programming language continues to rise in popularity, and as such, warrants the close attention of the programming languages community. In this work, we present a new foundational contribution towards the theoretical understanding of Rust’s semantics. We prove that LLBC, a high-level, borrow-centric model previously proposed for Rust’s semantics and execution, is sound with regards to a low-level pointer-based language \`{a} la CompCert. Specifically, we prove the following: that LLBC is a correct view over a traditional model of execution; that LLBC’s symbolic semantics are a correct abstraction of LLBC programs; and that LLBC’s symbolic semantics act as a borrow-checker for LLBC, i.e.&nbsp;that symbolically-checked LLBC programs do not get stuck when executed on a heap-and-addresses model of execution.</p>
<p>To prove these results, we introduce a new proof style that considerably simplifies our proofs of simulation, which relies on a notion of hybrid states. Equipped with this reasoning framework, we show that a new addition to LLBC’s symbolic semantics, namely a join operation, preserves the abstraction and borrow-checking properties. This in turn allows us to add support for loops to the Aeneas framework; we show, using a series of examples and case studies, that this unlocks new expressive power for Aeneas.</p>
<h2 id="artifact-description">Artifact Description</h2>
<p>The artifact contains the Aeneas project modified to integrate the changes described in the paper to support loops (section 5). It also contains the tests we refer to in section 6. In addition to the virtual machine, we provide two different ways of building the sources and running the tests: - either you use <strong>nix</strong> (easy) - or you build the <strong>Rust</strong> and <strong>OCaml</strong> sources with cargo and dune (more work)</p>

},
keywords = {Compiler, Semantics}
}

@software{10.5281/zenodo.11500966,
author = {Winterhalter, Th\'{e}o},
title = {ICFP 2024 Artefact: Dependent Ghosts Have a Reflection for Free},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11500966},
abstract = {
    <p>Coq formalisation of the submission ‘Dependent Ghosts Have a Reflection for Free’.</p>
<p>A README is provided in the zip file. It also explains how to run the VM provided as a QEMU file (artefact.qcow2).</p>

},
keywords = {coq formalisation, dependent types, ghost data}
}

@software{10.5281/zenodo.11502426,
author = {Melquiond, Guillaume and Moreau, Josu\'{e}},
title = {A Safe Low-level Language for Computer Algebra and its Formally Verified Compiler},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11502426},
abstract = {
    <p>This is the artifact for submission A Safe Low-level Language for Computer Algebra and its Formally Verified Compiler at ICFP’24.</p>

},
keywords = {compiler, formal proof, programming language, safety}
}

@software{10.5281/zenodo.11507455,
author = {Kura, Satoshi and Unno, Hiroshi},
title = {Artifact for "Automated Verification of Higher-Order Probabilistic Programs via a Dependent Refinement Type System"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11507455},
abstract = {
    <p>The artifact is to reproduce the experimental result (Table 2) in the paper.</p>

},
keywords = {dependent refinement type system, higher-order program}
}

@software{10.5281/zenodo.11508050,
author = {Kurashige, Cole and Ji, Ruyi and Giridharan, Aditya and Barbone, Mark and Noor, Daniel and Itzhaky, Shachar and Jhala, Ranjit and Polikarpova, Nadia},
title = {CCLemma: E-Graph Guided Lemma Discovery for Inductive Equational Proofs},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11508050},
abstract = {
    <p>Artifact for ICFP’24: CCLemma: E-Graph Guided Lemma Discovery for Inductive Equational Proofs.</p>
<p>C.C. Lemma is a tool for automating equational proofs. It is implemented as a command-line tool that takes as input a file specifying inductive datatype definitions, function definitions, and equalities over these datatypes and functions. It attempts to prove each equality, optionally outputting a proof in Liquid Haskell*.</p>
<p>We include with our tool all of the datasets necessary to run the evaluation from our paper as well as scripts and instructions on how to reproduce our results. We also include the tools we evaluate against, which the scripts will also run.</p>
<p>Our code can be found at https://github.com/cole-k/cc-lemma/tree/icfp-24.</p>
<p>C.C. Lemma is implemented in Rust. At this time we do not expect there to be any special requirements for machines: modern laptops are sufficient, although even older machines ought to work fine. Some benchmarks, especially many in the optimization dataset, will run to timeout. We estimate running all benchmarks to take around 120 minutes in the worst-case; however, by default we set a much lower timeout so that testing the tool will only take a few minutes.</p>
<p>*Proof emission is experimental and not guaranteed to generate proofs that Liquid Haskell accepts, although users may find it useful to inspect the proofs to see how C.C. Lemma proved an equality.</p>

},
keywords = {Automated Theorem Proving, Equational Reasoning, Lemma Synthesis, Synthesis, Verification}
}

@software{10.5281/zenodo.12656335,
author = {Kov\'{a}cs, Andr\'{a}s},
title = {ICFP 2024 artifact - "Closure-Free Functional Programming in a Two-Level Type Theory"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12656335},
abstract = {
    <p>Artifact for the paper “Closure-Free Functional Programming in a Two-Level Type Theory”</p>

},
keywords = {staged compilation, two-level type theory}
}

@software{10.5281/zenodo.12659179,
author = {Vandenbogaerde, Bram and Sti\'{e}venart, Quentin and De Roover, Coen},
title = {Blame-Correct Support for Receiver Properties in Recursively-Structured Actor Contracts (Artifact)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12659179},
abstract = {
    <p>This replication package contains an executable semantics as a PLT-Redex implementation for the formalisation presented in the paper titled “Blame-Correct Support for Receiver Properties in Recursively-Structured Actor Contracts”. It also contains an implementation of our contract language in Racket. This implementation is used for testing all examples presented in the paper which are also included in the replication package. Finally, the replication package also contains a virtual machine image which contains all prerequisites for running the replication package.</p>

},
keywords = {actors, design-by-contract, formalisation, plt-redex, racket}
}

@software{10.5281/zenodo.12684335,
author = {Elsman, Martin},
title = {Artifact for the ICFP 2024 paper Double-Ended Bit-Stealing for Algebraic Data Types},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12684335},
abstract = {
    <p>The artifact aims at replicating the performance results reported in the paper.</p>

},
keywords = {Compilation, Data-type representations, Functional languages, Unboxing}
}

@software{10.5281/zenodo.12702677,
author = {Chen, Jiawei and de Mendon\c{c}a, Jos\'{e} Luiz Vargas and Ayele, Bereket Shimels and Bekele, Bereket Ngussie and Jalili, Shayan and Sharma, Pranjal and Wohlfeil, Nicholas and Zhang, Yicheng and Jeannin, Jean-Baptiste},
title = {Artifact for "Synchronous Programming with Refinement Types"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12702677},
abstract = {
    <p>Experimental data, source code, and an executable artifact image for MARVeLus, based on the Z\'{e}lus project.</p>

},
keywords = {refinement types, robotics, synchronous programming}
}

@software{10.5281/zenodo.12704905,
author = {Binder, David and Tzschentke, Marco and M\"{u}ller, Marius and Ostermann, Klaus},
title = {Grokking the Sequent Calculus (Artifact)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12704905},
abstract = {
    <p>A Haskell implementation of the algorithms described in the paper, together with a parser and type inference algorithm for the surface language. Code snippets can be run either on the console or via a web interface.</p>

},
keywords = {compiler, intermediate representations, sequent calculus}
}

@software{10.5281/zenodo.12792675,
author = {Serrano, Manuel and Findler, Robert Bruce},
title = {The Functional, the Imperative, and the Sudoku (artifact)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.12792675},
abstract = {
    <p>This artifact will let you run the HipHop solver described in the companion paper and let you conduct some experiments with new puzzles and solver extensions. The objective is to offer you a taste of programming in HipHop. For that, first, we briefly present the structure and organization of the solver and then we suggest three assignments to get you familiar with HipHop and the codebase.</p>
<p>The artifact has no special requirement. It can be run within the provided virtual machine or installed locally using the GIT repository:</p>
<pre><code>The VM can be download at: https://zenodo.org/records/11481893
The source of the artifact is available at: https://github.com/manuel-serrano/icfp2024-sudoku</code></pre>

},
keywords = {Esterel, HipHop, JavaScript, Sudoku}
}

@software{10.5281/zenodo.11070973,
author = {Beyer, Dirk and Chien, Po-Chun and Jankola, Marek and Lee, Nian-Ze},
title = {Reproduction Package for FSE 2024 Article `A Transferability Study of Interpolation-Based Hardware Model Checking for Software Verification'},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11070973},
abstract = {
    <p>This artifact is a reproduction package for the article “A Transferability Study of Interpolation-Based Hardware Model Checking for Software Verification”, accepted at FSE 2024. It is archived on Zenodo with the DOI 10.5281/zenodo.11070973.</p>
<p>The FSE article investigates the transferability of the claims reported in two prior publications on interpolation-based hardware model checking to software verification. The two publications are (1) Interpolation-Sequence-Based Model Checking (Vizel and Grumberg, 2009) and (2) Intertwined Forward-Backward Reachability Analysis Using Interpolants (Vizel, Grumberg, and Shoham, 2013), proposing model-checking algorithms ISMC and DAR for hardware circuits, respectively. In the FSE article, we adopted ISMC and DAR for programs and implemented them in a software-verification framework CPAchecker. This artifact supports the reproduction of the experiments in the FSE article, which compared the implementations of ISMC and DAR against existing interpolation-based verification techniques in CPAchecker, including IMC (McMillan, 2003), Impact (McMillan, 2006), and PredAbs (Henzinger, Jhala, Majumdar, and McMillan, 2004), to validate the claims in the above two publications as well as investigate their performance characteristics versus classical approaches for software verification.</p>
<p>The artifact consists of source code, precompiled executables, and input data used in the evaluation of the transferability study, as well as the results produced from the experiments. Specifically, it includes the source code and binaries of CPAchecker (at revision 45787 of branch “itp-mc-with-slt”), which implements the verification algorithms compared in the article, the SV-COMP 2023 benchmark suite, the experimental data generated from the evaluation, and instructions to run the tools and experiments.</p>
<p>This reproduction package works best with the SoSy-Lab Virtual Machine, which runs Ubuntu 22.04 LTS and has all the required dependencies installed. If you test this artifact with this VM, you do not need to install any package.</p>
<p>By default, we assign 2 CPU cores, 15 GB of memory, and 1800 s of CPU time limit to each verification task. A full reproduction of all experiments took more than 10 months of CPU time on our machines. For demonstration purposes, a subset of the benchmark tasks can be executed, which requires roughly 2 hours of CPU time in total.</p>

},
keywords = {CPAchecker, Craig Interpolation, Formal Verification, Invariant Synthesis, Model Checking, Program Analysis, Replicability, Reproducibility, Software Verification, Transferability}
}

@software{10.5281/zenodo.10570961,
author = {Birchler, Christian and Mohammed, Tanzil Kombarabettu and Rani, Pooja and Nechita, Teodora and Kehrer, Timo and Panichella, Sebastiano},
title = {Replication Package - "How does Simulation-based Testing for Self-driving Cars match Human Perception?"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10570961},
abstract = {
    <p>Software metrics such as coverage and mutation scores have been extensively explored for the automated quality assessment of test suites. While traditional tools rely on such quantifiable software metrics, the field of self-driving cars (SDCs) has primarily focused on simulation-based test case generation using quality metrics such as the out-of-bound (OOB) parameter to determine if a test case fails or passes. However, it remains unclear to what extent this quality metric aligns with the human perception of the safety and realism of SDCs, which are critical aspects in assessing SDC behavior. To address this gap, we conducted an empirical study involving 50 participants to investigate the factors that determine how humans perceive SDC test cases as safe, unsafe, realistic, or unrealistic. To this aim, we developed a framework leveraging virtual reality (VR) technologies, called SDC-Alabaster, to immerse the study participants into the virtual environment of SDC simulators. Our findings indicate that the human assessment of the safety and realism of failing and passing test cases can vary based on different factors, such as the test’s complexity and the possibility of interacting with the SDC. Especially for the assessment of realism, the participants’ age as a confounding factor leads to a different perception. This study highlights the need for more research on SDC simulation testing quality metrics and the importance of human perception in evaluating SDC behavior.</p>

},
keywords = {Human Perception, Self-driving Cars, Simulation, Software Testing, VR}
}

@software{10.5281/zenodo.10656106,
author = {Xiao, Tao and Hata, Hideaki and Treude, Christoph and Matsumoto, Kenichi},
title = {Research Artifact - Generative AI for Pull Request Descriptions: Adoption, Impact, and Developer Interventions},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10656106},
abstract = {
    <p>This is a research artifact for “Generative AI for Pull Request Descriptions: Adoption, Impact, and Developer Interventions”. This artifact is a repository that includes lists of studied PRs from GitHub, both with and without the use of Copilot for PRs. It also provides the features of PRs that were either generated or not generated by Copilot for PRs (pertaining to RQ2), coding results for RQ3, and scripts. The purpose of this artifact is enabling researchers to replicate our results of the paper, and to reuse our dataset of Copilot for PRs for further research.</p>

},
keywords = {Copilot, Generative AI, GitHub, Pull Requests}
}

@software{10.5281/zenodo.10669580,
author = {Kim, Tae Eun and Choi, Jaeseung and Im, Seongjae and Heo, Kihong and Cha, Sang Kil},
title = {Evaluating Directed Fuzzers: Are We Heading in the Right Direction? (Paper Artifact)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10669580},
abstract = {
    <p>A research artifact associated with the paper “Evaluating Directed Fuzzers: Are We Heading in the Right Direction?” (FSE 2024). This artifact provides the end-to-end system to reproduce the experiments in the paper either by running the experiment or analyzing the experimental data used in the paper.</p>

},
keywords = {Directed fuzzing, Fuzz testing, Fuzzer evaluation}
}

@software{10.5281/zenodo.11068809,
author = {Zhang, Zhaoxu and Tawsif, Fazle Mohammed and Ryu, Komei and Yu, Tingting and Halfond, William G. J.},
title = {Reproduction Package for "Mobile Bug Report Reproduction via Global Search on the App UI Model"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11068809},
abstract = {
    <p>This is the artifact of the paper “Mobile Bug Report Reproduction via Global Search on the App UI Model” accepted by FSE 2024.</p>

},
keywords = {Bug Report Reproduction}
}

@software{10.5281/zenodo.11069504,
author = {Haroon, Sabaat and Brown, Chris and Gulzar, Muhammad Ali},
title = {Reproduction package for "DeSQL: Interactive Debugging of SQL in Data-Intensive Scalable Computing".},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11069504},
abstract = {
    <p>DeSQL artifacts provide clear and detailed documentation that guides users through a verified local setup process, ensuring the system is both functional and resuable, which streamlines the experience from installation to utilization.</p>

},
keywords = {data intensive scalable computing, Debugging, SQL}
}

@software{10.5281/zenodo.11072823,
author = {Gong, Jingzhi and Chen, Tao},
title = {Artifact Repository for Paper "Predicting Configuration Performance in Multiple Environments with Sequential Meta-Learning"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11072823},
abstract = {
    <p>This repository contains the key codes, full data used, raw experiment results, and the supplementary tables for the paper.</p>

},
keywords = {configuration performance learning, configuration performance prediction, deep learning, highly configurable software, machine learning, meta-learning, software engineering}
}

@software{10.5281/zenodo.11077099,
author = {Cheng, Xiao and Ren, Jiawei and Sui, Yulei},
title = {Fast Graph Simplification for Path-Sensitive Typestate Analysis through Tempo-Spatial Multi-Point Slicing (Artifact)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11077099},
abstract = {
    <p>This artifact is for Fast Graph Simplification for Path-Sensitive Typestate Analysis through Tempo-Spatial Multi-Point Slicing by Xiao Cheng, Jiawei Ren and Yulei Sui published at FSE 2024. The artifact can be reused to analyze customized programs. The source code can also be modified to fit specific needs.</p>
<p>Typestate analysis is a commonly used static technique to identify software vulnerabilities by assessing if a sequence of operations violates temporal safety specifications defined by a finite state automaton. Path-sensitive typestate analysis (PSTA) offers a more precise solution by eliminating false alarms stemming from infeasible paths. To improve the efficiency of path-sensitive analysis, previous efforts have incorporated sparse techniques, with a focus on analyzing the path feasibility of def-use chains. However, they cannot be directly applied to detect typestate vulnerabilities requiring temporal information within the control flow graph, e.g., use-to-use information.</p>
<p>In this paper, we introduce FGS, a Fast Graph Simplification approach designed for PSTA by retaining multi-point temporal information while harnessing the advantages of sparse analysis. We propose a new multi-point slicing technique that captures the temporal and spatial correlations within the program. By doing so, it optimizes the program by only preserving the necessary program dependencies, resulting in a sparser structure for precision-preserving PSTA. Our graph simplification approach, as a fast preprocessing step, offers several benefits for existing PSTA algorithms. These include a more concise yet precision-preserving graph structure, decreased numbers of variables and constraints within execution states, and simplified path feasibility checking. As a result, the overall efficiency of the PSTA algorithm exhibits significant improvement.</p>
<p>We evaluated FGS using NIST benchmarks and ten real-world large-scale projects to detect four types of vulnerabilities, including memory leaks, double-frees, use-after-frees, and null dereferences. On average, when comparing FGS against ESP (baseline PSTA), FGS reduces 89\% of nodes, 86\% of edges, and 88\% of calling context of the input graphs, obtaining a speedup of 116<span class="math inline">\texttimes{}</span> and a memory usage reduction of 93\% on the large projects evaluated. Our experimental results also demonstrate that FGS outperforms six open-source tools (IKOS, ClangSA , Saber, Cppcheck, Infer, and Sparrow) on the NIST benchmarks, which comprises 846 programs. Specifically, FGS achieves significantly higher precision, with improvements of up to 171\% (42\% on average), and detects a greater number of true positives, with enhancements of up to 245\% (52\% on average). Moreover, among the ten large-scale projects, FGS successfully found 105 real bugs with a precision rate of 82\%. In contrast, our baseline tools not only missed over 42\% of the real bugs but also yielded an average precision rate of just 13\%.</p>

},
keywords = {Graph simplification, Multi-point slicing, Path-sensitive typestate analysis}
}

@software{10.5281/zenodo.11090237,
author = {Wu, Yaoxuan and Humayun, Ahmad and Gulzar, Muhammad Ali and Kim, Miryung},
title = {Reproduction Package for Article "Natural Symbolic Execution-based Testing for Big Data Analytics"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11090237},
abstract = {
    <p>This artifact includes NaturalSym, a symbolic-execution-based test generator. Given subject DISC programs, NaturalSym can produce high path-coverage and natural-looking test cases. This package contains both NaturalSym itself and all the necessary components to reproduce our evaluation results.</p>

},
keywords = {DISC Applications, Naturalness, Symbolic Execution}
}

@software{10.5281/zenodo.11091402,
author = {Yoon, Jaehan and Cha, Sooyoung},
title = {(Artifact Evaluation) FeatMaker: Automated Feature Engineering for Search Strategy of Symbolic Execution},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11091402},
abstract = {
    <p>FeatMaker is a novel technique that automatically generates state features to enhance the search strategy of symbolic execution. This technique is implemented on the top of KLEE, a widely adopted symbolic execution tool for testing C programs.</p>

},
keywords = {software testing, Symbolic execution}
}

@software{10.5281/zenodo.11094092,
author = {Pham, Luan and Ha, Huong and Zhang, Hongyu},
title = {Software Artifact for "BARO: Robust Root Cause Analysis for Microservices via Multivariate Bayesian Online Change Point Detection"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11094092},
abstract = {
    <p>This repository contains the Software Artifact for reproducing the main experimental results in our paper accepted to FSE 2024: “BARO: Robust Root Cause Analysis for Microservices via Multivariate Bayesian Online Change Point Detection”</p>
<p>The artifact is also available in the Github repository: https://github.com/phamquiluan/baro</p>

},
keywords = {Anomaly Detection, Microservice Systems, Root Cause Analysis}
}

@software{10.5281/zenodo.11095172,
author = {Bittner, Paul Maximilian and Schulthei\ss{}, Alexander and Moosherr, Benjamin and Kehrer, Timo and Th\"{u}m, Thomas},
title = {Demo for Article 'Variability-Aware Differencing with DiffDetective'},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11095172},
abstract = {
    <p>This is a small demonstration of <a href="https://github.com/VariantSync/DiffDetective">DiffDetective</a> (DOI: 10.5281/zenodo.11095140), and the supplementary artifact to our paper <em>Variability-Aware Differencing with DiffDetective</em>. The purpose of this demo is to provide an example of how to use DiffDetective and to serve as a template project for you to clone and adapt as a quickstart for developing with DiffDetective. There is a screencast available on YouTube, guiding you through the demo’s setup with Maven in IntelliJ and how to implement variability-aware differencing and analyses of Git histories. For further information (including installation instructions and documentation) please head to the respective <a href="https://github.com/VariantSync/DiffDetective-Demo">website</a> or <a href="https://doi.org/10.5281/zenodo.11095172">archive</a>.</p>

},
keywords = {software evolution, software product lines, software variability}
}

@software{10.5281/zenodo.11095274,
author = {Drosos, Georgios-Petros and Sotiropoulos, Thodoris and Spinellis, Diomidis and Mitropoulos, Dimitris},
title = {Artifact for "Bloat beneath Python's Scales: A Fine-Grained Inter-Project Dependency Analysis"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11095274},
abstract = {
    <p>This artifact complements the FSE’24 paper titled “Bloat beneath Python’s Scales: A Fine-Grained Inter-Project Dependency Analysis” by providing comprehensive resources for reproducing its research findings. The artifact includes a meticulously structured dataset, comprising of the code bloat metrics of 1,302 Python projects and their 3,232 dependencies analyzed in the paper. It offers detailed scripts and tools for analyzing software bloat at multiple granular levels—dependencies, files, and methods and reproducing the tables and figures presented in the paper. Additionally, the artifact provides step-by-step instructions for reapplying these analyses and for constructing fine-grained project dependency graphs (FPDGs). Moreover, it includes data on identified software vulnerabilities within bloated code sections, enabling users to recreate the vulnerability assessment presented in the paper. The DOI of the artifact is the following: https://doi.org/10.5281/zenodo.11095274</p>

},
keywords = {call graph, debloating, dependencies, PyPI}, Python, software bloat}
}

@software{10.5281/zenodo.11097202,
author = {Bouzenia, Islem and Krishan, Bajaj Piyush and Pradel, Michael},
title = {DyPyBench Docker Image},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11097202},
abstract = {
    <p>The first benchmark of Python projects that is large-scale, diverse, ready-to-run (i.e., with fully configured and prepared test suites), and ready-to-analyze (i.e., using an integrated Python dynamic analysis framework). The benchmark encompasses 50 popular open-source projects from various application domains, with a total of 681K lines of Python code, and 30K test cases.</p>

},
keywords = {Benchmarking of Software Systems, Executable collection of software, Program analysis, Python}
}

@software{10.5281/zenodo.11194557,
author = {Chen, Zhiyang and Liu, Ye and Beillahi, Sidi Mohamed and Li, Yi and Long, Fan},
title = {Reproduction package of the paper "Demystifying Invariant Effectiveness for Securing Smart Contracts"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11194557},
abstract = {
    <p>This artifact accompanies the paper titled “Demystifying Invariant Effectiveness for Securing Smart Contracts” and provides the source code along with a complete replication package. The purpose of this artifact is to facilitate the validation and reproduction of the research results presented in the paper. Users can explore the methodologies, execute the provided scripts, and verify the findings by using this carefully prepared package.</p>
<p>The main artifact repo is https://github.com/Trace2Inv-Artifact/Trace2Inv-Artifact-FSE24.git, which also contains instructions for using Docker</p>
<p>For results related to the invariant study discussed in the paper, please refer to a separate repository available at <a href="https://github.com/Trace2Inv-Artifact/Trace2Inv-Invariant-Study-FSE24">another separate repository</a></p>
<p>For benchmarks used in this paper, please refer to a separate repository available at <a href="https://github.com/Trace2Inv-Artifact/Trace2Inv-Benchmarks">another separate repository</a></p>

},
keywords = {Blockchain, Dynamic Analysis, Invariant Generation, Program Analysis, Runtime Guard, Security, Smart Contract}
}

@software{10.5281/zenodo.11406940,
author = {Chen, Yuntianyi and Huai, Yuqi and Li, Shilong and Hong, Changnam and Garcia, Joshua},
title = {ConfVE},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11406940},
abstract = {
    <p>Source code and data of ConfVE</p>

},
keywords = {Autonomous driving systems, Software configuration}
}

@software{10.5281/zenodo.11528723,
author = {Landauer, Max and Skopik, Florian and Wurzenberger, Markus},
title = {Reproduction package for article "A Critical Review of Common Log Data Sets Used for Evaluation of Sequence-Based Anomaly Detection Techniques"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11528723},
abstract = {
    <p>The repository contains scripts to analyze publicly available log data sets (HDFS, BGL, OpenStack, Hadoop, Thunderbird, ADFA, AWSCTD) that are commonly used to evaluate sequence-based anomaly detection techniques. The repository contains documentation and code to get the data sets, parse and group them into sequences of event types, and apply some basic anomaly detection techniques. The repository also comes with some pre-processed samples in each data set directory, which allow to get started without having to download all the data sets.</p>

},
keywords = {anomaly detection, data sets, log data analysis}
}

@software{10.5281/zenodo.11563223,
author = {Beyer, Dirk and Kettl, Matthias and Lemberger, Thomas},
title = {Reproduction Package for FSE 2024 Article `Decomposing Software Verification Using Distributed Summary Synthesis'},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11563223},
abstract = {
    <h2 id="distributed-summary-synthesis">Distributed Summary Synthesis</h2>
<p>We distribute the verification of a single task by dividing the task into smaller verification tasks. We communicate new pre- and violation conditions through messages.</p>
<p>VM username: vagrant VM password: vagrant</p>
<h3 id="system-requirements">System Requirements</h3>
<p>The artifact requires 8 CPU cores and 16 GB of RAM. Additionally, we require 15 GB of empty disk space. The VM was tested on Ubuntu 22.04 with Virtual Box Version 7.0.10 r158379 (Qt5.15.3).</p>
<h3 id="implementation">Implementation</h3>
<p>The core parts of the implementation of DSS can be found in the package <code>~/DSS/cpachecker/src/org/sosy_lab/cpachecker/core/algorithm/distributed_summaries</code>. It contains several packages: - <code>block_analysis</code> (The DSS algorithm) - <code>decomposition</code> (All available decomposition algorithms) - <code>distributed_cpa</code> ((De-)serialization of abstract states for different CPAs) - <code>exchange</code> (Definitions of messages) - <code>visualization</code> (Utility for exporting an HTML report of DSS) - <code>worker</code> (The actors of the actor model) Additionally, we added a BlockCPA to ensure that CPAcheckers’ analysis stays within the assigned block. Its implementation can be found in the package <code>~/DSS/cpachecker/src/org/sosy_lab/cpachecker/cpa/block</code>.</p>
<h3 id="reproduction">Reproduction</h3>
<h4 id="reproduce-the-example-in-the-paper">Reproduce the Example in the Paper</h4>
<p>Navigate to <code>~/DSS</code> and execute <code>./example.sh test/programs/block_analysis/abstraction_safe.c</code>.</p>
<p>CPAchecker will decompose the example program in blocks and verify the program using DSS. The example program is located at <code>~/DSS/cpachecker/test/programs/block_analysis/abstraction_safe.c</code> After DSS finished, an HTML page containing the block graph and a table of messages automatically appears. We use a simplified version of the block graph in our paper, however, the idea and the verification works as described in the paper. In case, it does not appear automatically, execute <code>open ~/DSS/cpachecker/output/block_analysis/visualized/report.html</code>.</p>
<p>Red messages represent violation conditions (ERROR_CONDITION). Yellow messages represent preconditions (BLOCK_POSTCONDITION). The column of the message indicates which block sent the message. On the far left, the passed time in nanoseconds since the start of the execution is displayed.</p>
<p>We observe that blocks “L1” and “L2” send the summary “x = y”. No new violation conditions emerge, therefore DSS finds a proof (FOUND_RESULT in green).</p>
<p>We expect the last messages of “L1” and “L2” in the automatically opened browser tab to look like this:</p>
<pre><code>↓ React to message from &lt;SNIP&gt; (ID: &lt;SNIP&gt;):

Calculated new BLOCK_POSTCONDITION message for &lt;SNIP&gt;

{"readable":"(`=_T(18)` main::x@1 main::y@1)"}</code></pre>
<p>The last lines in the terminal should look like this:</p>
<pre><code>&lt;--SNIP--&gt;
Starting analysis ... (CPAchecker.runAlgorithm, INFO)

Starting block analysis... (BlockSummaryAnalysis.run, INFO)

Decomposed CFA in 6 blocks using the MERGE_DECOMPOSITION. (BlockSummaryAnalysis.run, INFO)

Block analysis finished. (BlockSummaryAnalysis.run, INFO)

Stopping analysis ... (CPAchecker.runAlgorithm, INFO)

Verification result: TRUE. No property violation found by chosen configuration.
More details about the verification run can be found in the directory "./output".
Graphical representation included in the file "./output/Report.html".</code></pre>
<p>Script <code>~/DSS/more_examples.sh</code> runs DSS on more examples with subsequent visual output. DSS should finish verification of programs with the postfix "_safe" in the filename with</p>
<pre><code>Verification result: TRUE. No property violation found by chosen configuration.</code></pre>
<p>and with</p>
<pre><code>Verification result: FALSE. Property violation found by chosen configuration.
More details about the verification run can be found in the directory "./output".</code></pre>
<p>if the postfix is "_unsafe".</p>
<h4 id="reproduce-the-plots-in-the-paper">Reproduce the Plots in the Paper</h4>
<p>Navigate to <code>~/DSS</code> and execute <code>./reproduce-plots.sh</code>.</p>
<p>The script runs <code>./evaluation.py paper-csvs</code> on our original data in <code>paper-csvs</code>. A short while later, the directory <code>~/DSS/plots</code> should open automatically. It contains all reproduced plots. The filenames equal the figure/table numbers in the paper.</p>
<p>For a fast comparison, we copied the original plots to <code>~/DSS/paper-plots</code>. Note that rerunning the script, forcefully removes the directory <code>~/DSS/plots</code> before reproducing them again.</p>
<p>We expect the following output in the terminal:</p>
<pre><code>=======Loading CSVs=======
paper-csvs/forward2.csv has 2549 results for SoftwareSystems.
paper-csvs/dcpa4.csv has 2549 results for SoftwareSystems.
paper-csvs/dcpa8.csv has 2549 results for SoftwareSystems.
paper-csvs/kind.csv has 2549 results for SoftwareSystems.
paper-csvs/dcpa2.csv has 2549 results for SoftwareSystems.
paper-csvs/dcpa1.csv has 2549 results for SoftwareSystems.
paper-csvs/imc.csv has 2549 results for SoftwareSystems.
==========================

Task with most threads (unsolved): 751
Task with most threads (solved): 476 

===Analysis of Overhead===
dcpa8backward analysis time (s)    45.719659
dcpa8decomposition time (s)         0.078870
dcpa8deserialization time (s)      53.193505
dcpa8forward analysis time (s)     21.183128
dcpa8instrumentation time (s)       0.081529
dcpa8proceed time (s)               6.998556
dcpa8serialization time (s)         1.064093
dcpa8cputime (s)                   88.211899
overhead                           54.417997
dtype: float64

Data in sections 'Communication Model' and 'Choice of Decomposition':
Decomposition takes 0.18183334764521225 \% of overall time
Packing takes 1.2062918037371835 \% of overall time
Unpacking takes 60.30196127528197 \% of overall time
==========================

Removed 64 tasks because they contain unsupported features.

Max. speed-up in parallel portfolio 15.912337391444877 

=======Unique tasks=======
ERROR                58
TIMEOUT               2
ERROR (recursion)     1
Name: imcstatus, dtype: int64
DCPA solved 61 tasks uniquely, compared to IMC
ERROR (recursion)    5
TIMEOUT              2
Name: kindstatus, dtype: int64
DCPA solved 7 tasks uniquely, compared to k-Induction
TIMEOUT              9
ERROR (recursion)    4
OUT OF MEMORY        1
Name: forward2status, dtype: int64
DCPA solved 14 tasks uniquely, compared to predicate analysis
==========================
Plots are reproduced and named accordingly</code></pre>
<p>Note that 2549 - 64 = 2485 equals the number of benchmark tasks we describe in the paper.</p>
<h4 id="reproduce-the-experiments">Reproduce the Experiments</h4>
<p>Navigate to <code>~/DSS</code> and execute <code>./reproduce-all.sh</code>.</p>
<p>After a month of computations, the directory containing all plots named according to the number of the respective figure/table in the paper should appear automatically. We store the plots in <code>~/DSS/plots</code>.</p>
<p>Benchexec stores the raw data of the benchmarks in <code>~/DSS/cpachecker/test/results</code>. The CSVs of the raw data are stored in <code>~/DSS/csvs-reproduced</code>. To reproduce the plots with the newly obtained raw data without executing the benchmarks again, run <code>./evaluation.csv csvs-reproduced</code> from <code>~/DSS</code>.</p>
<p>ATTENTION: Rerunning <code>./reproduce-all.sh</code> removes all results in <code>~/DSS/csvs-reproduced</code> and <code>~/DSS/cpachecker/test/results</code> and the progress will be lost.</p>
<p>30 seconds after executing the shell script the output in the terminal should be similar to:</p>
<pre><code>vagrant@vagrant:~/DSS$ ./reproduce-all.sh 
2024-04-30 22:21:02 - WARNING - Ignoring specified resource requirements in local-execution mode, only resource limits are used.
2024-04-30 22:21:02 - INFO - Unable to find pqos_wrapper, please install it for cache allocation and monitoring if your CPU supports Intel RDT (cf. https://gitlab.com/sosy-lab/software/pqos-wrapper).

executing run set 'DCPA1'     (2983 files)
2024-04-30 22:21:02 - INFO - LXCFS is not available, some host information like the uptime leaks into the container.
22:21:02   aws-c-common/aws_add_size_checked_harness.yml                                                                                                                                      EXCEPTION                   18.74   18.90
&lt;--SNIP--&gt;               </code></pre>
<h4 id="reproduce-a-subset">Reproduce a Subset</h4>
<p>Navigate to <code>~/DSS</code> and execute <code>./reproduce-selection.sh</code>.</p>
<p>The script runs our full pipeline of our evaluation on a small subset of 11 tasks. The small selection should illustrate that, in general, the work distributes better when more cores are available and that there are tasks that DSS solves faster than standard predicate analysis (and vice-versa). Additionally, it creates all plots using the newly obtained data.</p>
<p>After approximately 30 minutes, the directory containing all plots appear automatically. The plots are named after the figure/table number in the paper. We store the plots in <code>~/DSS/plots</code>.</p>
<p>The selection contains one unsafe task (a task where function reach_error is indeed reachable) to illustrate DSS’s capability of finding violations. However, as stated in the paper, the evaluation focuses on safe programs. Therefore, the unsafe tasks does not appear in the generated plots/tables.</p>
<p>Benchexec stores the raw data of the benchmarks in <code>~/DSS/cpachecker/test/results</code>. The CSVs of the raw data are stored in <code>~/DSS/csvs-reproduced</code>. To reproduce the plots with the newly obtained raw data without executing the benchmarks again, run <code>./evaluation.csv csvs-selected</code> from <code>~/DSS</code>.</p>
<p>ATTENTION: Rerunning <code>./reproduce-selection.sh</code> removes all results in <code>~/DSS/csvs-selected</code> and <code>~/DSS/cpachecker/test/results</code> and the progress will be lost.</p>
<p>90 seconds after executing the shell script the output in the terminal should be similar to:</p>
<pre><code>vagrant@vagrant:~/DSS$ ./reproduce-selection.sh 
2024-04-30 21:59:46 - WARNING - Ignoring specified resource requirements in local-execution mode, only resource limits are used.
2024-04-30 21:59:46 - INFO - Unable to find pqos_wrapper, please install it for cache allocation and monitoring if your CPU supports Intel RDT (cf. https://gitlab.com/sosy-lab/software/pqos-wrapper).

executing run set 'DCPA1.ReachSafety-Selection'     (11 files)
2024-04-30 21:59:46 - INFO - LXCFS is not available, some host information like the uptime leaks into the container.
21:59:46   ldv-linux-3.4-simple/43_1a_cilled_ok_nondet_linux-43_1a-drivers--char--tpm--tpm_nsc.ko-ldv_main0_sequence_infinite_withcheck_stateful.cil.out.yml                            true                        36.69   37.13
22:00:23   ldv-linux-3.4-simple/43_1a_cilled_ok_nondet_linux-43_1a-drivers--watchdog--sch311x_wdt.ko-ldv_main0_sequence_infinite_withcheck_stateful.cil.out.yml                         true                        42.26   43.08
22:01:07   ldv-linux-3.4-simple/43_1a_cilled_ok_nondet_linux-43_1a-drivers--watchdog--it8712f_wdt.ko-ldv_main0_sequence_infinite_withcheck_stateful.cil.out.yml                         true
&lt;--SNIP--&gt;               </code></pre>
<h4 id="interpret-the-data">Interpret the Data</h4>
<h5 id="benchexec">Benchexec</h5>
<p>Benchexec produces XML results files. They keep track of the used memory, the consumed response time (walltime) and the consumed CPU time per task. Since the data is barely readable for humans, we create CSV files in <code>~/DSS/csvs</code>. The data is organized in a nice table where the columns list the consumed resources per task (row).</p>
<h5 id="plots">Plots</h5>
<p>The plots as described in the paper are stored in <code>~/DSS/paper-plots</code> or can be found in <code>~/DSS/plots</code> after running a reproduction script.</p>
<h3 id="artifact-structure">Artifact Structure</h3>
<p>All tools and data are stored in <code>~/DSS</code>. The VM comes with pre-installed and pre-configured benchexec 3.16. CPAchecker is installed in <code>~/DSS/cpachecker</code>. The SV-COMP benchmark set is cloned into <code>~/DSS/sv-benchmarks</code>. In the beginning, <code>~/DSS</code> contains the following files: - <code>~/DSS/evaluation.py</code>: Python script to reproduce the plots. - <code>~/DSS/example.sh</code>: Shell script to reproduce the example in the paper with CPAchecker - <code>~/DSS/LICENSE</code>: LICENSE of the artifact. - <code>~/DSS/ReadMe.md</code>: This file. - <code>~/DSS/removed.txt</code>: 64 excluded tasks from the benchmark set due to unsupported features. - <code>~/DSS/reproduce-all.sh</code>: Script to reproduce the full evaluation. - <code>~/DSS/reproduce-selection.sh</code>: Script to reproduce parts of our evaluation. - <code>~/DSS/reproduce-plots.sh</code>: Script to reproduce all plots on the raw data of our runs. - <code>~/DSS/requirements.md</code>: Lists all requirements and shows what which commands we executed to create this VM. - <code>~/DSS/requirements.txt</code>: List of required and already installed python packages. - <code>~/DSS/software-systems.csv</code>: All tasks belonging to the software-systems category of SV-benchmarks. - <code>~/DSS/INSTALL.md</code>: Instructions for installing CPAchecker and how to check if the VM works as intended. - <code>~/DSS/more_examples.sh</code>: A small collection of examples including visual representation after calculation finished.</p>

},
keywords = {Block Summaries, Decomposition Strategies, Parallelization, Program Analysis, Software Model Checking}
}

@software{10.5281/zenodo.8388488,
author = {Song, Yahui and Gao, Xiang and Li, Wenhua and Chin, Wei-Ngan and Roychoudhury, Abhik},
title = {ProveNFix: Temporal Property guided Program Repair},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8388488},
abstract = {
    <p>This is the supporting data from a paper submission to FSE24, including the source code and the benchmarks, by the time of the submission.</p>
<p>However, please check out the latest implementation and documentation (and paper) on Github: https://github.com/songyahui/infer_TempFix.</p>
<p>The summary of all the bugs in different projects is in the folder “notes.zip”; the appendixes are attached.</p>
<p>We recommend you to try out our docker image with all the benchmarked integrated and configured inside:</p>
<p>https://github.com/songyahui/infer_TempFix/blob/main/ProveNFix_Artifact_Evaluation.pdf</p>

},
keywords = {Design Science, Program analysis, Program repair, Program synthesis, Programming languages}
}

@software{10.6084/m9.figshare.25999807.v1,
author = {Misu, Md Rakib Hossain and Lopes, Cristina V. and Ma, Iris and Noble, James},
title = {Artifacts@FSE24: Towards AI-Assisted Synthesis of Verified Dafny Methods},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.25999807.v1},
abstract = {
    <p>This release presents the artifact of our work “Towards AI-Assisted Synthesis of Verified Dafny Methods.” This release has been reviewed in FSE24@Artifacts-Evaluation.</p>
<p>In this work, we conduct the first empirical study of LLMs synthesizing verifiable Dafny methods. Using 178 programming problems from the MBPP dataset, we prompt two contemporary models (GPT-4 and PaLM-2) to synthesize methods in Dafny. We demonstrate that a prompt following the principles of Chain of Thought (CoT) with semantically similar few-shot examples explaining how to decompose a problem step-by-step, can synthesize verified and correct Dafny methods with meaningful specifications for 58\% of problems in our test dataset.</p>
<p>The primary purpose of this artifact is to provide a benchmark dataset MBPP-DFY-153, a collection of 153 programming problems with specifications, solutions, and tests in/for Dafny, based on the MBPP (Mostly Basic Python Programming) dataset curated by Google Research. By executing our scripts, researchers should be able to try different prompts and synthesize Dafny methods from natural language problem descriptions. Scripts are also available to run verification and tests for all verified Dafny methods.</p>
<p>This release has been prepared to claim three badges: “Available”, “Reusable” and “Functional”. For a thorough evaluation of our artifact, we suggest that reviewers have familiarity with Dafny, and its installation, Bash scripts, and UNIX command-line operations. Artifacts related to our paper are publicly accessible in our GitHub repository at Artifacts@FSE24-Reviewed.</p>

},
keywords = {Dafny, LLM, Program Synthesis, Program Verification}
}

@software{10.5281/zenodo.10723168,
author = {Chatterjee, Krishnendu and Goharshady, Ehsan Kafshdar and Novotn\'{y}, Petr and \v{Z}ikeli\'{c}, undefinedor\dj{}e},
title = {Equivalence and Similarity Refutation for Probabilistic Programs},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10723168},
abstract = {
    <p>This repository contains the artifact of the paper titled “Equivalence and Similarity Refutation for Probabilistic Programs” accepted at PLDI 2024.</p>
<p>The tool takes two probabilistic transition systems with specified initial configurations as input and based on user preferences either (i) tries to prove whether the two programs generate equivalent output distributions, or (ii) tries to find a lowerbound on Kantorovich distance between the output distributions of the input programs.</p>

},
keywords = {Kantorovich distance, Martingales, Probabilistic programming, Probability distribution equivalence, Static program analysis}
}

@software{10.5281/zenodo.10729070,
author = {Yuan, Charles and Carbin, Michael},
title = {The T-Complexity Costs of Error Correction for Control Flow in Quantum Computation},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10729070},
abstract = {
    <p>The artifact contains the sources for the Spire compiler, the benchmark programs and circuits used in the paper, and the evaluation package.</p>

},
keywords = {quantum compilers, quantum programming languages}
}

@software{10.5281/zenodo.10775789,
author = {Nikolaev, Ruslan and Ravindran, Binoy},
title = {A Family of Fast and Memory Efficient Lock- and Wait-Free Reclamation - Artifact for PLDI'24},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10775789},
abstract = {
    <p>The artifact contains a VM image (VirtualBox) with preinstalled Ubuntu 18.04 and the (precompiled) benchmark. The artifact also contains source code and instructions for manual (bare-metal) installations. The artifact also includes our data measurements and scripts for generating plots. Please see README.txt for more details.</p>

},
keywords = {hazard pointers, memory reclamation, wait-free}
}

@software{10.5281/zenodo.10781381,
author = {Fang, Wang and Ying, Mingsheng},
title = {Artifact: Symbolic Execution for Quantum Error Correction Programs},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10781381},
abstract = {
    <p>We define QSE, a symbolic execution framework for quantum programs by integrating symbolic variables into quantum states and the outcomes of quantum measurements.&nbsp;The soundness of QSE is established through a theorem that ensures the correctness of symbolic execution within operational semantics.&nbsp;We further introduce symbolic stabilizer states, which symbolize the phases of stabilizer generators, for the efficient analysis of quantum error correction (QEC) programs.&nbsp;Within the QSE framework, we can use symbolic expressions to characterize the possible discrete Pauli errors in QEC, providing a significant improvement over existing methods that rely on sampling with simulators.&nbsp;We implement QSE &nbsp;with the support of symbolic stabilizer states in a prototype tool named QuantumSE.jl. Our experiments on representative QEC codes, including quantum repetition codes, Kitaev’s toric codes, and quantum Tanner codes, demonstrate the efficiency of QuantumSE.jl for debugging QEC programs with over 1000 qubits.&nbsp;In addition, by substituting concrete values in symbolic expressions of measurement results, QuantumSE.jl is also equipped with a sampling feature for stabilizer circuits.&nbsp;Despite a longer initialization time than the state-of-the-art stabilizer simulator, Google’s Stim, QuantumSE.jl offers a quicker sampling rate in the experiments.</p>

},
keywords = {quantum error correction, quantum programs, stabilizer formalism, symbolic execution}
}

@software{10.5281/zenodo.10790231,
author = {Lorenzen, Anton and Leijen, Daan and Swierstra, Wouter and Lindley, Sam},
title = {The Functional Essence of Imperative Binary Search Trees (Artifact)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10790231},
abstract = {
    <p>Our artifact contains implementations of the binary search tree algorithms discussed in the paper in Koka, C, OCaml and Haskell as well as a benchmarking setup to reproduce our numbers. We also include the AddressC proofs of all lemmas in the paper.</p>

},
keywords = {FBIP, FIP, Splay Trees, Tail Recursion Modulo Cons, Zip Trees, Zippers}
}

@software{10.5281/zenodo.10795858,
author = {Hong, Jaemin and Ryu, Sukyoung},
title = {Don't Write, but Return: Replacing Output Parameters with Algebraic Data Types in C-to-Rust Translation (Artifact)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10795858},
abstract = {
    <p>This artifact is for the paper Don’t Write, but Return: Replacing Output Parameters with Algebraic Data Types in C-to-Rust Translation. It introduces static analysis that identifies output parameters and program transformation that removes these parameters, enhancing automatic C-to-Rust translation. The tool, Nopcrat, which embodies the proposed method, is developed in Rust. Our evaluation dataset comprises 35 real-world C programs. You need the capability to run Docker containers, as the artifact is provided via a Docker image. To replicate the study’s results, a computer with at least 32 GB of RAM is necessary.</p>
<p>Nopcrat translates C code to Rust while replacing output parameters with Rust’s algebraic data types. It consists of four components: a modified version of the C2Rust translator, Extern2use, a static analyzer, and a code transformer. The translator translates C code to Rust. Extern2use replaces extern declarations in C2Rust-generated code with use. The analyzer analyzes the Rust code to identify output parameters and stores the information in a JSON file. The transformer removes output parameters in the Rust code using the analysis results.</p>
<p>The artifact supports the claims made in Section 5 of the paper by allowing the reproduction of the experimental results.</p>

},
keywords = {Algebraic Data Type, Automatic Translation, C, Output Parameter, Rust}
}

@software{10.5281/zenodo.10801691,
author = {Albert, Elvira and Garcia de la Banda, Maria and Hern\'{a}ndez-Cerezo, Alejandro and Ignatiev, Alexey and Rubio, Albert and Stuckey, Peter J.},
title = {Artifact for "SuperStack: Superoptimization of Stack-Bytecode via Greedy, Constraint-based, and SAT Techniques"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10801691},
abstract = {
    <p>This artifact includes the necessary data to reproduce the experiments in the paper “SuperStack: Superoptimization of Stack-Bytecode via Greedy, Constraint-based, and SAT Techniques,” accepted in PLDI’24.</p>

},
keywords = {EVM, Program Synthesis, SAT, Superoptimization, WebAssembly}
}

@software{10.5281/zenodo.10802176,
author = {Parthasarathy, Gaurav and Dardinier, Thibault and Bonneau, Benjamin and M\"{u}ller, Peter and Summers, Alexander J.},
title = {Towards Trustworthy Automated Program Verifiers: Formally Validating Translations into an Intermediate Verification Language -- Artifact},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10802176},
abstract = {
    <p>This artifact includes (1) a formalisation in the Isabelle theorem prover formalising the rules and definitions in the paper, (2) our proof-producing fork of the existing Viper-to-Boogie translation (implemented in Scala), which generates proofs in Isabelle on every run, and (3) the verifier test suites on which we evaluated our tool on as well as some of the corresponding verifiers (Gobra and VerCors) to generate the corresponding Viper files. The artifact describes the Isabelle formalisation and the proof-producing fork, and shows how to do the evaluation described in the paper. The entire artifact is packaged as a virtual machine using VirtualBox.</p>

},
keywords = {Boogie, Intermediate Verification Languages, Proof Certification, Viper}
}

@software{10.5281/zenodo.10802503,
author = {Lubin, Justin and Ferguson, Jeremy and Ye, Kevin and Yim, Jacob and Chasins, Sarah E.},
title = {Reproduction Package for "Equivalence by Canonicalization for Synthesis-Backed Refactoring"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10802503},
abstract = {
    <p>This artifact is a self-contained virtual machine for the artifact evaluation of the paper “Equivalence by Canonicalization for Synthesis-Backed Refactoring.” It includes our program synthesizer (Cobbler) as well as the data necessary for our empirical evaluation.</p>

},
keywords = {Program Equivalence Checking, Program Synthesis, Refactoring}
}

@software{10.5281/zenodo.10802748,
author = {Geng, Chujun and Blanas, Spyros and Bond, Michael D. and Wang, Yang},
title = {Reproduction Package for 'IsoPredict: Dynamic Predictive Analysis for Detecting Unserializable Behaviors in Weakly Isolated Data Store Applications'},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10802748},
abstract = {
    <p>The artifact contains IsoPredict and its benchmarks. IsoPredict was written in Python and benchmarks were written in Java and Rust. The benchmarks generate traces that will be analyzed by IsoPredict. IsoPredict will perform both predictive analysis and validation. Everything will be provided as a docker container image. We recommend running them on a Linux machine with at least 16GB of RAM.</p>

},
keywords = {concurrency, database isolation levels, Dynamic predictive analysis, software debugging}
}

@software{10.5281/zenodo.10802849,
author = {Kellison, Ariel E. and Hsu, Justin},
title = {Artifact for Numerical Fuzz: A Type System for Rounding Error Analysis},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10802849},
abstract = {
    <p>This is the artifact for NumFuzz (“Numerical Fuzz”), a prototype implementation of the type system and floating-point error analysis tool described in the paper “Numerical Fuzz: A Type System for Rounding Error Analysis”.</p>

},
keywords = {Floating point, Linear type systems, Roundoff error}
}

@software{10.5281/zenodo.10806044,
author = {Barri\`{e}re, Aur\`{e}le and Pit-Claudel, Cl\'{e}ment},
title = {Artifact for "Linear Matching of JavaScript Regular Expressions" at PLDI 2024},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10806044},
abstract = {
    <p>Description of artifact</p>
<p>The artifact consists of the source code and build scripts for our OCaml matchers; the patches that we wrote for V8; scripts to compute statistics on regex corpora; and the scripts to run our performance experiments and plot their results.</p>
<p>We have documented the directory structure of the OCaml matcher and the correspondence between the paper’s definitions and the source code in the OCaml matcher’s README in ocaml/allf/README.md. We recommend using this README as a guide to the OCaml code while reading the paper. Required hardware</p>
<p>We recommend running on an Ubuntu 22.04 LTS machine with at least 16GB of RAM. The VM is configured to use:</p>
<pre><code>12GB of RAM (to run experiments)
A CPU supporting the RDTSC instruction (for benchmarking)
40GB of free space on your hard drive (each V8 build takes ~12GB)</code></pre>

},
keywords = {Automata, JavaScript, Regex}
}

@software{10.5281/zenodo.10806323,
author = {Gruetter, Samuel and Fukala, Viktor and Chlipala, Adam},
title = {Code Artifact for Live Verification in an Interactive Proof Assistant},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10806323},
abstract = {
    <p>Code artifact submitted to Artifact Evaluation</p>

},
keywords = {interactive proof assistants, software verification, symbolic execution}
}

@software{10.5281/zenodo.10806686,
author = {Zhou, Zhe and Ye, Qianchuan and Delaware, Benjamin and Jagannathan, Suresh},
title = {PLDI2024 Artifact: A HAT Trick: Automatically Verifying Representation Invariants Using Symbolic Finite Automata},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10806686},
abstract = {
    <p>This artifact contains:</p>
<ol type="1">
<li>README.md : the artifact guide.</li>
<li>marple-original-submission.pdf: the original submitted paper.</li>
<li>marple:pldi-2024.tar.gz: the docker image (optional, we recommend to pull from the docker hub, see README.md).</li>
<li>Dockerfile: the docker file that can reproduce the docker image (optional, we recommend to pull from the docker hub, see README.md).</li>
</ol>

},
keywords = {refinement types, representation invariants, symbolic finite automata}
}

@software{10.5281/zenodo.10806719,
author = {Rivera, Joao and Franchetti, Franz and P\"{u}schel, Markus},
title = {Artifact: Floating-Point TVPI Abstract Domain},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10806719},
abstract = {
    <p>Artifact for the paper “Floating-Point TVPI Abstract Domain” at PLDI 2024. The artifact comes in the form of a virtual machine running Ubuntu 20.04. It contains the full source code of TVPI-FP, and benchmarks and scripts for reproducing main experiments.</p>

},
keywords = {abstract interpretation, numerical program analysis}
}

@software{10.5281/zenodo.10806736,
author = {Jung, Jaehwang and Kim, Jeonghyeon and Parkinson, Matthew J. and Kang, Jeehoon},
title = {Artifact for "Concurrent Immediate Reference Counting"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10806736},
abstract = {
    <p>This is the artifact for PLDI 2024 paper: “Concurrent Immediate Reference Counting”.</p>
<p>This artifact comprises the following files:</p>
<ul>
<li><code>circ-benchmark.zip</code>: This archive mainly contains a benchmark suite used to produce the results presented in the paper. Additionally, it contains:
<ul>
<li><code>README.md</code>: instructions on how to reproduce the benchmark results, and</li>
<li><code>paper-results</code>: generated result files that are included in the paper.</li>
</ul></li>
<li><code>circ-docker.tar.gz</code>: This file is a pre-built Docker image for conveniently running the benchmark.</li>
</ul>
<p>Refer to the README.md in the attached file for more information on this artifact.</p>

},
keywords = {automatic memory reclamation, concurrent data structures, reference counting}
}

@software{10.5281/zenodo.10806763,
author = {Liu, Jiawen and Qu, Weihao and Gaboardi, Marco and Garg, Deepak and Ullman, Jonathan},
title = {Adaptfun: Program analysis for Adaptive analysis},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10806763},
abstract = {
    <p>The software of program anlaysis tool Adaptfun, which provides the estimated upper bound on the adaptivity of adaptive data analysis algorithms. The tool is implemened using OCaml and Python. The reuslts are also evaluated in Python.</p>

},
keywords = {Adaptive data analysis, dependency graph, program analysis}
}

@software{10.5281/zenodo.10807084,
author = {Erbsen, Andres and Philipoom, Jade and Jamner, Dustin and Lin, Ashley and Gruetter, Samuel and Pit-Claudel, Cl\'{e}ment and Chlipala, Adam},
title = {Proof Artifact for `Foundational Integration Verification of a Cryptographic Server'},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10807084},
abstract = {
    <p>This is the computer-checked-proof artifact for `Foundational Integration Verification of a Cryptographic Server’. It contains the component proofs, integration proofs, and software for checking them, supporting all verification claims in the paper. Static quantiative-evaluation claims about memory usage are also supported by these proofs.</p>

},
keywords = {bare-metal programming, elliptic-curve cryptography, proof assistants}
}

@software{10.5281/zenodo.10807175,
author = {Sharma, Ritvik and Achour, Sara},
title = {DARE Qutrit Compiler},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10807175},
abstract = {
    <p>This contains all code required to regenerate results of Compilation of Qubit Circuits to Optimized Qutrit Circuits and use the DARE compiler.</p>

},
keywords = {Quantum computing, Qutrits, Rewriting Tools, Synthesis}
}

@software{10.5281/zenodo.10807316,
author = {Banerjee, Debangshu and Xu, Changming and Singh, Gagandeep},
title = {Input-Relational Verification of Deep Neural Networks},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10807316},
abstract = {
    <p>We consider the verification of input-relational properties defined over deep neural networks (DNNs) such as robustness against universal adversarial perturbations, monotonicity, etc. Precise verification of these properties requires reasoning about multiple executions of the same DNN. We introduce a novel concept of difference tracking to compute the difference between the outputs of two executions of the same DNN at all layers. We design a new abstract domain, DiffPoly for efficient difference tracking that can scale large DNNs. DiffPoly is equipped with custom abstract transformers for common activation functions (ReLU, Tanh, Sigmoid, etc.) and affine layers and can create precise linear cross-execution constraints. We implement a input-relational verifier for DNNs called RaVeN which uses DiffPoly and linear program formulations to handle a wide range of input-relational properties. Our experimental results on challenging benchmarks show that by leveraging precise linear constraints defined over multiple executions of the DNN, RaVeN gains substantial precision over baselines on a wide range of datasets, networks, and input-relational properties.</p>

},
keywords = {Abstract Interpretation, Deep Learning, Relational Verification}
}

@software{10.5281/zenodo.10808233,
author = {Herklotz, Yann and Wickerson, John},
title = {Artefact: Hyperblock Scheduling for Verified High-Level Synthesis},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10808233},
abstract = {
    <p>Artefact of the implementation and verification of hyperblock scheduling on top of an existing verified high-level synthesis tool called Vericert. The artefact includes a VM with all software pre-installed to reproduce the results of the paper. The instructions can be found in README.pdf and README.md.</p>

},
keywords = {CompCert, Coq, operation chaining, symbolic evaluation, translation validation}
}

@software{10.5281/zenodo.10808236,
author = {Dardinier, Thibault and M\"{u}ller, Peter},
title = {Hyper Hoare Logic: (Dis-)Proving Program Hyperproperties (artifact)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10808236},
abstract = {
    <p>This artifact supports the PLDI 2024 paper “Hyper Hoare Logic: (Dis-)Proving Program Hyperproperties”. It consists of an Isabelle/HOL mechanization that fully supports the formal claims made in the paper and a VirtualBox VM image with Ubuntu 22.04 that contains Isabelle 2023 and our mechanization.</p>

},
keywords = {Compositionality, Hoare Logic, Hyper Hoare Logic, Hyperproperties, Incorrectness Logic, Isabelle, Program Logic}
}

@software{10.5281/zenodo.10808465,
author = {Theodoridis, Theodoros and Su, Zhendong},
title = {PLDI 2024 Artifact for "Refined Input, Degraded Output: The Counterintuitive World of Compiler Behavior"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10808465},
abstract = {
    <p>Ths artifact consists of a docker image with instructions, the dataset, and the code necessary to reproduce the evaluation of Refined Input, Degraded Output: The Counterintuitive World of Compiler Behavior PLDI 2024.</p>

},
keywords = {automated compiler testing, missed compiler optimizations}
}

@software{10.5281/zenodo.10892762,
author = {Ball, Thomas and de Halleux, Peli and Devine, James and Hodges, Steve and Moskal, Micha\l{}},
title = {Jacdac: Service-based Prototyping of Embedded Systems (PLDI 2024 Artifact Evaluation)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10892762},
abstract = {
    <p>This artifact allows others to reproduce and explore the results seen in “Jacdac: Service-based Prototyping of Embedded Systems”. The artifact contains a prebuilt docker image and the Dockerfile source used to produce the prebuilt docker image. Evaluators should follow the README contained in this artifact for complete instruction.</p>

},
keywords = {embedded systems, microcontrollers, plug-and-play, services}
}

@software{10.5281/zenodo.10892936,
author = {Lei, Yuxiang and Bossut, Camille and Sui, Yulei and Zhang, Qirun},
title = {Artifact of "Context-Free Language Reachability via Skewed Tabulation"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10892936},
abstract = {
    <p>This is the artifact of the paper “Context-Free Language Reachability via Skewed Tabulation” accepted to PLDI 2024. The artifact is packaged as a Docker image “cflskewed.tar.gz”, which is to reproduce the experiment results of the paper.</p>

},
keywords = {CFL-reachability, performance, tabulation schemes}
}

@software{10.5281/zenodo.10895582,
author = {Lesbre, Dorian and Lemerre, Matthieu},
title = {Artifact for paper "Compiling with abstract interpretation"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10895582},
abstract = {
    <p>This is an artifact for the paper Compiling with Abstract Interpretation, submitted at PLDI 2024. It contains two abstract interpreters:</p>
<pre><code>TAI, very simple frama-c plugin that closely follows the paper definitions, but only supports a small subset of C (only integer variables, macro, and non-recursive function calls). It is used to demonstrate our technique but isn't very time or memory efficient.

It's a frama-c plugin but only uses frama-c as a C parser, so no knowledge of frama-c is required to understand it.

Codex: a much larger abstract interpretation library. It supports every aspect of C (as a frama-c plugin) and a number of binary formats (as a binsec plugin). This library implements many techniques and domains beyond the scope of the paper, but some ideas from our paper such as translation to SSA as an abstract interpretation pass have made it into its codebase.</code></pre>

},
keywords = {Abstract Interpretation, Compilation, Frama-C, OCaml, SSA}
}

@software{10.5281/zenodo.10895770,
author = {Mikek, Benjamin and Zhang, Qirun},
title = {STAUB: SMT Theory Arbitrage from Unbounded to Bounded},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10895770},
abstract = {
    <p>Implementation of STAUB in C++ and experimental data reflecting STAUB’s effectiveness in speeding up SMT solving for unbounded constraints.</p>

},
keywords = {abstract interpretation, constraint solving, SMT}
}

@software{10.5281/zenodo.10897200,
author = {Wang, Peixin and Yang, Tengshun and Fu, Hongfei and Li, Guanyan and Ong, C.-H. Luke},
title = {Updated Artifact for "Static Posterior Inference of Bayesian Probabilistic Programming via Polynomial Solving"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10897200},
abstract = {
    <p>This is the artifact for the paper “Static Posterior Inference of Bayesian Probabilistic Programming via Polynomial Solving”, which aims to derive guaranteed bounds for the normalised posterior distribution (NPD) over probabilistic programs.</p>

},
keywords = {F#, Matlab, Mosek}
}

@software{10.5281/zenodo.10901598,
author = {Wang, Ziteng and Pailoor, Shankara and Prakash, Aaryan and Wang, Yuepeng and Dillig, I\c{s}\i{}l},
title = {Software Artifact for `From Batch to Stream: Automatic Generation of Online Algorithms'},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10901598},
abstract = {
    <p>Opera is written in Python using both Poetry and Nix for managing dependencies. A recent installation of Nix (version 2.18.1 or higher) is the only prerequisite to get started. Additionally, we offer a Docker-based solution for running Nix.</p>

},
keywords = {Incremental Computation, Online Algorithms, Program Synthesis, Stream Processing}
}

@software{10.5281/zenodo.10906088,
author = {Fitzgibbons, Michael and Paraskevopoulou, Zoe and Mushtak, Noble and Thalakottur, Michelle and Sulaiman Manzur, Jose and Ahmed, Amal},
title = {RichWasm Artifact},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10906088},
abstract = {
    <p>This artifact is a self-contained environment to reproduce the claims in the PLDI’24 paper “RichWasm: Bringing Safe, Fine-Grained, Shared-Memory Interoperability Down to WebAssembly”. This artifact contains, a mechanized proof of RichWasm’s type safety, compilers from ML and L3 to RIchWasm, an annotator and type checker for RichWasm code and a compiler from RichWasm to WebAssembly. This artifact can be used to compile the proofs, use the various compilers and run and inspect their tests.</p>

},
keywords = {RichWasm, Type-Preserving Compilation, WebAssembly}
}

@software{10.5281/zenodo.10906216,
author = {Laird, Avery and Liu, Bangtian and Bj\o{}rner, Nikolaj and Dehnavi, Maryam Mehri},
title = {SpEQ: Translation of Sparse Codes using Equivalences},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10906216},
abstract = {
    <p>Software to replicate the results of “SpEQ: Translation of Sparse Codes using Equivalences.”</p>

},
keywords = {Equality Saturation, Equivalence Checking, Program Analysis, Verification}
}

@software{10.5281/zenodo.10906305,
author = {Jang, Minseong and Rhee, Jungin and Lee, Woojin and Zhao, Shuangshuang and Kang, Jeehoon},
title = {Modular Hardware Design of Pipelined Circuits with Hazards},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10906305},
abstract = {
    <p>This is the <strong>Modular Hardware Design of Pipelined Circuits with Hazards</strong> paper artifact submitted for evaluation of the 45th ACM SIGPLAN conference on Programming Language Design and Implementation (PLDI`24).</p>
<p>It contains two files:</p>
<ul>
<li><code>hazardflow-artifact-pldi2024.zip</code>: Repository of the artifacts. Follow the README inside to reproduce the results.</li>
<li><code>artifact_evaluation_latest.tar.gz</code>: Docker image to run the CPU experiments.</li>
</ul>

},
keywords = {Functional Hardware Description, HazardFlow, PLDI24}
}

@software{10.5281/zenodo.10909272,
author = {Qiu, Longfei and Kim, Yoonseung and Shin, Ji-Yong and Kim, Jieung and Honor\'{e}, Wolf and Shao, Zhong},
title = {Artifact for PLDI 2024 paper #290: LiDO: Linearizable Byzantine Distributed Objects with Refinement-Based Liveness Proofs.},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10909272},
abstract = {
    <p>This is artifact for PLDI 2024 paper #290: LiDO: Linearizable Byzantine Distributed Objects with Refinement-Based Liveness Proofs.</p>
<p>Included files are the LiDO model formalized in Coq, together with three implementations of LiDO (unpipelined Jolteon, unpipelined Jolteon with improved pacemaker, and pipelined Jolteon), each having safety and liveness proofs.</p>
<p>See README.md inside artifact package for more details.</p>

},
keywords = {byzantine fault-tolerance, consensus protocols, distributed systems, formal verification, liveness, proof assistants, refinement, safety}
}

@software{10.5281/zenodo.10909730,
author = {Buckley, Anita and Chuprikov, Pavel and Otoni, Rodrigo and Soul\'{e}, Robert and Rand, Robert and Eugster, Patrick},
title = {Artifact for the article An Algebraic Language for Specifying Quantum Networks},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10909730},
abstract = {
    <p>The artifact is a Haskell library bellkat plus several examples provided as executables within the same Haskell package.</p>

},
keywords = {entanglement, Kleene algebra, quantum networks}
}

@software{10.5281/zenodo.10910395,
author = {Jiang, Hanru},
title = {Artifact for PLDI' 24 submission #350 "Qubit Recycling Revisited"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10910395},
abstract = {
    <p>This is the artifact of PLDI’24 submission #350 “Qubit Recycling Revisited”, containing a certified prototype qubit recycler featuring various heuristics reported in the paper, and a subset of RevLib circuits for evaluation purpose. It is provided to reproduce the results of Sec. 7, and to check the mechanized proof of Theorem6.8. It also comes with a Docker image with the experimental environment setup, to make this artifact cross-platform.</p>

},
keywords = {Certified Compilation, Quantum Circuit Optimization}
}

@software{10.5281/zenodo.10912439,
author = {G\"{a}her, Lennard and Sammler, Michael and Jung, Ralf and Krebbers, Robbert and Dreyer, Derek},
title = {Artifact for "RefinedRust: A Type System for High-Assurance Verification of Rust Programs"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10912439},
abstract = {
    <p>This is the artifact for the PLDI’24 paper “RefinedRust: A Type System for High-Assurance Verification of Rust Programs”. It contains the implementation of RefinedRust and Coq development formalizing the results of the paper.</p>

},
keywords = {Iris, program verification, Rust, separation logic}
}

@software{10.5281/zenodo.10918754,
author = {Jia, Xiaodong and Tan, Gang},
title = {V-Star Artifact},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10918754},
abstract = {
    <p>This artifact includes the V-Star library, detailed instructions, and a Docker image file necessary to reproduce the results presented in Table 1 of the paper V-Star: Learning Visibly Pushdown Grammars from Program Inputs.</p>

},
keywords = {artifact, grammar inference, v-star, visibly pushdown grammars}
}

@software{10.5281/zenodo.10925596,
author = {Svyatlovskiy, Mikhail and Mermelstein, Shai and Lahav, Ori},
title = {Coq Mechanization for "Compositional Semantics for Shared-Variable Concurrency" (PLDI 2024)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10925596},
abstract = {
    <p>Coq mechanization for the paper “Compositional Semantics for Shared-Variable Concurrency” (PLDI 2024)</p>

},
keywords = {Compiler Optimizations, Concurrency, Denotational Semantics, Shared-Memory}
}

@software{10.5281/zenodo.10930752,
author = {Laursen, Mathias Rud and Xu, Wenyuan and M\o{}ller, Anders},
title = {Artifact for "Reducing Static Analysis Unsoundness with Approximate Interpretation", PLDI 2024},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10930752},
abstract = {
    <p>This artifact consists of a VirtualBox image that contains program code and experimental data for the paper Reducing Static Analysis Unsoundness with Approximate Interpretation by Mathias Rud Laursen, Wenyuan Xu and Anders M\o{}ller, PLDI 2024.</p>

},
keywords = {call graphs, JavaScript, points-to analysis, program analysis}
}

@software{10.5281/zenodo.10932109,
author = {Liu, Amanda and Bernstein, Gilbert and Chlipala, Adam and Ragan-Kelley, Jonathan},
title = {A Verified Compiler for a Functional Tensor Language},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10932109},
abstract = {
    <p>Virtual machine for AEC PLDI 2024. This contains the source for the ATL language, its verified rewrite framework, and the proof of correctness for its lowering algorithm embedded and implemented in Coq.</p>

},
keywords = {array programming, formal verification, functional programming, tensors, type systems}
}

@software{10.5281/zenodo.10932590,
author = {Lutze, Matthew and Madsen, Magnus},
title = {Associated Effects (Artifact)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10932590},
abstract = {
    <p>This artifact contains a Flix compiler, modified to support associated effects, as detailed in the paper. The artifact includes example files from the standard library, accessible in a QEMU virtual machine, in order to allow browsing files using Flix’s VSCode extension.</p>

},
keywords = {ad-hoc polymorphism, associated effects, associated types, effect systems, generic programming, type classes, type functions}
}

@software{10.5281/zenodo.10933110,
author = {Chen, Tianyu and Siek, Jeremy G.},
title = {Agda code for 'Quest Complete: The Holy Grail of Gradual Security'},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10933110},
abstract = {
    <p>The artifact contains Agda code of the definitions and proofs in the paper ‘Quest Complete: The Holy Grail of Gradual Security’.</p>

},
keywords = {Agda, gradual typing, information flow security, machine-checked proofs}
}

@software{10.5281/zenodo.10933398,
author = {Park, Sunho and Kim, Jaewoo and Mulder, Ike and Jung, Jaehwang and Lee, Janggun and Krebbers, Robbert and Kang, Jeehoon},
title = {Artifact for "A Proof Recipe for Linearizability in Relaxed Memory Separation Logic", PLDI 2024},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10933398},
abstract = {
    <p>This is the formalization for the paper “A Proof Recipe for Linearizability in Relaxed Memory Separation Logic”, written in Coq, along with a Docker image file (<code>artifact.tar.gz</code>) that contains a compiled version of the project and all dependencies installed.</p>
<p>Detailed instructions and explanations are written in the README.md inside <code>pldi24-36-artifact.zip</code>.</p>

},
keywords = {automation, linearizability, relaxed memory, separation logic}
}

@software{10.5281/zenodo.10935596,
author = {Becker, McCoy R. and Lew, Alexander K. and Wang, Xiaoyan and Ghavami, Matin and Huot, Mathieu and Rinard, Martin C. and Mansinghka, Vikash K.},
title = {Reproduction Packager for Article "Probabilistic Programming with Programmable Variational Inference"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10935596},
abstract = {
    <p>A package which contains the JAX implementation that accompanies the paper “Probabilistic Programming with Programmable Variational Inference”, as well as the experiments used to generate figures and numbers in the empirical evaluation section.</p>

},
keywords = {automatic differentiation, probabilistic programming, variational inference}
}

@software{10.5281/zenodo.10936488,
author = {Ferreira, Mafalda and Monteiro, Miguel and Brito, Tiago and Coimbra, Miguel E. and Santos, Nuno and Jia, Limin and Santos, Jos\'{e} Fragoso},
title = {Artifact for paper "Efficient Static Vulnerability Analysis for JavaScript with Multiversion Dependency Graphs"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10936488},
abstract = {
    <p>This artifact evaluates Graph.js, a novel static vulnerability detection tool for Node.js applications, that detects taint-style and prototype pollution vulnerabilities. The repository includes all source code, reference datasets and instructions on how to build and run the experiments. These experiments result in the tables and plots presented in the paper, which can be used to validate the results.</p>

},
keywords = {JavaScript, Static Analysis, Vulnerability Detection}
}

@software{10.5281/zenodo.10937074,
author = {Pham, Long and Saad, Feras A. and Hoffmann, Jan},
title = {Hybrid Resource-Aware ML},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10937074},
abstract = {
    <p>Hybrid Resource-Aware ML (Hybrid RaML) is a program analysis tool that takes in an OCaml program and infers its polynomial cost bound using the technique Hybrid Automatic Amortized Resource Analysis (AARA). It integrates data-driven resource analysis (specifically linear programming and Bayesian inference) and static resource analysis (specifically the conventional AARA). Hybrid RaML is wrapped inside a Docker image, and it comes with (i) a guide README.pdf describing how to use run the software and (ii) a paper paper.pdf describing Hybrid AARA.</p>

},
keywords = {Bayesian inference, data-driven analysis, hybrid analysis, program analysis, resource analysis, static analysis, type systems, worst-case costs}
}

@software{10.5281/zenodo.10940320,
author = {Spies, Simon and G\"{a}her, Lennard and Sammler, Michael and Dreyer, Derek},
title = {Artifact and Appendix for Quiver: Guided Abductive Inference of Separation Logic Specifications in Coq},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10940320},
abstract = {
    <p>This is the artifact for “Quiver: Guided Abductive Inference of Separation Logic Specifications in Coq”, submitted to PLDI 2024. It consists of a Coq implementation of a new specification inference technique in separation logic introduced in the paper.</p>

},
keywords = {abduction, Coq, functional correctness, Iris, specification inference}
}

@software{10.5281/zenodo.10949342,
author = {Zakhour, George and Weisenburger, Pascal and Salvaneschi, Guido},
title = {Automated Verification of Fundamental Algebraic Laws},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10949342},
abstract = {
    <p>Propel – Automated Verification of Fundamental Algebraic Laws</p>
<p>Artifact for the paper #174 “Automated Verification of Fundamental Algebraic Laws”</p>
<h2 id="claims-addressed-by-this-artifact">CLAIMS ADDRESSED BY THIS ARTIFACT</h2>
<p>This artifact addresses the following claims made in the paper:</p>
<ul>
<li><p>Propel is implemented in Scala for proving a subset of Scala (cf.&nbsp;“USING PROPEL AS A SCALA DSL”) translated into an intermediate representation (cf.&nbsp;“USING PROPEL STANDALONE (OUTSIDE OF SCALA)”).</p></li>
<li><p>Propel outperforms cvc5, vawpire, Zeno, HipSpec, and CycleQ as claimed in Table 1 Section 4 (cf. “RUNNING THE BENCHMARKS”) on 142 algebraic properties.</p></li>
<li><p>The implementation of Propel is in Scala 3 and is about 10 K lines long throughout 46 Scala files (cf.&nbsp;“STRUCTURE OF THE PROPEL SOURCE CODE”).</p></li>
</ul>
<h2 id="getting-started">GETTING STARTED</h2>
<h3 id="building-and-loading-the-docker-image">BUILDING AND LOADING THE DOCKER IMAGE</h3>
<p>We provide you with <code>propel.tar.xz</code>, which is a pre-built container image that contains all necessary programs. To load, run the following command:</p>
<pre><code>$ docker load &lt; propel.tar.xz</code></pre>
<p>Further, we also provide the option to build the contain anew. To build, run the following command which takes between 10 and 20 minutes:</p>
<pre><code>$ docker build -t propel .</code></pre>
<p>Rebuilding the image may not work on Apple M1 machines because of incomplete emulation of system calls (specifically the inotify kernel subsystem). Hence, we recommend rebuilding the image on a platform fully supported by Docker, like x86-64 systems.</p>
<h3 id="checking-if-the-container-and-the-relevant-programs-run-correctly">CHECKING IF THE CONTAINER AND THE RELEVANT PROGRAMS RUN CORRECTLY</h3>
<p>We provide a script that runs fast checks on Propel and the other provers (HipSpec, Zeno, CycleQ, cvc5, Vampire) used in the evaluation.</p>
<p>The check verifies commutativity of natural number addition – a task which all programs are able to prove correct quickly. The following command runs the check:</p>
<pre><code>$ docker run -it --rm propel /check_image/check</code></pre>
<p>If you see in green the line “Check Done” at the end, the container is behaving as expected.</p>
<p>The check will show the provers’ output, which should look similar to the following (shortened) excerpt:</p>
<pre><code>Checking Zeno

[...]

Searching for proofs... 
Proved "CommutativityAddition.prop_add_comm : add x y = add y x"

[...]

Checking HipSpec

[...]

Proved:
    add m n == add n m
    add m (add n o) == add n (add m o)
    prop_add_comm {- add x y == add y x -}


Checking cvc5
"comm nat_add2p"
unsat

Checking Vampire

[...]

\% Termination reason: Refutation

[...]

Checking CycleQ

[...]

Attempting to prove: prop_nat_add1_rightid
Success!

Checking Propel

✔ Check successful.

Check Done</code></pre>
<p>Note that cvc5 and Vampire report <code>unsat</code> or <code>Refutation</code>, respectively. This is because properties are verified by SMT solvers by finding a counterexample for their negation.</p>
<h2 id="step-by-step-instructions">STEP-BY-STEP INSTRUCTIONS</h2>
<h3 id="compiling-propel">COMPILING PROPEL</h3>
<p>The provided container already contains a binary executable of Propel.</p>
<p>To compile Propel to Java bytecode yourself, run the following command:</p>
<pre><code>$ docker run -it --rm propel bash -c 'cd /propel; sbt clean compile'</code></pre>
<p>To compile Propel to a native binary yourself, run the following command:</p>
<pre><code>$ docker run -it --rm propel bash -c 'cd /propel; sbt clean nativeLink'</code></pre>
<p>Compiling Propel, to bytecode or to a native executable, may not work inside the Docker container on Apple M1 machines for the reasons mentioned earlier.</p>
<p>The resulting binary is at <code>/propel/.native/target/scala-3.3.0/propel</code>. The <code>propel</code> executable in the PATH is already symlinked to that binary file. Hence, by default, you can just run <code>propel</code>.</p>
<h3 id="testing-propel">TESTING PROPEL</h3>
<p>To run the tests in Propel, execute:</p>
<pre><code>$ docker run -it --rm propel bash -c 'cd /propel &amp;\&amp; sbt test'</code></pre>
<p>Running the Propel tests may not work inside the Docker container on Apple M1 machines for the reasons mentioned earlier.</p>
<p>Note that running all unit tests can take several minutes. The output should look similar to the following (shortened) excerpt:</p>
<pre><code>[info] SuccessfulPropertyChecks:
[info] - nat_add2p
[info] - nat_add3p
[info] - nat_mult2p
[info] - bv_add

[...]

[info] FailingPropertyChecks:
[info] - nat_add2p_acc !!! IGNORED !!!
[info] - nat_add3p_acc !!! IGNORED !!!

[...]

[info] Total number of tests run: 49
[info] Suites: completed 2, aborted 0
[info] Tests: succeeded 49, failed 0, canceled 0, ignored 15, pending 0
</code></pre>
<p>The <code>SuccessfulPropertyChecks</code> contain the examples for which Propel can verify all properties. The <code>FailingPropertyChecks</code> contain the examples for which Propel is unable to verify all properties, hence their unit tests are disabled (<code>IGNORED</code>).</p>
<h3 id="running-the-benchmarks">RUNNING THE BENCHMARKS</h3>
<p>The benchmarks in Table 1 on pages 15, 16 and 16 can be re-executed with the container. The number of the properties that (1) could be proven, (2) could not be proven and (3) timed out should match the content of tables and the figures. The given time may differ depending on the system where the benchmarks are run. Due to the timeout of one minute, not only the amount of seconds can differ but also the type of the result. It could be the case that the benchmark succeeds or fails in less than 60s on one setup but takes more than 60s on a different setup, in which case it would time out.</p>
<p>To execute the benchmarks on HipSpec, run:</p>
<pre><code>$ docker run -it --rm propel /benchmarks/hipspec/run</code></pre>
<p>To execute the benchmarks on Zeno, run:</p>
<pre><code>$ docker run -it --rm propel /benchmarks/zeno/run</code></pre>
<p>To execute the benchmarks on CycleQ, run:</p>
<pre><code>$ docker run -it --rm propel /benchmarks/cycleq/run</code></pre>
<p>To execute the benchmarks on cvc5, run:</p>
<pre><code>$ docker run -it --rm propel /benchmarks/cvc5/run</code></pre>
<p>To execute the benchmarks on Vampire, run:</p>
<pre><code>$ docker run -it --rm propel /benchmarks/vampire/run</code></pre>
<p>To execute the benchmarks on Propel, run:</p>
<pre><code>$ docker run -it --rm propel /benchmarks/propel/run</code></pre>
<p>To execute the benchmarks on Propel without inequalities, run:</p>
<pre><code>$ docker run -it --rm propel /benchmarks/propel/run_no_ineq</code></pre>
<p>To execute the benchmarks that count the explored auxilliary lemmas, run:</p>
<pre><code>$ docker run -it --rm propel /benchmarks/propel/run_count_lemmas</code></pre>
<p>The results in Table 1 on pages 15, 16 and 16 correspond to one line from the output of each previous command.</p>
<h3 id="using-propel-as-a-scala-dsl">USING PROPEL AS A SCALA DSL</h3>
<p>Propel as described in Section 2.1 is a DSL in Scala. To experiment with the DSL, we invite you take a look into <code>/propel/src/test/scala/propel/ScalaExamplesNat.scala</code>, <code>/propel/src/test/scala/propel/ScalaExamplesNum.scala</code> and <code>/propel/src/test/scala/propel/ScalaExamplesList.scala</code> inside the container.</p>
<p>As an example, you can execute the following commands to run a shell, explore the files and recompile the project:</p>
<pre><code>$ docker run -it --rm propel bash                               # open a shell
$ nano /propel/src/test/scala/propel/ScalaExamplesList.scala    # open the file

# edit and save the file

$ cd /propel &amp;\&amp; sbt Test/compile                                # recompile</code></pre>
<p>Compiling the examples may not work inside the Docker container on Apple M1 machines for the reasons mentioned earlier.</p>
<p>You may define your own function using the following syntax:</p>
<pre><code>def myFunction = prop[(FunctionProperties) := (T1, T1) =&gt;: T2] { (x, y) =&gt; body }
// or
def myRecursiveFunction = prop.rec[(FunctionProperties) := (T1, T1) =&gt;: T2] { myRecursiveFunction =&gt; (x, y) =&gt; body }</code></pre>
<p>Here, <code>myFunction</code> is the name of the function, <code>FunctionProperties</code> is a list of function properties the function has (separated by <code>&amp;</code>), <code>T1</code> is the type of the arguments of the binary function, <code>T2</code> is the return type of the function, <code>x</code> and <code>y</code> are the names of the function arguments, and <code>body</code> is the function body.</p>
<p>The function properties are chosen from the following list: <code>Comm</code>, <code>Assoc</code>, <code>Idem</code>, <code>Sel</code>, <code>Refl</code>, <code>Antisym</code>, <code>Trans</code>, <code>Conn</code>, and <code>Sym</code>. Their semantics is defined in Section 2.2.</p>
<p>If Propel is able to prove the properties that the function is annotated with, then compilation succeeds. If the properties cannot be proven, then a compilation error indicates which property could not be proven</p>
<p>We hope that the integration into Scala makes the artifact easily usable by other researchers, either (1) by directly using the DSL to check algebraic and relational properties of their programs or (2) by building on Propel’s verification engine. To facilitate the latter, the implementation of Propel’s Scala DSL (<code>propel.dsl</code> package) is separated from the verification mechanism (<code>propel.evaluator</code> package), which researchers can adopt independently of the Scala integration (an overview of the package structure is in the last section).</p>
<h4 id="example">Example</h4>
<p>You can create a file in <code>/propel/src/test/scala/propel</code> with the following preamble:</p>
<pre><code>package propel

import propel.dsl.scala.*</code></pre>
<p>You can copy the <code>add1</code> example from the paper (Listing 1):</p>
<pre><code>enum ℕ:
  case Z
  case S(pred: ℕ)

def add1 = prop.rec[(Comm \&amp; Assoc) := (ℕ, ℕ) =&gt;: ℕ]: add1 =&gt;
  case (ℕ.Z, y) =&gt; y
  case (ℕ.S(x), y) =&gt; ℕ.S(add1(x, y))</code></pre>
<p>To define custom properties to be proven, you can add a <code>props</code> clause to the definition of <code>add1</code>. For instance, the following example proves the left and right identity laws:</p>
<pre><code>def add1 = prop.rec[(Comm \&amp; Assoc) := (ℕ, ℕ) =&gt;: ℕ]: add1 =&gt;
  props(
    (x: ℕ) =&gt; add1(ℕ.Z, x) =:= x, // left identity
    (x: ℕ) =&gt; add1(x, ℕ.Z) =:= x, // right identity
  ):
    case (ℕ.Z, y) =&gt; y
    case (ℕ.S(x), y) =&gt; ℕ.S(add1(x, y))</code></pre>
<p>You can execute <code>sbt Test/compile</code> to check all the annotated properties.</p>
<h3 id="using-propel-standalone-outside-of-scala">USING PROPEL STANDALONE (OUTSIDE OF SCALA)</h3>
<p>Propel can be directly reused as a verification tool in other projects (without the Scala and JVM dependency) through the <code>propel</code> binary. The binary consumes ASTs of Propel’s calculus in an S-expression-based syntax.</p>
<p>Our Scala implementation of the full surface language also follows the approach of translating Scala programs to terms in the calculus and passing them to the verification mechanism. A similar approach can be adopted by other tools that use Propel. Note that the AST is a bit more low-level then the Scala implementation and the calculus presented in the paper. In particular, the properties that are captured in the type of a function need to be propagated to the call sites of the function, i.e., function calls are syntactically annotated with the properties that should hold for them. The concrete format is described in the FORMAT.md file.</p>
<p>We provide all benchmarks in this format in the <code>/benchmarks/propel</code> directory. For example, the <code>nat_add1_comm.propel</code> is a direct translation of the <code>add1</code> function of Listing 1. This file can be checked by running:</p>
<pre><code>propel -f /benchmarks/propel/nat_add1_comm.propel</code></pre>
<p>Additional information about the proof attempts can be shown using the <code>-d</code> and <code>-r</code> flags.</p>
<h3 id="structure-of-the-propel-source-code">STRUCTURE OF THE PROPEL SOURCE CODE</h3>
<p>Propel is organized into the following packages:</p>
<ul>
<li><code>ast</code>: Abstract syntax tree definitions for the verifier</li>
<li><code>dsl</code>: Scala DSL</li>
<li><code>evaluator</code>: Rewrite engine (used by an implementation of the calculus’ dynamic semantics and by the verifier)</li>
<li><code>evaluator.properties</code>: Verifier for algebraic and relational properties (call <code>evaluator.properties.check</code> on an <code>ast.Term</code> to verify properties)</li>
<li><code>parser</code>: Parser for Propel’s serialization format (as used by the benchmarks)</li>
<li><code>printing</code>: Pretty-printer for Propel ASTs</li>
<li><code>typer</code>: Standard type checker (not checking algebraic and relational properties)</li>
<li><code>util</code>: Small, useful definitions</li>
</ul>

},
keywords = {Algebraic Properties, Type Systems, Verification}
}

@software{10.5281/zenodo.10949799,
author = {Huot, Mathieu and Ghavami, Matin and Lew, Alexander K. and Schaechtle, Ulrich and Freer, Cameron E. and Shelby, Zane and Rinard, Martin C. and Saad, Feras A. and Mansinghka, Vikash K.},
title = {PLDI artifact evaluation for "GenSQL: A Probabilistic Programming System for Querying Generative Models of Database Tables"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10949799},
abstract = {
    <p>This tarball provides evaluators with all means necessary to fully reproduce the results we show in the paper. We recommend users to check out the official GitHub repositories for GenSQL at https://github.com/OpenGen/GenSQL.query.</p>

},
keywords = {Experimental evaluation}
}

@software{10.5281/zenodo.10951313,
author = {Li, Shaohua and Theodoridis, Theodoros and Su, Zhendong},
title = {Artifact for PLDI'2024 paper "Boosting Compiler Testing by Injecting Real-world Code"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10951313},
abstract = {
    <p>This is the artifact for the PLDI’2024 paper “Boosting Compiler Testing by Injecting Real-World Code”. Please first untar the package and then refer to the README.pdf file for detailed instructions.</p>

},
keywords = {Compiler testing, compilers, miscompilation, reliability, testing}
}

@software{10.5281/zenodo.10951760,
author = {Ji, Ruyi and Zhao, Yuwei and Polikarpova, Nadia and Xiong, Yingfei and Hu, Zhenjiang},
title = {Artifact for PLDI'24: Superfusion: Eliminating Intermediate Data Structures via Inductive Synthesis},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10951760},
abstract = {
    <p>This project will be maintained at https://github.com/jiry17/SuFu.</p>

},
keywords = {Fusion, Inductive Program Synthesis, Program Optimization}
}

@software{10.5281/zenodo.10951893,
author = {Li, Jianlin and Wang, Eric and Zhang, Yizhou},
title = {Artifact for Paper 'Variable Elimination for an Expressive Probabilistic Programming Language'},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10951893},
abstract = {
    <p>This repository contains the tool source code, benchmarks and instructions to reproduce the results in paper ‘Variable Elimination for an Expressive Probabilistic Programming Language’.</p>

},
keywords = {compiler, continuation-passing style, CPS, information flow type system, probabilistic programming, type checker, type system, variable elimination}
}

@software{10.5281/zenodo.10951930,
author = {Gladshtein, Vladimir and Zhao, Qiyuan and Ahrens, Willow and Amarasinghe, Saman and Sergey, Ilya},
title = {LGTM: the Logic for Graceful Tensor Manipulation},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10951930},
abstract = {
    <p>This is the research artefact for the paper Mechanised Hypersafety Proofs about Structured Data to appear in the proceedings of the 45th ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI 2024).</p>

},
keywords = {coq, mechanised proofs, relational logic, sparse data structures}
}

@software{10.5281/zenodo.10953315,
author = {Girol, Guillaume and Lacombe, Guilhem and Bardin, S\'{e}bastien},
title = {Quantitative Robustness for Vulnerability Assessment},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10953315},
abstract = {
    <p>Most software analysis techniques focus on bug reachability. However, this approach is not ideal for security evaluation as it does not take into account the difficulty of triggering said bugs. The recently introduced notion of robust reachability tackles this issue by distinguishing between bugs that can be reached independently from uncontrolled inputs, from those that cannot. Yet, this qualitative notion is too strong in practice as it cannot distinguish mostly replicable bugs from truly unrealistic ones.</p>
<p>In this work we propose a more flexible quantitative version of robust reachability together with a dedicated form of symbolic execution, in order to automatically measure the difficulty of triggering bugs. This quantitative robust symbolic execution (QRSE) relies on a variant of model counting, called functional E-MAJSAT, which allows to account for the asymmetry between attacker-controlled and uncontrolled variables. While this specific model counting problem has been studied in AI research fields such as Bayesian networks, knowledge representation and probabilistic planning, its use within the context of formal verification presents a new set of challenges. We show the applicability of our solutions through security-oriented case studies, including real-world vulnerabilities such as CVE-2019-20839 from libvncserver.</p>

},
keywords = {Security, Static Analysis, Verification (automated)}
}

@software{10.5281/zenodo.10960926,
author = {Yi, Qiuping and Yu, Yifan and Yang, Guowei},
title = {Reproduction Package For Article `Compatible Branch Coverage Driven Symbolic Execution for Efficient Bug Finding`},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10960926},
abstract = {
    <p>The current artifact comprises all the tool source code related to the paper, along with the scripts and data needed to reproduce the experiments. We provide both source code and Docker build options.</p>

},
keywords = {program analysis, software testing, symbolic execution}
}

@software{10.5281/zenodo.10961123,
author = {Moeller, Mark and Jacobs, Jules and Belanger, Olivier Savary and Darais, David and Schlesinger, Cole and Smolka, Steffen and Foster, Nate and Silva, Alexandra},
title = {KATch: A Fast Symbolic Verifier for NetKAT},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10961123},
abstract = {
    <p>The artifact is the Scala implementation of the symbolic NetKAT verifier described in the paper, along with the NetKAT input files corresponding to the benchmark sets.</p>

},
keywords = {Automata equivalence, Kleene Algebra with Tests, NetKAT Verifier, Network Verification}
}

@software{10.5281/zenodo.10961342,
author = {Chen, Hongzheng and Zhang, Niansong and Xiang, Shaojie and Zeng, Zhichen and Dai, Mengjia and Zhang, Zhiru},
title = {Allo: A Programming Model for Composable Accelerator Design},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10961342},
abstract = {
    <p>This artifact contains scripts for setting up environments and reproducing results presented in the PLDI 2024 paper entitled “Allo: A Programming Model for Composable Accelerator Design”. Please refer to our github repo for instructions on how to install and run the artifact. https://github.com/cornell-zhang/allo-pldi24-artifact</p>

},
keywords = {accelerator design language, compiler optimization, Hardware accelerators, schedule language}
}

@software{10.5281/zenodo.10961908,
author = {Wimmer, Christian and Stancu, Codrut and Kozak, David and W\"{u}rthinger, Thomas},
title = {Scaling Points-to Analysis using Saturation - Artifact},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10961908},
abstract = {
    <p>The artifact presents our work on scaling points-to analysis using saturation. The content is a docker image containing GraalVM release and our benchmarking infrastructure. There is no need for special hardware, everything should work out of the box. The evaluation runs GraalVM Native Image in various configurations on our benchmarks and output the results, so that they can be compared with the values presented in the paper. However, due to resource constraints, we chose only a small subset that finishes fast. We provide a full configuration as well, but please note the full setup would take weeks to finish is executed on a single machine.</p>

},
keywords = {GraalVM, Java, pointer analysis, points-to analysis, static analysis}
}

@software{10.5281/zenodo.10963124,
author = {Murali, Adithya and Rivera, Cody and Madhusudan, P.},
title = {Artifact for ``Predictable Verification using Intrinsic Definitions''},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10963124},
abstract = {
    <p>This is the artifact for our paper “Predictable Verification using Intrinsic Definitions”.</p>
<p>ids-artifact.zip contains our benchmarks, while ids-docker.zip contains a Docker image. Please see README.md for instructions on how to use the artifact.</p>

},
keywords = {Boogie, Dafny, Decidability, Ghost-Code Annotations, Intrinsic Definitions, Predictable Verification, Verification of Linked Data Structures}
}

@software{10.5281/zenodo.10965986,
author = {Raskind, Joseph and Babakol, Timur and Mahmoud, Khaled and Liu, Yu David},
title = {Reproduction Artifact for VESTA},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10965986},
abstract = {
    <p>An artifact that reproduces the VESTA model</p>

},
keywords = {BPF, Java virtual machines, language runtimes, power modeling}
}

@software{10.5281/zenodo.10966813,
author = {Diatchki, Iavor S. and Dodds, Mike and Goldstein, Harrison and Harris, Bill and Holland, David A. and Razet, Benoit and Schlesinger, Cole and Winwood, Simon},
title = {Daedalus},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10966813},
abstract = {
    <p>Daedalus artifact submitted to PLDI</p>

},
keywords = {parser-generator, parsing}
}

@software{10.5281/zenodo.10971411,
author = {Kokologiannakis, Michalis and Marmanis, Iason and Vafeiadis, Viktor},
title = {Replication Package for "SPORE: Combining Symmetry and Partial Order Reduction"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10971411},
abstract = {
    <p>The artifact contains the tools GenMC (which implements theTruStalgorithm) and SPORE, as well as the tests used in the evaluation section of the paper.</p>
<p>SPORE is publicly available as part of GenMC: https://github.com/MPI-SWS/genmc.</p>

},
keywords = {concurrency, model checking, partial order reduction, symmetry reduction, weak memory models}
}

@software{10.5281/zenodo.10972076,
author = {Pitchanathan, Arjun and Grover, Kunwar and Grosser, Tobias},
title = {Artifact for "Falcon: A Scalable Analytical Cache Model"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10972076},
abstract = {
    <h2 id="artifact-for-falcon-a-scalable-analytical-cache-model">Artifact for Falcon: A Scalable Analytical Cache Model</h2>
<p>This is the supporting artifact for the Falcon paper. It can be used to replicate all results in the submitted version of the paper (submission_paper.pdf), given enough time and appropriate hardware. To be precise, it takes around two weeks to reproduce all the results.</p>
<h3 id="quick-version-of-the-artifact">Quick Version of the Artifact</h3>
<p>To facilitate evaluation, we also provide a “quick” version of the artifact that reproduces the main results. It reproduces all the evaluation figures in the paper, with the following differences:</p>
<ul>
<li><p>Figure 1: we run the models at all x values of 20 up to 100 instead of multiples of 5. This is sufficient to establish the same trend.</p></li>
<li><p>Figure 6 \&amp; 7: we evaluate on the last four benchmarks files in the ordering of Figure 6, showing that even on the “worst” inputs in the benchmark, Falcon takes minutes. (base models time out after four hours)</p></li>
<li><p>Figure 8: we evaluate on thread counts [1, 2, 4, 8, 12, 16] instead of all counts up to 16. This is sufficient to establish the same trend.</p></li>
</ul>
<p>All of the above choices can be easily customized by the user before running the artifact; see “Running the Artifact” below.</p>
<h3 id="hardware-requirements">Hardware Requirements</h3>
<h4 id="requirements-for-the-quick-version">Requirements for the quick version</h4>
<p>For hardware measurement, our method requires a machine with an AMD Zen3/Zen4 CPU and access to the <code>perf_event_open</code> syscall. Note that many cloud machines disallow this syscall. If such a machine is not available, you can still use the hardware measurement data from our machine and run the rest of the artifact. The only difference will be that the accuracy figures will be plotted against our measurement data on our machine instead of yours.</p>
<p>For the parallelism experiment, a machine with 16 cores is required. If there are fewer cores, then running on 16 threads will not improve performance as much so the speedup would be less than that reported in the paper. Other than that, the artifact will still work fine on a machine with fewer cores.</p>
<h4 id="requirements-for-the-full-version">Requirements for the full version</h4>
<p>For the complete version, a machine with 192 GiB RAM is required. This is because the baseline model Haystack that we compare against can sometimes take a large amount of RAM.</p>
<p>When the full artifact is run on a machine with insufficient RAM, if Haystack runs out of memory when running some file, that file will be gracefully dropped from Figure 6. Otherwise, the rest of the artifact will continue to function normally. In such a scenario it may help system stability to run <code>./earlyoom.sh</code> before running the models, though when we tested on a low RAM machine, we did not find this to be necessary.</p>
<p>It may be difficult to obtain a single machine satisfying the high RAM requirement as well as the requirement to have access to the <code>perf_event_open</code> syscall, as the latter is often not available on cloud machines. Therefore, we provide the option to run each part on a different machine, as long as one machine is available with high RAM and another with the requirements specific for hardware measurements.</p>
<h3 id="software-requirements">Software Requirements</h3>
<p>The artifact requires <a href="https://docs.docker.com/get-docker/">Docker</a>. We tested on version <code>24.0.6</code> on a Linux machine.</p>
<h3 id="getting-started">Getting Started</h3>
<p>The artifact comes with pre-built binaries. To rebuild from scratch, see that section below. To setup the artifact and docker image:</p>
<ol type="1">
<li>Extract the provided archive and <code>cd</code> into the extracted directory.</li>
<li>Load the provided docker image with <code>docker load -i docker/docker_image.tar</code>.</li>
<li>Run the image with <code>docker run -v $(pwd):/app -it --security-opt seccomp=docker/seccomp.json falcon-artifact</code></li>
</ol>
<p>This mounts the project root directory (which should be the current directory) to the VM. Changes made in the VM will be persisted here.</p>
<p>The argument <code>--security-opt seccomp=docker/seccomp.json</code> loads a custom security configuration. The only difference between the custom one and the default is that the <code>perf_event_open</code> syscall is permitted, which is required for hardware measurement. The argument can be omitted if hardware measurement is not needed. If the measurement test assert-fails as described in the next section even though you expect it to work on your system, you can try adding the flag <code>--privileged</code>, though we did not need it during testing.</p>
<p>Note that during development, our tool was called <code>lazystack</code>, so it is referred to as such in scripts and source code.</p>
<h4 id="test-running-hardware-measurement">Test-running hardware measurement</h4>
<p>To test the hardware measurement, run <code>examples/measurement-example</code>. If it succeeds, the output will contain four numbers. On our system, we got:</p>
<pre><code>0.18134
1359152
16981
68</code></pre>
<p>The first output number is runtime and the next three are cache accesses and misses; none of these numbers are expected to be zero. If any of the last three lines are zero then your CPU is probably unsupported. In this case, you can use the measurement data from our system (see below for more details).</p>
<p>On the other hand, if the <code>perf_event_open</code> syscall is not supported, an error like the following will be reported:</p>
<pre><code>measurement-example: ../src/c-gen-perf-main.cpp:66: read_format&lt;nr&gt; disable_and_get_count_group(int) [nr = 3U]: Assertion `data.nr == nr' failed.
Aborted (core dumped)</code></pre>
<h4 id="test-running-the-cache-models">Test-running the cache models</h4>
<p><code>cd</code> into the <code>experiments</code> directory and run <code>python perf-all.py -b polybench-S -c 512,512 --output-suffix test --filter gemm</code>. This should produce output like the following.</p>
<pre><code>root@53846d9af34b:/app/experiments# python perf-all.py -b polybench-S -c 512,512 --output-suffix test --filter gemm
Will output to data/perf-polybench-S-512-512-test.json
Runnning haystack on gemm
Running warping on gemm
Running lazystack on gemm... 78ms
{
  "gemm": {
    "haystack": {
      "L1": 0,
      "L2": 0,
      "L3": 0,
      "accesses": 1352400,
      "capacity": 0,
      "compulsory": 1000,
      "misses": 1000,
      "time": 188.77
    },
    "lazystack": {
      "accesses": 1352400,
      "misses": 1000,
      "misses_L1": 1000,
      "misses_L2": 0,
      "ops": 6,
      "peak_mem": 42892,
      "stack_t": 36.9719,
      "symbolic_t": 16.7869,
      "thresh_t": 8.84229,
      "time": 55.1991,
      "varheur_t": 0.015209
    },
    "warping": {
      "access_level": [
        1352400
      ],
      "accesses": 1352400,
      "miss_level": [
        926
      ],
      "misses": 926,
      "time": 293.0
    }
  }
}
Saving to data/perf-polybench-S-512-512-test.json</code></pre>
<p>The main thing to check is that all three models haystack, lazystack, and warping ran successfully, producing a section in the output for each.</p>
<h3 id="running-the-experiments">Running the experiments</h3>
<p>To perform experiments, <code>cd</code> into the <code>experiments</code> directory.</p>
<p>To perform hardware measurement, run <code>./run_measurement.py</code>. This may take around 4 hours and should be done on a machine with an AMD Zen3/Zen4 CPU and access to the <code>perf_event_open</code> syscall. You should run the docker image with the provided seccomp for this part. Now run <code>./get_system_cache_conf.sh</code> on the same machine and note down the two numbers; these are the number of cache lines in the cache and the size of each cache line in bytes.</p>
<p>To run the full version of the model evaluation, run <code>./run_prediction.sh &lt;cache line count&gt; &lt;line size&gt;</code>. This may take around 2 weeks and requires a machine with 192 GiB of RAM.</p>
<p>To run the quick version of the model evaluation, run <code>./run_prediction_fast.sh &lt;cache line count&gt; &lt;line size&gt;</code>. This may take around 2-3 days. If you want to customize any of the parameters of the quick run described in the introduction of this document, it is easy to do so by modifying the environment variables exported in that script; they are well documented.</p>
<p>For more info on manually customizing the running of the benchmarks beyond the provided shell scripts see <code>MoreInfo.md</code>.</p>
<h4 id="using-our-hardware-measurement-data-in-case-of-unsupported-cpu">Using our hardware measurement data in case of unsupported CPU</h4>
<p>If you do not have a supported AMD CPU for the hardware measurement, you can use our hardware measurement data. To do this, simply copy the <code>perf-perf-1.json</code> file from <code>experiments</code> into the <code>experiments/data</code> directory and run the prediction scripts as usual. Our machine has 512 cache lines and the line size is 64 (bytes); use those settings when running the prediction. You can then proceed to plotting (see below).</p>
<h3 id="plotting-and-comparing-results">Plotting and comparing results</h3>
<p>To plot the data collected, run <code>./plot.sh</code> in the <code>experiments</code> directory. This will generate a report in <code>experiments/report/report.pdf</code>. This document lists all the generated figures along with their figure number in the submitted paper.</p>
<p>You can now compare these figures with those in the submitted paper <code>submitted_paper.pdf</code> and confirm that the interpretations in the captions of the figures in the submission continue to hold in the figures in the report generated from the artifact.</p>
<p>If you ran Polybench, you can print the speedups on it with <code>python print_polybench_speedup.py</code>. It also mentions the speedup reported in the paper with line number for reference.</p>
<p>Finally, in the paper we checked our tool’s correctness by comparing the outputs against Haystack. Run <code>python check.py</code> to replicate this; it will compare against all available Haystack outputs from the artifact.</p>
<h3 id="building-from-scratch">Building from Scratch</h3>
<p>The artifact comes with pre-built binaries for convenience, but can support a fresh build too. To do so, first run <code>./clean_all.sh</code> to delete pre-built data.</p>
<p>To build the binaries used for hardware measurement, run <code>./setup_measurement.sh</code></p>
<p>To build the cache models, run <code>./setup_prediction.sh</code>. The binary of our tool will be produced in <code>cmake-build-release/bin/lazystack</code>, which can be used for manually running it on a given MLIR file.</p>
<h3 id="source-code-organization">Source Code Organization</h3>
<p>The source code of our tool is in the directories <code>include</code>, <code>src</code>, and <code>lib</code>. Some modifications have also been made to the external libraries in <code>polybase/barvinok</code> and <code>polybase/isl</code>. The entrypoint into the actual cache model is in the <code>CacheModel::compute</code> function in <code>lib/Analysis/CacheModel.cpp</code>.</p>
<p>The key function is the <code>CacheModel::computeSink</code> function. This computes the cache misses at each level, for the given sink in the program. This corresponds to the body of the loop in Algorithm 1 in the paper.</p>
<p>The dependences are computed by the call to <code>Lazy::compute</code>, implemented in <code>lib/Analysis/Lazy.cpp</code>. Threshold couting is performed in the call to <code>ThresholdCounting::compute</code>, implemented in <code>lib/Analysis/ThresholdCounting.cpp</code>.</p>

},
keywords = {cache modeling, performance analysis, static analysis}
}

@software{10.5281/zenodo.10976438,
author = {Cui, Guofeng and Wang, Yuning and Qiu, Wenjie and Zhu, He},
title = {ReGuS - Reproduction Package for Article `Reward-Guided Synthesis of Intelligent Agents with Control Structures`},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10976438},
abstract = {
    <p>This artifact is provided as a Docker image. Before proceeding, ensure you have Docker installed. The artifact was tested with Docker version 20.10.23. We recommend that your machine has at least 16GB of memory and 16GB of available disk space for building and running Docker images. All benchmarks were tested on a Mac Mini 2023 with an Apple M2 Pro CPU and 16GB of RAM. Please refer to the README file for instructions on reproducing the experiments.</p>

},
keywords = {Program Synthesis, Reinforcement Learning, Sequential Decision Making}
}

@software{10.5281/zenodo.11097757,
author = {Blaauwbroek, Lasse and Ol\v{s}\'{a}k, Miroslav and Geuvers, Herman},
title = {Artifact for: Hashing Modulo Context-Sensitive Alpha-Equivalence},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11097757},
abstract = {
    <p>Reference implementation for hashing modulo context-sensitive alpha-equivalence</p>

},
keywords = {Alpha Equivalence, Bisimilarity, Hashing, Lambda Calculus, Syntax Tree}
}

@software{10.5281/zenodo.11099781,
author = {Brahmakshatriya, Ajay and Rinard, Chris and Ghobadi, Manya and Amarasinghe, Saman},
title = {Replication package for the PLDI 2024 paper: NetBlocks: Staging Layouts for High-Performance Custom Host Network Stacks},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.11099781},
abstract = {
    <p>Replication package for the PLDI 2024 paper: NetBlocks: Staging Layouts for High-Performance Custom Host Network Stacks</p>

},
keywords = {compilers, layouts, network-protocols}
}

@software{10.1145/3580431,
author = {Lee, Edward and Zhao, Yaoyu and Lhot\'{a}k, Ond\v{r}ej and You, James and Satheeskumar, Kavin and Brachth\"{a}user, Jonathan Immanuel},
title = {Artifact for the OOPSLA 2024 paper ’Qualifying System F-sub’},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3580431},
abstract = {
    <p>Mechanized proofs for the calculi described in the paper ’Qualifying System F-sub’.</p>

},
keywords = {Coq, Mechanized proofs, System F-sub-Q}
}

@software{10.1145/3580432,
author = {Lu, Kuang-Chen and Krishnamurthi, Shriram},
title = {Reproduction Package for Article `Identifying and Correcting Programming Language Behavior Misconceptions'},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3580432},
abstract = {
    <p>We claim in the paper (Section 7) that “we provide all the misinterpreters in the artifact.” To support this claim, this artifact provides the source code of all misinterpreters in ./Misinterpreters. In addition, we provide the source code of the reference interpreter ./Misinterpreters/smol-referential.rkt, which represents the correct conception. ./Misinterpreters contains a few other files:</p>
<ul>
<li>Metadata that makes the folder a Racket package: ./Misinterpreters/info.rkt</li>
<li>The definitions of AST and a parser (from S-expressions to AST): ./Misinterpreters/smol-syntax.rkt and ./Misinterpreters/parse.rkt</li>
<li>Shared helper functions for all (mis)interpreters: ./Misinterpreters/utilities.rkt</li>
</ul>
<p>We present statistical results in the paper. Though not promised in the paper, to support all those claims, this artifact also provides an R Markdown ./Paper.Rmd that computes (most of) the numbers, generates the figures, and performs the hypothesis tests. For numbers that cannot be computed, the R Markdown gives justification.</p>
<p>./Paper.Rmd depends on the ./SMoL Tutor folder, which includes</p>
<ul>
<li>Metadata about SMoL Tutor: ./SMoL Tutor/Tasks.csv and ./SMoL Tutor/Choices.csv</li>
<li>Data collected by SMoL Tutor: ./SMoL Tutor/Datasets/</li>
<li>A script that tags wrong answers with misinterpreters: ./SMoL Tutor/Tag_Answers.rkt</li>
</ul>

},
keywords = {automated interactive tutors, misconceptions, program behavior/semantics}
}

@software{10.5281/zenodo.10452601,
author = {Yuan, Charles and Villanyi, Agnes and Carbin, Michael},
title = {Artifact for Quantum Control Machine: The Limits of Control Flow in Quantum Programming},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10452601},
abstract = {
    <p>This artifact contains an implementation of a simulator for the quantum control machine and the programs from the case study as presented in the paper.</p>

},
keywords = {quantum instruction set architectures, quantum programming languages}
}

@software{10.5281/zenodo.10457566,
author = {Chatterjee, Krishnendu and Goharshady, Amir Kafshdar and Meggendorfer, Tobias and \v{Z}ikeli\'{c}, undefinedor\dj{}e},
title = {Artefact for: Quantitative Bounds on Resource Usage of Probabilistic Programs},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10457566},
abstract = {
    <p>The artefact for the OOPSLA 2024 paper “Quantitative Bounds on Resource Usage of Probabilistic Programs”.</p>

},
keywords = {Cost Analysis, Martingales, Probabilistic Programming, Quantitative Bounds, Static Analysis}
}

@software{10.5281/zenodo.10463878,
author = {Yadavally, Aashish and Li, Yi and Wang, Shaohua and Nguyen, Tien N.},
title = {Artifact for "A Learning-Based Approach to Static Program Slicing"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10463878},
abstract = {
    <p>NS-Slicer is a learning-based static program slicing tool, which extends such an analysis to partial Java programs. The source code, data, and model artifacts are publicly available on GitHub (https://github.com/aashishyadavally/ns-slicer), and Zenodo (https://zenodo.org/records/10463878).</p>

},
keywords = {AI4SE, Debugging, Neural Networks, Pre-Trained Language Models, Static Slicing, Vulnerability Detection}
}

@software{10.5281/zenodo.10463960,
author = {Nelson, Tim and Greenman, Ben and Prasad, Siddhartha and Dyer, Tristan and Bove, Ethan and Chen, Qianfan and Cutting, Charles and Del Vecchio, Thomas and LeVine, Sidney and Rudner, Julianne and Ryjikov, Ben and Varga, Alexander and Wagner, Andrew and West, Luke and Krishnamurthi, Shriram},
title = {Artifact for Forge: A Tool and Language for Teaching Formal Methods},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10463960},
abstract = {
    <p>The purpose of this artifact is to show that Forge works as advertised. To that end, we provide instructions for installing Forge (similar to what our students see), links to the documentation, and code from the paper.</p>

},
keywords = {formal-methods education, language levels, lightweight formal-methods}
}

@software{10.5281/zenodo.10517828,
author = {Avanzini, Martin and Barthe, Gilles and Gr\'{e}goire, Benjamin and Moser, Georg and Vanoni, Gabriele},
title = {ehoare},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10517828},
abstract = {
    <p>This artifact provides a docker image that contains a working installation of Easycrypt together with three proof scripts related to the examples given in the paper.</p>
<ul>
<li><code>qselect.ec</code> contains the formalisation of quickselect from Section 3. It relies on an auxiliary library <code>partition.eca</code> concerned with properties of the partitioning scheme.</li>
<li><code>skip_list.ec</code> contains the formalisation of skip-lists outlined in Section 6</li>
<li><code>adversary.ec</code> contains the prototypical cryptography proof example outlined in Section 7</li>
</ul>

},
keywords = {expectation logic, skip list}
}

@software{10.5281/zenodo.10701642,
author = {Ye, Qianchuan and Delaware, Benjamin},
title = {Taypsi: Static Enforcement of Privacy Policies for Policy-Agnostic Oblivious Computation: OOPSLA24 Artifact},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10701642},
abstract = {
    <p>This is the artifact for the OOPSLA24 paper “Taypsi: Static Enforcement of Privacy Policies for Policy-Agnostic Oblivious Computation”. It contains:</p>
<ul>
<li>README.md: artifact instructions in markdown format</li>
<li>README.pdf: artifact instructions in pdf format</li>
<li>taypsi-image-amd64.tar.xz: docker image for amd64 (x86_64) architecture</li>
<li>taypsi-image-arm64.tar.xz: docker image for arm64 architecture</li>
<li>Dockerfile: docker file used to generate the docker images</li>
<li>taypsi.tar.xz: source code of the Taypsi type checker, compiler, examples and benchmarks</li>
<li>taype-pldi.tar.xz: source code of the Taype type checker and compiler (PLDI23), extended with additional benchmarks for comparison with Taypsi</li>
<li>taype-sa.tar.xz: source code of a version of Taype with an additional optimization (smart array) for a fairer comparison with Taypsi</li>
<li>taype-drivers.tar.xz: source code of drivers that implement the cryptographic primitives and oblivious array, used by taypsi and taype-sa</li>
<li>taype-drivers-legacy.tar.xz: source code of the drivers used by taype-pldi</li>
<li>taypsi-theories.tar.xz: Coq formalization of the Taypsi core calculus</li>
<li>taype-vscode.tar.xz: source code of a VS Code extension that provides basic syntax highlighting for Taypsi programs</li>
</ul>
<p>To evaluate this artifact, you only need to download the docker image for your architecture. Other tarballs provide clean versions of the source code, but you do not need them for evaluation. See README.md / README.pdf for details about this artifact and evaluation instructions. The same README.md is also available in the docker images.</p>

},
keywords = {Algebraic Data types, Coq Proof Assistant, Dependent Types, Oblivious Computation, Secure Multiparty Computation}
}

@software{10.5281/zenodo.10775922,
author = {Chen, Zhe and Zhu, Yunlong and Wang, Zhemin},
title = {Reproduction Package for Article `Design and Implementation of an Aspect-Oriented C Programming Language'},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10775922},
abstract = {
    <p>The artifact contains the Movec compiler for Aclang and all the benchmarks used in our experiments. The purpose of the artifact is to reproduce the experiments in Section 7 and support the main claims in the paper.</p>

},
keywords = {aspect-oriented programming, C language, compiler, instrumentation, semantics, transformation}
}

@software{10.5281/zenodo.10777503,
author = {Paradis, Anouk and Dekoninck, Jasper and Bichsel, Benjamin and Vechev, Martin},
title = {Reproduction Package for the Article "Synthetiq: Fast and Versatile Quantum Circuit Synthesis"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10777503},
abstract = {
    <p>This artifact contains the code for the paper ‘Synthetiq: Fast and Versatile Quantum Circuit Synthesis’. Synthetiq is a tool to synthesize quantum circuits implementing a given (partial) specification over arbitrary finite gate sets and is faster and more versatile than existing works.</p>
<p>This artifact contains: - the code of our tool Synthetiq and installation instructions; - precise instructions to reproduce our evaluation; - usage guide to use Synthetiq on new operators; - all quantum circuits found by Synthetiq and mentioned in the paper.</p>

},
keywords = {Clifford+T, Quantum Circuits, Synthesis}
}

@software{10.5281/zenodo.10779424,
author = {Binder, David and Skupin, Ingo and S\"{u}berkr\"{u}b, Tim and Ostermann, Klaus},
title = {Artifact for the article "Deriving Dependently-Typed OOP from First Principles"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10779424},
abstract = {
    <p>Contained in the artifact is a Rust implementation of a dependently-typed programming language. This implementation contains a typechecker as well as an LSP server, VScode plugin and the infrastructure necessary to produce a static website in which snippets from the programming language can be typechecked in the browser. The language server provides a code action which can transform any codata type into a data type using defunctionalization, and any data type into a codata type using refunctionalization.</p>

},
keywords = {algebraic data types, codata, defunctionalization, dependent types, refunctionalization}
}

@software{10.5281/zenodo.10782412,
author = {Klinkenberg, Lutz and Blumenthal, Christian and Chen, Mingshuai and Haase, Darion and Katoen, Joost-Pieter},
title = {Exact Bayesian Inference for Loopy Probabilistic Programs using Generating Functions - Artifact},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10782412},
abstract = {
    <p>The artifact includes a Docker image with the Prodigy tool and program examples that were used for the benchmarks in the paper. It includes scripts and documentation to allow for easy replication of the presented benchmark results.</p>

},
keywords = {Bayesian inference, conditioning, denotational semantics, generating functions, non-termination, probabilistic programs, quantitative verification}
}

@software{10.5281/zenodo.10783906,
author = {Xu, Ziyang and Chon, Yebin and Su, Yian and Tan, Zujun and Apostolakis, Sotiris and Campanoni, Simone and August, David I.},
title = {Artifact for Paper "PROMPT: A Fast and Extensible Memory Profiling Framework"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10783906},
abstract = {
    <p>This repository contains the artifact evaluation for the PROMPT paper. PROMPT is a fast and extensible memory profiling framework.</p>

},
keywords = {compiler optimizations, memory profiling, profiler framework}
}

@software{10.5281/zenodo.10791709,
author = {Wang, Di and Reps, Thomas},
title = {Newtonian Program Analysis of Probabilistic Programs (Artifact)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10791709},
abstract = {
    <p>This artifact provides a prototype implementation of the framework of Newtonian Program Analysis with Pre-Markov Algebras (NPA-PMA). NPA-PMA is an interprocedural dataflow-analysis framework for designing and implementing (partially) non-iterative program analyses of probabilistic programs with unstructured control-flow, nondeterminism, and general recursion. To demonstrate the usage of NPA-PMA, this artifact also includes five instantiations for four analyses: Bayesian-inference analysis, higher-moment analysis of accumulated rewards, expectation-invariant analysis, and expectation-recurrence analysis.</p>

},
keywords = {Algebraic Program Analysis, Interprocedural Program Analysis, Newton's Method, Probabilistic Programs}
}

@software{10.5281/zenodo.10794350,
author = {Smith, Scott and Zhang, Robert},
title = {Software Artifact for A Pure Demand Operational Semantics with Applications to Program Analysis},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10794350},
abstract = {
    <p>This artifact facilitates building, testing, benchmarking, and evolving the interpreter and program analyses presented in the paper.</p>

},
keywords = {Higher-Order Functional Programming, Operational Semantics, Program Analysis}
}

@software{10.5281/zenodo.10796440,
author = {Alshnakat, Anoud and Lundberg, Didrik and Guanciale, Roberto and Dam, Mads},
title = {OOPSLA 2024 Artifact: HOL4P4: Mechanized Small-Step Semantics for P4},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10796440},
abstract = {
    <p>For a detailed description of this artifact, see OVERVIEW.md or OVERVIEW.pdf among the files.</p>
<p>HOL4P4-OOPSLA2024-source.tar.gz is a compressed directory with the source code, and hol4p4-amd64.tar.gz and hol4p4-aarch64.tar.gz are compressed Docker images for x86_64-based and ARM64-based CPUs, respectively.</p>

},
keywords = {formal verification, interactive theorem proving, P4, programming language semantics}
}

@software{10.5281/zenodo.10797791,
author = {Marshall, Daniel and Orchard, Dominic},
title = {Functional Ownership through Fractional Uniqueness (Artefact)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10797791},
abstract = {
    <p>Artifact for the paper of the same title that appears at OOPSLA 2024. Includes code examples in both Granule and Rust. See overview.pdf for more information.</p>

},
keywords = {borrowing, fractional permissions, graded modal types, ownership}
}

@software{10.5281/zenodo.10798266,
author = {Kravchuk-Kirilyuk, Anastasiya and Feng, Gary and Iskander, Jonas and Zhang, Yizhou and Amin, Nada},
title = {Persimmon: Nested Family Polymorphism with Extensible Variant Types (Artifact)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10798266},
abstract = {
    <p>Our implementation consists of the Persimmon type checker and our prototype compiler to Scala.</p>

},
keywords = {composable extensions, extensibility, family polymorphism, nested inheritance, Persimmon}
}

@software{10.5281/zenodo.10798571,
author = {Crichton, Will and Krishnamurthi, Shriram},
title = {Artifact for "Profiling Programming Language Learning"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10798571},
abstract = {
    <p>These are Docker images that contain the codebase, data, and analysis scripts for our OOPSLA 2024 paper “Profiling Programming Language Learning”.</p>

},
keywords = {digital textbooks, item response theory, rust education}
}

@software{10.5281/zenodo.10897277,
author = {Zhang, Yifan and Shi, Yuanfeng and Zhang, Xin},
title = {Learning Abstraction Selection for Bayesian Program Analysis (Paper Artifact)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10897277},
abstract = {
    <p>Our artifact includes all code, scripts, data, and statistics in our experiments. It supports the following things: 1. Reproduction of all results in our experiments automatically. 2. Transformation from the results to Tables 7-11 and Figures 8-10 in our paper automatically. 3. Reusability guide for applying BinGraph framework to other settings and extensions.</p>

},
keywords = {abstract interpretation, alarm ranking, Bayesian network, machine learning for program analysis, Static analysis}
}

@software{10.5281/zenodo.10440364,
author = {Michelland, S\'{e}bastien and Deleuze, Christophe and Gonnord, Laure},
title = {Replication package for article: From low-level fault modeling (of a pipeline attack) to a proven hardening scheme},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10440364},
abstract = {
    <p>This software package is the Docker image of a project about protecting RISC-V processors against certain low-level fault attacks. It mainly contains a modified LLVM, GNU binutils, QEMU, and test scripts.</p>
<p>Project repository from which this image is built: https://gricad-gitlab.univ-grenoble-alpes.fr/michelse/fetch-skips-hardening</p>
<p>Instructions for using this software and reproducing results: https://gricad-gitlab.univ-grenoble-alpes.fr/michelse/fetch-skips-hardening/-/blob/main/README.md?ref_type=heads</p>

},
keywords = {Compilation, LLVM, Software fault resistance}
}

@software{10.5281/zenodo.10457086,
author = {Salvador Rohwedder, Caio and L. De Carvalho, Jo\~{a}o P. and Amaral, Jos\'{e} Nelson},
title = {Artifact of "Region-Based Data Layout via Data Reuse Analysis"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10457086},
abstract = {
    <ul>
<li>docker-artifact.tar.gz: docker image for the execution of experiments.</li>
<li>results.zip: log files, graphs, and tables that were used in the paper, as well as additional figures/tables not shown in the paper due to space constraints.</li>
<li>region-packing-pass.zip: source code for the out-of-tree LLVM implementation of the analysis that finds region-based data layout transformation candidates (.so file in docker image).</li>
<li>region-packing-scripts.zip: scripts used to run experiments and Dockerfile source (also provided in docker image).</li>
<li>artifact-appendix.pdf: Instructions on how to use this artifact.</li>
</ul>

},
keywords = {Data-Layout Transformation, LLVM, Structure Splitting}
}

@software{10.5281/zenodo.10525151,
author = {Dura, Alexandru and Reichenbach, Christoph},
title = {Reproduction Package for 'Clog: A Declarative Language for C Static Code Checkers'},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10525151},
abstract = {
    <p>Clog is a declarative language for describing static code checkers for C. Clog is a dialect of Datalog and adds syntactic pattern matching over the C language. We have built Clog using the MetaDL framework and the Clang C compiler frontend. The MetaDL framework supports Datalog evaluation and syntactic patterns, while the Clang frontend provides AST facts and an AST matching mechanism.</p>
<p>We provide the Clog artifact as a Docker image. The artifact contains the Clog implementation, the evaluation framework and the test suites we have used in our evaluation.</p>

},
keywords = {C, Datalog, Static Analysis Frameworks, Syntactic Patterns}
}

@software{10.5281/zenodo.10566216,
author = {Li, Wei and He, Dongjie and Gui, Yujiang and Chen, Wenguang and Xue, Jingling},
title = {Artifact for "A Context-Sensitive Pointer Analysis Framework for Rust and Its Application to Call Graph Construction"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10566216},
abstract = {
    <p>This is the artifact for the CC’24 paper titled “A Context-Sensitive Pointer Analysis Framework for Rust and Its Application to Call Graph Construction”. It includes a docker image and a READEME file.</p>

},
keywords = {Call Graph Construction, Pointer Analysis, Rust}
}

@software{10.5281/zenodo.10567311,
author = {Mavrogeorgis, Nikolaos and Vasiladiotis, Christos and Mu, Pei and Khordadi, Amir and Franke, Bj\"{o}rn and Barbalace, Antonio},
title = {Reproduction Package for Article 'UNIFICO: Thread Migration in Heterogeneous-ISA CPUs without State Transformation'},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10567311},
abstract = {
    <p>Artifact of the paper “UNIFICO: Thread Migration in Heterogeneous-ISA CPUs without State Transformation”. - unificocc24-unifico.tar.gz: docker image for the execution of experiments - llvm-unifico.tar.gz: LLVM source code with Unifico implementation (binaries in docker image) - unifico.tar.gz: scripts used to run experiments, the NPB benchmark suite, logs, plots, and Dockerfile source (also provided in docker image)</p>
<ul>
<li>figures.tar.gz: generated result plots from the paper</li>
</ul>

},
keywords = {Compilers, Computer Systems, LLVM}
}

@software{10.5281/zenodo.10570638,
author = {Zhu, Yifan and Cat, Quartic and Ge, Boluo and Sun, Shaotong},
title = {Paguroidea: Fused Parser Generator with Transparent Semantic Actions},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10570638},
abstract = {
    <p>This artifact provides source code and detailed guidance on building and benchmarking the Paguroidea parser generator. Paguroidea integrates lexer-parser fusion alongside a unique transparent encoding of semantic actions, delivering flexibility and performance. Developed using the Rust programming language, the Paguroidea enjoys good portability. Therefore, the setup process and the acquisition of results would not require too much effort.</p>

},
keywords = {compiler, context-free grammar, parser, parser generator, substructural logic}
}

@software{10.5281/zenodo.10571103,
author = {Drescher, Florian and Engelke, Alexis},
title = {Artifact for CC'24 paper on "Fast Template-Based Code Generation for MLIR"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10571103},
abstract = {
    <p>The artifact contains the sources for building the template-based MLIR compiler and the dependent LLVM sources (commit 5d4927 with some modifications). It compiles and executes MLIR programs consisting of supported operations (multiple sample programs are included; similar to mlir-cpu-runner); on first execution, it generates required templates and persists them. Furthermore, the artifact contains the modified sources for LingoDB with integrated template-based code-generation backend and Polygeist (commit fd4194b) for conversion of C files to MLIR upstream dialect operations. Sample MLIR programs and scripts for preparing/running the benchmarks from Figures 2-5 are attached.</p>

},
keywords = {Binary Code Patching, Fast Compilation, JIT Compilation, MLIR, Template-based Compilation}
}

@software{10.5281/zenodo.10124427,
author = {Frumin, Dan and Timany, Amin and Birkedal, Lars},
title = {Coq formalization of Guarded Interaction Trees},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10124427},
abstract = {
    <p>This is the Coq formalization of guarded interaction trees, associated examples and case studies.</p>

},
keywords = {coq, formalization, separation logic}
}

@software{10.5281/zenodo.8423866,
author = {Mansky, William and Du, Ke},
title = {VST on Iris},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8423866},
abstract = {
    <p>An Iris Instance for Verifying CompCert C Programs.</p>

},
keywords = {concurrent separation logic, interactive theorem
proving, Iris, program verification, software verification, Verified Software Toolchain}
}

@software{10.1145/3580424,
author = {Liu, Yiyun and Chan, Jonathan and Shi, Jessica and Weirich, Stephanie},
title = {Artifact associated with Internalizing Indistinguishability with Dependent Types},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3580424},
abstract = {
    <p>This artifact contains the complete mechanized Coq proofs of the lemmas and theorems about DCOI and its prototype implementation in Haskell. The VM image is preinstalled with the dependencies required to validate the Coq proofs and run the prototype type checker. No special hardware is required as long as the host machine has 4 GiB of memory available to run the VM.</p>

},
keywords = {Coq, Dependent Types, Formalization, Modes}
}

@software{10.1145/3580425,
author = {Grodin, Harrison and Niu, Yue and Sterling, Jonathan and Harper, Robert},
title = {**calf**: A Cost-Aware Logical Framework},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3580425},
abstract = {
    <p>The <strong>calf</strong> language is a <strong>c</strong>ost-<strong>a</strong>ware <strong>l</strong>ogical <strong>f</strong>ramework for studying quantitative aspects of functional programs.</p>
<p>This repository contains the Agda implementation of <strong>calf</strong>, as well as some case studies of varying complexity.</p>

},
keywords = {algorithm analysis, amortized analysis, behavioral verification, cost models, equational reasoning, intensional property, mechanized proof, modal type theory, noninterference, parallel algorithms, phase distinction, proof assistants, recurrence relations}
}

@software{10.17863/CAM.104080,
author = {Hammond, Angus and Liu, Zongyuan and P\'{e}rami, Thibaut and Sewell, Peter and Birkedal, Lars and Pichon-Pharabod, Jean},
title = {Research data for "An Axiomatic Basis for Computer Programming on the Relaxed Arm-A Architecture: The AxSL Logic"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.17863/CAM.104080},
abstract = {
    <p>Formal proof development for the AxSL logic</p>
<p>This artifact is a mechanised proof development that contains formalised definitions and proofs that can be checked by the Coq proof assistant. It contains all the results presented in the paper.</p>

},
keywords = {AxSL}
}

@software{10.5281/zenodo.10009365,
author = {Van Muylder, Antoine and Nuyts, Andreas and Devriese, Dominique},
title = {Agda --bridges virtual machine},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10009365},
abstract = {
    <p>This is an Ubuntu 20.04 virtual machine (.ova format) to play with Agda –bridges, a proof assistant extending the Agda 2.6.3 proof assistant with internal parametricity. The virtual machine contains (see desktop):</p>
<ul>
<li><p>The Agda –bridges repository (a fork of Agda). Sources of Agda –bridges have been pre-compiled. The resulting binaries live in <code>/home/vboxuser/.local/bin/</code>.</p></li>
<li><p>The cubical library repo.</p></li>
<li><p>The bridgy library, an Agda –bridges library featuring abstractions to prove internal free theorems modularly.</p></li>
</ul>
<p>Quick start: After having imported the VM into your system, load <code>/home/vboxuser/Desktop/bridgy-lib/Everything.agda</code> in emacs (C-c C-l) within the VM.</p>
<p>Alternatively: install Agda –bridges directly on your machine.</p>
<p>Detailed instructions: See README.md in the artifact.</p>

},
keywords = {Agda, cubical type theory, parametricity, structure relatedness principle, type theory}
}

@software{10.5281/zenodo.10015321,
author = {Smeding, Tom J. and V\'{a}k\'{a}r, Matthijs I. L.},
title = {Artifact for Efficient CHAD},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10015321},
abstract = {
    <p>Contains a proof, formalised in Agda, of the main complexity result in the paper.</p>

},
keywords = {Agda, automatic differentiation, complexity, formalized proof, source transformation}
}

@software{10.5281/zenodo.10023424,
author = {Pottier, Fran\c{c}ois and Gu\'{e}neau, Arma\"{e}l and Jourdan, Jacques-Henri and M\'{e}vel, Glen},
title = {Artifact for "Thunks and Debits in Separation Logic with Time Credits"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10023424},
abstract = {
    <p>This is the artifact for the POPL 2024 paper “Thunks and Debits in Separation Logic with Time Credits”.</p>
<p>The artifact is provided both as a VirtualBox virtual machine and as a .tar.gz file. They both contain the same Coq development, accessible in the following public GitLab repository:</p>
<pre><code> https://gitlab.inria.fr/cambium/iris-time-proofs</code></pre>
<h3 id="the-virtual-machine">The virtual machine</h3>
<p>The virtual machine contains the content of the archive, fully compiled, and all the software needed to compile it. When booting, it should automatically log in. In case it is necessary, it can be logged in using the user “vagrant” and the password “vagrant”.</p>
<p>The relevent files are in the directory coq-iris-time on the desktop. They can be seen using Coqide, which can be run using the icon on the desktop.</p>
<h3 id="building-the-artifact-from-the-archive">Building the artifact from the archive</h3>
<p>The archive can be compiled by following the instructions bellow.</p>
<h4 id="step-1-creating-an-opam-switch">Step 1: Creating an opam switch</h4>
<p>If opam is not already installed:_ See instructions <a href="https://opam.ocaml.org/doc/Install.html">there</a> to install it; then:</p>
<pre><code>opam init
eval $(opam env)</code></pre>
<p>(This will create a <code>~/.opam</code> directory.)</p>
<p>Extract the archive, and move to the directory:</p>
<pre><code>tar -xzvf coq-iris-time.tar.gz
cd coq-iris-time</code></pre>
<p>If opam (≥ 2.0) is already installed:_ Create a local switch for the project in the current directory:</p>
<pre><code>opam update
opam switch create --no-install . ocaml-base-compiler.4.14.1
eval $(opam env)</code></pre>
<h4 id="step-2-installing-the-dependencies">Step 2: Installing the dependencies</h4>
<p>In an opam switch as created above, the commands</p>
<pre><code>opam repo add coq-released https://coq.inria.fr/opam/released
opam repo add iris-dev git+https://gitlab.mpi-sws.org/iris/opam.git
opam update
opam pin add -n coq 8.16.1
make builddep</code></pre>
<p>will pin and install the dependencies at the correct version.</p>
<p>If you want to browse the Coq development using CoqIDE (a graphical, interactive toplevel for Coq), install it as well:</p>
<pre><code>opam install coqide</code></pre>
<h4 id="step-3-compiling-the-proof-scripts">Step 3: Compiling the proof scripts</h4>
<p>When all required libraries can be found (e.g.&nbsp;in an opam switch as configured above), compile the proof scripts with:</p>
<pre><code>make -j</code></pre>
<p>Other recipes are available, such as <code>all</code>, <code>clean</code> and <code>userinstall</code>.</p>
<h3 id="supporting-the-claims-of-the-paper">Supporting the claims of the paper</h3>
<h4 id="piggy-banks">Piggy banks</h4>
<p>The piggy bank construction is formalized in file <code>theories/thunks/PiggyBank.v</code>. Each rule in Figure 2 of the paper is formalized by a lemma in this file, named after the name of the rule.</p>
<h4 id="thunks">Thunks</h4>
<p>The common interface of thunks, base thunks and proxy thunks is defined as the <code>CommonThunkAPI</code> typeclass in file <code>theories/thunks/ThunksAPI.v</code>. Lemma <code>base_thunk_api</code> shows that base thunks implement this API (second part of Theorem 4.1).</p>
<p>Base thunks and the <code>ThunkVal</code> predicate are defined in file <code>theories/thunks/ThunksBase.v</code>. Rules in Figure 7 are proved by lemmas in the same file, named after the name of the rule (last part of Theorem 4.1). The rule Thunk-Create for base thunks is proved by lemma <code>base_thunk_create</code> (first part of Theorem 4.1).</p>
<p>Proxy thunks are defined in file <code>theories/thunks/ThunksStep.v</code>. Theorem 4.2 is proved by instance <code>step_thunk_api</code> and lemma <code>proxythunk_consequence</code>.</p>
<p>Thunks are defined in file <code>theories/thunks/ThunksFull.v</code>. Theorem 4.3 is proved by instance <code>thunk_api</code>, lemma <code>thunk_create</code> and lemma <code>thunk_consequence</code>.</p>
<h4 id="height-indexed-thunks">Height-indexed thunks</h4>
<p>Height-indexed thunks are defined in file <code>theories/thunks/HThunks.v</code>. Rules in Figure 11 are formalized in lemmas whose name should be self-explanatory, except for rule HThunk-Inc-Height-Debit, split into lemmas <code>hthunk_covariant_in_h</code> and <code>hthunk_increase_debt</code>.</p>
<h4 id="streams">Streams</h4>
<p>The code of the stream library is given in file <code>theories/streams/StreamsCode.v</code>, and its specification formalized in file <code>theories/streams/Streams.v</code>.</p>
<p>Rules of Figure 13 are formalized by lemmas with the same name, except for Stream-Increase-Height, which is backed by lemma <code>stream_covariant</code>.</p>
<p>Rules of Figure 14 are constructor of inductive predicate <code>subdebits</code>.</p>
<p>Rule Sub-Variance is split into lemmas <code>subdebits_covariant_in_slack</code> and <code>subdebits_contravariant_in_rest</code>.</p>
<p>Rule Sub-Refl is backed by lemma <code>subdebits_reflexive</code>.</p>
<p>Rule Sub-Trans is backed by lemma <code>subdebits_transitive</code>.</p>
<p>Rule Sub-Append is backed by lemma <code>subdebits_app</code>.</p>
<p>Rule Sub-Add-Slack is backed by lemma <code>subdebits_add_slack</code>.</p>
<p>Rule Sub-Repeat is backed by lemma <code>subdebits_repeat</code>.</p>
<p>Lemma 6.1 is backed by lemma <code>subdebits_alternate_characterization</code>.</p>
<h4 id="bankers-queue">Banker’s queue</h4>
<p>The code of the banker’s queue is in file <code>theories/bqueue/Code.v</code>. Its specification is in file <code>theories/bqueue/Proof.v</code>.</p>
<p>Rule Banker-Persistent is proved by lemma <code>is_queue_persistent</code>.</p>
<p>Rule Banker-Empty is proved by lemma <code>empty_spec</code>.</p>
<p>Rule Banker-Snoc is proved by lemma <code>snoc_spec</code>.</p>
<p>Rule Banker-Extract is proved by lemma <code>extract_spec</code>.</p>
<p>Rule Banker-Check is proved by lemma <code>check_spec</code>.</p>
<h4 id="the-physiscists-queue-implicit-queues.">The physiscist’s queue, implicit queues.</h4>
<p>The physiscist’s queue is formalized in directory <code>theories/pqueue</code>.</p>
<p>Implicit queus are formalized in directory <code>theories/iqueue</code>.</p>

},
keywords = {program verification, separation logic, time complexity}
}

@software{10.5281/zenodo.10023528,
author = {Li, Xiang and Zhou, Xiangyu and Dong, Rui and Zhang, Yihong and Wang, Xinyu},
title = {Reproduction Package for 'Efficient Bottom-Up Synthesis for Programs with Local Variables'},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10023528},
abstract = {
    <p>This artifact includes the Arborist program synthesizer for web automation. It also contains all the necessary benchmark data to reproduce the RQ1 main results (Figure 21 of the paper).</p>

},
keywords = {Observational Equivalence, Program Synthesis, Web Automation}
}

@software{10.5281/zenodo.10026970,
author = {Randone, Francesca and Bortolussi, Luca and Incerto, Emilio and Tribastone, Mirco},
title = {Reproduction Package for the Paper "Inference of Probabilistic Programs with Moment-Matching Gaussian Mixtures"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10026970},
abstract = {
    <p>This is the replication package for the paper “Inference of Probabilistic Programs with Moment-Matching Gaussian Mixtures”</p>
<h3 id="contents">Contents</h3>
<ul>
<li>soga_docker.tar.gz contains the docker image of SOGA</li>
<li>soga_code.tar.gz contains the SOGA source code</li>
</ul>
<h3 id="requirements">Requirements</h3>
<ul>
<li>For running this package a valid docker (https://docs.docker.com/engine/install/) installation is required with version &gt;=24.0.6.</li>
<li>For compatibility issues with the external tools used for the evaluation, the image is based on x86_64 architecture</li>
</ul>
<h3 id="reproducibility">Reproducibility</h3>
<ul>
<li><p>The provided docker images can be loaded in two ways: A) using the one provided in this package and B) using the one stored on Dockerhub. To load the images provided in this package, download it and issue the following command:</p>
<p>docker load –input soga_docker.tar.gz</p></li>
<li><p>In both cases, A or B, for creating the container issue:</p>
<p>docker container create -i -t –name SOGA bistrulli/soga:0.1 docker container start SOGA docker attach SOGA</p></li>
<li><p>The detailed instructions for reproducing the paper results are reported in the README.md file within the docker image</p></li>
</ul>

},
keywords = {Gaussian Mixtures, Inference, Moment-Matching, Probabilistic Programming}
}

@software{10.5281/zenodo.10036618,
author = {Zhang, Ling and Wang, Yuting and Wu, Jinhua and Koenig, J\'{e}r\'{e}mie and Shao, Zhong},
title = {Artifact for `Fully Composable and Adequate Verified Compilation with Direct Refinements between Open Modules`},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10036618},
abstract = {
    <p>This is the artifact for the POPL 2024 paper “Fully Composable and Adequate Verified Compilation with Direct Refinements between Open Modules”.</p>
<p>The artifact is a VM image in .ova format. We have tested the VM in VirtualBox version 7.0.8 running on a host Windows 11 machine with 64-bit Ubuntu LTS 20.04. The source code can be found in the directory ‘/home/authors/direct-refinement-popl24-artifact’. Follow the ‘README.md’ file in this directory to evaluate the artifact.</p>
<p>The VM should also work on Linux host machines. Note that the VM will not run on Mac computers with M-series chips as it is based on X86.</p>
<p>You may also compile from the source code on your local Linux machine. The up-to-date source code and instructions for compiling it can be found at the following address:</p>
<p>https://github.com/SJTU-PLV/direct-refinement-popl24-artifact/blob/main/README.md</p>
<p>We suggest you look at the instructions in the above URL if you have difficulty reading README.md file directly in the VM.</p>
<p>The technical report of our paper can be found at the following address:</p>
<p>https://arxiv.org/abs/2302.12990</p>

},
keywords = {Compiler Verification, Direct Refinements, Kripke Relations, Program Verification, Verified Compositional Compilation}
}

@software{10.5281/zenodo.10039066,
author = {Yao, Jianan and Tao, Runzhou and Gu, Ronghui and Nieh, Jason},
title = {Artifact for Article "Mostly Automated Verification of Liveness Properties for Distributed Protocols with Ranking Functions"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10039066},
abstract = {
    <p>This artifact provides a docker image which includes the Python source code of LVR and the evaluated mypyvy protocols. See README for instructions to run. Please use the latest version if available.</p>

},
keywords = {distributed protocols, formal verification, liveness properties, ranking functions}
}

@software{10.5281/zenodo.10040534,
author = {Sieczkowski, Filip and Stepanenko, Sergei and Sterling, Jonathan and Birkedal, Lars},
title = {The Essence of Generalized Algebraic Data Types (Coq mechanization)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10040534},
abstract = {
    <p>Coq mechanization supplement for The Essence of Generalized Algebraic Data Types paper.</p>

},
keywords = {Functional languages, Semantic models, Type systems/inference/theory}
}

@software{10.5281/zenodo.10054966,
author = {Deng, Haowei and Tao, Runzhou and Peng, Yuxiang and Wu, Xiaodi},
title = {A Case for Synthesis of Recursive Quantum Unitary Programs},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10054966},
abstract = {
    <p>QSynth’s source code for POPL24 artifact evaluation.</p>

},
keywords = {Program Synthesis, SMT Solver}
}

@software{10.5281/zenodo.10069757,
author = {Cyphert, John and Kincaid, Zachary},
title = {Reproduction Package for Article Solvable Polynomial Ideals: The Ideal Reflection for Program Analysis},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10069757},
abstract = {
    <p>The artifact consists of a virtual machine (VM) in OVA format. The VM contains an installation of Ubuntu 22.04, along with the required software to verify the experimental claims in the article Solvable Polynomial Ideals: The Ideal Reflection for Program Analysis. The VM contains an executable duet.exe which implements the ideas described in the article. The VM also contains software to compare the ideas of the article with the tools ChilonInv, CRA, Veriabs, and Ultimate Automizer on benchmarks sourced from the software verification competition (SV-COMP).</p>

},
keywords = {Algebraic Program Analysis, Monotone Analysis, Polynomial Invariants}
}

@software{10.5281/zenodo.10073582,
author = {Cohen, Liron and Jabarin, Adham and Popescu, Andrei and Rowe, Reuben N. S.},
title = {The Complex(ity) Landscape of Checking Infinite Descent (Software Artifact)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10073582},
abstract = {
    <p>This is the accompanying artifact for the POPL 2024 paper “The Complex(ity) Landscape of Checking Infinite Descent” by Liron Cohen, Adham Jabarin, Andrei Popescu and Reuben N. S. Rowe. It contains the following:</p>
<ol type="1">
<li><p>Extension of the Cyclist automated theorem prover (cyclist-prover.org) by new algorithms for checking the Infinite Descent property.</p></li>
<li><p>Experimental dataset for algorithms checking Infinite Descent.</p></li>
</ol>

},
keywords = {B\"{u}chi automaton, cyclic proof, Cyclist theorem prover, infinite descent, relational criterion}
}

@software{10.5281/zenodo.10077754,
author = {Sotiropoulos, Thodoris and Chaliasos, Stefanos and Su, Zhendong},
title = {Replication Pakcage for Article "API-Driven Program Synthesis for Testing Static Typing Implementations"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10077754},
abstract = {
    <p>The purpose of this artifact is to reproduce the results presented in the POPL 2024 paper titled “API-Driven Program Synthesis for Testing Static Typing Implementations”. The artifact contains the instructions and scripts to re-run the evaluation described in the paper. The artifact has the following structure:</p>
<ul>
<li>scripts/: This directory contains the scripts needed to re-run the experiments and re-produce the figures and tables presented in the paper.</li>
<li>data/: This is the directory that contains the pre-computed results of the evaluation.</li>
<li>data/packages.csv: A CSV file that contains the 95 Maven libraries whose APIs have been used in the evaluation.</li>
<li>database/bug_schema.sql: This is the database schema that contains the bugs discovered by our approach.</li>
<li>database/bugdb.sqlite3: This is the <code>sqlite3</code> database file corresponding to our bug database.</li>
<li>database/bugs.json: Our bug reports in a JSON format.</li>
<li>stdlib/: API specification of the standard libraries of three languages: Java, Scala, Kotlin. This not the complete API specification, but rather some common API components (e.g., java.util.*) that are used frequently in third-party libraries.</li>
<li>thalia/: Contains the source code of our tool (provided as a git submodule) used for testing the compilers of Scala, Kotlin, and Groovy using API-driven program synthesis. The name of our tool is <code>thalia</code>.</li>
<li>hephaestus/: Contains the source code of the state-of-the-art tool named Hephaestus used for finding compiler typing bugs. In our evaluation, we compare Thalia` with Hephaestus.</li>
<li>doc2json/: This is a submodule that contains the source code of an auxiliary tool used to convert API documentation pages into JSON documents. More details can be found at: https://github.com/hephaestus-compiler-project/doc2json</li>
<li>installation_scripts/: Contains helper scripts used to install all dependencies (e.g., compiler versions from <a href="https://sdkman.io/">SDKMAN</a>).</li>
<li>figures/: This directory will be used to save the figures of our paper.</li>
<li>Dockerfile: The Dockerfile used to create a Docker image of our artifact. This image contains all data and dependencies.</li>
</ul>

},
keywords = {API, compiler bugs, compiler testing, enumeration, Groovy, Kotlin, library, Scala, static typing}
}

@software{10.5281/zenodo.10100892,
author = {Timany, Amin and Gregersen, Simon Oddershede and Stefanesco, L\'{e}o and Hinrichsen, Jonas Kastberg and Gondelman, L\'{e}on and Nieto, Abel and Birkedal, Lars},
title = {Trillium: Higher-Order Concurrent and Distributed Separation Logic for Intensional Refinement - Coq Artefact},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10100892},
abstract = {
    <p>Coq artifact accompanying the paper “Trillium: Higher-Order Concurrent and Distributed Separation Logic for Intensional Refinement”.</p>

},
keywords = {liveness, refinement, Separation logic, step-indexing}
}

@software{10.5281/zenodo.10116628,
author = {Popescu, Andrei},
title = {Nominal Recursors as Epi-Recurors (Mechanized Proofs Artifact)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10116628},
abstract = {
    <p>This is the Isabelle mechanization associated to the POPL 2024 paper “Nominal Recursors as Epi-Recursors” by Andrei Popescu. The formal proofs are located in the archive isabelle_nominal_recursors_and_corecursors.zip . They can be processed with Isabelle2023, available for download from https://isabelle.in.tum.de/ .</p>

},
keywords = {epi-(co)recuror, formal reasoning, Isabelle/HOL, nominal logic, nominal recursion and corecursion, syntax with bindings, theorem proving}
}

@software{10.5281/zenodo.10120126,
author = {Tang, Wenhao and Hillerstr\"{o}m, Daniel and Lindley, Sam and Morris, J. Garrett},
title = {Artifact for Soundly Handling Linearity},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10120126},
abstract = {
    <p>This artifact contains the implementation of the extension of Links with control-flow linearity as described in Section 4 of the paper:</p>
<p>Wenhao Tang, Daniel Hillerstr\"{o}m, Sam Lindley, J. Garrett Morris, “Soundly Handling Linearity”, Proc. ACM Program. Lang. 8(POPL), 2024.</p>

},
keywords = {effect handlers, linear resources, linear types}
}

@software{10.5281/zenodo.10125015,
author = {Andrici, Cezar-Constantin and Ciob\^{a}c\u{a}, undefinedtefan and Hri\c{t}cu, C\u{a}t\u{a}lin and Mart\'{\i}nez, Guido and Rivas, Exequiel and Tanter, \'{E}ric and Winterhalter, Th\'{e}o},
title = {Artifact for the POPL 2024 paper `Securing Verified IO Programs Against Unverified Code in F*`},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10125015},
abstract = {
    <p>The artifact contains a formalization of the contributions of the paper. The artifact contains the SCIO* framework, the mechanized proofs of sound enforcement of a global trace property and Robust Relational Hyperproperty Preservation (RrHP), as well as a few examples.</p>

},
keywords = {F*, formal verification, input-output, proof assistants, secure compilation}
}

@software{10.5281/zenodo.10125129,
author = {Zhou, Litao and Qin, Jianxing and Wang, Qinshi and Appel, Andrew W. and Cao, Qinxiang},
title = {Artifact for VST-A: A Foundationally Sound Annotation Verifier},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10125129},
abstract = {
    <p>This is the artifact for the paper “VST-A: A Foundationally Sound Annotation Verifier.” VST-A is an annotation verifier built upon VST, designed for the functional correctness verification of assertion annotated C programs. Users are guided to first install the OPAM package manager and subsequently set up OCaml 4.10.2, Menhir 20190924, and Coq 8.12.2 to facilitate the artifact’s compilation. The artifact is self-contained, incorporating a modified CompCert compiler capable of parsing annotated programs and a patched VST-2.5. The development of VST-A, encompassing formalization, implementation, and evaluation examples outlined in the paper, is consolidated within the <code>VST-A/</code> directory.</p>

},
keywords = {Annotated Programs, Coq, Foundational Verification}
}

@software{10.5281/zenodo.10125136,
author = {Elad, Neta and Padon, Oded and Shoham, Sharon},
title = {An Infinite Needle in a Finite Haystack: Finding Infinite Counter-Models in Deductive Verification &nbsp;(Artifact)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10125136},
abstract = {
    <p>Artifact for the POPL ’24 paper “An Infinite Needle in a Finite Haystack: Finding Infinite Counter-Models in Deductive Verification”.</p>
<p>The artifact is provded as a virtual machine, and includes the Python package for the FEST tool, and benchmarks (encoded in Z3’s programmatic API).</p>
<p>For more details, see the <code>README.md</code> file.</p>
<p>Note that the run times of the benchmarks inside the virtual machine can be 2x-5x slower than the times measured (in Table 2). Still, they remain below the 10 minutes threshold.</p>

},
keywords = {counter-models, deductive verification, infinite models, Paxos}
}

@software{10.5281/zenodo.10125602,
author = {Qin, Xueying and O’Connor, Liam and van Glabbeek, Rob and H\"{o}fner, Peter and Kammar, Ohad and Steuwer, Michel},
title = {Artifact for Shoggoth - A Formal Foundation for Strategic Rewriting},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10125602},
abstract = {
    <p>This is the artifact for the paper Shoggoth : A Formal Foundation for Strategic Rewriting. We provide all mechanised proofs developed in Isabelle/HOL. In total we provide nine files (with .thy extension) containing our proof scripts for the denotational semantics, operational semantics, semantic equivalence, weakest precondition calculus and soundness of the weakest precondition calculus are discussed in the paper. Please refer to README.md for detail information as well as instructions for installing and executing this artifact.</p>

},
keywords = {formal verification, semantics, weakest precondition}
}

@software{10.5281/zenodo.10126819,
author = {Rinaldi, Francis and wunder, june and Azevedo de Amorim, Arthur and Muller, Stefan K.},
title = {Implementation for "Pipelines and Beyond: Graph Types for ADTs with Futures"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10126819},
abstract = {
    <p>This artifact accompanies the paper “Pipelines and Beyond: Graph Types for ADTs with Futures”, published at POPL 2024. It implements an engine to infer vertex structure annotations and graph types for a subset of OCaml, following the language and the type system presented in the paper.</p>

},
keywords = {affine type system, computation graphs, cost graphs, futures, graph types, parallel programs, pipelining}
}

@software{10.5281/zenodo.10129703,
author = {Zhao, Eric and Maroof, Raef and Dukkipati, Anand and Blinn, Andrew and Pan, Zhiyi and Omar, Cyrus},
title = {Artifact for Total Type Error Localization and Recovery with Holes},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10129703},
abstract = {
    <p>The artifact contains the complete formalization of and extensions to the marked lambda calculus, the Agda mechanization, and the implementation of Hazel including type hole inference, as described in the paper.</p>

},
keywords = {bidirectional typing, gradual typing, type errors, type inference}
}

@software{10.5281/zenodo.10129930,
author = {Ding, Yuantian and Qiu, Xiaokang},
title = {Reproduction Package (VirtualBox Image) for the POPL 2024 Article `Enhanced Enumeration Techniques for Syntax-Guided Synthesis of Bit-Vector Manipulations'},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10129930},
abstract = {
    <p>This is the artifact for the ACM PACMPL article Enhanced Enumeration Techniques for Syntax-Guided Synthesis of Bit-Vector Manipulations. We provide our artifact as an easy-to-use VirtualBox image, which contains the benchmarks, our tools for bit-vector synthesis, and the scripts for generating the results showcased in the paper.</p>

},
keywords = {Bit vector, Enumeration, Large language model, Syntax-guided synthesis, Term graph}
}

@software{10.5281/zenodo.10146270,
author = {Mell, Stephen and Zdancewic, Steve and Bastani, Osbert},
title = {Artifact for "Optimal Program Synthesis via Abstract Interpretation"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10146270},
abstract = {
    <p>The artifact reproduces our experimental results (Figure 2 and Table 1) and may be useful for performing synthesis on other trajectory datasets or implementing our algorithm for other DSLs.</p>

},
keywords = {abstract interpretation, optimal synthesis, program synthesis}
}

@software{10.5281/zenodo.10151333,
author = {Moy, Cameron and Dimoulas, Christos and Felleisen, Matthias},
title = {Artifact: Effectful Software Contracts},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10151333},
abstract = {
    <p>This artifact contains a Docker image for the effect/racket language implementation along with appendices accompanying the paper.</p>

},
keywords = {effect handlers, software contracts}
}

@software{10.5281/zenodo.10155221,
author = {Castagna, Giuseppe and Laurent, Micka\"{e}l and Nguy\~{\^e}n, Kim},
title = {Prototype: Polymorphic Type Inference for Dynamic Languages},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10155221},
abstract = {
    <p>This is a prototype for the article: Polymorphic Type Inference for Dynamic Languages. See README.md for instructions.</p>

},
keywords = {intersection types, OCaml, polymorphism, type reconstruction, union types}
}

@software{10.5281/zenodo.10207465,
author = {Timany, Amin and Gu\'{e}neau, Arma\"{e}l and Birkedal, Lars},
title = {Artifact for the paper "The Logical Essence of Well-Bracketed Control Flow"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10207465},
abstract = {
    <p>This artifact includes the accompanying technical appendix and the Coq formalization of the paper “The Logical Essence of Well-Bracketed Control Flow”.</p>

},
keywords = {Coq, logical relations, program logics, program verification, semantic typing, stack discipline, well-bracketedness}
}

@software{10.5281/zenodo.8409115,
author = {Crichton, Will and Krishnamurthi, Shriram},
title = {Artifact for "A Core Calculus for Documents"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8409115},
abstract = {
    <p>These are Docker images that contain the codebase for our POPL 2024 paper “A Core Calculus for Documents”. Download the README.pdf for instructions on how to run the artifact and for details about its contents.</p>

},
keywords = {document languages, markup, templates}
}

@software{10.5281/zenodo.8414566,
author = {Moine, Alexandre and Westrick, Sam and Balzer, Stephanie},
title = {DisLog: A Separation Logic for Disentanglement - Artifact},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8414566},
abstract = {
    <p>This is the artifact corresponding to the article entitled “DisLog: A Separation Logic for Disentanglement”, and its associated documentation.</p>

},
keywords = {Coq, Disentanglement, Iris, Separation Logic}
}

@software{10.5281/zenodo.8417774,
author = {Cohen, Joshua M. and Johnson-Freyd, Philip},
title = {Coq Formalization for the paper "A Formalization of Core Why3 in Coq"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8417774},
abstract = {
    <p>This artifact contains a formalization of the logic fragment of the Why3 language, used as a backend for many verification tools, including Frama-C.</p>

},
keywords = {Coq, First-Order Logic, Formal Semantics, Why3}
}

@software{10.5281/zenodo.8421879,
author = {Sellami, Yanis and Girol, Guillaume and Recoules, Fr\'{e}d\'{e}ric and Courouss\'{e}, Damien and Bardin, S\'{e}bastien},
title = {Reproduction Package for Article `Inference of Robust Reachability Constraints'},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8421879},
abstract = {
    <p>This is the Artifact for the POPL 2024 Paper `Inference of Robust Reachability Constraints’. The artifact takes the form of a virtual machine disk image from which one can regenerate the paper’s tables and graphs from the logs of the experiments and rerun the experiments for reproducibility.</p>

},
keywords = {abduction, precondition inference, program analysis, software security engineering, symbolic execution}
}

@software{10.5281/zenodo.8422415,
author = {Bergstr\"{a}\ss{}er, Pascal and Ganardi, Moses and Lin, Anthony W. and Zetzsche, Georg},
title = {Ramsey Quantifiers in Linear Arithmetics - Artifact},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8422415},
abstract = {
    <p>The purpose of the artifact is to reproduce the experimental results of the paper “Ramsey Quantifiers in Linear Arithmetics”. It consists of a “README.pdf” and the four files “ramsey.py”, “elimination_benchmarks.py”, “mondec_benchmarks.py”, and “example.py”. The file “ramsey.py” contains the main functions “eliminate_ramsey” and “is_mondec”. The purpose of the function “eliminate_ramsey” is to compute an equivalent existential formula from a given Ramsey quantified existential formula. The function “is_mondec” takes a quantifier-free formula and returns true if the formula is monadically decomposable and false otherwise. We assume the formulas to be in Linear Integer Arithmetic, in Linear Real Arithmetic, or a decomposition of a Linear Integer Real Arithmetic formula. The benchmarks that are mentioned in the paper are available in the files “elimination_benchmarks.py” and “mondec_benchmarks.py”.</p>

},
keywords = {Infinite Chains, Infinite Cliques, Linear Integer Arithmetic, Linear Real Arithmetic, Liveness, Monadic Decomposability, Ramsey Quantifiers, Satisfiability Modulo Theories, Termination}
}

@software{10.5281/zenodo.8422532,
author = {Kidney, Donnacha Ois\'{\i}n and Yang, Zhixuan and Wu, Nicolas},
title = {Artefact for "Algebraic Effects Meet Hoare Logic in Cubical Agda"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8422532},
abstract = {
    <p>This artefact contains the Agda formalisation of the paper “Algebraic Effects Meet Hoare Logic in Cubical Agda”.</p>

},
keywords = {algebraic effects, Cubical Agda, Hoare logic, program verification}
}

@software{10.5281/zenodo.8422755,
author = {Jacobs, Jules and Hinrichsen, Jonas Kastberg and Krebbers, Robbert},
title = {Linear Actris Artifact},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8422755},
abstract = {
    <h2 id="linear-actris-artifact">Linear Actris Artifact</h2>
<p>A version of Actris where Hoare triples prove deadlock and leak freedom.</p>
<p>This artifact contains Coq source code that proves the results in the paper “Deadlock-Free Separation Logic: Linearity Yields Progress for Dependent Higher-Order Message Passing”.</p>

},
keywords = {concurrency, deadlocks, message passing, Separation logic}
}

@software{10.5281/zenodo.8423335,
author = {DeYoung, Henry and Mordido, Andreia and Pfenning, Frank and Das, Ankush},
title = {Parametric Subtyping for Structural Parametric Polymorphism (Artifact)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8423335},
abstract = {
    <p>This artifact consists of a Standard ML implementation of the parametric subtyping algorithm described in the POPL 2024 paper “Parametric Subtyping for Structural Parametric Polymorphism” by Henry DeYoung, Andreia Mordido, Frank Pfenning, and Ankush Das, as well as a file containing all of the examples from the paper. The up-to-date source code is maintained in a repository at https://bitbucket.org/structural-types/polyte/src/main/. For convenience, a VirtualBox VM image with the source code, necessary SML dependencies, and a pre-built binary is also available at https://zenodo.org/records/8423335.</p>

},
keywords = {parametric polymorphism, saturation-based algorithm, structural subtyping, type constructors}
}

@software{10.5281/zenodo.8423505,
author = {Patton, Noah and Rahmani, Kia and Missula, Meghana and Biswas, Joydeep and Dillig, I\c{s}\i{}l},
title = {Programming-by-Demonstration for Long-Horizon Robot Tasks},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8423505},
abstract = {
    <p>This artifact contains the source code for running the experiments in Programming-by-Demonstration for Long-Horizon Robot Tasks. We include scripts and a docker file to run the experiments as specified in the README.</p>

},
keywords = {Abstract Interpretation, Learning from Demonstrations, Program Synthesis}
}

@software{10.5281/zenodo.8423710,
author = {Peng, Yuxiang and Young, Jacob and Liu, Pengyu and Wu, Xiaodi},
title = {Artifact for SimuQ: a Framework for Programming Quantum Hamiltonian Simulation with Analog Compilation},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8423710},
abstract = {
    <p>This is the artifact for SimuQ, a framework for programming quantum Hamiltonian simulation with analog compilation. The main folder for the artifact evaluation is in <code>SimuQ/notebooks/artifact_evaluation</code>.</p>

},
keywords = {analog quantum computing, pulse-level programming, quantum simulation}
}

@software{10.5281/zenodo.8423764,
author = {Krishna, Shankaranarayanan and Lal, Aniket and Pavlogiannis, Andreas and Tuppe, Omkar},
title = {On-The-Fly Static Analysis via Dynamic Bidirected Dyck Reachability Artifact},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8423764},
abstract = {
    <p>Implementation of paper On-The-Fly Static Analysis via Dynamic Bidirected Dyck Reachability. The Dynamic Bidirected Dyck Reachability Tool accepts an initial graph and a sequence of update edge operations as input. It then calculates Bidirected Dyck reachability among nodes after executing the specified update operations on the initial graph.</p>

},
keywords = {CFL reachability, dynamic algorithms, static analysis}
}

@software{10.5281/zenodo.8423782,
author = {Frank, Justin and Quiring, Benjamin and Lampropoulos, Leonidas},
title = {Reproduction Package for Article `Generating Well-Typed Terms That Are Not “Useless”`},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8423782},
abstract = {
    <p>The artifact includes the OCaml source code for the generator, the Coq proofs that the generation steps are well-typed, and the evaluation setup used to compare our generator with the Palka generator for finding bugs in GHC’s strictness analyzer.</p>

},
keywords = {property-based testing, test generation, well-typed lambda terms}
}

@software{10.5281/zenodo.8423903,
author = {Jayanti, Prasad and Jayanti, Siddhartha and Yavuz, Ugur Y. and Hernandez, Lizzie},
title = {Artifact for "A Universal, Sound, and Complete Forward Reasoning Technique for Machine-Verified Proofs of Linearizability", POPL 2024},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8423903},
abstract = {
    <p>This is the software artifact for the TLAPS proofs from the paper “A Universal, Sound, and Complete Forward Reasoning Technique for Machine-Verified Proofs of Linearizability” (POPL 2024). The artifact contains machine-verified proofs of the linearizability of the Herlihy-Wing queue and Jayanti’s single-scanner snapshot, and a proof of the strong linearizability of the Jayanti-Tarjan union-find object. All the proofs are by the ‘tracking method’ introduced in the paper and are verified in the TLA+ Proof System.</p>
<p>Details and instructions can be found in the README.md file within this Zenodo repository. The artifact is also available at the following GitHub repository: https://github.com/uguryavuz/machine-certified-linearizability.</p>

},
keywords = {linearizability, machine-verified, meta-configuration, queue, snapshot, strong linearizability, tracker method, union-find}
}

@software{10.5281/zenodo.8424490,
author = {Gregersen, Simon Oddershede and Aguirre, Alejandro and Haselwarter, Philipp G. and Tassarotti, Joseph and Birkedal, Lars},
title = {Asynchronous Probabilistic Couplings in Higher-Order Separation Logic - Coq Artifact},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8424490},
abstract = {
    <p>Coq artifact accompanying the paper “Asynchronous Probabilistic Couplings in Higher-Order Separation Logic”.</p>

},
keywords = {coq, iris, probabilistic, probabilistic coupling, separation logic}
}

@software{10.5281/zenodo.8424626,
author = {Ang, Zhendong and Mathur, Umang},
title = {Artefact for ``Predictive Monitoring against Pattern Regular Languages''},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8424626},
abstract = {
    <p>This artefact implements the predictive monitoring tool PatternTrack and the algorithm Bertoni described in our paper. We provide evaluation workflow in this artefact to demonstrate the bug-finding ability and the scalability of our tool PatternTrack.</p>

},
keywords = {concurrent system, dynamic analysis, predictive monitoring}
}

@software{10.5281/zenodo.8424750,
author = {Parreaux, Lionel and Boruch-Gruszecki, Aleksander and Fan, Andong and Chau, Chun Yin},
title = {When Subtyping Constraints Liberate: A Novel Type Inference Approach for First-Class Polymorphism (Artifact)},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8424750},
abstract = {
    <p>This is the artifact of our POPL 2024 paper entitled “When Subtyping Constraints Liberate: A Novel Type Inference Approach for First-Class Polymorphism”. You can find the latest version of the project at github.com/hkust-taco/superf and a web demo at hkust-taco.github.io/superf.</p>

},
keywords = {constraint solving, first-class polymorphism, subtyping, type inference}
}

@software{10.5281/zenodo.8424953,
author = {Heim, Philippe and Dimitrova, Rayna},
title = {Artifact of "Solving Infinite-State Games via Acceleration"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8424953},
abstract = {
    <p>This artifact contains the code and benchmarks for reproducing the results from the paper “Solving Infinite-State Games via Acceleration”.</p>

},
keywords = {infinite-duration games, infinite-state games, reactive synthesis}
}

@software{10.5281/zenodo.8425392,
author = {Zhang, Xing and Xie, Ruifeng and Guo, Guanchen and He, Xiao and Zan, Tao and Hu, Zhenjiang},
title = {Reproduction Package for Article 'Fusing Direct Manipulations into Functional Programs'},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8425392},
abstract = {
    <p>Our paper (Fusing Direct Manipulations into Functional Programs) proposes a new operation-based framework for bidirectional live programming with a key technique that can fuse direct manipulations into general-purpose functional programs. The artifact FuseDM is a prototype tool to support our operation-based bidirectional live programming framework. As shown below, FuseDM supports developers not only to write functional programs on the left editor and get the output (i.e., SVG) on the right, but also to directly manipulate the output on the right, and automatically synchronize the left code to get the manipulated output. FuseDM offers a series of direct manipulations, as listed in Table 5 of our paper, to edit the output SVG graphics. We successfully designed 14 benchmark examples starting from blank code using direct manipulations supported by FuseDM.</p>

},
keywords = {Bidirectional Live Programming, Direct Manipulations, FuseDM}
}

@software{10.5281/zenodo.8425443,
author = {Elsman, Martin},
title = {Artifact for the POPL 2024 paper Explicit Effects and Effect Constraints in ReML},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8425443},
abstract = {
    <p>This artifact includes (1) a tutorial aiming at demonstrating the features of ReML presented in the POPL 2024 paper “Explicit Effects and Effect Constraints in ReML”, and (2) the source code for ReML, including a description of the implementation aspects of ReML. The artifact consists of a docker image containing a preinstalled version of the ReML compiler, demonstration programs, and the source code for ReML. The artifact establishes the following main claims mentioned in the paper:</p>
<ul>
<li><p>ReML has been implemented and syntactic constructs are available on top of Standard ML syntax to control the underlying region inference process.</p></li>
<li><p>A few larger ReML examples demonstrate how ReML can be used to reason about effects and in particular about the lack of allocation races (Mergesort, ray tracing, and Mandelbrot).</p></li>
</ul>

},
keywords = {Effect Systems, Memory Management, Parallelism, Region-inference}
}

@software{10.5281/zenodo.8425960,
author = {Borkowski, Michael H. and Vazou, Niki and Jhala, Ranjit},
title = {Artifact for "Mechanizing Refinement Types"},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8425960},
abstract = {
    <p>Artifact containing the mechanized proofs for POPL 2024 paper “Mechanizing Refinement Types.”</p>

},
keywords = {Coq, LiquidHaskell, Mechanized metatheory}
}

@software{10.5281/zenodo.10213773,
author = {Hu, Siyu and Zhao, Tong and Sha, Qiuchen and Li, Enji and Meng, Xiangyu and Liu, Liping and Wang, Lin-Wang and Tan, Guangming and Jia, Weile},
title = {Training one DeePMD Model in Minutes: a Step towards Online Learning},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10213773},
abstract = {
    
                <p>Artifact appendix item for PPoPP24</p>
              
}
}

@software{10.5281/zenodo.10222938,
author = {Wheatman, Brian and Burns, Randal and Buluc, Aydin and Xu, Helen},
title = {CPMA: An Efficient Batch-Parallel Compressed Set Without Pointers},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10222938},
abstract = {
    
                <p>Artifact appendix item for PPoPP24</p>
              
}
}

@software{10.5281/zenodo.10223442,
author = {Muller, Stefan K},
title = {Language-Agnostic Static Deadlock Detection for Futures},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10223442},
abstract = {
    
                <p>Artifact appendix item for PPoPP24</p>
              
}
}

@software{10.5281/zenodo.10224742,
author = {Li, Yifei and Zhou, Bole and Zhang, Jiejing and Wei, Xuechao and Li, Yinghan and Chen, Yingda},
title = {POSTER: RadiK: Scalable Radix Top-K Selection on GPUs},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10224742},
abstract = {
    
                <p>Artifact appendix item for PPoPP24</p>
              
}
}

@software{10.5281/zenodo.10225523,
author = {Chen, Yuetao and Li, Kun and Wang, Yuhao and Bai, Donglin and Wang, Lei and Ma, Lingxiao and Yuan, Liang and Zhang, Yunquan and Cao, Ting and Yang, Mao},
title = {ConvStencil: Transform Stencil Computation to Matrix Multiplication on Tensor Cores},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10225523},
abstract = {
    
                <p>Artifact appendix item for PPoPP24</p>
              
}
}

@software{10.5281/zenodo.10226261,
author = {Kim, Daewoo and Brown, Trevor and Singh, Ajay},
title = {Are Your Epochs Too Epic? Batch Free Can Be Harmful},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10226261},
abstract = {
    
                <p>Artifact appendix item for PPoPP24</p>
              
}
}

@software{10.5281/zenodo.10252149,
author = {Dong, Xiaojun and Dhulipala, Laxman and Gu, Yan and Sun, Yihan},
title = {Parallel Integer Sort: Theory and Practice},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10252149},
abstract = {
    
                <p>Artifact appendix item for PPoPP24</p>
              
}
}

@software{10.5281/zenodo.10253798,
author = {Liu, Quanquan C. and Shun, Julian and Zablotchi, Igor},
title = {Parallel k-Core Decomposition with Batched Updates and Asynchronous Reads},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10253798},
abstract = {
    
                <p>Artifact appendix item for PPoPP24</p>
              
}
}

@software{10.5281/zenodo.10257908,
author = {Khalaji, Mohammad and Brown, Trevor and Daudjee, Khuzaima and Aksenov, Vitaly},
title = {Practical Hardware Transactional vEB Trees},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10257908},
abstract = {
    
                <p>Artifact appendix item for PPoPP24</p>
              
}
}

@software{10.5281/zenodo.10430776,
author = {Bhosale, Akshay and Eigenmann, Rudolf},
title = {Recurrence Analysis for Automatic Parallelization of Subscripted Subscripts},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10430776},
abstract = {
    
                <p>Artifact appendix item for PPoPP24</p>
              
}
}

@software{10.5281/zenodo.10437290,
author = {Lin, Zhiheng and Meng, Ke and Shui, Chaoyang and Zhang, Kewei and Xiao, Junmin and Tan, Guangming},
title = {Exploiting Fine-Grained Redundancy in Set-Centric Graph Pattern Mining},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10437290},
abstract = {
    
                <p>Artifact appendix item for PPoPP24</p>
              
}
}

@software{10.5281/zenodo.10447532,
author = {Blelloch, Guy E. and Wei, Yuanhao},
title = {VERLIB: Concurrent Versioned Pointers},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10447532},
abstract = {
    
                <p>Artifact appendix item for PPoPP24</p>
              
}
}

@software{10.5281/zenodo.10449841,
author = {Liu, Xiaoyan and Zheng, Xuegui and Yang, Hailong and Luan, Zhongzhi and Qian, Depei},
title = {Tetris: Accelerating Sparse Convolution by Exploiting Memory Reuse on GPU},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10449841},
abstract = {
    
                <p>Artifact appendix item for PPoPP24</p>
              
}
}

@software{10.5281/zenodo.10475796,
author = {McCoy, Hunter and Pandey, Prashant},
title = {Gallatin: A General-Purpose GPU Memory Manager},
year = {2024},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10475796},
abstract = {
    
                <p>Artifact appendix item for PPoPP24</p>
              
}
}

@software{10.1145/3580408,
author = {Eberlein, Martin and Smytzek, Marius and Steinh\"{o}fel, Dominic and Grunske, Lars and Zeller, Andreas},
title = {Replication Package for "Semantic Debugging"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3580408},
abstract = {
    <p>This Replication Package contains the code to execute, develop and test our debugging prototype Avicenna.</p>
<p>Avicenna is a debugging tool designed to automatically determine the causes and conditions of program failures. It leverages both generative and predictive models to satisfy constraints over grammar elements and detect relations of input elements. Our tool uses the ISLa specification language to express complex failure circumstances as predicates over input elements. Avicenna learns input properties that are common across failing inputs and employs a feedback loop to refine the current debugging diagnoses by systematic experimentation. The result is crisp and precise diagnoses that closely match those determined by human experts, offering a significant advancement in the realm of automated debugging.</p>

},
keywords = {behavior explanation, debugging, testing}
}

@software{10.1145/3580427,
author = {Wei, Siwei and Song, Guyang and Zhu, Senlin and Ruan, Ruoyi and Zhu, Shihao and Cai, Yan},
title = {Tool and Reproduction Package for Paper 'Discovering Parallelisms in Python Programs'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3580427},
abstract = {
    <p>A tool for automatically discovering parallelisms in Python programs</p>

},
keywords = {Parallelism, Python, Ray}
}

@software{10.5281/zenodo.10205261,
author = {Du, Xiaohu and Chen, Xiao and Cao, Jialun and Wen, Ming and Cheung, Shing-Chi and Jin, Hai},
title = {Reproduction Package for Article "Understanding the Bug Characteristics and Fix Strategies of Federated Learning Systems"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10205261},
abstract = {
    <p>The data, source code, and the results of this paper.</p>

},
keywords = {Bug Characteristics, Empirical Study, Federated Learning}
}

@software{10.5281/zenodo.10205548,
author = {Kim, Soomin and Kim, Hyungseok and Cha, Sang Kil},
title = {Artifact for `FunProbe: Probing Functions from Binary Code through Probabilistic Analysis`},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10205548},
abstract = {
    <p>This is an artifact for `FunProbe: Probing Functions from Binary Code through Probabilistic Analysis’, which will be published in the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering 2023. FunProbe is a function identification tool based on Bayesian Network. The artifact contains the implementation of FunProbe, experimental scripts, and the dataset used to evaluate FunProbe.</p>

},
keywords = {binary code analysis, function identification, probabilistic analysis}
}

@software{10.5281/zenodo.10208075,
author = {Mikek, Benjamin and Zhang, Qirun},
title = {SLOT: SMT-LLVM Optimizing Translation},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10208075},
abstract = {
    <p>SLOT (SMT-LLVM Optimizing Translation) is a software tool that speeds up SMT solving in a solver-agnostic way by simplifying constraints. It converts SMT constraints to LLVM, applies the existing LLVM optimizer, and translates back.</p>

},
keywords = {compiler optimization, LLVM, SMT solving}
}

@software{10.5281/zenodo.10211988,
author = {Zhao, Zhongkai and Kou, Bonan and Ibrahim, Mohamed Yilmaz and Chen, Muhao and Zhang, Tianyi},
title = {Reproduction Package for Article "Knowledge-Based Version Incompatibility Detection for Deep Learning"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10211988},
abstract = {
    <p>The artifact contains the data and code of DECIDE, a version incompatibility detection tool based on pre-trained language models proposed in “Knowledge-based Version Incompatibility Detection for Deep Learning”. Meanwhile, this artifact also contains data and code to replicate experiment results in the paper. The artifact has been made publicly available on GitHub to support Open Science.</p>

},
keywords = {Deep Learning, Knowledge Extraction, Version Compatibility}
}

@software{10.5281/zenodo.10214179,
author = {Nicolae, Maria-Irina and Eisele, Max and Zeller, Andreas},
title = {Implementation of paper "Revisiting Neural Program Smoothing for Fuzzing"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.10214179},
abstract = {
    <p>The package contains two Python artifacts: - Neuzz++: the implementation of neural program smoothing for fuzzing designed in the paper - MLFuzz: a benchmarking framework for fuzzing with machine learning.</p>

},
keywords = {fuzzing, machine learning, neural networks, neural program smoothing, Python}
}

@software{10.5281/zenodo.8237328,
author = {Feldman, Kobi and Kellogg, Martin and Chaparro, Oscar},
title = {Replication package for the paper: "On the Relationship Between Code Verifiability and Understandability"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8237328},
abstract = {
    <p>This is the FSE’23 replication package of our meta-analysis that assesses the relationship between code verifiability and understandability. The package includes code snippets, human-based comprehensibility measurements, verification tools, scripts to process tool output and produce the study results, the raw study results, and documentation for replication.</p>

},
keywords = {code comprehension, meta-analysis, static analysis, Verification}
}

@software{10.5281/zenodo.8256377,
author = {So, Sunbeom and Oh, Hakjoo},
title = {Artifact for "SmartFix: Fixing Vulnerable Smart Contracts by Accelerating Generate-and-Verify Repair using Statistical Models"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8256377},
abstract = {
    <p>This artifact contains the package for reproducing the main experimental results in our paper accepted to ESEC/FSE 2023: “SmartFix: Fixing Vulnerable Smart Contracts by Accelerating Generate-and-Verify Repair using Statistical Models”</p>

},
keywords = {generate-and-verify repair, smart contract, statistical model}
}

@software{10.5281/zenodo.8267114,
author = {Zhang, Mengxiao and Xu, Zhenyang and Tian, Yongqiang and Jiang, Yu and Sun, Chengnian},
title = {Artifact for "PPR: Pairwise Program Reduction"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8267114},
abstract = {
    <p>This artifact contains the source code, benchmarks, scripts, and documentation for reproduce the evaluation results described in the paper “PPR: Pairwise Program Reduction” accepted at ESEC/FSE 2023.</p>

},
keywords = {Bug Isolation, Delta Debugging, Program Reduction}
}

@software{10.5281/zenodo.8267404,
author = {Lee, Seongmin and B\"{o}hme, Marcel},
title = {Reproduction Package for Article `Statistical Reachability Analysis'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8267404},
abstract = {
    <h2 id="artifact-for-the-project-statistical-reachability-analysis">Artifact for the project “Statistical Reachability Analysis”</h2>
<p>This repository contains the artifact of the paper “Statistical Reachability Analysis” submitted to the FSE/ESEC 2023 conference.q</p>
<h2 id="artifact-structure">Artifact structure</h2>
<p>The artifact is structured as follows:</p>
<pre><code>├── README.md (this file)
├── rq1 (folder containing the data for the results of RQ1)
│&nbsp;&nbsp; ├── laplace (folder containing the data for the Laplace estimator)
|   |   └── RQ1-Laplace.ipynb (Jupyter notebook to generate the RQ1 results for the Laplace estimator)
│&nbsp;&nbsp; ├── preach (folder containing the data for the PReach)
│&nbsp;&nbsp; └── pse (folder containing the data for the PSE)
├── rq2 (folder containing the data for the results of RQ2)
│&nbsp;&nbsp; ├── fuzz-data (folder containing the fuzzing data)
│&nbsp;&nbsp; ├── figures (folder containing the figures)
|   ├── esti-result (folder containing the estimation results of statistical reachability estimators)
|   ├── scripts (folder containing the scripts to generate the estimation results)
|   ├── sra (folder containing the source code of the SRA tool)
|   RQ2-estimate.ipynb (Jupyter notebook to generate the RQ2 estimation results)
└── RQ2-timespent.ipynb (Jupyter notebook to generate the RQ2 time spent results)</code></pre>

},
keywords = {Markov chain, Quantitative reachability analysis, Reaching probability, Statistical reachability analysis}
}

@software{10.5281/zenodo.8269801,
author = {Correnson, Arthur and Steinh\"{o}fel, Dominic},
title = {Artifact for "Engineering a Formally Verified Automated Bug Finder"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8269801},
abstract = {
    <p>This artifact comprises the Docker image with the WiSE and PyWiSE prototypes presented in the paper&nbsp;“’Engineering a Formally Verified Automated Bug Finder” at ESEC/FSE’23.</p>
<p>The artifact contains the following files:</p>
<p>README.md: This file provides an overview of the artifact, including information on running the examples provided in the paper and on navigating our Coq source code. REQUIREMENTS.md: The requirements for running our artifact. STATUS.md: The list of ESEC/FSE badges we apply for by submitting this artifact. LICENSE.md: The distribution rights for this artifact’s code and documentation. INSTALL.md: Installation instructions. wise-docker-20230821.tar.gz: The Docker container with our artifacts in a working environment.&nbsp;</p>

},
keywords = {Program Verification, Proof Assistants, Symbolic Execution, Symbolic Semantics, Testing}
}

@software{10.5281/zenodo.8270900,
author = {Souza, Beatriz and Pradel, Michael},
title = {Artifact for LExecutor: Learning-Guided Execution},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8270900},
abstract = {
    <p>This artifact contains the implementation of LExecutor and supplementary material for the paper “LExecutor: Learning-Guided Execution” (FSE’23).</p>

},
keywords = {dynamic analysis, execution, neural models}
}

@software{10.5281/zenodo.8271853,
author = {Ahmed, Shibbir and Imtiaz, Sayem Mohammad and Khairunnesa, Samantha Syeda and Cruz, Breno Dantas and Rajan, Hridesh},
title = {Replication Package of the ESEC/FSE 2023 Paper Entitled "Design by Contract for Deep Learning APIs"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8271853},
abstract = {
    <p>This repository contains the reproducibility package, source code, benchmark, and results for the paper - “Design by Contract for Deep Learning APIs”, which appeared in ESEC/FSE’2023: The 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering at San Francisco, California.</p>

},
keywords = {API contracts, Deep learning, specification language}
}

@software{10.5281/zenodo.8271984,
author = {Xu, Xiangzhe and Xuan, Zhou and Feng, Shiwei and Cheng, Siyuan and Ye, Yapeng and Shi, Qingkai and Tao, Guanhong and Yu, Le and Zhang, Zhuo and Zhang, Xiangyu},
title = {PEM},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8271984},
abstract = {
    <p>This repository contains the artifacts of PEM. We provide a runnable docker image for the artifact evaluation. In addition, for future research and development, we provide the source code of PEM and a detailed instruction on how to compile it from the source code.</p>

},
keywords = {Binary Similarity, Dynamic Analysis}
}

@software{10.5281/zenodo.8272687,
author = {Peng, Yaohui and Xie, Jing and Yang, Qiongling and Guo, Hanwen and Li, Qingan and Xue, Jingling and Yuan, Mengting},
title = {Reproduction Package for Article `Statistical Type Inference for Incomplete Programs'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8272687},
abstract = {
    <p>Stir is a novel two-stage approach for inferring types in incomplete programs that may be ill-formed, where whole-program syntactic analysis often fails. In the first stage, Stir predicts a type tag for each token by using neural networks, and consequently, infers all the simple types in the program. In the second stage, Stir refines the complex types for the tokens with predicted complex type tags. Unlike existing machine-learning-based approaches, which solve type inference as a classification problem, Stir reduces it to a sequence-to-graph parsing problem. This artifact contains the implementation and evaluation program of Stir, which can be used to reproduce the evaluation results, and can also serve as a standalone application for general use of the approach. This artifact contains the implementation and evaluation program, which can be used to reproduce the evaluation results, and can also serve as a standalone application for general use.</p>
<p>This artifact is organized as follows: - <code>abstract.md</code>: file describing the artifact itself. - <code>README.md</code>: main document file. - <code>INSTALL.md</code>: instructions for obtaining the artifact and setting up the environment. - <code>REQUIREMENTS.md</code>: requirements for the hardware and software environment. - <code>STATUS.md</code>: badges that this artifact applies for and the reasons for applying for them. - <code>LICENSE</code>: license (MIT License) of the artifact. - <code>main.py</code>: the main entry file. - <code>first/</code>: the source code of the first stage of STIR. - <code>second/</code>: the source code of the second stage of STIR. - <code>data/</code>: the data used in the evaluation. - <code>pretrained/</code>: the pretrained model used in the evaluation. - <code>Dockerfile</code>: Dockerfile for building the Docker image with the software environment to reproduce the evaluation results. - <code>environment.yml</code>: conda environment file for reproducing the evaluation results.</p>

},
keywords = {deep learning, graph generation, structured learning, Type inference}
}

@software{10.5281/zenodo.8272808,
author = {Srivastava, Prashast and Toffalini, Flavio and Vorobyov, Kostyantyn and Gauthier, Fran\c{c}ois and Bianchi, Antonio and Payer, Mathias},
title = {Reproduction Package for paper "Crystallizer: A Hybrid Path Analysis Framework To Aid in Uncovering Deserialization Vulnerabilities"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8272808},
abstract = {
    <p>The is a reproduction package containing source code of our framework along with scripts, auxiliary data required to run our experiments along with data to reproduce the results presented in the paper.</p>

},
keywords = {deserialization testing, hybrid analysis, Java}
}

@software{10.5281/zenodo.8272828,
author = {Zhao, Qiyuan and Luo, Chuan and Cai, Shaowei and Wu, Wei and Lin, Jinkun and Zhang, Hongyu and Hu, Chunming},
title = {Artifact for ESEC/FSE 2023 Article `CAmpactor: A Novel and Effective Local Search Algorithm for Optimizing Pairwise Covering Arrays'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8272828},
abstract = {
    <p>Combinatorial interaction testing (CIT) stands as a widely adopted testing technique for testing interactions among options within highly configurable systems. Within the realm of CIT, covering arrays refer to the test suites that are able to cover all such interactions, usually subject to certain hard constraints. Specifically, pairwise covering arrays (PCAs) are extensively utilized, because they are capable of obtaining a good balance between testing costs and the capability to disclose faults.</p>
<p>CAmpactor is a novel and effective local search algorithm for compacting given PCAs into smaller-sized ones, and it significantly advances the state of the art in building PCAs. In this artifact, we provide the implementation of CAmpactor, the testing instances adopted in the experiments and the detailed evaluation results.</p>

},
keywords = {Covering array, Local search, Software testing}
}

@software{10.5281/zenodo.8281250,
author = {Wei, Yuxiang and Xia, Chunqiu Steven and Zhang, Lingming},
title = {Reproduction Package (Docker Image) for the ESEC/FSE 2023 Paper "Copiloting the Copilots: Fusing Large Language Models with Completion Engines for Automated Program Repair"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8281250},
abstract = {
    <p>This is the artifact accompanying our ESEC/FSE’23 paper “Copiloting the Copilots: Fusing Large Language Models with Completion Engines for Automated Program Repair”. For user convenience, we deliver our artifact in the form of a Docker image that has resolved all the software dependencies beforehand. The Docker image comprises (1) the source code of <strong>Repilot</strong>, the patch generation tool introduced in the paper, (2) all the data needed to reproduce the experiments done for the paper, (3) a detailed documentation on how to achieve the experimental results step-by-step, and (4) the <code>Dockerfile</code> we use to create this image.</p>

},
keywords = {Artifact, Docker Image, Repilot}
}

@software{10.5281/zenodo.8283633,
author = {Wang, Bo and Li, Ruishi and Li, Mingkai and Saxena, Prateek},
title = {Reproduction Package for Article `TransMap: Pinpointing Mistakes in Neural Code Translation'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8283633},
abstract = {
    <p>This is the artifact for the paper “TransMap: Pinpointing Mistakes in Neural Code Translation” published in ESEC/FSE 2023</p>
<p>The latest artifact can be found here: https://github.com/HALOCORE/TransMap</p>
<p>This artifact (TransMap) is a tool to pinpoint semantic mistakes in neural code translation by Codex or ChatGPT. More specifically, it focuses on Python to JavaScript code translation.</p>
<p>It takes a standalone Python program and its JavaScript translation (by Codex or ChatGPT) as input. It will first generate a source mapping between statements in the target program and the source program, using Codex or ChatGPT. Next, it will use the generated source map to aid in tracing the execution of the translated program and comparing it against the source reference program to pinpoint semantic mistakes in the translated program.</p>

},
keywords = {Code Translation, Large Language Models, Semantic Mistakes}
}

@software{10.5281/zenodo.8289599,
author = {Benoit, Tristan and Marion, Jean-Yves and Bardin, S\'{e}bastien},
title = {Artifacts - Scalable Program Clone Search through Spectral Analysis},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8289599},
abstract = {
    <h2 id="artifacts---scalable-program-clone-search-through-spectral-analysis">Artifacts - Scalable Program Clone Search through Spectral Analysis</h2>
<p>We focus on the problem of program clone search, which involves finding the program in a repository most similar to a target program. Program clone search has important applications, including malware detection and program clustering.</p>
<p>In solving this problem, the inherent workflow involves disassembly, feature extraction (or preprocessing), clone searches, and subsequent generation of tables.</p>
<p>A good similarity metric is crucial to finding the repository’s closest program. It has to be precise and robust even in cross-architecture scenarios and fast even when dealing with huge repositories. This artifact encompasses 21 distinctive clone search methods. Each method is different, and therefore, their workflow may be slightly different. Overall, the artifact is a purposely-built framework for clone search method comparison. It is easily extensible and can be tweaked to carry out new measurements.</p>
<p>The artifact includes four datasets with vast numbers of programs: Basic (1K), BinKit (98K), IoT (20K), and Windows (85K). Due to the enormous scale of these datasets, this artifact demands significant time consumption. To offer a perspective, the disassembly process on these considerable datasets can take days even when operating on 20 cores. The subsequent steps, such as preprocessing and clone searches, can also demand hundreds of hours. Note that we have gathered 2 TB of disassembled files throughout accumulating this data.</p>
<p>To tackle these time and space constraints, we have ensured that precomputed data are available within this artifact at multiple workflow phases. This enables a quick transition from reproducing one workflow phase to another. However, we could not include all disassembled files, so we mainly focused on the last phases, such as a clone search.</p>
<h3 id="examples-of-use">Examples of Use</h3>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true"></a><span class="ex">conda</span> activate PSS_Base</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true"></a><span class="ex">python3</span> MakeTables.py</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true"></a><span class="ex">python3</span> MakeAblationTables.py</span></code></pre></div>
<p>The above will produce in a few minutes the Tables of our article using precomputed results.</p>
<p>See <a href="/do/10.5281/zenodo.8289599/export-citation-abs/EXAMPLES.md">EXAMPLES.md</a> for five quick examples of replications using this artifact.</p>
<h3 id="usage---basic-dataset">Usage - Basic Dataset</h3>
<h4 id="replication-script">Replication Script</h4>
<p>To replicate clone searches on the Basic dataset with all methods without any preprocessing phases, use the script provided:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true"></a><span class="ex">conda</span> activate PSS_Base</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true"></a><span class="ex">python3</span> SetAbsolutePath.py</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true"></a><span class="fu">bash</span> ReplicateCloneSearchesBasic.py</span></code></pre></div>
<p>It requires 40 cores and at least 100 GB of memory and should run for between 140 hours and 350 hours.</p>
<h4 id="generalities">Generalities</h4>
<p>For Basic dataset computations, ensure you have run <code>python3 SetAbsolutePath.py</code>.</p>
<p>Inside a method folder: - <code>RunMakeMD3.py</code> will compute all similarity indices using precomputed features. - <code>RunMakeMD.py</code> will utilize these indices to compute the test field results.</p>
<p>To reproduce the feature extraction, usually a script called <code>Preprocess.py</code> can be run.</p>
<p>Some frameworks have a more complex feature extraction workflow that can take a certain amount of computation.</p>
<p>For instance, a function embedding such as AlphaDiff requires a learning phase of around 60 hours with 100 GB of RAM.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true"></a><span class="ex">conda</span> activate PSS_Base</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true"></a><span class="bu">cd</span> AlphaDiff/Train</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true"></a><span class="fu">unzip</span> datasetAD.Py</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true"></a><span class="ex">python3</span> main.py</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true"></a><span class="fu">rm</span> datasetAD.h5</span></code></pre></div>
<p>It is followed, by an embedding computation phase of 5 hours.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true"></a><span class="bu">cd</span> AlphaDiff/Embeds/</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true"></a><span class="ex">python3</span> MakeEmbeds.py</span></code></pre></div>
<p>Then, a distance computation phase of between 18 and 40 hours using 40 cores and 100 GB of RAM.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true"></a><span class="bu">cd</span> AlphaDiff/AD_gDist/</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true"></a><span class="ex">python3</span> Run.py</span></code></pre></div>
<p>After that, similarity indices can be made from these computations.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true"></a><span class="bu">cd</span> AlphaDiff/makeResults/</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true"></a><span class="ex">python3</span> RunMakeMD3.py</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true"></a><span class="ex">python3</span> RunMakeMD.py</span></code></pre></div>
<h3 id="usage---binkit-dataset">Usage - BinKit Dataset</h3>
<h4 id="replication-script-1">Replication Script</h4>
<p>To replicate clone searches on the BinKit dataset without any preprocessing phases, use the script provided:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true"></a><span class="ex">conda</span> activate PSS_Base</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true"></a><span class="fu">bash</span> ReplicateCloneSearchesBinKit.py</span></code></pre></div>
<p>It requires 40 cores and at least 100 GB of memory and should run for between 80 hours and 200 hours.</p>
<h4 id="generalities-1">Generalities</h4>
<p>The <code>BinKit</code> directory has two subdirectories, namely, <code>Obfus</code>, which deals with obfuscated programs, and <code>Normal</code>. Each subdirectory entails a <code>DataGeneration</code> folder which holds the disassembly scripts, and a unique folder for each method. These method folders have scripts to extract features and embeds from samples.</p>
<p>Each subdirectory contains three significant scripts: 1. <code>Run.py</code>: This script reproduces clone searches using precomputed features stored in folders like <code>NORMAL_EMBEDS_2</code>. 2. <code>Read.py</code>: It converts the results into a readable output. 3. <code>ReadElapsed.py</code>: It converts the results into a dictionary storing runtimes.</p>
<p>The <code>Redaction</code> subdirectory within <code>BinKit</code> holds scripts that compute tables based on results obtained within each subdataset.</p>
<h3 id="usage---iot-and-windows-datasets">Usage - IoT and Windows Datasets</h3>
<h4 id="replication-script---iot">Replication Script - IoT</h4>
<p>To replicate clone searches on the IoT malware dataset without any preprocessing phases, use the script provided:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true"></a><span class="ex">conda</span> activate PSS_Base</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true"></a><span class="fu">bash</span> ReplicateCloneSearchesIoT.py</span></code></pre></div>
<p>It requires 40 cores and at least 100 GB of memory and should run for between 1 hours and 3 hours.</p>
<h4 id="replication-script---windows">Replication Script - Windows</h4>
<p>To replicate clone searches on the Windows dataset without any preprocessing phases, use the script provided:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true"></a><span class="ex">conda</span> activate PSS_Base</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true"></a><span class="fu">bash</span> ReplicateCloneSearchesWindows.py</span></code></pre></div>
<p>It requires 40 cores and at least 100 GB of memory and should run for between 55 hours and 140 hours.</p>
<h4 id="generalities-2">Generalities</h4>
<p>Both <code>IoT</code> and <code>Windows</code> folders contain a <code>DataGeneration</code> subdirectory with disassembly scripts and scripts for each method to extract features and embeddings from samples. Additionally, each dataset has a <code>DataLabelling</code> subdirectory, which contains scripts for labeling data.</p>
<p>Experiment folders such as <code>XP</code> include <code>Run.py</code> scripts for conducting clone searches using precomputed embeddings. Lastly, the <code>Redaction</code> subdirectory in each dataset includes scripts for computing tables from the results of experiment folders.</p>
<h3 id="psso-study">PSSO Study</h3>
<p>To replicate clone searches for the PSSO Study on the Windows dataset, without any preprocessing phases, use the script provided:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true"></a><span class="ex">conda</span> activate PSS_Base</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true"></a><span class="fu">bash</span> ReplicateCloneSearchesPSSOStudy.py</span></code></pre></div>
<p>It requires 40 cores and at least 100 GB of memory and should run for between 4 hours and 10 hours.</p>
<h3 id="ablation-study">Ablation Study</h3>
<p>To replicate clone searches for the Ablation Study, without any preprocessing phases, use the script provided:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true"></a><span class="ex">conda</span> activate PSS_Base</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true"></a><span class="fu">bash</span> ReplicateCloneSearchesAblation.py</span></code></pre></div>
<p>It requires 40 cores and at least 100 GB of memory and should run for between 7 hours and 18 hours.</p>

},
keywords = {binary code analysis, clone search, cyber security, dataset, software, software engineering, spectral analysis}
}

@software{10.5281/zenodo.8319975,
author = {Liu, Jiawei and Peng, Jinjun and Wang, Yuyao and Zhang, Lingming},
title = {ESEC/FSE'23 Artifact for "NeuRI: Diversifying DNN Generation via Inductive Rule Inference"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8319975},
abstract = {
    <p>This is the artifact for the ESEC/FSE’23 paper “NeuRI: Diversifying DNN Generation via Inductive Rule Inference”.</p>
<p>Deep Learning (DL) is prevalently used in various industries to improve decision-making and automate processes, driven by the ever-evolving DL libraries and compilers. The correctness of DL systems is crucial for trust in DL applications.<br>
As such, the recent wave of research has been studying the automated synthesis of test-cases (i.e., DNN models and their inputs) for fuzzing DL systems. However, existing model generators only subsume a limited number of operators, lacking the ability to pervasively model operator constraints.<br>
To address this challenge, we propose NeuRI, a fully automated approach for generating valid and diverse DL models composed of hundreds of types of operators. NeuRI adopts a three-step process:<br>
(i) collecting valid and invalid API traces from various sources;<br>
(ii) applying inductive program synthesis over the traces to infer the constraints for constructing valid models; and<br>
(iii) using hybrid model generation which incorporates both symbolic and concrete operators.<br>
Our evaluation shows that NeuRI improves branch coverage of TensorFlow and PyTorch by 24\% and 15\% over the state-of-the-art model-level fuzzers. NeuRI finds 100 new bugs for PyTorch and TensorFlow in four months, with 81 already fixed or confirmed. Of these, 9 bugs are labelled as high priority or security vulnerability, constituting 10\% of all high-priority bugs of the period.<br>
Open-source developers regard error-inducing tests reported by us as “high-quality” and “common in practice”.</p>
<p>The artifact includes evidences of real-world bug finding (RQ3) as well as procedures to replicate experiments on coverage evaluation (RQ1) and rule inference (RQ2).</p>
<p>For more information, please check the artifact GitHub repository: https://github.com/ise-uiuc/neuri-artifact</p>

},
keywords = {Compiler Testing, Deep Learning Compilers, Fuzzing}
}

@software{10.6084/m9.figshare.21990386.v8,
author = {Trabish, David and Rinetzky, Noam and Shoham, Sharon and Sharma, Vaibhav},
title = {Evaluation Artifact: State Merging with Quantifiers in Symbolic Execution},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.21990386.v8},
abstract = {
    <p>The artifact contains a docker image with all the required resources for running the experiments from the paper.</p>

},
keywords = {State Merging, Symbolic Execution}
}

@software{10.6084/m9.figshare.23993463.v1,
author = {Zhao, Kunsong and Li, Zihao and Li, Jianfeng and Ye, He and Luo, Xiapu and Chen, Ting},
title = {Reproduction Package for DeepInfer: Deep Type Inference from Smart Contract Bytecode},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.23993463.v1},
abstract = {
    <p>In this replication package, we describe how to replicate the results of our FSE’23 paper, [DeepInfer: Deep Type Inference from Smart Contract Bytecode]. Our replication package allows for an accurate reconstruction of results presented within our paper, as well as the source code for the tool that we built to generate these results.</p>

},
keywords = {Deep Learning, Smart Contract, Type Inference}
}

@software{10.1145/3580415,
author = {Iraci, Grant and Chuang, Cheng-En and Hu, Raymond and Ziarek, Lukasz},
title = {Rate Based Session Types: Rust Implementation},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3580415},
abstract = {
    <p>This artifact contains a prototype implementation of rate-based session types as a Rust crate. The overall artifact is split into two parts: the Rust standard library based crate implementation in rust_pst and a version specialized to FreeRTOS on the STM32F407 in STM32_FreeRTOS.</p>

},
keywords = {rate-based systems, session types, type systems}
}

@software{10.1145/3580417,
author = {Flatt, Matthew and Allred, Taylor and Angle, Nia and De Gabrielle, Stephen and Findler, Robert Bruce and Firth, Jack and Gopinathan, Kiran and Greenman, Ben and Kasivajhula, Siddhartha and Knauth, Alex and McCarthy, Jay and Phillips, Sam and Porncharoenwase, Sorawee and S\o{}gaard, Jens Axel and Tobin-Hochstadt, Sam},
title = {Artifact for "Rhombus: A New Spin on Macros without All the Parentheses"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3580417},
abstract = {
    <p>Rhombus is a programming language with conventional expression syntax that is built on Racket and that is macro-extensible in the same way as Racket. The paper aims to show that Rhombus is realizable via a novel synthesis of macro technology. This artifact provides a working implementation of Rhombus along with example programs in Rhombus that show this realization. The artifact is an OVA file which can be imported into VirtualBox (and perhaps other virtualization software).</p>

},
keywords = {binding spaces, infix syntax, macros}
}

@software{10.1145/3580420,
author = {Larsen, Jens Kanstrup and Guanciale, Roberto and Haller, Philipp and Scalas, Alceste},
title = {P4R-Type},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3580420},
abstract = {
    <p>This artifact consists mainly of the code for the P4R-Type API and the associated type generator, as well examples that use the P4R-Type API. It contains also a virtual machine that can be used to set up a simulation network using mininet, which is used for testing the API. The virtual machine comes both in the form of a ready-to-use VM image as well as Vagrant configuration files for building the image yourself.</p>

},
keywords = {Match types, P4, P4Runtime, Protobuf, Scala 3, Software-defined networking}
}

@software{10.5281/zenodo.8140951,
author = {Pal, Anjali and Saiki, Brett and Tjoa, Ryan and Richey, Cynthia and Zhu, Amy and Flatt, Oliver and Willsey, Max and Tatlock, Zachary and Nandi, Chandrakana},
title = {Reproduction package for "Equality Saturation Theory Exploration \`{a} la Carte"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8140951},
abstract = {
    <p>This is the software package that contains Enumo, a new domain-specific language presented in our paper “Equality Saturation Theory Exploration \`{a} la Carte.” It contains the code and tests for the Enumo DSL as well as automated scripts to replicate the five experiments presented in the paper.</p>

},
keywords = {equality saturation, program synthesis, Rewrite rules}
}

@software{10.5281/zenodo.8146987,
author = {Schr\"{o}er, Philipp and Batz, Kevin and Kaminski, Benjamin Lucien and Katoen, Joost-Pieter and Matheja, Christoph},
title = {Reproduction Package for Article 'A Deductive Verification Infrastructure for Probabilistic Programs'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8146987},
abstract = {
    <p>Contained within the artifact: * Our tool <em>Caesar</em>, which parses HeyVL programs and tries to verify them. Caesar constitutes our main implementation contribution and is the focus of this artifact. * A script to reproduce our benchmarks (Table 2). * We also include our prototypical tool <em>pgcl2heyvl</em>, which takes pGCL programs with annotations and produces a HeyVL file that encodes the required proof obligations. * Our full source code is contained within the artifact as well.</p>

},
keywords = {automated reasoning, deductive verification, probabilistic programs, quantitative verification, real-valued logics, weakest preexpectations}
}

@software{10.5281/zenodo.8148784,
author = {Greenman, Ben and Felleisen, Matthias and Dimoulas, Christos},
title = {Artifact: How Profilers Can Help Navigate Type Migration},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8148784},
abstract = {
    <h4 id="contents">Contents:</h4>
<ul>
<li><code>artifact.tar.gz</code> code for reproducing our rational programmer experiment</li>
<li><code>benchmarks.tar.gz</code> GTP Benchmarks without and with modifications</li>
<li><code>cloudlab.tar.gz</code> for measuring performance on CloudLab</li>
<li><code>figure-data.tar.gz</code> figures and summarized data for the paper</li>
<li><code>rational-trails.tar.gz</code> output from the rational programmer</li>
<li><code>raw-data.tar.gz</code> running times, boundary profile output, and statistical profile output for all benchmarks</li>
</ul>

},
keywords = {gradual typing, migratory typing, profiling, rational programmer}
}

@software{10.5281/zenodo.8149701,
author = {Cao, Huanqi and Tang, Shizhi and Zhu, Qianchao and Yu, Bowen and Chen, Wenguang},
title = {Artifact of Mat2Stencil: A Modular Matrix-Based DSL for Explicit and Implicit Matrix-Free PDE Solvers on Structured Grid},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8149701},
abstract = {
    <p>The artifact submitted for evaluation of OOPSLA 23 conditionally accepted paper “Mat2Stencil: A Modular Matrix-Based DSL for Explicit and Implicit Matrix-Free PDE Solvers on Structured Grid”.</p>

},
keywords = {compiler, finite difference method, multi-stage programming, omain-specific language, performance optimization, polyhedral compilation, stencil, structured grid}
}

@software{10.5281/zenodo.8289595,
author = {Chen, Yu-Fang and Chocholat\'{y}, David and Havlena, Vojt\v{e}ch and Hol\'{\i}k, Luk\'{a}\v{s} and Leng\'{a}l, Ond\v{r}ej and S\'{\i}\v{c}, Juraj},
title = {Artifact for the OOPSLA'23 paper "Solving String Constraints with Lengths by Stabilization"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8289595},
abstract = {
    <p>This is an artifact for the OOPSLA’23 paper “Solving String Constraints with Lengths by Stabilization”. It contains a virtual machine with Ubuntu GNU/Linux and all solvers, benchmarks, and supporting scripts to reproduce all experiments in the paper.</p>

},
keywords = {length constraints, regular languages, SMT solving, stabilization, string constraints, word equations}
}

@software{10.5281/zenodo.8310917,
author = {Renaux, Thierry and Van den Vonder, Sam and De Meuter, Wolfgang},
title = {Secure RDTs: Enforcing Access Control Policies for Offline Available JSON Data (Artifact)},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8310917},
abstract = {
    <p>This is an artifact associated with a paper called “Secure RDTs: Enforcing Access Control Policies for Offline Available JSON Data”. The paper associated with this artifact describes the SRDT, a secure replicated data type. To specify exactly how SRDTs work and to verify that they are secure, the paper uses a formal specification implemented in Redex, a library in the Racket language to specify executable formal semantics. The purpose of this artifact is to guide the reader on how to interact with the formal semantics, such that they can explore exactly how SRDTs work, are able to verify the claims of the paper, and are able to reproduce SRDTs for other systems.</p>

},
keywords = {conflict-free replicated data types, racket, redex, replicated data types, security}
}

@software{10.5281/zenodo.8314677,
author = {Gourdin, L\'{e}o and Bonneau, Benjamin and Boulm\'{e}, Sylvain and Monniaux, David and B\'{e}rard, Alexandre},
title = {Formally Verifying Optimizations with Block Simulations},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8314677},
abstract = {
    <p>The goal of this artifact is to show that the optimizations presented in our paper are effectively applied, and proved thanks to our translation validation by symbolic execution mechanism. Moreover, we demonstrate that even on large or randomly generated tests, the validation does not produce any false alarm. The artifact also provides a means of reproducing runtime benchmarks (performance in number of cycles), although this requires specific hardware.</p>

},
keywords = {Formal verification of compiler optimizations, Symbolic Execution, The Coq proof assistant, Translation validation}
}

@software{10.5281/zenodo.8315298,
author = {M\"{u}ller, Marius and Schuster, Philipp and Starup, Jonathan Lindegaard and Ostermann, Klaus and Brachth\"{a}user, Jonathan Immanuel},
title = {Artifact of the paper 'From Capabilities to Regions: Enabling Efficient Compilation of Lexical Effect Handlers'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8315298},
abstract = {
    <p>The artifact consists of the benchmarks conducted for the evaluation of the compilation approach presented in the paper. It contains a Dockerfile which can be used to build a Docker image for a container with all necessary languages installed. The benchmarks can hence be run inside this container.</p>

},
keywords = {effect handlers, lift inference, region inference}
}

@software{10.5281/zenodo.8318658,
author = {Madsen, Magnus and van de Pol, Jaco and Henriksen, Troels},
title = {Fast and Efficient Boolean Unification for Hindley-Milner-Style Type and Effect Systems},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8318658},
abstract = {
    <p>This artifact supports the paper Fast and Efficient Boolean Unification for Hindley-Milner-Style Type and Effect Systems. It reproduces the main quantifiable results of the paper, in particular the performance of six of the seven proposed strategies for Boolean unification (Strategy 1 is too slow to actually function). The artifact reproduces Figures 3-7 of the paper, as well as various other minor metrics referenced listed in the paper.</p>
<p>See documentation in artifact itself for more information.</p>

},
keywords = {flix, performance, type inference}
}

@software{10.5281/zenodo.8320212,
author = {Cheeseman, Luke and Parkinson, Matthew J. and Clebsch, Sylvan and Kogias, Marios and Drossopoulou, Sophia and Chisnall, David and Wrigstad, Tobias and Li\'{e}tar, Paul},
title = {Artifact for "When Concurrency Matters: Behaviour Oriented Concurrency"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8320212},
abstract = {
    <p>This contains the docker image to support the OOPSLA 2023 paper “When Concurrency Matters: Behavioural Oriented Concurrency”.</p>

},
keywords = {actors, concurrent programming, parallel programming, threads and locks}
}

@software{10.5281/zenodo.8320642,
author = {Chen, Qinlin and Zhang, Nairen and Wang, Jinpeng and Tan, Tian and Xu, Chang and Ma, Xiaoxing and Li, Yue},
title = {The Essence of Verilog: A Tractable and Tested Operational Semantics for Verilog (Artifact)},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8320642},
abstract = {
    <p>This is the artifact of the paper “The Essence of Verilog: A Tractable and Tested Operational Semantics for Verilog”. It provides a Java implementation of <span class="math inline"><em>λ</em><sub><em>V</em></sub></span>, which is a core language of Verilog. The implementation includes an <span class="math inline"><em>λ</em><sub><em>V</em></sub></span> interpreter based on its formal semantics and a frontend that converts Verilog code into <span class="math inline"><em>λ</em><sub><em>V</em></sub></span>. Furthermore, this artifact offers an evaluation environment that allows for the reproduction of the results presented in our paper. For more detailed instructions on how to run our <span class="math inline"><em>λ</em><sub><em>V</em></sub></span> implementation and reproduce the results from our paper, please refer to the README.pdf included in the artifact. You can download the artifact from the following URL: https://doi.org/10.5281/zenodo.8320642.</p>

},
keywords = {Core Languages, Hardware Description Languages, Semantics, Verilog}
}

@software{10.5281/zenodo.8321488,
author = {Chitre, Khushboo and Kedia, Piyus and Purandare, Rahul},
title = {Rapid: Region-based Pointer Disambiguation},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8321488},
abstract = {
    <p>This includes the source code of Rapid and all the required artifacts.</p>

},
keywords = {CPU SPEC 2017, LLVM, Mimalloc, Polybench, Scout}
}

@software{10.5281/zenodo.8327699,
author = {Park, Kanghee and D'Antoni, Loris and Reps, Thomas},
title = {Docker Image for Article 'Synthesizing Specifications'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8327699},
abstract = {
    <p>This is the artifact for paper “Synthesizing Specifications”. Following are the contents of the artifact.</p>
<ul>
<li>spyro_oopsla23.tar.gz: A Docker image containing the source code and the dependencies to run Spyro[SMT] and Spyro[Sketch].</li>
<li>README.md: A readme containing all the step-by-step instructions to reproduce the results shown in the paper.</li>
</ul>

},
keywords = {Program Specifications, Program Synthesis}
}

@software{10.5281/zenodo.8328524,
author = {Zhang, Quan and Zhou, Chijin and Xu, Yiwen and Yin, Zijing and Wang, Mingzhe and Su, Zhuo and Sun, Chengnian and Jiang, Yu and Sun, Jiaguang},
title = {Artifact for "Building Dynamic System Call Sandbox with Partial Order Analysis"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8328524},
abstract = {
    <p>This is the artifact for the OOPSLA 2023 paper, titled “Building Dynamic System Call Sandbox with Partial Order Analysis”. It contains the DynBox prototype as well as the relevant data needed to replicate the results.</p>

},
keywords = {Attack Surface Reduction, Program Analysis, System Call Sandbox}
}

@software{10.5281/zenodo.8328742,
author = {Zhou, Chijin and Zhang, Quan and Guo, Lihua and Wang, Mingzhe and Jiang, Yu and Liao, Qing and Wu, Zhiyong and Li, Shanshan and Gu, Bin},
title = {Towards Better Semantics Exploration for Browser Fuzzing},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8328742},
abstract = {
    <p>This is the artifact for “Towards Better Semantics Exploration for Browser Fuzzing”, published in SPLASH/OOPSLA 2023. All instructions can be found in the readme.pdf file.</p>

},
keywords = {Browser Fuzzer, Browser Security, Context-Sensitive Grammar, Semantics-Aware Fuzzing}
}

@software{10.5281/zenodo.8329645,
author = {Sano, Chuta and Kavanagh, Ryan and Pientka, Brigitte},
title = {Mechanization of SCP for article 'Mechanizing Session-Types using a Structural View: Enforcing Linearity without Linearity'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8329645},
abstract = {
    <p>Mechanization of Structural Classical Processes as introduced in the article ‘Mechanizing Session-Types using a Structural View: Enforcing Linearity without Linearity’ in the proof assistant Beluga using weak higher-order abstract syntax. The artifact includes the encoding of the language alongside a mechanized proof of type preservation.</p>

},
keywords = {concurrency, linear logic, mechanization, session types}
}

@software{10.5281/zenodo.8329679,
author = {Zakhour, George and Weisenburger, Pascal and Salvaneschi, Guido},
title = {Type-Safe Dynamic Placement with First-Class Placed Values},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8329679},
abstract = {
    <h2 id="dyno">Dyno</h2>
<h3 id="artifact-for-the-paper-type-safe-dynamic-placement-with-first-class-placed-values">Artifact for the paper “Type-Safe Dynamic Placement with First-Class Placed Values”</h3>
<p>The artifact is available at: https://doi.org/10.5281/zenodo.8329679</p>
<h2 id="getting-started">GETTING STARTED</h2>
<h3 id="building-and-loading-the-docker-image">BUILDING AND LOADING THE DOCKER IMAGE</h3>
<p>We provide you with <code>dyno.tar.xz</code>, which is a pre-built container image that contains all necessary programs. To load, run the following command:</p>
<pre><code>docker load &lt; dyno.tar.xz</code></pre>
<p>Running the image may not work on Apple M1/M2 machines, or any machine with Apple’s ARM-based chips, because of incomplete emulation of system calls (specifically the inotify kernel subsystem). Hence, we recommend running the image on a platform fully supported by Docker, like x86-64 systems.</p>
<h2 id="step-by-step-instructions">STEP-BY-STEP INSTRUCTIONS</h2>
<h3 id="compiling-dyno">COMPILING DYNO</h3>
<p>The provided container already contains the pre-compiled jar files of Dyno.</p>
<p>To compile Dyno yourself, run the following command:</p>
<pre><code>docker run -it --rm dyno bash -c 'cd /dyno; sbt clean publishLocal'</code></pre>
<p>Compiling Propel may not work inside the Docker container on Apple M1/M2 machines for the reasons mentioned earlier.</p>
<p>The resulting jar files are in <code>~/.ivy2/local/io.github.dyno/</code>. You can run this command to see all of them <code>find ~/.ivy2/local/io.github.dyno/ -name "*.jar"</code></p>
<h3 id="testing-dyno">TESTING DYNO</h3>
<p>To run the tests in Dyno, execute:</p>
<pre><code>docker run -it --rm dyno bash -c 'cd /dyno &amp;\&amp; SBT_OPTS="-Xmx4G" sbt lociJVM/test'</code></pre>
<p>Running the Dyno tests may not work inside the Docker container on Apple M1/M2.</p>
<p>Running the tests may take up to five minutes.</p>
<h3 id="executing-paper-evaluations">EXECUTING PAPER EVALUATIONS</h3>
<h4 id="variants-analysis-section-8.1">VARIANTS ANALYSIS (Section 8.1)</h4>
<h5 id="verification-of-the-numbers-in-table-1">Verification of the numbers in Table 1</h5>
<p>Each variant is implemented under <code>/evaluation/casestudies</code>. In each variant’s folder there are three folders for each implementation: <code>dyno/</code>, <code>rmi/</code>, and <code>akka/</code>.</p>
<p>Reference creation, acquisition, and access are all labeled in the source code in each implementation. Creations are labeled with a comment <code>/*ref-creation*/</code> that follows immediately every expression that creates (or simulates a creation) of a reference. Similarly, an acquisition and an access are labeled with the comments <code>/*ref-acquire*/</code> and <code>/*ref-use*/</code> respectively and they follow immediately every expression that is relevant.</p>
<p>Counting each comment should match with the numbers we provide in Table 1 in the paper.</p>
<h5 id="running-each-variant">Running each variant</h5>
<h6 id="resources-variant">Resources Variant</h6>
<p>In the resources variant, the client asks the user to input their identifier (it can be any string), the supervisor takes over in case the identifier is new or untrusted and asks whether the identifier should be trusted or not. If the supervisor says yes then all subsequent calls will result in the same resource generated for that identifier, otherwise no resource will be given.</p>
<h6 id="dyno-implementation">Dyno Implementation</h6>
<p>First start by running a new container image with <code>docker run -it --rm dyno bash</code> in a console.</p>
<p>To run the Dyno Resources evaluation, you must execute in six different consoles the following commands in order:</p>
<ol type="1">
<li>On console 1, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/casestudies/resources/dyno; sbt "runMain loci.resources.TrustedKeyDb"'</code></li>
<li>On console 2, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/casestudies/resources/dyno; sbt "runMain loci.resources.PublicKeyDb"'</code></li>
<li>On console 3, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/casestudies/resources/dyno; sbt "runMain loci.resources.KeyManager"'</code></li>
<li>On console 4, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/casestudies/resources/dyno; sbt "runMain loci.resources.ResourceManager"'</code></li>
<li>On console 5, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/casestudies/resources/dyno; sbt "runMain loci.resources.Supervisor"'</code></li>
<li>On console 6, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/casestudies/resources/dyno; sbt "runMain loci.resources.Clienct"'</code></li>
</ol>
<p>The <code>CONTAINER_ID</code> variable can be found by executing: <code>docker container ls | grep dyno | head -n 1 | cut -f1 -d' '</code>.</p>
<p>Please allow each command to complete compilation and to begin running before you execute the next one.</p>
<h6 id="rmi-implementation">RMI Implementation</h6>
<p>First start by running a new container image with <code>docker run -it --rm dyno bash</code> in a console.</p>
<p>To run the RMI Resources evaluation, you must execute in six different consoles the following commands in order:</p>
<ol type="1">
<li>On console 1, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/casestudies/resources/rmi; sbt "runMain loci.resources.TrustedKeyDbMain"'</code></li>
<li>On console 2, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/casestudies/resources/rmi; sbt "runMain loci.resources.PublicKeyDbMain"'</code></li>
<li>On console 3, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/casestudies/resources/rmi; sbt "runMain loci.resources.KeyManagerMain"'</code></li>
<li>On console 4, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/casestudies/resources/rmi; sbt "runMain loci.resources.ResourceManagerMain"'</code></li>
<li>On console 5, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/casestudies/resources/rmi; sbt "runMain loci.resources.SupervisorMain"'</code></li>
<li>On console 6, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/casestudies/resources/rmi; sbt "runMain loci.resources.ClienctMain"'</code></li>
</ol>
<p>Please allow each command to complete compilation and to begin running before you execute the next one.</p>
<h6 id="akka-implementation">Akka Implementation</h6>
<p>To run the Akka Resources evaluation, you must execute the following command:</p>
<pre><code>docker run -it --rm dyno bash -c 'cd /evaluation/casestudies/resources/akka; sbt run'</code></pre>
<p>This will spawn, for each peer, different actors that run in the same process.</p>
<h6 id="sessions-variant">Sessions Variant</h6>
<p>In the sessions variant, the client navigates an application that consists of different components. To login in some components you can use the username <code>admin</code> and the password <code>adminPassword</code>.</p>
<h6 id="dyno-implementation-1">Dyno Implementation</h6>
<p>First start by running a new container image with <code>docker run -it --rm dyno bash</code> in a console.</p>
<p>To run the Dyno Sessions evaluation, you must execute in four different consoles the following commands in order:</p>
<ol type="1">
<li>On console 1, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/casestudies/session/dyno; sbt "runMain loci.sessions.Auth"'</code></li>
<li>On console 2, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/casestudies/session/dyno; sbt "runMain loci.sessions.AdminPanel"'</code></li>
<li>On console 3, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/casestudies/session/dyno; sbt "runMain loci.sessions.Server"'</code></li>
<li>On console 4, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/casestudies/session/dyno; sbt "runMain loci.sessions.Client"'</code></li>
</ol>
<p>Please allow each command to complete compilation and to begin running before you execute the next one.</p>
<h6 id="rmi-implementation-1">RMI Implementation</h6>
<p>First start by running a new container image with <code>docker run -it --rm dyno bash</code> in a console.</p>
<p>To run the RMI Sessions evaluation, you must execute in four different consoles the following commands in order:</p>
<ol type="1">
<li>On console 1, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/casestudies/session/rmi; PEER_TYPE=Server sbt "runMain loci.sessions.ServerMain"'</code></li>
<li>On console 2, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/casestudies/session/rmi; PEER_TYPE=Auth sbt "runMain loci.sessions.AuthMain"'</code></li>
<li>On console 3, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/casestudies/session/rmi; PEER_TYPE=AdminPanel sbt "runMain loci.sessions.AdminPanelMain"'</code></li>
<li>On console 4, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/casestudies/session/rmi; PEER_TYPE=Client sbt "runMain loci.sessions.ClientMain"'</code></li>
</ol>
<p>Please allow each command to complete compilation and to begin running before you execute the next one.</p>
<h6 id="akka-implementation-1">Akka Implementation</h6>
<p>To run the Akka Sessions evaluation, you must execute the following command:</p>
<pre><code>docker run -it --rm dyno bash -c 'cd /evaluation/casestudies/session/akka; sbt run'</code></pre>
<h6 id="unifeed-variant">Unifeed Variant</h6>
<p>In the unifeed variant the unifier takes two streams of tweets and toots and merges them in a single feed chronologically. Tweets come from Twitter and require you to have an API key. You can obtain an API key by following the instructions on: https://developer.twitter.com/en/docs/authentication/oauth-1-0a/api-key-and-secret Toots come from Mastodon. If you are on mastodon.social you can create an API key on this URL https://mastodon.social/settings/applications/new</p>
<p>The Mastodon key is called “Your access token” and the Twitter key is called “Bearer Token”. We refer to them in the following commands using <code>&lt;MASTODON_KEY&gt;</code> and <code>&lt;TWITTER_KEY&gt;</code> respectively.</p>
<p>Twitter’s API support has been getting more and more restrictive for developers. If you are developer with a Basic or Pro Twitter subscription then please apply the patch suggested at the end of this section to unify a twitter stream with a mastodon stream. If you do not have a Basic or Pro twitter subscription then you can not use the API endpoints that this application requires. The provided example instead unified two Mastodon streams.</p>
<h6 id="dyno-implementation-2">Dyno Implementation</h6>
<p>First start by running a new container image with <code>docker run -it --rm dyno bash</code> in a console.</p>
<p>To run the Dyno Unifeed evaluation, you must execute in four different consoles the following commands in order:</p>
<ol type="1">
<li>On console 1, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/casestudies/unifeed/dyno; ACCESS_TOKEN=&lt;TWITTER_KEY&gt; sbt "runMain loci.unifeed.Twitter"'</code></li>
<li>On console 2, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/casestudies/unifeed/dyno; ACCESS_TOKEN=&lt;MASTODON_KEY&gt; sbt "runMain loci.unifeed.Mastodon"'</code></li>
<li>On console 3, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/casestudies/unifeed/dyno; sbt "runMain loci.unifeed.Unifier"'</code></li>
<li>On console 4, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/casestudies/unifeed/dyno; sbt "runMain loci.unifeed.Client"'</code></li>
</ol>
<p>Please allow each command to complete compilation and to begin running before you execute the next one.</p>
<h6 id="rmi-implementation-2">RMI Implementation</h6>
<p>First start by running a new container image with <code>docker run -it --rm dyno bash</code> in a console.</p>
<p>To run the RMI Unifeed evaluation, you must execute in three different consoles the following commands in order:</p>
<ol type="1">
<li>On console 1, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/casestudies/unifeed/rmi; ACCESS_TOKEN=&lt;TWITTER_KEY&gt; sbt "runMain loci.unifeed.TwitterMain"'</code></li>
<li>On console 2, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/casestudies/unifeed/rmi; ACCESS_TOKEN=&lt;MASTODON_KEY&gt; sbt "runMain loci.unifeed.MastodonMain"'</code></li>
<li>On console 3, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/casestudies/unifeed/rmi; sbt "runMain loci.sessions.ClientMain"'</code></li>
</ol>
<p>Please allow each command to complete compilation and to begin running before you execute the next one.</p>
<h6 id="akka-implementation-2">Akka Implementation</h6>
<p>To run the Akka Unifeed evaluation, you must execute the following command:</p>
<pre><code>docker run -it --rm dyno bash -c 'cd /evaluation/casestudies/unifeed/akka; TWITTER_KEY=&lt;TWITTER_KEY&gt; MASTODON_KEY=&lt;MASTODON_KEY&gt; sbt run'</code></pre>
<h6 id="patch-to-use-twitter-api">Patch to use Twitter API</h6>
<p>If you wish to use the twitter API you can go use the object that’s commented out in the source code and preceded with the string <code>TWITTER_API:</code></p>
<h4 id="performance-section-8.2">PERFORMANCE (Section 8.2)</h4>
<h5 id="running-the-dyno-version">Running the Dyno version</h5>
<p>First start by running a new container image with <code>docker run -it --rm dyno bash -c 'bash -c "service mariadb start" 2&gt;/dev/null; redis-server'</code> in a console.</p>
<p>To run the Dyno performance evaluation, you must execute in three different consoles the following commands, in order:</p>
<ol type="1">
<li>On console 1, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/performance; sbt "runMain loci.dbcachedyno.Database"'</code></li>
<li>On console 2, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/performance; sbt "runMain loci.dbcachedyno.Cache"'</code></li>
<li>On console 3, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/performance; sbt "runMain loci.dbcachedyno.Client"'</code></li>
</ol>
<h5 id="running-the-rmi-version">Running the RMI version</h5>
<p>First start by running a new container image with <code>docker run -it --rm dyno bash -c 'bash -c "service mariadb start" 2&gt;/dev/null; redis-server'</code> in a console.</p>
<p>To run the Dyno performance evaluation, you must execute in three different consoles the following commands, in order:</p>
<ol type="1">
<li>On console 1, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/performance; sbt "runMain loci.dbcachermi.DatabaseMain"'</code></li>
<li>On console 2, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/performance; sbt "runMain loci.dbcachermi.CacheMain"'</code></li>
<li>On console 3, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /evaluation/performance; sbt "runMain loci.dbcachermi.ClientMain"'</code></li>
</ol>
<h5 id="reading-the-output">Reading the Output</h5>
<p>The output will be visible in console 3.</p>
<p>The client first does a warmup trial that may take up to two minutes. Thus no output will be visible during the warmup. The whole experiment is not expected to take more than fifteen minutes.</p>
<p>The output is in the CSV format with 3 columns. The first column is the Hit percentage, from 0\% to 100\% in steps of 10\%. The second column is the time in milliseconds that N=5K queries took. The third column is the number of trials.</p>
<h5 id="changing-the-parameters">Changing the parameters</h5>
<p>If you wish to modify the number of trials, you must edit the value of the <code>N</code> value defined in <code>/evaluation/performance/src/main/scala/DbCache.scala</code> at line 77. The database already contains 200,001 unique keys. Therefore to preserve the correctness of the evaluation we recommend to keep N &lt; 200,000.</p>
<h4 id="antenna-pod-case-study-section-8.3">ANTENNA-POD CASE STUDY (Section 8.3)</h4>
<p>For the sake of completeness we describe in high-level the evaluation of Section 8.3 that we do not expect reviewers to repeat in full-details.</p>
<p>To demonstrate the bug we have found in AntennaPod we provide the following minimal RSS feed that you can host online:</p>
<pre><code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;rss version="2.0"
    xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd"&gt;
  &lt;channel&gt;
    &lt;title&gt;A Bad Feed&lt;/title&gt;
    &lt;itunes:owner&gt;
        &lt;itunes:email&gt;anon@anon.non&lt;/itunes:email&gt;
    &lt;/itunes:owner&gt;
    &lt;itunes:author&gt;Anon&lt;/itunes:author&gt;
    &lt;description&gt;A Really Bad Feed&lt;/description&gt;
    &lt;link&gt;https://bad.feed/&lt;/link&gt;
    &lt;item&gt;
      &lt;title&gt;A Bad Episode&lt;/title&gt;
      &lt;description&gt;A Really Bad Episode&lt;/description&gt;
      &lt;pubDate&gt;Tue, 14 Mar 2017 12:00:00 GMT&lt;/pubDate&gt;
      &lt;enclosure url=/do/10.5281/zenodo.8329679/export-citation-abs/"/idonotexist.mp3" type="audio/mpeg" length="34216300"/&gt;
      &lt;itunes:duration&gt;30:00&lt;/itunes:duration&gt;
    &lt;/item&gt;
  &lt;/channel&gt;
&lt;/rss&gt;</code></pre>
<p>After installing AntennaPod on your Android device from the Google Play store or F-Droid you can do the following steps:</p>
<ol type="1">
<li>Open the hamburger menu.</li>
<li>Click on the “+ Add Podcast” menu.</li>
<li>In the Advanced section, click on “Add Podcast by RSS address”.</li>
<li>In the popup window you can enter the URL of the bad RSS feed.</li>
<li>After pressing confirm a new popup should show up. Click on “A Bad Episode”.</li>
<li>A “Preview” button should appear. Click on it.</li>
<li>The player will attempt to play the file for a few seconds then it hides the “Preview” button.</li>
<li>Press the “back” button on your device and you will see the following Java error message:</li>
</ol>
<blockquote>
<p>com.google.android.exoplayer2.upstream.FileDataSource$FileDataSourceException: java.io.FileNotFoundException: /idonotexist.mp3: open failed: ENOENT (No such file or directory)</p>
</blockquote>
<h4 id="f-droid-case-study-section-8.4">F-DROID CASE STUDY (Section 8.4)</h4>
<p>For the sake of completeness we describe in high-level the evaluation of Section 8.4 that we do not expect reviewers to repeat in full-details.</p>
<ul>
<li>The F-Droid repository is available at https://f-droid.org/repo/index-v2.json which we also provide in <code>/fdroid_index.json</code></li>
<li>After cloning all git repositories in the index we kept those whose source code matched the following regular expression: <code>startsWith("file|equals("file|equalsIgnoreCase("file|startsWith("content|equals("content|equalsIgnoreCase("content</code></li>
<li>The result were 133 projects whose IDs we provide in the <code>/fdroid_matches.txt</code> file</li>
<li>The code snippets we provide in Section 8.4 illustrating the treatment of URLs are given in full-context in the <code>/fdroid_snippets/</code> folder</li>
</ul>
<h2 id="a-small-starting-example">A SMALL STARTING EXAMPLE</h2>
<p>Dyno is a general library that can be reused in other applications. We invite you to start with <code>/examples/src/main/scala/simple_example</code> which contains the source code for a small and simple example. It is made of a single file <code>SimpleExample.scala</code> that is annotated with comments explaining the details of the program.</p>
<p>The program consists of three peers. The first, <code>FirstProvider</code> contains an integer. Running this peer will prompt (repeatedly) the user to input a number that it will store inside its integer. The second, <code>SecondProvider</code> behaves exactly the same. The third, <code>Selector</code> starts by prompting the user to choose the peer from which it will retrieve a reference to its integer. If the user inputs <code>1</code> then they have chosen to use the value from <code>FirstProvider</code>, if the user inputs <code>2</code> they have chosen to use the value from <code>SecondProvider</code>. Any other input will re-prompt the user. Once a reference is obtained the user will be repeatedly prompted to press enter to dereference the integer reference. If the value has changed in between dereferences then the selector must observe these changes.</p>
<p>First start by running a new container image with <code>docker run -it --rm dyno bash</code> in a console.</p>
<p>To run these examples, you must execute in three different consoles the following commands, in order:</p>
<ol type="1">
<li>On console 1, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /examples; sbt "runMain loci.simple_example.FirstProvider"'</code></li>
<li>On console 2, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /examples; sbt "runMain loci.simple_example.SecondProvider"'</code></li>
<li>On console 3, execute <code>docker exec -it $CONTAINER_ID bash -c 'cd /examples; sbt "runMain loci.simple_example.Selector"'</code></li>
</ol>
<p>The <code>CONTAINER_ID</code> variable can be found by executing: <code>docker container ls | grep dyno | head -n 1 | cut -f1 -d' '</code>.</p>
<p>Please allow each command to complete compilation and to begin running before you execute the next one.</p>
<p>Now you are ready to interact with the peers.</p>
<p>sudo docker exec -it $(sudo docker container ls | grep dyno | head -n1 | cut -f1 -d’ ‘) bash -c ’bash -c “service mariadb start” 2&gt;/dev/null; cd /evaluation/performance; sbt “runMain loci.dbcachedyno.Database”’</p>

},
keywords = {Distributed Programming, Dynamic Placement, Multitier Programming, Placement Types, Scala, Union Types}
}

@software{10.5281/zenodo.8329703,
author = {Mohan, Anshuman and Liu, Yunhe and Foster, Nate and Kapp\'{e}, Tobias and Kozen, Dexter},
title = {Reproduction Package for 'Formal Abstractions for Packet Scheduling'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8329703},
abstract = {
    <p>This artifact contains an implementation of PIFO trees as described in the paper, along with several key definitions and concepts. The implementation obeys the semantics we describe formally in the paper. Further, the artifact contains an implementation of the embedding algorithm that we describe in our paper, along with a simulator that allows a PCAP of packets to be “run” through a PIFO tree scheduler. There is small tool to generate your own synthetic PCAPs, and also a visualization tool that generates the graphs that we show in our paper.</p>

},
keywords = {formal semantics, packet scheduling, programmable scheduling}
}

@software{10.5281/zenodo.8329922,
author = {Liu, Fengyun and Lhot\'{a}k, Ond\v{r}ej and Hua, David and Xing, Enze},
title = {Initializing Global Objects: Time and Order},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8329922},
abstract = {
    <p>An artifact for the OOPSLA 2023 paper Initializing Global Objects: Time and Order.</p>
<p>The interested audience can check out the latest Dotty, which already contains the checker as part of its source code.</p>

},
keywords = {Dotty, global objects, initialization safety, initialization-time irrelevance}
}

@software{10.5281/zenodo.8329981,
author = {Liu, Jiangyi and Zhu, Fengmin and He, Fei},
title = {Artifact of paper "Automated Ambiguity Detection in Layout-Sensitive Grammars"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8329981},
abstract = {
    <p>This is the artifact for the paper “Automated Ambiguity Detection in Layout-Sensitive Grammars” at OOPSLA’23. The main purpose of this artifact is to support our evaluation results in §7 (mostly Table 1) and the theoretical results in §3 – §5 (the main conclusions are Theorem 5.9 and Theorem 5.10).</p>
<p>This artifact consists of two parts (each is a directory):</p>
<ul>
<li><p>tool/: our prototype tool that implements the ambiguity detection approach (following §5), together with necessary data and scripts for reproducing the evaluation (§7);</p></li>
<li><p>proof/: our Coq mechanization (§6) of all the definitions and theorems mentioned in §3 – §5.</p></li>
</ul>

},
keywords = {ambiguity, Coq, layout-sensitive grammar, SMT}
}

@software{10.5281/zenodo.8330884,
author = {Mehta, Meetesh Kalpesh and Krynski, Sebasti\'{a}n and Gualandi, Hugo Musso and Thakur, Manas and Vitek, Jan},
title = {Artifact of "Reusing Just-in-Time Compiled Code"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8330884},
abstract = {
    <p>This is the artifact to accompany our OOPSLA 2023 submission on “Reusing Just-in-Time Compiled Code”. The artifact consists of a virtual machine for the R language, called \v{R}, set of benchmarks for evaluation, and scripts to generate the plots. The instructions to run the artifact and reproduce the results are also attached (oopsla23aec-paper45-artifact_documentation.md).</p>

},
keywords = {Code reuse, JIT compilation, Specialization}
}

@software{10.5281/zenodo.8331210,
author = {Gu\'{e}neau, Arma\"{e}l and Hostert, Johannes and Spies, Simon and Sammler, Michael and Birkedal, Lars and Dreyer, Derek},
title = {Artifact for "Melocoton: A Program Logic for Verified Interoperability Between OCaml and C"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8331210},
abstract = {
    <p>This is the artifact for the OOPSLA’23 paper “Melocoton: A Program Logic for Verified Interoperability Between OCaml and C”. It contains the Coq development for the paper.</p>

},
keywords = {angelic non-determinism, C, Coq, foreign-function interfaces, garbage collection, Iris, multi-language semantics, OCaml, program logics, separation logic, transfinite step-indexing}
}

@software{10.5281/zenodo.8331495,
author = {Nazari, Amirmohammad and Huang, Yifei and Samanta, Roopsha and Radhakrishna, Arjun and Raghothaman, Mukund},
title = {Reproduction Package for Article "Explainable Program Synthesis by Localizing Specifications"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8331495},
abstract = {
    <p>This is the artifact package accompanying our OOPSLA 2023 submission titled Explainable Program Synthesis By Localizing Specifications. Our paper presents a new approach to explain the programs produced by program synthesis tools. We call this concept the sub-specification. Our paper presents examples of how subspecs can be useful and an algorithm to synthesize subspecifications. We have implemented this algorithm, which we call S3, for two program synthesis settings, SyGuS and DreamCoder. Our paper includes a user study and an experimental evaluation of the subspec synthesis procedure.</p>
<p>This artifact contains all the tools (S3, CVC5, EUSolver), benchmark files, and scripts to reproduce the experiments described in the paper. In this document, we will describe the outline of these experiments, how to run them, and also describe how one may use S3 to calculate sub-specifications on SyGuS solver and DreamCoder’s results of their own.</p>

},
keywords = {explainability, program comprehension, Program synthesis}
}

@software{10.5281/zenodo.8332129,
author = {Bhanuka, Ishan and Parreaux, Lionel and Binder, David and Brachth\"{a}user, Jonathan Immanuel},
title = {Reproduction Package for "Getting into the Flow: Towards Better Type Error Messages for Constraint-Based Type Inference"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8332129},
abstract = {
    <p>Source code for HMloc type system implementation described in the paper. It contains - * Source code * Instructions for running the code - oopsla23-artifact-overview.md * A guide explaining the code - hmloc-codebase-doc.md</p>

},
keywords = {front-end, functional programming, type systems, user-centered techniques}
}

@software{10.5281/zenodo.8332577,
author = {D'Souza, Matt and You, James and Lhot\'{a}k, Ond\v{r}ej and Prokopec, Aleksandar},
title = {Artifact for paper "TASTyTruffle: Just-in-time Specialization of Parametric Polymorphism"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8332577},
abstract = {
    <p>This is the accompanying artifact for the paper “TASTyTruffle: Just-in-time Specialization of Parametric Polymorphism”. It contains the source code for TASTyTruffle and the accompanying benchmark scripts required to execute the benchmarks included in the evaluation.</p>

},
keywords = {just-in-time compiler, parametric polymorphism, reified types, Scala, specialization, Truffle}
}

@software{10.5281/zenodo.8332724,
author = {Laurel, Jacob and Qian, Siyuan Brant and Singh, Gagandeep and Misailovic, Sasa},
title = {Reproduction Artifact for "Synthesizing Precise Static Analyzers for Automatic Differentiation"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8332724},
abstract = {
    <p>This artifact contains all of the source code for Pasado and all of the experimental scripts needed to reproduce the evaluation from our paper “Synthesizing Precise Static Analyzers for Automatic Differentiation”. This artifact is hosted on both Zenodo, as well as on github at the following repository: “https://github.com/uiuc-arc/Pasado”</p>

},
keywords = {Abstract Interpretation, Automatic Differentiation, Differentiable Programming, Static Analysis}
}

@software{10.5281/zenodo.8332960,
author = {Porncharoenwase, Sorawee and Pombrio, Justin and Torlak, Emina},
title = {Artifact for A Pretty Expressive Printer},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8332960},
abstract = {
    <p>This artifact consists of - Lean proofs of PrettyExpressive’s functional correctness; - Rosette proofs related to cost factories; - An implementation of PrettyExpressive in OCaml and Racket, and their documentation; - A Racket code formatter that employs PrettyExpressive; and - Benchmarks to reproduce our evaluation to show that PrettyExpressive and practically efficient and optimal. See the README file for more details.</p>

},
keywords = {pretty printer}
}

@software{10.5281/zenodo.8333815,
author = {Larose, Octave and Kaleba, Sophie and Burchell, Humphrey and Marr, Stefan},
title = {AST vs. Bytecode: Interpreters in the Age of Meta-Compilation (Artifact)},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8333815},
abstract = {
    <p>This artifact accompanies our paper AST vs.&nbsp;Bytecode: Interpreters in the Age of Meta-Compilation to enable others to reuse our experimental setup and methodology, and verify our claims.</p>
<p>Specifically, the artifacts covers our three contributions:</p>
<pre><code>It contains the implementation of our methodology to identify run-time performance and memory usage tradeoffs between AST and bytecode interpreters. Thus, it contains all benchmarks and experiments for reproduction of results, and reuse for new experiments, as well as the data we collected to verify our analysis.
It contains PySOM and TruffleSOM, which both come with an AST and a bytecode interpreter to enable their comparison. It further contains all the variants of PySOM and TruffleSOM that assess the impact of specific optimizations.
It allows to verify the key claim of our paper, that bytecode interpreters cannot be assumed to be faster than AST interpreters in the context of metacompilation systems.</code></pre>

},
keywords = {abstract-syntax-tree, bytecode, case study, comparison, interpreters, just-in-time compilation, language implementation, meta-tracing, partial evaluation}
}

@software{10.5281/zenodo.8336774,
author = {Cui, Chen and Jiang, Shengyi and Oliveira, Bruno C. d. S.},
title = {Greedy Implicit Bounded Quantification (Artifact)},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8336774},
abstract = {
    <p>The artifact includes the implementation, proofs, and the extended version of the paper “Greedy Implicit Bounded Quantification”.</p>

},
keywords = {Abella, Bounded Quantification, Mechanical Formalization, Type Inference}
}

@software{10.1145/3580399,
author = {Breitner, Joachim},
title = {Reproduction package for Functional Pearl "More Fixpoints!"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3580399},
abstract = {
    <p>This artifact contains the rec-def library described in the Functional Pearl “More Fixpoints!”, as published on Hackage, together with a virtual machine that has its dependencies installed.</p>

},
keywords = {Haskell}
}

@software{10.1145/3580401,
author = {Liu, Yiyun and Weirich, Stephanie},
title = {Artifact associated with Dependently-Typed Programming with Logical Equality Reﬂection},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3580401},
abstract = {
    <p>This artifact contains the complete mechanized Coq proofs of the lemmas and theorems about System DE. The VM image is preinstalled with the dependencies required to build and verify the Coq development.</p>

},
keywords = {Coq, Dependent types, Mechanized metatheory}
}

@software{10.5281/zenodo.7978326,
author = {Scott, Ryan G. and Dodds, Mike and Perez, Ivan and Goodloe, Alwyn E. and Dockins, Robert},
title = {Artifact for "Trustworthy Runtime Verification via Bisimulation (Experience Report)"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7978326},
abstract = {
    <p>This contains two files:</p>
<ul>
<li><p>copilot-verifier-artifact-vm-<md5sum>.tgz: A virtual machine containing the artifact for the ICFP 2023 paper Trustworthy Runtime Verification via Bisimulation (Experience Report).</md5sum></p></li>
<li><p>copilot-verifier-artifact-source-<md5sum>.tgz: The source code for the artifact itself. (The virtual machine above comes with this pre-installed.)</md5sum></p></li>
</ul>

},
keywords = {assurance, formal methods, Runtime verification}
}

@software{10.5281/zenodo.7986916,
author = {Keidel, Sven and Erdweg, Sebastian and Homb\"{u}cher, Tobias},
title = {Artifact for paper "Combinator-Based Fixpoint Algorithms for Big-Step Abstract Interpreters"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7986916},
abstract = {
    <p>The artifact contains the code of the fixpoint combinators and the case studies.</p>

},
keywords = {Big-Step Abstract Interpretation, Fixpoint Algorithm, Static Analysis}
}

@software{10.5281/zenodo.7988049,
author = {Goldstein, Harrison and Frohlich, Samantha and Wang, Meng and Pierce, Benjamin C.},
title = {Reflecting on Random Generation: Reflective Generators Development and Experiments},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7988049},
abstract = {
    <p>The code and virtual machine necessary to replicate the results from the paper Reflecting on Random Generation to be published at ICFP 2023.</p>

},
keywords = {bidirectional programming, property-based testing, random generation}
}

@software{10.5281/zenodo.7988150,
author = {Lorenzen, Anton and Leijen, Daan and Swierstra, Wouter},
title = {FP^2: Fully in-Place Functional Programming Artifact},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7988150},
abstract = {
    <p>This is a QEMU VM image containing benchmarks and the compiler for fully in-place programming.</p>
<p>Start the <code>disk.qcow</code> image in QEMU using <code>./start.sh</code> or <code>start.bat</code>. Log in as <code>artifact</code> with the password <code>password</code>. Change to the test directory:</p>
<blockquote>
<p>cd koka/test/fip</p>
</blockquote>
<p>See the README.md in that folder for further information.</p>

},
keywords = {fip, fully in-place programming, koka, perceus, reuse}
}

@software{10.5281/zenodo.7990832,
author = {Matsuda, Kazutaka and Frohlich, Samantha and Wang, Meng and Wu, Nicolas},
title = {Embedding by Unembedding Code Artifact},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7990832},
abstract = {
    <p>This is a proof-of-concept implementation of embedding-by-unembedding, with a number of application examples.</p>

},
keywords = {EDSL, functional programming, higher-order abstract syntax}
}

@software{10.5281/zenodo.7992509,
author = {Bourgeat, Thomas and Clester, Ian and Erbsen, Andres and Gruetter, Samuel and Singh, Pratap and Wright, Andy and Chlipala, Adam},
title = {A Haskell-based RISC-V formal semantics and some of its use cases},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7992509},
abstract = {
    <p>Our paper at ICFP 2023 describes the formal semantics we built for the RISC-V instruction-set family. This artifact contains that semantics as well as the applications of it that we summarize in the paper. Others may wish to use this semantics as documentation or for testing or formal verification (of different styles).</p>

},
keywords = {formal semantics, instruction sets, type classes}
}

@software{10.5281/zenodo.7993904,
author = {Jacobs, Jules and Hinrichsen, Jonas Kastberg and Krebbers, Robbert},
title = {Dependent Session Protocols in Separation Logic from First Principles (Artifact)},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7993904},
abstract = {
    <p>Artifact for the paper “Dependent Session Protocols in Separation Logic from First Principles”. See README.pdf for details.</p>

},
keywords = {concurrency, message passing, separation logic, session types, verification}
}

@software{10.5281/zenodo.8083298,
author = {Varshosaz, Mahsa and Ghaffari, Mohsen and Johnsen, Einar Broch and W\k{a}sowski, Andrzej},
title = {Formal Specification and Testing for Reinforcement Learning (Supplementary Material)},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8083298},
abstract = {
    <p>This is the supplementary material for our paper on formal specification and testing for reinforcement learning, accepted at the ACM SIGPLAN International Conference on Functional Programming (ICFP) 2023. It contains a virtual machine image to facilitate reproducing the experiment results and the source for the artifact.</p>

},
keywords = {reinforcement learning, Scala, specification-based testing}
}

@software{10.5281/zenodo.8097872,
author = {Xie, Ningning and White, Leo and Nicole, Olivier and Yallop, Jeremy},
title = {MacoCaml: Staging Composable and Compilable Macros (Artifact)},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8097872},
abstract = {
    <p>Artifact to accompany the ICFP’23 paper “MacoCaml: Staging Composable and Compilable Macros”.</p>

},
keywords = {Compile-time code generation, Macros, OCaml, Staging}
}

@software{10.5281/zenodo.8099902,
author = {Baudon, Tha\"{\i}s and Radanne, Gabriel and Gonnord, Laure},
title = {Ribbit Compiler and Benchmarks for Article `Bit-Stealing Made Legal'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8099902},
abstract = {
    <p>Ribbit is a pattern matching compiler for custom memory layouts of algebraic data types. This artifact contains our ribbit compiler, implemented in OCaml and using LLVM as a backend, along with several example programs, including the ones used as benchmarks in the article.</p>

},
keywords = {Algebraic Data Types, Compilation, Data Layouts, Pattern Matching}
}

@software{10.5281/zenodo.8116889,
author = {Hubers, Alex and Morris, J. Garrett},
title = {Generic Programming with Extensible Data Types; Or, Making Ad Hoc Extensible Data Types Less Ad Hoc---Artifact.},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8116889},
abstract = {
    <p>We provide an intrinsically-typed mechanization of System Rω with a shallow embedding / denotation into Agda.</p>

},
keywords = {agda, denotational semantics, extensible data types, intrinsic typing, language mechanization, row polymorphism, row types}
}

@software{10.5281/zenodo.8119348,
author = {Abel, Andreas and Danielsson, Nils Anders and Eriksson, Oskar},
title = {An Agda Formalization of a Graded Modal Type Theory with a Universe and Erasure},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8119348},
abstract = {
    <p>The Agda formalization accompanying the paper “A Graded Modal Dependent Type Theory with a Universe and Erasure, Formalized”.</p>

},
keywords = {dependent types, erasure, formalization, graded modal type theory, linearity, modalities}
}

@software{10.5281/zenodo.8121688,
author = {Gondelman, L\'{e}on and Hinrichsen, Jonas Kastberg and Pereira, M\'{a}rio and Timany, Amin and Birkedal, Lars},
title = {Companion artifact for the paper "Verifying Reliable Network Components in a Distributed Separation Logic with Dependent Separation Protocols"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8121688},
abstract = {
    <p>Virtual Machine image (file base-image.tar.xz) containing the artifact submitted as part of the ICFP 2023 evaluation process. Our paper is entitled “Verifying Reliable Network Components in a Distributed Separation Logic with Dependent Separation Protocols”.</p>
<p>The Virtual Machine contains the Coq source files of the Aneris project, the source code of the OCaml to Aneris-lang compiler, as well as several examples verified with the proposed framework.</p>
<p>We also include a .zip file (source_icfp.zip) containing the source files for the artifact’s dependencies, namely the Aneris project and the OCaml2Lang compiler.</p>

},
keywords = {Aneris, causal consistency, Distributed systems, higher-order logic, Iris, OCaml, separation logic}
}

@software{10.5281/zenodo.8124116,
author = {Bahr, Patrick and Hutton, Graham},
title = {Supplementary Material for "Calculating Compilers for Concurrency"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8124116},
abstract = {
    <p>This artifact includes Agda formalisations of all calculations in the paper “Calculating Compilers for Concurrency”.</p>

},
keywords = {Agda, choice trees, codensity monad, compiler calculation, concurrency}
}

@software{10.5281/zenodo.8126809,
author = {Fowler, Simon and Attard, Duncan Paul and Sowul, Franciszek and Gay, Simon J. and Trinder, Phil},
title = {Artifact for "Special Delivery: Programming with Mailbox Types"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8126809},
abstract = {
    <p>This artifact contains the typechecker for the Pat language, following the algorithmic type system described in the paper.</p>

},
keywords = {actor languages, concurrent programming languages, functional programming, mailbox types}
}

@software{10.5281/zenodo.8139133,
author = {Lutze, Matthew and Madsen, Magnus and Schuster, Philipp and Brachth\"{a}user, Jonathan Immanuel},
title = {With or Without You: Programming with Effect Exclusion (Artifact)},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8139133},
abstract = {
    <p>This artifact contains the source code for the Flix compiler, modified to support effect exclusion, as detailed in the paper. The modifications include the addition of the without expression for excluding effects, and a change to the effect system to support the described Boolean set-based effects.</p>
<p>In addition, it contains the 59 case studies: Code fragments from various open source repositories, where comments indicate a need for effect exclusion. For each fragment, a corresponding Flix code fragment enforces the effect exclusion through a signature or use of the without construct.</p>
<p>The artifact also contains two working examples of effect exclusion in realistic applications: a small GUI library and application demonstrating its use, and an eventbus library with a accompanying program.</p>
<p>These elements are all packaged in a virtual machine containing a Visual Studio Code installation with a Flix extension to support standard IDE features, allowing the Flix code to be inspected, modified, and run.</p>

},
keywords = {effect exclusion, polymorphic types and effects, without construct}
}

@software{10.5281/zenodo.8160553,
author = {Shi, Jessica and Keles, Alperen and Goldstein, Harrison and Pierce, Benjamin C. and Lampropoulos, Leonidas},
title = {Artifact for Etna: An Evaluation Platform for Property-Based Testing},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8160553},
abstract = {
    <p>Our artifact contains the source code for Etna, a platform for empirical evaluation and comparison of property-based testing techniques. This includes code in Python, Haskell, and Coq. The README provides detailed instructions on how to reproduce the experiments in the paper, and the VM image comes pre-installed with the required dependencies.</p>

},
keywords = {empirical evaluation, mutation testing, property-based testing}
}

@software{10.5281/zenodo.8161214,
author = {Shen, Gan and Kashiwa, Shun and Kuper, Lindsey},
title = {HasChor},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8161214},
abstract = {
    <p>A library for choreographic programming in Haskell.</p>

},
keywords = {Choreographic programming, freer monads}
}

@software{10.5281/zenodo.8161357,
author = {Ho, Son and Fromherz, Aymeric and Protzenko, Jonathan},
title = {Artifact for ICFP 2023 paper: Modularity, Code Specialization, and Zero-Cost Abstractions for Program Verification},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8161357},
abstract = {
    <p>This is the artifact for the ICFP 2023 submission: Modularity, Code Specialization, and Zero-Cost Abstractions for Program Verification.</p>
<p>=====</p>
<p>For all the successes in verifying low-level, efficient, security-critical code, little has been said or studied about the structure, architecture and engineering of such large-scale proof developments. We present the design, implementation and evaluation of a set of language-based techniques that allow the programmer to modularly write and prove code at a high level of abstraction, while retaining control over the compilation process and producing high-quality, zero-overhead, low-level code suitable for integration into mainstream software.</p>
<p>We implement our techniques within the F* proof assistant, and specifically its shallowly-embedded Low* toolchain that compiles to C. Through our evaluation, we establish that our techniques were critical in scaling the popular HACL* library past 100,000 lines of verified source code, and brought about significant gains in proof engineer productivity. The exposition of our methodology converges on one final, novel case study: the streaming API, a finicky API that has historically caused many bugs in high-profile software. Using our approach, we manage to capture the streaming semantics in a generic way, and apply it ``for free’’ to over a dozen use-cases. Six of those have made it into the reference implementation of the Python programming language, replacing the previous CVE-ridden code.</p>

},
keywords = {Cryptographic Primitives, Proof Engineering}
}

@software{10.5281/zenodo.8164971,
author = {Thiemann, Peter},
title = {Artifact for the article 'Intrinsically Typed Sessions with Callbacks'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8164971},
abstract = {
    <p>This is an artifact accompanying a paper accepted at the International Conference on Functional Programming, ICFP 2023. It contains a qemu image along with instructions how to run the material inside. It also contains a source code distribution. The artifact contains a README that explains use and installation.</p>

},
keywords = {Agda, dependent types, domain specific languages, session types}
}

@software{10.5281/zenodo.7896362,
author = {Zohdinasab, Tahereh and Riccio, Vincenzo and Tonella, Paolo},
title = {DeepAtash: Focused Test Generation for Deep Learning systems},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7896362},
abstract = {
    <p>The source code and the data of the article “DeepAtash: Focused Test Generation for Deep Learning systems”</p>

},
keywords = {deep learning, search based software engineering, software testing}
}

@software{10.5281/zenodo.7922486,
author = {Levine, Reese and Cho, Mingun and McKee, Devon and Quinn, Andrew and Sorensen, Tyler},
title = {GPUHarbor: Testing GPU Memory Consistency At Large (Experience Paper): Artifact},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7922486},
abstract = {
    <p>Artifact for the ISSTA 2023 paper “GPUHarbor: Testing GPU Memory Consistency At Large (Experience Paper)”, containing the data used in the paper as well as the tools we used to collect and analyze the data.</p>

},
keywords = {GPUs, memory consistency, mutation testing}
}

@software{10.5281/zenodo.7939536,
author = {Du, Hang and Palepu, Vijay Krishna and Jones, James A.},
title = {Reproduction Package for An Empricial Study of Mutation Testing Kills},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7939536},
abstract = {
    <p>This project provides an experimental replication setup and source code for To Kill a Mutant: An Empirical Study of Mutation Testing Kills. Artifact’s data structure, experiments’ general setups and detailed instructions are provided.</p>

},
keywords = {empirical study, mutant detection, mutation testing, test failure classification}
}

@software{10.5281/zenodo.7955514,
author = {Wang, Zihan and Nie, Pengbo and Miao, Xinyuan and Chen, Yuting and Wan, Chengcheng and Bu, Lei and Zhao, Jianjun},
title = {Artifact for Paper "GenCoG: A DSL-Based Approach to Generating Computation Graphs for TVM Testing"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7955514},
abstract = {
    <p>This is the artifact for the ISSTA ’23 paper “GenCoG: A DSL-Based Approach to Generating Computation Graphs for TVM Testing”. This artifact contains the implementation of GenCoG, the adapted versions or reimplementation of the baselines, and the bug-triggering cases.</p>

},
keywords = {Computation Graph Generation, Constraint Solving, Deep Learning Compiler}
}

@software{10.5281/zenodo.7965678,
author = {He, Dongjie and Gui, Yujiang and Gao, Yaoqing and Xue, Jingling},
title = {Reducing the Memory Footprint of IFDS-based Data-Flow Analyses Using Fine-Grained Garbage Collection (Artifact)},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7965678},
abstract = {
    <p>The artifact contains our implementation of the Fine-grained Garbage Collection algorithm introduced in our paper “Reducing the Memory Footprint of IFDS-based Data-Flow Analyses Using Fine-Grained Garbage Collection”. The artifact includes all scripts and benchmarks for reproducing the results and claims made in our paper.</p>

},
keywords = {IFDS, Path Edge Collection, Taint Analysis}
}

@software{10.5281/zenodo.7970349,
author = {Alsaeed, Ziyad and Young, Michal},
title = {Artifact: Finding Short Slow Inputs Faster with Grammar-Based Search},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7970349},
abstract = {
    <p>Two grammar based performance fuzzing tools. SlackLine and TreeLine that find short strings that trigger worst-case performance.</p>
<p>TreeLine and SlackLine artifact, each in its own compressed file, which has a dedicated README file. These are related to the ISSTA’23 publication titled “Finding Short Slow Inputs Faster with Grammar-Based Search.”</p>
<p>The attached files are the ISSTA’23 snapshots of the projects. The up-to-date versions can be found in the dedicated GitHub repos of each project.</p>
<p>TreeLine: https://github.com/uo-se-research/treeline SlackLine: https://github.com/uo-se-research/slackline In addition, each tool has its own Docker repository. They can be found through the following links:</p>
<p>TreeLine: https://hub.docker.com/r/zalsaeed/treeline SlackLine: https://hub.docker.com/r/zalsaeed/slackline We share all the experimental data in a compressed file. The data size is slightly larger than 7GB when you uncompress it.</p>
<p>https://doi.org/10.6084/m9.figshare.22114373.v1</p>

},
keywords = {Input Generation, MCTS, Performance Analysis}
}

@software{10.5281/zenodo.7970822,
author = {Alonso, Juan C. and Segura, Sergio and Ruiz-Cort\'{e}s, Antonio},
title = {[Supplementary material] AGORA: Automated Generation of Test Oracles for REST APIs},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7970822},
abstract = {
    <p>In order to enable reproducibility of the results reported in this paper, we provide a supplementary material containing the source code of the scripts and projects developed, videos explaining how to use the provided software, the data generated in our experiments, bug reports with the corresponding responses from the developers, as well as a Docker image and an Ubuntu virtual machine with all the projects configured. With these resources, we aim to provide a robust foundation for replicating and validating our findings.</p>
<p>To use the most up-to-date version of AGORA, please refer to the official GitHub repository: https://github.com/isa-group/Beet</p>

},
keywords = {automated testing, invariant detection, REST APIs, test oracle}
}

@software{10.5281/zenodo.7976968,
author = {Cheng, Kai and Zheng, Yaowen and Liu, Tao and Guan, Le and Liu, Peng and Li, Hong and Zhu, Hongsong and Ye, Kejiang and Sun, Limin},
title = {Reproduction Package for Article `Detecting Vulnerabilities in Linux-based Embedded Firmware with SSE-based On-demand Alias Analysis'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7976968},
abstract = {
    <p>EmTaint, a novel static analysis tool for accurate and fast detection of taint-style vulnerabilities in embedded firmware. In EmTaint, we design a structured symbolic expression-based (SSE-based) on-demand alias analysis technique, which serves as a basis for resolving both implicit data flow and control flow on potential vulnerable paths. Based on it, we come up with indirect call resolution and accurate taint analysis scheme. Combined with sanitization rule checking, EmTaint can eventually discovers a large number of taint-style vulnerabilities accurately within a limited time.</p>

},
keywords = {Embedded firmware, On-demand alias analysis, Taint analysis}
}

@software{10.5281/zenodo.7977752,
author = {Lehmann, Daniel and Thalakottur, Michelle and Tip, Frank and Pradel, Michael},
title = {Artifact for "That’s a Tough Call: Studying the Challenges of Call Graph Construction for WebAssembly"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7977752},
abstract = {
    <p>This artifact contains supplementary material for the paper “That’s a Tough Call: On Static Call Graph Construction for WebAssembly Binaries” (ISSTA’23).</p>

},
keywords = {call graphs, dataset, WebAssembly}
}

@software{10.5281/zenodo.7978251,
author = {Even-Mendoza, Karine and Sharma, Arindam and Donaldson, Alastair F. and Cadar, Cristian},
title = {Artifact of GrayC: Greybox Fuzzing of Compilers and Analysers for C},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7978251},
abstract = {
    <p>This is the official artifact of the paper: GrayC: Greybox Fuzzing of Compilers and Analysers for C (ISSTA 2023).</p>
<p>The artifacts contains the data for bug reports and raw data for the whole paper, including for the evaluation in section 4 and section 5. In addition, we included all the sets generated with the tools in the evaluation in our artifact as 10-sets-of-test-programs-tool-name.zip.</p>
<p>Note 1: This work was supported by EPSRC (EP/R011605/1 and EP/R006865/1). Note 2: The first two authors both contributed equally to this research. Note 3: Karine Even-Mendoza: A major part of this work was done as an Imperial College London employee.</p>

},
keywords = {Artifact, Bug Reports, Clang, code mutators, compilers, Frama-C, Fuzzing, GCC, GrayC, Greybox fuzzing, LibFuzzer, LLVM, MSVC, program analysers}
}

@software{10.5281/zenodo.7978808,
author = {Xu, Xiangzhe and Feng, Shiwei and Ye, Yapeng and Shen, Guangyu and Su, Zian and Cheng, Siyuan and Tao, Guanhong and Shi, Qingkai and Zhang, Zhuo and Zhang, Xiangyu},
title = {Artifact for DiEmph},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7978808},
abstract = {
    <p>This repo contains the artifact for paper “Improving Binary Code Similarity Transformer Models by Semantics-driven Instruction Deemphasis” published on ISSTA’23. Please refer to <code>README.md</code> for details.</p>

},
keywords = {Binary Similarity Analysis, Program Analysis, Transformer}
}

@software{10.5281/zenodo.7981577,
author = {Tan, Tian and Li, Yue},
title = {Tai-e: A Developer-Friendly Static Analysis Framework for Java by Harnessing the Good Designs of Classics (Artifact)},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7981577},
abstract = {
    <p>This artifact is provided to reproduce the results of RQ4 in Section 6 of our companion paper, i.e., the data in: Table 1 (for pointer analysis) and Table 2 (for data flow analysis).</p>

},
keywords = {Java, static analysis}
}

@software{10.5281/zenodo.8021593,
author = {Zhang, Zhaoxu and Winn, Robert and Zhao, Yu and Yu, Tingting and Halfond, William G.J.},
title = {Reproduction Package for Article "Automatically Reproducing Android Bug Reports using Natural Language Processing and Reinforcement Learning"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8021593},
abstract = {
    <p>This is the artifact of our work “Automatically Reproducing Android Bug Reports using Natural Language Processing and Reinforcement Learning” accepted at The ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA) 2023. This artifact has the source code of the research prototype, evaluation data and results of the paper. We provided detailed instructions for running our tool in the REAEME file.</p>

},
keywords = {Android Bug Report Reproduction}
}

@software{10.5281/zenodo.8023076,
author = {Eisele, Max and Ebert, Daniel and Huth, Christopher and Zeller, Andreas},
title = {Replication Package for 'Fuzzing Embedded Systems using Debugger Interfaces'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8023076},
abstract = {
    <p>The idea of GDBFuzz is to leverage hardware breakpoints from microcontrollers as feedback for coverage-guided fuzzing. Therefore, GDB is used as a generic interface to enable broad applicability. For binary analysis of the firmware, Ghidra is used. The code contains a benchmark setup for evaluating the method. Additionally, example firmware files are included. The replication package allows the users to reproduce and extend the results reported in the paper.</p>

},
keywords = {embedded fuzzing, embedded systems, fuzzing, gdb, ghidra, hardware breakpoint}
}

@software{10.5281/zenodo.8127914,
author = {Kim, YoungJae and Han, Seungheon and Khamit, Askar Yeltayuly and Yi, Jooyong},
title = {SimAPR framework used in "Automated Program Repair from Fuzzing Perspective"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8127914},
abstract = {
    <p>This artifact contains the SimAPR framework designed to simulate the existing and new patch-scheduling algorithms of APR tools. SimAPR enables users to easily assess the efficiency of a patch-scheduling algorithm under study without the need to run APR tools. Currently, SimAPR supports six APR tools: AlphaRepair, Recoder, TBar, Avatar, FixMiner, and kPar. Furthermore, SimAPR can be expanded to include additional APR tools.</p>
<p>SimAPR also supports the new patch-scheduling algorithm named Casino, as presented in the paper titled “Automated Program Repair from Fuzzing Perspective.”</p>

},
keywords = {Automated Program Repair, Fuzzing, Multi-Armed Bandit, Patch Scheduling}
}

@software{10.5281/zenodo.8135199,
author = {Chen, Yang and Yildiz, Alperen and Marinov, Darko and Jabbarvand, Reyhaneh},
title = {Reproduction package of "Transforming Test Suites Into Croissants"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.8135199},
abstract = {
    <p>This package includes all data and code to reproduce the results for paper “Transforming Test Suites Into Croissants”.</p>

},
keywords = {Fault Injection, Mutation Testing, Software Testing, Test Flakiness}
}

@software{10.6084/m9.figshare.19726945.v1,
author = {Callaghan, Dylan and Fischer, Bernd},
title = {Replication package for article "Improving Spectrum-Based Localization of Multiple Faults by Iterative Test Suite Reduction"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.19726945.v1},
abstract = {
    <p>This artifact contains all necessary components to replicate the experiments described in the paper “Improving Spectrum-Based Localization of Multiple Faults by Iterative Test Suite Reduction”. This includes the FLITSR tool described in the paper and additional scripts to run the full-scale experiments, as well as the two datasets used for evaluation in the paper.</p>

},
keywords = {Automated Debugging, Fault Localization}
}

@software{10.5281/zenodo.7684001,
author = {Isemann, Raphael and Giuffrida, Cristiano and Bos, Herbert and van der Kouwe, Erik and Gleissenthall, Klaus von},
title = {Artifact for "Don’t Look UB: Exposing Sanitizer-Eliding Compiler Optimizations"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7684001},
abstract = {
    <p>This artifact contains the fuzzing and static analysis setups of the respective paper.</p>

},
keywords = {compilers, fuzzing, sanitizers}
}

@software{10.5281/zenodo.7703886,
author = {Gopinathan, Kiran and Keoliya, Mayank and Sergey, Ilya},
title = {Reproduction Artefact for Article 'Mostly Automated Proof Repair for Verified Libraries'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7703886},
abstract = {
    <p>This artefact is for our tool, Sisyphus, which is a functional, reusable, and extensible framework for automated repair of Coq proofs.</p>
<p>The artefact contains the source code and build scripts for Sisyphus, a corpus of individual OCaml programs which can be used to reproduce the experimental results in the paper, and a self-contained Docker file to automate setting up the development environment.</p>
<p>The artefact also contains a README in markdown that provides detailed step-by-step instructions for running Sisyphus and reproducing the experimental results.</p>

},
keywords = {invariant inference, mechanised proofs, proof repair, separation logic}
}

@software{10.5281/zenodo.7706984,
author = {Muller, Stefan K. and Singer, Kyle and Keeney, Devyn Terra and Neth, Andrew and Agrawal, Kunal and Lee, I-Ting Angelina and Acar, Umut A.},
title = {Responsive Parallelism with Synchronization Case Studies},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7706984},
abstract = {
    <p>Implementations of the type system described in “Responsive Parallelism with Synchronization” in C++ and Rust, as well as implementations of the case studies. Included are instructions on how to build and execute the case studies, as well as a Docker container environment that can be used for compilation and execution.</p>

},
keywords = {C++, Cilk, condition variable, cost semantics, priority inversion, Rust, type system}
}

@software{10.5281/zenodo.7709500,
author = {Moseley, Dan and Nishio, Mario and Perez Rodriguez, Jose and Saarikivi, Olli and Toub, Stephen and Veanes, Margus and Wan, Tiki and Xu, Eric},
title = {Artifact for "Derivative Based Nonbacktracking Real-World Regex Matching with Backtracking Semantics"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7709500},
abstract = {
    <p>This artifact contains the necessary software and data for reproducing results for the paper “Derivative Based Nonbacktracking Real-World Regex Matching with Backtracking Semantics”. It is based on a benchmark of regex engines available in various programming languages by Mario Ju\'{a}rez. A docker image with all the necessary software for running the benchmark is included. The work described in the paper is part of .NET 7, the source code of which is also included.</p>

},
keywords = {.net, benchmark, dotnet, regex, regular expression, source code}
}

@software{10.5281/zenodo.7709794,
author = {Zhang, Yihong and Wang, Yisu Remy and Flatt, Oliver and Cao, David and Zucker, Philip and Rosenthal, Eli and Tatlock, Zachary and Willsey, Max},
title = {Artifact for "Better Together: Unifying Datalog and Equality Saturation"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7709794},
abstract = {
    <p>This artifact contains the egglog system, as well as data and scripts needed to reproduce the microbenchmarks and two case studies as described in the paper.</p>

},
keywords = {Datalog, program optimization, program synthesis}
}

@software{10.5281/zenodo.7709916,
author = {Nigam, Rachit and Azevedo de Amorim, Pedro Henrique and Sampson, Adrian},
title = {Reproduction Package for "Modular Hardware Design with Timeline Types"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7709916},
abstract = {
    <p>The artifact contains the source code for the language and compiler presented in the paper (Filament) along with Verilog modules generated from the Aetherling and Reticle compilers. It provides scripts to regenerate the tables and results in the paper. The reproducer must manually install the Vivado toolchain, as instructed in the README, in order to obtain the resource usage numbers.</p>

},
keywords = {Hardware design language, type system}
}

@software{10.5281/zenodo.7710435,
author = {Kuepper, Joel and Erbsen, Andres and Gross, Jason and Conoly, Owen and Sun, Chuyue and Tian, Samuel and Wu, David and Chlipala, Adam and Chuengsatiansup, Chitchanok and Genkin, Daniel and Wagner, Markus and Yarom, Yuval},
title = {Evaluation package for ‘ CryptOpt: Verified Compilation with Randomized Program Search for Cryptographic Primitives’},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7710435},
abstract = {
    <p>This artifact contains copies of CryptOpt, Fiat Cryptography and AssemblyLine. It also contains Dockerfiles to create a Docker container to run optimizations for the cryptographic primitives mentioned in the paper. It contains scripts to validate the claims, along with instructions how to build, run and evaluate. To create and build, an Internet connection is required to download dependencies.</p>

},
keywords = {Assembly, asymmetric cryptography, bet-and-run, C, Coq, cryptography, Docker, formal verification, Intel x86-64, Node.js, performance, performance measurements, random local search, straight line code}
}

@software{10.5281/zenodo.7711063,
author = {Lee, Dongjae and Cho, Minki and Kim, Jinwoo and Moon, Soonwon and Song, Youngju and Hur, Chung-Kil},
title = {Coq development for Fair Operational Semantics},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7711063},
abstract = {
    <p>This artifact is the Coq development for the 2023 PLDI paper `Fair Operational Semantics’. It contains the formalization of the theory of FOS and proofs for the examples in the paper.</p>

},
keywords = {Concurrency, Coq Proof Assistant, Fairness, Separation Logic}
}

@software{10.5281/zenodo.7711823,
author = {Beurer-Kellner, Luca and Fischer, Marc and Vechev, Martin},
title = {LMQL as described in Prompting Is Programming: A Query Language for Large Language Models},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7711823},
abstract = {
    <p>LMQL is a query language for large language models (LLMs). It facilitates LLM interaction by combining the benefits of natural language prompting with the expressiveness of Python. With only a few lines of LMQL code, users can express advanced, multi-part and tool-augmented LM queries, which then are optimized by the LMQL runtime to run efficiently as part of the LM decoding loop.</p>
<p>An up to date version can be found at https://github.com/eth-sri/lmql</p>

},
keywords = {language model programming, prompt programming}
}

@software{10.5281/zenodo.7712285,
author = {Brandon, William and Driscoll, Benjamin and Dai, Frank and Berkow, Wilson and Milano, Mae},
title = {Reproduction Package for Article "Better Defunctionalization Through Lambda Set Specialization"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7712285},
abstract = {
    <p>The repository contains a compressed docker image file, containing the artifact for the PLDI 2023 paper “Better Defunctionalization through Lambda Set Specialization.” To use this artifact, first decompress the file (using <code>tar</code> or an archiving program like 7zip), and then use <code>docker load</code> to load up the decompressed docker image. Information for reproducing the results from our PLDI paper is available in README.md files in the ‘morphic/’ and ‘LSSIsabelle/’ directories inside the Docker image. Note: the Docker archive must be decompressed and then loaded with <code>docker load</code> (<em>not</em> <code>docker import</code>, as our archive does not use squashed layers).</p>

},
keywords = {defunctionalization, monomorphization, type systems}
}

@software{10.5281/zenodo.7776035,
author = {Pailoor, Shankara and Chen, Yanju and Wang, Franklyn and Rodr\'{\i}guez, Clara and Van Geffen, Jacob and Morton, Jason and Chu, Michael and Gu, Brian and Feng, Yu and Dillig, I\c{s}\i{}l},
title = {Automated Detection of Under-constrained Circuits in Zero-Knowledge Proofs},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7776035},
abstract = {
    <p>Research Artifact for PLDI’23 Paper “Automated Detection of Under-constrained Circuits in Zero-Knowledge Proofs”</p>

},
keywords = {Automated reasoning, Cryptographic protocols, Program analysis, Program verification}
}

@software{10.5281/zenodo.7782305,
author = {Kanabar, Hrutvik and Vivien, Samuel and Abrahamsson, Oskar and Myreen, Magnus O. and Norrish, Michael and Pohjola, Johannes \r{A}man and Zanetti, Riccardo},
title = {Artifact for “PureCake: A Verified Compiler for a Lazy Functional Language”},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7782305},
abstract = {
    <p><code>README.md</code> describes how to understand and use this artifact. <code>correspondences.md</code> links the artifact to the paper.</p>

},
keywords = {compiler verification, Haskell, HOL4, interactive theorem proving}
}

@software{10.5281/zenodo.7787371,
author = {Lei, Yuxiang and Sui, Yulei and Tan, Shin Hwei and Zhang, Qirun},
title = {Artifact of "Recursive State Machine Guided Graph Folding for Context-Free Language Reachability"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7787371},
abstract = {
    <p>This is the artifact of the paper “Recursive State Machine Guided Graph Folding for Context-Free Language Reachability” accepted to PLDI 2023. The artifact is packaged as a Docker image “gf.tar.gz”, which is to reproduce the experiment results of the paper. Please see README.pdf for detailed usage of the artifact.</p>

},
keywords = {CFL-reachability, graph simplification, recursive state machines}
}

@software{10.5281/zenodo.7799158,
author = {Alberdingk Thijm, Timothy and Beckett, Ryan and Gupta, Aarti and Walker, David},
title = {Artifact associated with the PLDI 2023 submission "Modular Control Plane Verification via Temporal Invariants".},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7799158},
abstract = {
    <p>The artifact provides the code of the Timepiece GitHub repository, which includes the code implementing our modular verification procedure, along with libraries to reproduce and run the benchmarks given in the paper. Fattree benchmarks are contained in the Timepiece.Benchmarks subproject. The Internet2 benchmark can be run by using the Timepiece.Angler subproject to convert an .angler.json file into a Timepiece benchmark: such a .json file can be created from the included Angler repository, which translates network configurations read by Batfish to the .angler.json format. The core of our implementation can be found in the Timepiece subproject of the repository.</p>
<p>Tooling is included to generate the plots from our paper via pgfplots, using a template plot.tex file. We also include a run_all.py Python script for conveniently running and gathering data on our fattree benchmarks, and a Dockerfile for building a Docker image to run the code.</p>

},
keywords = {control plane, dotnet, modular verification, network configurations, network verification, python}
}

@software{10.5281/zenodo.7799173,
author = {Mulder, Ike and Czajka, \L{}ukasz and Krebbers, Robbert},
title = {Artifact and Appendix of 'Beyond Backtracking: Connections in Fine-Grained Concurrent Separation Logic'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7799173},
abstract = {
    <p>This is the artifact and appendix for the PLDI ‘23 paper ’Beyond Backtracking: Connections in Fine-Grained Concurrent Separation Logic’. It contains the source code of an extension of Diaframe that has better support for disjunctions, a VM containing a compiled version of this source code, instructions for evaluation, and the technical appendix.</p>

},
keywords = {backtracking, Coq, disjunctions, fine-grained concurrency, Iris, proof automation, Separation logic}
}

@software{10.5281/zenodo.7800226,
author = {Jin, Ende and Amin, Nada and Zhang, Yizhou},
title = {Artifact for Extensible Metatheory Mechanization via Family Polymorphism},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7800226},
abstract = {
    <p>This artifact includes 3 components: (1) a complete document for interacting with this artifact; (2) a docker image for directly interacting with our plugin without setup; and (3) source code to build our plugin and work with it without virtualization</p>

},
keywords = {Coq., dependent type theory, expression problem, extensible frameworks, inductive types, interactive theorem proving, late binding, mixins, modules, Proof engineering, reuse}
}

@software{10.5281/zenodo.7801911,
author = {Avanzini, Martin and Moser, Georg and Schaper, Michael},
title = {Ev-Imp: Research Artifact},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7801911},
abstract = {
    <p>Ev-imp implements an expected value analysis for probabilistic, imperative programs featuring dynamic sampling instructions, non-deterministic choice, nested loops and most crucially recursive procedure declarations. Concretely, it estimates the value returned by a procedure, in average, as a function of the initial state. To this end, it implements the inference machinery described in Section 5 of our paper. For an overview of the concrete syntax of programs and usage of the tool, we kindly refer the reader to the accompanying README.md.</p>

},
keywords = {automation, expected value analysis, probabilistic programming, weakest pre-expectation semantics}
}

@software{10.5281/zenodo.7803910,
author = {Elsman, Martin},
title = {Artifact for the PLDI 2023 paper 'Garbage-Collection Safety for Region-Based Type-Polymorphic Programs'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7803910},
abstract = {
    <p>This artifact reproduces the content of Figure 9 in the paper. For a detailed overview of the artifact, including instructions on how to use it, please consult the Zenodo page.</p>

},
keywords = {Garbage collection, PLDI, Region inference, SML}
}

@software{10.5281/zenodo.7804200,
author = {Li, Ziyang and Huang, Jiani and Naik, Mayur},
title = {Reproduction package for article "Scallop: A Language for Neurosymbolic Programming"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7804200},
abstract = {
    <p>This artifact includes source code of the software and experiments presented in the paper `Scallop: A Language for Neurosymbolic Programming’. Instructions to reproduce the results are documented in the artifact.</p>

},
keywords = {Differentiable Programming, Logic Programming, Neurosymbolic Method, Programming Language}
}

@software{10.5281/zenodo.7804667,
author = {Mordido, Andreia and Spaderna, Janek and Thiemann, Peter and Vasconcelos, Vasco T.},
title = {AlgST},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7804667},
abstract = {
    <p>Implementation of “Parameterized Algebraic Protocols”</p>

},
keywords = {algebraic datatypes, algebraic session types, interpreter, nominal types, parameterized protocols, polymorphism, session types, type checker}
}

@software{10.5281/zenodo.7806981,
author = {Ye, Qianchuan and Delaware, Benjamin},
title = {Taype: A Policy-Agnostic Language for Oblivious Computation: PLDI23 Artifact},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7806981},
abstract = {
    <p>This is the artifact for the PLDI23 paper “Taype: A Policy-Agnostic Language for Oblivious Computation”. Visit the Zenodo link for more details.</p>

},
keywords = {Algebraic Data Types, Dependent type systems, Oblivious computation}
}

@software{10.5281/zenodo.7807290,
author = {Tao, Zhe and Nawas, Stephanie and Mitchell, Jacqueline and Thakur, Aditya V.},
title = {Reproduction Package for the PLDI 2023 Article "Architecture-Preserving Provable Repair of Deep Neural Networks"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7807290},
abstract = {
    <p>This is the artifact of the PLDI 2023 article “Architecture-Preserving Provable Repair of Deep Neural Networks”. Please refer to the README.md file for the instructions. The latest version of the artifact can be found at https://github.com/95616ARG/APRNN/</p>

},
keywords = {Bug fixing, Deep Neural Networks, Repair, Synthesis}
}

@software{10.5281/zenodo.7808384,
author = {Ma, Wenjie and Yang, Shengyuan and Tan, Tian and Ma, Xiaoxing and Xu, Chang and Li, Yue},
title = {Context Sensitivity without Contexts: A Cut-Shortcut Approach to Fast and Precise Pointer Analysis (Artifact)},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7808384},
abstract = {
    <p>This is the artifact of PLDI’23 paper Context Sensitivity without Contexts: A Cut-Shortcut Approach to Fast and Precise Pointer Analysis.</p>

},
keywords = {Alias Analysis, Context Sensitivity, Java, Pointer Analysis}
}

@software{10.5281/zenodo.7808708,
author = {Rao, Xiaojia and Georges, A\"{\i}na Linn and Legoupil, Maxime and Watt, Conrad and Pichon-Pharabod, Jean and Gardner, Philippa and Birkedal, Lars},
title = {Iris-Wasm: Robust and Modular Verification of WebAssembly Programs (Artefact)},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7808708},
abstract = {
    <p>This is the artefact for the paper “Iris-Wasm: Robust and Modular Verification of WebAssembly Programs”.</p>
<p>The artefact contains the Coq proofs accompanying the paper. These proofs are built using the Iris framework.</p>
<p>These proofs are available either as a .tar.gz archive, which can be compiled following the instructions in the README contained, or as a virtual machine image for VirtualBox (7.0.6) containing the already compiled Coq proofs with browsing tools (Emacs + Proof General) installed. The credentials for the account of the VM are provided in the README inside the .tar.gz archive.</p>

},
keywords = {Coq, Iris, Mechanized proofs, Separation logic, WebAssembly}
}

@software{10.5281/zenodo.7809285,
author = {Xu, Amanda and Molavi, Abtin and Pick, Lauren and Tannu, Swamit and Albarghouthi, Aws},
title = {Synthesizing Quantum-Circuit Optimizers Artifact (QUESO)},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7809285},
abstract = {
    <p>This software artifact includes the source code for QUESO (a tool for synthesizing quantum-circuit optimizers) as well as a README.md with instructions for reproducing results using the provided scripts and benchmarks in the Docker image. See https://arxiv.org/abs/2211.09691 for the full version of the paper.</p>

},
keywords = {probabilistic verification, quantum circuit optimization, quantum computing}
}

@software{10.5281/zenodo.7809333,
author = {Bagnall, Alexander and Stewart, Gordon and Banerjee, Anindya},
title = {Artifact for PLDI'23 paper 'Formally Verified Samplers From Probabilistic Programs With Loops and Conditioning'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7809333},
abstract = {
    <p>The artifact contains the Coq proof development and empirical evaluation scripts for reproducing the results of the paper ‘Formally Verified Samplers From Probabilistic Programs With Loops and Conditioning’. A Dockerfile is included for building a Docker container image with all dependencies installed.</p>

},
keywords = {Probabilistic Programming, Verified Compilers}
}

@software{10.5281/zenodo.7809600,
author = {Tun\c{c}, H\"{u}nkar Can and Mathur, Umang and Pavlogiannis, Andreas and Viswanathan, Mahesh},
title = {Artifact for Article "Sound Dynamic Deadlock Prediction in Linear Time"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7809600},
abstract = {
    <p>The artifact contains the source codes of the deadlock prediction tools developed in our paper. Moreover, the artifact contains the compared tools (partially), experimental data, and scripts that can reproduce the experimental evaluation performed in the paper. The artifact does not contain all the compared tools as we lack the necessary rights to redistribute certain tools.</p>

},
keywords = {concurrency, predictive analyses, runtime analyses}
}

@software{10.5281/zenodo.7810545,
author = {Elsman, Martin and Henriksen, Troels},
title = {Artifact for the PLDI 2023 paper 'Parallelism in a Region Inference Context'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7810545},
abstract = {
    <p>The artifact reproduces Figures 6(a), 6(b) and Tables 1 and 2 of the paper. For a detailed overview, including instructions for using the artifact, please consult the README.md file at the Zenodo page.</p>

},
keywords = {Parallelism, PLDI, SML}
}

@software{10.5281/zenodo.7810840,
author = {Milovan\v{c}evi\'{c}, Dragana and Kun\v{c}ak, Viktor},
title = {Proving and Disproving Equivalence of Functional Programming Assignments (Artifact)},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7810840},
abstract = {
    <p>This artifact contains the complete data set and instructions for reproducing the results from the PLDI’23 paper Proving and Disproving Equivalence of Functional Programming Assignments</p>

},
keywords = {automated grading, equivalence checking, functional induction}
}

@software{10.5281/zenodo.7811004,
author = {Zhou, Zhe and Mishra, Ashish and Delaware, Benjamin and Jagannathan, Suresh},
title = {PLDI2023 Artifact: Covering All the Bases: Type-Based Verification of Test Input Generators},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7811004},
abstract = {
    <p>This artifact contains:</p>
<ol type="1">
<li>README.md : the artifact guide.</li>
<li>poirot-full.pdf: full paper with the appendix.</li>
<li>poirot_pldi-2023.tar.gz: the docker image (optional, we recommend to pull from the docker hub, see README.md).</li>
<li>Dockerfile: the docker file that can reproduce the docker image (optional, we recommend to pull from the docker hub, see README.md).</li>
</ol>

},
keywords = {property-based testing, refinement types, underapproximate reasoning}
}

@software{10.5281/zenodo.7811236,
author = {Zhang, Jialun and Morrisett, Greg and Tan, Gang},
title = {Reproduction Package for Article "Interval Parsing Grammars for File Format Parsing"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7811236},
abstract = {
    <p>This package includes: (1) The parser generator for IPGs; (2) IPGs implementation for ELF, ZIP, PE, GIF and PDF; (3) A test script to reproduce all the evaluation results shown in the paper.</p>

},
keywords = {Context-sensitive Grammars, File Formats}
}

@software{10.5281/zenodo.7811406,
author = {Chen, Yu-Fang and Chung, Kai-Min and Leng\'{a}l, Ond\v{r}ej and Lin, Jyun-Ao and Tsai, Wei-Lun and Yen, Di-De},
title = {An Automata-based Framework for Verification and Bug Hunting in Quantum Circuits},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7811406},
abstract = {
    <p>We introduce a new paradigm for analysing and finding bugs in quantum circuits. In our approach, the problem is given by a triple <span class="math inline">{<em>P</em>}&nbsp;<em>C</em>&nbsp;{<em>Q</em>}</span> and the question is whether, given a set <span class="math inline"><em>P</em></span> of quantum states on the input of a circuit <span class="math inline"><em>C</em></span>, the set of quantum states on the output is equal to (or included in) a set <span class="math inline"><em>Q</em></span>. While this is not suitable to specify, e.g., functional correctness of a quantum circuit, it is sufficient to detect many bugs in quantum circuits. We propose a technique based on tree automata to compactly represent sets of quantum states and develop transformers to implement the semantics of quantum gates over this representation. Our technique computes with an algebraic representation of quantum states, avoiding the inaccuracy of working with floating-point numbers. We implemented the proposed approach in a prototype tool and evaluated its performance against various benchmarks from the literature. The evaluation shows that our approach is quite scalable, e.g., we managed to verify a large circuit with 40 qubits and 141,527 gates, or catch bugs injected into a circuit with 320 qubits and 1,758 gates, where all tools we compared with failed. In addition, our work establishes a connection between quantum program verification and automata, opening new possibilities to exploit the richness of automata theory and automata-based verification in the world of quantum computing.</p>

},
keywords = {quantum circuits, tree automata, verification}
}

@software{10.5281/zenodo.7811786,
author = {Fiala, Jon\'{a}\v{s} and Itzhaky, Shachar and M\"{u}ller, Peter and Polikarpova, Nadia and Sergey, Ilya},
title = {Reproduction Package for Article ``Leveraging Rust Types for Program Synthesis''},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7811786},
abstract = {
    <p>The purpose of this artifact is to reproduce the results presented in the PLDI 2023 paper titled “Leveraging Rust Types for Program Synthesis”. The artifact contains the instructions, tool, and Docker images to re-run the evaluation described in the paper. It also contains the appendix for the paper. The structure of the tool is described in the <code>sources/STRUCTURE.md</code> file.</p>

},
keywords = {ownership types, rust, synthesis}
}

@software{10.5281/zenodo.7811907,
author = {Yamazaki, Tetsuro and Nakamaru, Tomoki and Shioya, Ryota and Ugawa, Tomoharu and Chiba, Shigeru},
title = {Artifact - Collecting cyclic garbage across foreign function interfaces},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7811907},
abstract = {
    <p>All the programs to reproduce the evaluation presented in the corresponding paper.</p>

},
keywords = {FFI, Garbage collection, Memory Management}
}

@software{10.5281/zenodo.7811928,
author = {Cho, Kyeongmin and Jeon, Seungmin and Raad, Azalea and Kang, Jeehoon},
title = {Artifact for Article "Memento: A Framework for Detectable Recoverability in Persistent Memory"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7811928},
abstract = {
    <p>The accompanying artifact (also available at https://github.com/kaist-cp/memento) provides the implementation and the experimental results. The artifact is structured as follows.</p>
<ul>
<li><code>/memento/src/</code>: the implementation of the Memento framework and its primitives (§4).</li>
<li><code>/memento/src/</code>: the implementation of detectably persistent data structures (§5).</li>
<li><code>/memento/evaluation/</code>: the experiment script for correctness and performance (§6).</li>
<li><code>/evaluation_data/</code>: the complete experimental results (§6).</li>
</ul>
<p>Please refer to the artifact’s <code>README.md</code> for detailed instructions on how to reproduce the results.</p>

},
keywords = {concurrent data structure, detectable recovery, persistent memory}
}

@software{10.5281/zenodo.7812119,
author = {Tassarotti, Joseph and Tristan, Jean-Baptiste},
title = {Verified Density Compilation for a Probabilistic Programming Language (Artifact)},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7812119},
abstract = {
    <p>The artifact consists of the Coq and OCaml source code for ProbCompCert, the compiler described in the accompanying paper. ProbCompcert is implemented as an extension to CompCert. The artifact is available in 3 different forms: a copy of the source code, a Docker image, and a Qemu image. The latter two contain the compiler pre-built, along with scripts for re-running the experiments described in the paper.</p>

},
keywords = {compilers, formal verification, probabilistic programming}
}

@software{10.5281/zenodo.7812282,
author = {Ugare, Shubham and Banerjee, Debangshu and Misailovic, Sasa and Singh, Gagandeep},
title = {Incremental Verification of Neural Networks},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7812282},
abstract = {
    <p>Complete verification of deep neural networks (DNNs) can exactly determine whether the DNN satisfies a desired trustworthy property (e.g., robustness, fairness) on an infinite set of inputs or not. Despite the tremendous progress to improve the scalability of complete verifiers over the years on individual DNNs, they are inherently inefficient when a deployed DNN is updated to improve its inference speed or accuracy. The inefficiency is because the expensive verifier needs to be run from scratch on the updated DNN. To improve efficiency, we propose a new, general framework for incremental and complete DNN verification based on the design of novel theory, data structure, and algorithms. Our contributions implemented in a tool named IVAN yield an overall geometric mean speedup of 2.4x for verifying challenging MNIST and CIFAR10 classifiers and a geometric mean speedup of 3.8x for the ACAS-XU classifiers over the state-of-the-art baselines.</p>

},
keywords = {Neural Networks, Verification}
}

@software{10.5281/zenodo.7812534,
author = {Zhang, Tony Nuda and Sharma, Upamanyu and Kapritsos, Manos},
title = {Artifact for Article `Performal: Formal Verification of Latency Properties for Distributed Systems'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7812534},
abstract = {
    <p>This artifact includes source code used to produce the results the paper `Performal: Formal Verification of Latency Properties for Distributed Systems’. Instructions to reproduce the results are documented in the artifact.</p>

},
keywords = {distributed systems, formal software verification, latency, performance, systems verification}
}

@software{10.5281/zenodo.7812616,
author = {Yuan, Yongwei and Radhakrishna, Arjun and Samanta, Roopsha},
title = {Artifact for "Trace-Guided Inductive Synthesis of Recursive Functional Programs"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7812616},
abstract = {
    <p>The artifact includes the implementation of the synthesis algorithm, and necessary code to reproduce the experimental results.</p>

},
keywords = {Program Synthesis, Recursive Functional Programs}
}

@software{10.5281/zenodo.7813157,
author = {Liu, Zongyuan and Stepanenko, Sergei and Pichon-Pharabod, Jean and Timany, Amin and Askarov, Aslan and Birkedal, Lars},
title = {Artifact of "VMSL: A Separation Logic for Mechanised Robust Safety of Virtual Machines Communicating above FF-A"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7813157},
abstract = {
    <p>This is the artifact for the PLDI’23 paper “VMSL: A Separation Logic for Mechanised Robust Safety of Virtual Machines Communicating above FF-A”. It is the Coq mechanisation of all results presented in the paper.</p>

},
keywords = {FF-A, hypercall, Iris, logical relation, robust safety, separation logic}
}

@software{10.5281/zenodo.7813862,
author = {Eilers, Marco and Dardinier, Thibault and M\"{u}ller, Peter},
title = {Artifact of paper "CommCSL: Proving Information Flow Security for Concurrent Programs using Abstract Commutativity"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7813862},
abstract = {
    <p>The artifact is a VirtualBox VM that contains the Isabelle/HOL formalization and soundness proof of CommCSL as well as the implementation of CommCSL in the tool HyperViper, and the evaluation presented in the paper.</p>

},
keywords = {Commutativity, concurrency, information flow security, separation logic}
}

@software{10.5281/zenodo.7813942,
author = {Sewell, Thomas and Myreen, Magnus O. and Tan, Yong Kiam and Kumar, Ramana and Mihajlovic, Alexander and Abrahamsson, Oskar and Owens, Scott},
title = {Cakeml+Eval Artifact},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7813942},
abstract = {
    <p>This is a collection of CakeML and Candle artefacts to accompany “Cakes that Bake Cakes: Dynamic Computation in CakeML”.</p>
<p>In this modified version of CakeML, the REPL and Candle modes are built into the standard bootstrapped CakeML compiler. The compiler is built into a binary via the in-HOL4 verified self-bootstrap mechanism.</p>
<p>The resulting executable REPL, and the proof repositories it is built from, are provided pre-built in this artefact.</p>

},
keywords = {compiler verification, dynamic computation, interactive theorem proving}
}

@software{10.5281/zenodo.7814275,
author = {Bansal, Manya and Hsu, Olivia and Olukotun, Kunle and Kjolstad, Fredrik},
title = {Artifact for Mosaic: An Interoperable Compiler for Tensor Algebra},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7814275},
abstract = {
    <p>This artifact describes how to set up and run Mosaic, a compiler that can compose externally defined library functions to implement an arbitrary sparse tensor algebra expression. Mosaic fills in the gaps that are not provided by the libraries, guaranteeing generality in both expressions and data structures. The artifact also describes how to reproduce the quantitative experimental results presented in the paper.</p>

},
keywords = {Code Optimization, Compiler, External Functions, Sparse Tensor Algebra}
}

@software{10.5281/zenodo.7814374,
author = {Bertram, Noah and Levinson, Alex and Hsu, Justin},
title = {Prototype implementation of Slice, appearing in "Cutting the Cake: A Language for Fair Division"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7814374},
abstract = {
    <p>This is a prototype implementation of the cake-cutting language, Slice. For more details, view the readme.</p>

},
keywords = {automatic verification, fair division}
}

@software{10.5281/zenodo.7814715,
author = {Pick, Lauren and Desai, Ankush and Gupta, Aarti},
title = {Software for `Psym: Efficient Symbolic Exploration of Distributed Systems'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7814715},
abstract = {
    <p>The artifact contains the software used to achieve experimental results the paper `Psym: Efficient Symbolic Exploration of Distributed Systems’ as well some of the benchmarks that can be used to reproduce the results.</p>

},
keywords = {binary decision diagrams, distributed systems, systematic exploration}
}

@software{10.5281/zenodo.7816526,
author = {Tun\c{c}, H\"{u}nkar Can and Abdulla, Parosh Aziz and Chakraborty, Soham and Krishna, Shankaranarayanan and Mathur, Umang and Pavlogiannis, Andreas},
title = {Artifact for Article "Optimal Reads-From Consistency Checking for C11-Style Memory Models "},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7816526},
abstract = {
    <p>This artifact contains all the source codes and experimental data for replicating our evaluation in the paper. We implemented our programs as an extension to the C11Tester and GenMC tools. The provided experimental data contains all the benchmarks used in our evaluation. The artifact also contains Python scripts that fully automate the process of replicating our evaluation.</p>

},
keywords = {complexity, concurrency, weak memory models}
}

@software{10.5281/zenodo.7816533,
author = {Yoon, Yongho and Lee, Woosuk and Yi, Kwangkeun},
title = {Artifact of Inductive Program Synthesis via Iterative Forward-Backward Abstract Interpretation},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7816533},
abstract = {
    <p>The artifacts include the main tool(Simba), the other baseline solvers(Duet, Probe), benchmarks and evaluation scripts.</p>

},
keywords = {Abstract Interpretation, Program Synthesis}
}

@software{10.5281/zenodo.7817421,
author = {Zakhour, George and Weisenburger, Pascal and Salvaneschi, Guido},
title = {Type-Checking CRDT Convergence},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7817421},
abstract = {
    <p>Propel – Verifying the algebraic and relational properties of functions</p>
<p>Artifact for the paper “Type-Checking CRDT Convergence”</p>
<h2 id="getting-started">GETTING STARTED</h2>
<h3 id="building-and-loading-the-docker-image">BUILDING AND LOADING THE DOCKER IMAGE</h3>
<p>We provide you with <code>propel.tar.xz</code>, which is a pre-built container image that contains all necessary programs. To load, run the following command:</p>
<pre><code>$ docker load &lt; propel.tar.xz</code></pre>
<p>Further, we also provide the option to build the contain anew. To build, run the following command which takes between 10 and 20 minutes:</p>
<pre><code>$ docker build -t propel .</code></pre>
<p>Rebuilding the image may not work on Apple M1 machines because of incomplete emulation of system calls (specifically the inotify kernel subsystem). Hence, we recommend rebuilding the image on a platform fully supported by Docker, like x86-64 systems.</p>
<h3 id="checking-if-the-container-and-the-relevant-programs-run-correctly">CHECKING IF THE CONTAINER AND THE RELEVANT PROGRAMS RUN CORRECTLY</h3>
<p>We provide a script that runs fast checks on Propel and the other provers (HipSpec, Zeno, cvc5, Vampire) used in the evaluation.</p>
<p>The check verifies commutativity of natural number addition – a task which all programs are able to prove correct quickly. The following command runs the check:</p>
<pre><code>$ docker run -it --rm propel /check_image/check</code></pre>
<p>If you see in green the line “Check Done” at the end, the container is behaving as expected.</p>
<p>The check will show the provers’ output, which should look similar to the following (shortened) excerpt:</p>
<pre><code>Checking Zeno

[...]

Searching for proofs... 
Proved "CommutativityAddition.prop_comm_add : add x y = add y x"

[...]

Checking HipSpec

[...]

Proved:
    add m n == add n m
    add m (add n o) == add n (add m o)
    prop_comm_add {- add x y == add y x -}


Checking CVC5
"commutativity nat_add2p"
unsat

Checking Vampire

[...]

\% Termination reason: Refutation

[...]

Checking Propel

✔ Check successful.

Check Done</code></pre>
<p>Note that CVC5 and and Vampire report <code>unsat</code> or <code>Refutation</code>, respectively. This is because properties are verified by SMT solvers by finding a counterexample for their negation.</p>
<h2 id="step-by-step-instructions">STEP-BY-STEP INSTRUCTIONS</h2>
<h3 id="compiling-propel">COMPILING PROPEL</h3>
<p>The provided container already contains a binary executable of Propel.</p>
<p>To compile Propel to Java bytecode yourself, run the following command:</p>
<pre><code>$ docker run -it --rm propel bash -c 'cd /propel; sbt clean compile'</code></pre>
<p>To compile Propel to a native binary yourself, run the following command:</p>
<pre><code>$ docker run -it --rm propel bash -c 'cd /propel; sbt clean nativeLink'</code></pre>
<p>Compiling Propel, to bytecode or to a native executable, may not work inside the Docker container on Apple M1 machines for the reasons mentioned earlier.</p>
<p>The resulting binary is at <code>/propel/.native/target/scala-3.2.2/propel</code>. The <code>propel</code> executable in the PATH is already symlinked to that binary file. Hence, by default, you can just run <code>propel</code>.</p>
<h3 id="testing-propel">TESTING PROPEL</h3>
<p>To run the tests in Propel, execute:</p>
<pre><code>$ docker run -it --rm propel bash -c 'cd /propel &amp;\&amp; sbt test'</code></pre>
<p>Running the Propel tests may not work inside the Docker container on Apple M1 machines for the reasons mentioned earlier.</p>
<p>Note that running all unit tests can take several minutes. The output should look similar to the following (shortened) excerpt:</p>
<pre><code>[info] SuccessfulPropertyChecks:
[info] - nat_add2p
[info] - nat_add3p
[info] - nat_mult2p
[info] - bv_add

[...]

[info] FailingPropertyChecks:
[info] - nat_add2p_acc !!! IGNORED !!!
[info] - nat_add3p_acc !!! IGNORED !!!

[...]

[info] Total number of tests run: 49
[info] Suites: completed 2, aborted 0
[info] Tests: succeeded 49, failed 0, canceled 0, ignored 15, pending 0
</code></pre>
<p>The <code>SuccessfulPropertyChecks</code> contain the examples for which Propel can verify all properties. The <code>FailingPropertyChecks</code> contain the examples for which Propel is unable to verify all properties, hence their unit tests are disabled (<code>IGNORED</code>).</p>
<h3 id="running-the-benchmarks">RUNNING THE BENCHMARKS</h3>
<p>The benchmarks in Tables 2 and 3, and Figure 1 can be re-executed with the container. The number of the properties that (1) could be proven,(2) could not be proven and (3) timed out should match the content of tables and the figures. The given time may differ depending on the system where the benchmarks are run. Due the the timeout of one minute, not only the amount of seconds can differ but also the type of the result. It could be the case that the benchmark succeeds or fails in less than 60s on one setup but takes more than 60s on a different setup, in which case it would time out.</p>
<p>To execute the benchmarks on HipSpec, run the following command:</p>
<pre><code>$ docker run -it --rm propel /benchmarks/hipspec/run</code></pre>
<p>To execute the benchmarks on Zeno, run the following command:</p>
<pre><code>$ docker run -it --rm propel /benchmarks/zeno/run</code></pre>
<p>To execute the benchmarks on cvc5, run the following command:</p>
<pre><code>$ docker run -it --rm propel /benchmarks/cvc5/run</code></pre>
<p>To execute the benchmarks on Vampire, run the following command:</p>
<pre><code>$ docker run -it --rm propel /benchmarks/vampire/run</code></pre>
<p>To execute the benchmarks on Propel, run the following command:</p>
<pre><code>$ docker run -it --rm propel /benchmarks/propel/run</code></pre>
<p>The results in Table 2 correspond to one line from the output of each command. We list each CRDT benchmark and the token its corresponding line starts with:</p>
<ol type="1">
<li>GCounter (Peano number list)
<ul>
<li>commutativity: <code>natlist_gcounter_comm</code></li>
<li>associativity: <code>natlist_gcounter_assoc</code></li>
<li>idempotency: <code>natlist_gcounter_idem</code></li>
</ul></li>
<li>GCounter (bit vector list)
<ul>
<li>commutativity: <code>bvlist_gcounter_comm</code></li>
<li>associativity: <code>bvlist_gcounter_assoc</code></li>
<li>idempotency: <code>bvlist_gcounter_idem</code></li>
</ul></li>
<li>BCounter (Peano number list)
<ul>
<li>commutativity: <code>natlist_bcounter_comm</code></li>
<li>associativity: <code>natlist_bcounter_assoc</code></li>
<li>idempotency: <code>natlist_bcounter_idem</code></li>
</ul></li>
<li>BCounter (bit vector list)
<ul>
<li>commutativity: <code>bvlist_bcounter_comm</code></li>
<li>associativity: <code>bvlist_bcounter_assoc</code></li>
<li>idempotency: <code>bvlist_bcounter_idem</code></li>
</ul></li>
<li>PNCounter (Peano number list)
<ul>
<li>commutativity: <code>natlist_pncounter_comm</code></li>
<li>associativity: <code>natlist_pncounter_assoc</code></li>
<li>idempotency: <code>natlist_pncounter_idem</code></li>
</ul></li>
<li>PNCounter (bit vector list)
<ul>
<li>commutativity: <code>bvlist_pncounter_comm</code></li>
<li>associativity: <code>bvlist_pncounter_assoc</code></li>
<li>idempotency: <code>bvlist_pncounter_idem</code></li>
</ul></li>
<li>LWW Register (Peano numbers)
<ul>
<li>commutativity: <code>nat_lwwreg_comm</code></li>
<li>associativity: <code>nat_lwwreg_assoc</code></li>
<li>idempotency: <code>nat_lwwreg_idem</code></li>
</ul></li>
<li>LWW Register (bit vectors)
<ul>
<li>commutativity: <code>bv_lwwreg_comm</code></li>
<li>associativity: <code>bv_lwwreg_assoc</code></li>
<li>idempotency: <code>bv_lwwreg_idem</code></li>
</ul></li>
<li>GSet
<ul>
<li>commutativity: <code>gset_comm</code></li>
<li>associativity: <code>gset_assoc</code></li>
<li>idempotency: <code>gset_idem</code></li>
</ul></li>
<li>ORSet
<ul>
<li>commutativity: <code>orset_comm</code></li>
<li>associativity: <code>orset_assoc</code></li>
<li>idempotency: <code>orset_idem</code></li>
</ul></li>
<li>2PSet
<ul>
<li>commutativity: <code>twophaseset_comm</code></li>
<li>associativity: <code>twophaseset_assoc</code></li>
<li>idempotency: <code>twophaseset_idem</code></li>
</ul></li>
</ol>
<p>The results in Table 3 correspond to one line from the output of each command. We list each CRDT benchmark and the token its corresponding line starts with:</p>
<ol type="1">
<li>add2p
<ul>
<li>commutativity: <code>nat_add2p_comm</code></li>
<li>associativity: <code>nat_add2p_assoc</code></li>
</ul></li>
<li>add3p
<ul>
<li>commutativity: <code>nat_add3p_comm</code></li>
<li>associativity: <code>nat_add3p_assoc</code></li>
</ul></li>
</ol>
<p>Figure 2 provides further benchmark results from those benchmarks of the TIP 2015 (Tons of Inductive Problems, https://tip-org.github.io/) benchmark suite, which check algebraic and relational properties supported by Propel. They can be run using the following commands:</p>
<pre><code>$ docker run -it --rm propel /tip2015/hipspec/run
$ docker run -it --rm propel /tip2015/zeno/run
$ docker run -it --rm propel /tip2015/cvc5/run
$ docker run -it --rm propel /tip2015/vampire/run
$ docker run -it --rm propel /tip2015/propel/run</code></pre>
<h3 id="using-propel-as-a-scala-dsl">USING PROPEL AS A SCALA DSL</h3>
<p>Propel as described in Section 3 is a DSL in Scala. To experiment with the DSL, we invite you take a look into <code>/propel/src/test/scala/propel/ScalaExamplesNat.scala</code>, <code>/propel/src/test/scala/propel/ScalaExamplesNum.scala</code> and <code>/propel/src/test/scala/propel/ScalaExamplesList.scala</code> inside the container.</p>
<p>As an example, you can execute the following commands to run a shell, explore the files and recompile the project:</p>
<pre><code>$ docker run -it --rm propel bash                               # open a shell
$ nano /propel/src/test/scala/propel/ScalaExamplesList.scala    # open the file

# edit and save the file

$ cd /propel &amp;\&amp; sbt Test/compile                                # recompile</code></pre>
<p>Compiling the examples may not work inside the Docker container on Apple M1 machines for the reasons mentioned earlier.</p>
<p>You may define your own function using the following syntax:</p>
<pre><code>def myFunction = prop[(FunctionProperties) ::= (T1, T1) =&gt;: T2] { (x, y) =&gt; body }
// or
def myRecursiveFunction = prop.rec[(FunctionProperties) ::= (T1, T1) =&gt;: T2] { myRecursiveFunction =&gt; (x, y) =&gt; body }</code></pre>
<p>Here, <code>myFunction</code> is the name of the function, <code>FunctionProperties</code> is a list of function properties the function has (separated by <code>&amp;</code>), <code>T1</code> is the type of the arguments of the binary function, <code>T2</code> is the return type of the function, <code>x</code> and <code>y</code> are the names of the function arguments, and <code>body</code> is the function body.</p>
<p>The function properties are chosen from the following list: <code>Comm</code>, <code>Assoc</code>, <code>Idem</code>, <code>Sel</code>, <code>Refl</code>, <code>Antisym</code>, <code>Trans</code>, <code>Conn</code>, and <code>Sym</code>. Their semantics is defined in Table 1.</p>
<p>If Propel is able to prove the properties that the function is annotated with, then compilation succeeds. If the properties cannot be proven, then a compilation error indicates which property could not be proven</p>
<p>For example, you can add the GCounter CRDT example from the paper to one of the files in <code>/propel/src/test/scala/propel</code></p>
<pre><code>def mergeGCounter = prop[(Comm \&amp; Assoc \&amp; Idem) := (List[Num], List[Num]) =&gt;: List[Num]] { (x, y) =&gt; zipWith(maxNum)(x, y) }</code></pre>
<p>We hope that the integration into Scala makes the artifact easily usable by other researchers, either (1) by directly using the DSL to check algebraic and relational properties of their programs or (2) by building on Propel’s verification engine. To facilitate the latter, the implementation of Propel’s Scala DSL (<code>propel.dsl</code> package) is separated from the verification mechanism (<code>propel.evaluator</code> package), which researchers can adopt independently of the Scala integration (an overview of the package structure is in the last section).</p>
<h3 id="using-propel-standalone-outside-of-scala">USING PROPEL STANDALONE (OUTSIDE OF SCALA)</h3>
<p>Propel can be directly reused as a verification tool in other projects (without the Scala and JVM dependency) through the <code>propel</code> binary. The binary consumes ASTs of Propel’s calculus in an S-expression-based syntax.</p>
<p>Our Scala implementation of the full surface language also follows the approach of translating Scala programs to terms in the calculus and passing them to the verification mechanism. A similar approach can be adopted by other tools that use Propel. Note that the AST is a bit more low-level then the Scala implementation and the calculus presented in the paper. In particular, the properties that are captured in the type of a function need to be propagated to the call sites of the function, i.e., function calls are syntactically annotated with the properties that should hold for them. The concrete format is described in the FORMAT.md file.</p>
<p>We provide all benchmarks in this format in the <code>/benchmarks/propel</code> directory. For example, the <code>nat_add2p_comm.propel</code> is a direct translation of the <code>add2p</code> function of Listing 4. This file can be checked by running:</p>
<pre><code>propel -f /benchmarks/propel/nat_add2p_comm.propel</code></pre>
<p>Additional information about the proof attempts can be shown using the <code>-d</code> and <code>-r</code> flags.</p>
<h3 id="structure-of-the-propel-source-code">STRUCTURE OF THE PROPEL SOURCE CODE</h3>
<p>Propel is organized into the following packages:</p>
<ul>
<li><code>ast</code>: Abstract syntax tree definitions for the verifier</li>
<li><code>dsl</code>: Scala DSL</li>
<li><code>evaluator</code>: Rewrite engine (used by an implementation of the calculus’ dynamic semantics and by the verifier)</li>
<li><code>evaluator.properties</code>: Verifier for algebraic and relational properties (call <code>evaluator.properties.check</code> on an <code>ast.Term</code> to verify properties)</li>
<li><code>parser</code>: Parser for Propel’s serialization format (as used by the benchmarks)</li>
<li><code>printing</code>: Pretty-printer for Propel ASTs</li>
<li><code>typer</code>: Standard type checker (not checking algebraic and relational properties)</li>
<li><code>util</code>: Small, useful definitions</li>
</ul>

},
keywords = {Conflict-Free Replicated Data Types, Type Systems, Verification}
}

@software{10.5281/zenodo.7819755,
author = {Lecoeur, Bastien and Mohsin, Hasan and Donaldson, Alastair F.},
title = {Artifact for "Program Reconditioning: Avoiding Undefined Behaviour When Finding and Reducing Compiler Bugs", PLDI 2023},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7819755},
abstract = {
    <p>The artifact includes runnable versions of the GLSLsmith and WGSLsmith tools (both source code and binary distributions), together with instructions showing how to use them to find and reduce compiler bugs, plus data sets related to controlled experiments described in the paper.</p>

},
keywords = {compiler testing, OpenGL, Randomised testing, test-case reduction, undefined behaviour, WebGPU}
}

@software{10.5281/zenodo.7823993,
author = {Sisco, Zachary D. and Balkind, Jonathan and Sherwood, Timothy and Hardekopf, Ben},
title = {Artifact for "Loop Rerolling for Hardware Decompilation"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7823993},
abstract = {
    <p>The artifact consists of four components: (1) source code for hardware loop identification over the benchmark suite of netlists; (2) source code for hardware loop rerolling over the benchmark suite; (3) scripts for comparing simulation times between decompiled HDL code with rerolled loops and the original netlist using Verilator; and (4) Yosys scripts for converting Verilog designs to netlists in BLIF. We provide instructions to reproduce the results reported in the evaluation.</p>

},
keywords = {hardware decompilation, loop rerolling, program synthesis}
}

@software{10.5281/zenodo.7824069,
author = {Arora, Jatin and Westrick, Sam and Acar, Umut A.},
title = {Replication instructions for Article: Efficient Parallel Functional Programming with Effects},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7824069},
abstract = {
    <p>The artifact contains the implementation of our language MPL and also contains benchmarks for its evaluation w.r.t languages MLton, C/C++, Go, Java, and OCaml.</p>

},
keywords = {functional languages, memory management, parallel programming, parallelism}
}

@software{10.5281/zenodo.7824175,
author = {Guria, Sankha Narayan and Foster, Jeffrey S. and Van Horn, David},
title = {Artifact for "Absynthe: Abstract Interpretation-Guided Synthesis"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7824175},
abstract = {
    <p>The artifact is a Docker image that contains all of the source code, benchmarks, and experiment harnesses used in the development of the paper (set-up and ready to run). The README contains instructions to reproduce results from the paper, as well as pointers for how to use, extend or modify the tool and benchmarks.</p>

},
keywords = {abstract interpretation, program synthesis, Ruby}
}

@software{10.5281/zenodo.7824546,
author = {Bouajjani, Ahmed and Enea, Constantin and Rom\'{a}n-Calvo, Enrique},
title = {Transactional JPF - Artifact for "Dynamic Partial Order Reduction for Checking Correctness against Transaction Isolation Levels"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7824546},
abstract = {
    <p>Extension of Java PathFinder (JPF) for managing transactions as well as EXPLORE-CE algorithm’s implementation. It includes several benchmarks used in the article “Dynamic Partial Order Reduction for Checking Correctness against Transaction Isolation Levels” as well as graphical scripts for plotting the results.</p>

},
keywords = {Dynamic Partial-Order Reduction, Java PathFinder, Transactional Databases, Weak Isolation Levels}
}

@software{10.5281/zenodo.7824835,
author = {Yallop, Jeremy and Xie, Ningning and Krishnaswami, Neel},
title = {flap: A Deterministic Parser with Fused Lexing (artifact)},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7824835},
abstract = {
    <p>Artifact accompanying the paper “flap: A Deterministic Parser with Fused Lexing”. Please see the latest version: https://doi.org/10.5281/zenodo.7712770</p>

},
keywords = {fusion, lexing, multi-stage programming, optimization, parsing}
}

@software{10.5281/zenodo.7829982,
author = {Meyer, Roland and Wies, Thomas and Wolff, Sebastian},
title = {Artifact for "Embedding Hindsight Reasoning in Separation Logic"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7829982},
abstract = {
    <p>The artifact demonstrates that the implementation from the paper “Embedding Hindsight Reasoning in Separation Logic” [PLDI’23], an extension of the PLANKTON tool, (1) can automatically verify the Logical Ordering tree, and (2) compares the extension with the original version of PLANKTON in terms of performance and proof capabilities.</p>

},
keywords = {Automated reasoning, Hindsight, Hoare logic, Linearizability, Logical Ordering Tree, Program verification, Programming logic, Separation logic}
}

@software{10.5281/zenodo.7832346,
author = {Wilkinson, Lucas and Cheshmi, Kazem and Dehnavi, Maryam Mehri},
title = {Register Tiling for Unstructured Sparsity in Neural Network Inference Artifact},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7832346},
abstract = {
    <p>This is the code for the “Register Tiling for Unstructured Sparsity in Neural Network Inference” paper in PLDI 2023, please see the README in size <code>artifact_src.tgz</code> for instructions on how to use the code. Please see https://github.com/SpRegTiling/sparse-register-tiling for the latest version of the code.</p>

},
keywords = {Matrix Multiplication, Pruned Neural Networks, Register Tiling, Sparse Matrix, SpMM}
}

@software{10.5281/zenodo.7997778,
author = {M\"{u}ller, Mark Niklas and Fischer, Marc and Staab, Robin and Vechev, Martin},
title = {Abstract Interpretation of Fixpoint Iterators with Applications to Neural Networks - Artifact},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7997778},
abstract = {
    <p>An implementation of the abstract fixpoint iterator framework for monDEQs, CRAFT, as well as the CH-Zonotope domain. Included are the code, trained models, expected results, and detailed instructions on how to reproduce all results from the PLDI’23 paper “Abstract Interpretation of Fixpoint Iterators with Applications to Neural Networks”.</p>

},
keywords = {abstract interpretation, adversarial robustness, equlibrium models, fixpoint}
}

@software{10.1145/3554354,
author = {Wang, Chenglin and Lin, Fangzhen},
title = {Reproduction package for paper "Solving Conditional Linear Recurrences for Program Verification: The Periodic Case"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3554354},
abstract = {
    <p>This repo contains a conditional recurrence solver which tries to solve a conditional linear recurrence. As claimed by the Theorem 5.2 in the paper, if the index sequence of the input recurrence is ultimately periodic and the periodic constraints (formula (14) in the paper) lie in language <span class="math inline">ℒ</span>, then a closed-form solution to the recurrence will be computed successfully.</p>
<p>Solving parameterized conditional linear recurrences (Sec 7.1 of the paper), in which the initial values are unknown, is also be implemented.</p>
<p>To show the effectiveness of our recurrence solver for program verification, a program verifier that tries to verify the correctness of an assertion in a C program is also implemented.</p>

},
keywords = {invariant generation, loop summarization, Recurrence solving}
}

@software{10.5281/zenodo.7503088,
author = {Lin, Zhengyao and Chen, Xiaohong and Trinh, Minh-Thai and Wang, John and Ro\c{s}u, Grigore},
title = {Reproduction Docker Image for `Generating Proof Certificates for a Language-Agnostic Deductive Program Verifier'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7503088},
abstract = {
    <p>This artifact is an Docker image containing code and experiment setup for our paper.</p>

},
keywords = {Matching Logic, Program Verification, Reachability Logic}
}

@software{10.5281/zenodo.7510752,
author = {Winter, Levin N. and Buse, Florena and de Graaf, Daan and von Gleissenthall, Klaus and Kulahcioglu Ozkan, Burcu},
title = {Artifact for "Randomized Testing of Byzantine Fault Tolerant Consensus Algorithms"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7510752},
abstract = {
    <p>This upload is a virtual machine (VM) containing the artifact accompanying our paper “Randomized Testing of Byzantine Fault Tolerant Algorithms”. The VirtualBox VM image contains the source code for our testing algorithm and the systems under test. The VM has all the dependencies resolved.</p>

},
keywords = {Byzantine fault-tolerance, Distributed algorithms, Distributed consensus, Random testing, Software testing and debugging}
}

@software{10.5281/zenodo.7511039,
author = {Lattuada, Andrea and Hance, Travis and Cho, Chanhee and Brun, Matthias and Subasinghe, Isitha and Zhou, Yi and Howell, Jon and Parno, Bryan and Hawblitzel, Chris},
title = {Software Artifact (virtual machine, pre-built distributions) for "Verus: Verifying Rust Programs using Linear Ghost Types"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7511039},
abstract = {
    <p>This is the software artifact accompanying the OOPSLA 2023 Paper “Verus: Verifying Rust Programs using Linear Ghost Types”. Verus is an SMT-based tool for formally verifying Rust programs. With Verus, programmers express proofs and specifications using the Rust language, allowing proofs to take advantage of Rust’s linear types and borrow checking. We show how this allows proofs to manipulate linearly typed permissions that let Rust code safely manipulate memory, pointers, and concurrent resources. We demonstrate Verus on a series of examples, including pointer-manipulating code (an xor-based doubly linked list), code with interior mutability, and concurrent code.</p>
<p>The artifact contains a virtual machine image and pre-built distributions of Verus, and the examples and scripts used for evaluation in the paper. The artifact demonstrates that (i) Verus runs correctly, (ii) it successfully verifies example code that exercises the paper’s claims and (iii) the examples verify quickly. More detail is available on the artifact page on Zenodo.</p>

},
keywords = {linear types, Rust, systems verification}
}

@software{10.5281/zenodo.7574712,
author = {Wagner, Christopher and Jaber, Nouraldin and Samanta, Roopsha},
title = {Enabling Bounded Verification of Doubly-Unbounded Distributed Agreement-Based Systems via Bounded Regions (Artifact)},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7574712},
abstract = {
    <p>Venus is a tool for formal verification of doubly-unbounded distributed agreement-based (DAB) systems that combines a variable domain reduction with a recent tool, QuickSilver (ref: https://zenodo.org/record/5501650), for parameterized verification of DAB systems with finite-state processes.</p>

},
keywords = {Data Saturation, Layered Verification, Reduction}
}

@software{10.5281/zenodo.7697453,
author = {Goharshady, Amir Kafshdar and Hitarth, S. and Mohammadi, Fatemeh and Motwani, Harshit Jitendra},
title = {PolySynth},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7697453},
abstract = {
    <p>PolySynth is a tool for synthesis of polynomial programs in a C-like imperative programming language where all assignments, guards, and assertions are restricted to be polynomial expression over the program variables. Our tool is implemented in Python3 is open source. Our algorithm, as described in our paper, is based on Farkas’ Lemma, Handelman Theorem, and Putinar’s Positivstellensatz.</p>
<p>The artifact code consists of the following main directories.</p>
<ol type="1">
<li><p>The directory <code>benchmarks-polysynth</code> contains all the benchmarks in theformat that can be passed to our tool PolySynth.</p></li>
<li><p>The directory <code>benchmarks-rosette</code> contains all the benchmarks that can bepassed to Rosette.</p></li>
<li><p>The directory <code>benchmarks-sketch</code> contains all the benchmarks that can bepassed to Sketch.</p></li>
<li><p>The directory <code>Code</code> contains the code for our main algorithms.</p></li>
<li><p>The directory <code>polysynth-outputs</code> contains the output programs and other intermediate files our tool Polysynth creates for all of the benchmarks.</p></li>
</ol>
<p>Follow the following steps to run the synthesizer on a given benchmark:</p>
<p>Open the terminal and change the directory to <code>Code/</code></p>
<p>All the examples/benchmarks are stored in the folder <code>benchmarks-polysynth</code></p>
<p>The easiest way to run an example is to type the following command: sh run_polysynth_all_benchmarks.sh from the root directory of the repository.</p>
<p>Suppose you want to run the synthesizer for the example Closest_cube_root, then you would run the following command:</p>
<p><code>python3 synthesizer.py --filename Examples/Closest_cube_root/closest_cube_root.c</code></p>

},
keywords = {algebro-geometric algorithm, polynomial programs, program synthesis, template-based synthesis}
}

@software{10.5281/zenodo.7710436,
author = {Kang, Chan Gu and Oh, Hakjoo},
title = {Artifact for paper "Modular Component-Based Quantum Circuit Synthesis"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7710436},
abstract = {
    <p>This artifact manual aims to reproduce results in the paper “Modular Component-based Quantum Circuit Synthesis” submitted to OOPSLA 2023. Our algorithm produces a quantum circuit, given user-provided in/output spec and component gates for circuit synthesis. Following the artifact manual (attached artifiact_manual.pdf) will give:</p>
<ul>
<li>Reproduction of Table 3 in our paper, which is main result of our synthesis experiment</li>
<li>Explanation on how to give new input (i.e, new synthesis problem) to our program</li>
<li>Reproduction of qiskit’s transpiled circuit appeared in Figure 2, 7, 8 of our paper</li>
</ul>
<p>Our project also can be found in Github Repository (https://github.com/kupl/qsyn).</p>

},
keywords = {Quantum circuit synthesis, Quantum programming}
}

@software{10.5281/zenodo.7712620,
author = {Mulder, Ike and Krebbers, Robbert},
title = {Artifact of 'Proof Automation for Linearizability in Separation Logic'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7712620},
abstract = {
    <p>This is the artifact for the OOPSLA ‘23 paper ’Proof Automation for Linearizability in Separation Logic’. It contains the Diaframe 2.0 source code, a VM containing a compiled version of this source code, and instructions for evaluation.</p>
<p>Diaframe 2.0’s current development can be found at https://gitlab.mpi-sws.org/iris/diaframe .</p>

},
keywords = {automated reasoning, Coq, Iris, program verification, Separation logic}
}

@software{10.5281/zenodo.7713722,
author = {Yuan, Yongwei and Guest, Scott and Griffis, Eric and Potter, Hannah and Moon, David and Omar, Cyrus},
title = {Artifact for "Live Pattern Matching with Typed Holes"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7713722},
abstract = {
    <p>The artifact includes a proof mechanization that concludes the type safety of the system presented in the paper, and a minimal solver-based implementation of exhaustiveness and redundancy checker.</p>

},
keywords = {Functional Programming, Pattern Matching, Typed Holes}
}

@software{10.5281/zenodo.7713789,
author = {Barke, Shraddha and James, Michael B. and Polikarpova, Nadia},
title = {Replication Package for Article: "Grounded Copilot: How Programmers Interact with Code-Generating Models"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7713789},
abstract = {
    <p>This artifact contains: - The scripts to generate our plots - Detailed study information to re-run our user study - Livestreams that we observed and included in our dataset - Our codebook</p>

},
keywords = {AI Assistants, Grounded Theory, Program Synthesis}
}

@software{10.5281/zenodo.7723110,
author = {Roth, Ori and Gil, Yossi},
title = {Flunct: Functional Fluent API Generator},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7723110},
abstract = {
    <p>Accompanying artifact for the OOPSLA 2023 paper “Fluent APIs in Functional Languages”. Flunct compiles finite state machines specifying regular domain-specific languages or API protocols into functional fluent APIs in Standard ML.</p>

},
keywords = {API protocols, embedded DSLs, fluent API}
}

@software{10.1145/3554347,
author = {Popoola, Tobi and Zhao, Tuowen and St. George, Aaron and Bhetwal, Kalyan and Strout, Michelle Mills and Hall, Mary and Olschanowsky, Catherine},
title = {Reproduction Package for Code Synthesis for Sparse Tensor Format Conversion and Optimization},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3554347},
abstract = {
    <p>This artifact introduces a technique for data layout transformations based on constrained relationships between different forms of data. In this artifact, we apply this technique to generate code for transforming from one source format to another. We provide a docker container to replicate results. To ease testing we provide already generated transformation codes wrapped around necessary macros to evaluate our work. We also provide artifacts from the state-of-the-art discussed in our work.</p>

},
keywords = {Code synthesis, Index array properties, Polyhedral compilation, Sparse Format Conversion, Sparser Format Descriptors, Transformations, Uninterpreted functions}
}

@software{10.1145/3554349,
author = {Thangamani, Arun and Jost, Tiago Trevisan and Loechner, Vincent and Genaud, St\'{e}phane and Bramas, B\'{e}renger},
title = {Artifact for Lifting Code Generation of Cardiac Physiology Simulation to Novel Compiler Technology},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3554349},
abstract = {
    <p>This artifact provides all required tools and dependencies needed to compile and execute applications, and generate figures 2, 3, 4 (optional), and 5 mentioned in the paper titled Lifting Code Generation of Cardiac Physiology Simulation to Novel Compiler Technology published in CGO’23.</p>

},
keywords = {Code Generation and Optimization, Code translation and transformation, Domain-specific languages, Parallel computing, Vectorization}
}

@software{10.1145/3554350,
author = {Mu, Wenlong and Zhang, Yilei and Huang, Bo and Guo, Jianmei and Cui, Shiqiang},
title = {Reproduction Package for Article “A Hotspot-Driven Semi-automated Competitive Analysis Framework for Identifying Compiler Key Optimizations”},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3554350},
abstract = {
    <p>In order to identify the key optimizations adopted by some high-performance compilers, we propose a hotspot-driven semi-automatic framework for identifying key compiler optimizations through comparing the binaries generated by two different compilers. Firstly, the framework obtains the execution time and hotspot distribution information of binaries generated by two different compilers with the same source code through a performance analysis tool(Linux perf), and then the framework automatically selects the identified hotspots that cause the binaries‘ performance difference. We use DynamoRIO Client to analyze the instruction distribution characteristics of specific hotspots, which help us narrow down the scope of hotspots‘s binary analysis. All the above steps can be done automatically by the framework.</p>

},
keywords = {dynamic binary instrumentation, hotspots detection, semi-automated framework}
}

@software{10.1145/3554351,
author = {Rasch, Ari and Schulze, Richard and Shabalin, Denys and Elster, Anne and Gorlatch, Sergei and Hall, Mary},
title = {Reproduction Package for Article `(De/Re)-Compositions Expressed Systematically via MDH-Based Schedules'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3554351},
abstract = {
    <p>This artifact contains the workflow to reproduce the experiments presented in the paper `(De/Re)-Compositions Expressed Systematically via MDH-Based Schedules’ accepted for publication at the ACM SIGPLAN 2023 International Conference on Compiler Construction. The user is invited to perform the steps described in file README.txt.</p>

},
keywords = {CPU, GPU, scheduling languages}
}

@software{10.1145/3554352,
author = {Patabandi, Tharindu R. and Hall, Mary},
title = {Reproduction package for "Efficiently Learning Locality Optimizations by Decomposing Transformation Domains"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3554352},
abstract = {
    <p>The artifact contains executable binaries and trained predictive models to reproduce the results presented in the publication.</p>

},
keywords = {convolutional neural networks, data locality, loop permutation, Loop tiling, x86}
}

@software{10.5281/zenodo.7374334,
author = {Wilkins, Michael and Westrick, Sam and Kandiah, Vijay and Bernat, Alex and Suchy, Brian and Deiana, Enrico Armenio and Campanoni, Simone and Acar, Umut A. and Dinda, Peter and Hardavellas, Nikos},
title = {Artifact for "WARDen: Specializing Cache Coherence for High-Level Parallel Languages"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7374334},
abstract = {
    <p>This artifact is a virtual machine of Red Hat Enterprise Linux (RHEL) containing the WARDen prototype and its dependen- cies. The artifact is pre-installed in the “cgo_artifact” account. The password is the same as the username: cgo_artifact. All the PBBS benchmarks used in the paper are also included. This artifact requires VMware Workstation 17 player to load and run the VM, which can be freely downloaded online.</p>

},
keywords = {cache coherence, disentanglement}
}

@software{10.5281/zenodo.7374649,
author = {Dam\'{a}sio, Tha\'{\i}s and Canesche, Michael and Pacheco, Vin\'{\i}cius and Botacin, Marcus and Faustino da Silva, Anderson and Quint\~{a}o Pereira, Fernando M.},
title = {Reproduction Package for Article `A Game-Based Framework to Compare Program Classifiers and Evaders'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7374649},
abstract = {
    <p>This artifact compares different program classification techniques and pits them against different evasion techniques. In total, this artifact let us evaluate nine program encoding techniques; seven code obfuscation passes; and seven stochastic classification models. The artifact consists of a docker container with accompanying scripts to replicate Figures 5-15 automatically, plus the dataset and accompanying instructions to replicate Figure 16 manually. For a more up-to-date version of this source code, check: https://github.com/lac-dcc/yali</p>

},
keywords = {deep learning, obfuscation, ollvm, optimization}
}

@software{10.5281/zenodo.7459640,
author = {Brahmakshatriya, Ajay and Amarasinghe, Saman},
title = {Artifacts for the CGO23 paper: D2X: An eXtensible conteXtual Debugger for modern DSLs},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7459640},
abstract = {
    <p>Artifacts for the CGO23 paper: D2X: An eXtensible conteXtual Debugger for modern DSLs</p>

},
keywords = {compilers, debuggers, DSLs}
}

@software{10.5281/zenodo.7499096,
author = {Basso, Matteo and Ros\`{a}, Andrea and Omini, Luca and Binder, Walter},
title = {Artifact associated to the paper "Java Vector API: Benchmarking and Performance Analysis" published in CC'23},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7499096},
abstract = {
    <p>JVBench is the first open-source benchmark suite for the Java Vector API. It includes several realistic and diversified benchmarks, specifically designed for evaluating vectorization. This artifact consists of a ready-to-use Docker image embedding JVBench together with a set of tools/scripts that can be used to execute the JVBench workloads as well as collect, process and plot performance measurements to replicate the evaluation of JVBench presented in the paper “Java Vector API: Benchmarking and Performance Analysis” (CC’23). The artifact also contains the complete pre-collected performance measurements used to generated the original figures of the paper.</p>

},
keywords = {Benchmarks, Code optimization, Java, Just-in-time compilation, Parallelism, SIMD, Vector API}
}

@software{10.5281/zenodo.7499790,
author = {Ahrens, Willow and Donenfeld, Daniel and Kjolstad, Fredrik and Amarasinghe, Saman},
title = {Looplets: A Language For Structured Coiteration (The Artifact)},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7499790},
abstract = {
    <p>An artifact supporting the results in the submitted version of our paper. The submitted version is included as a PDF with the artifact instructions at the end, though they are also available as a readme in the artifact itself.</p>

},
keywords = {Array, Coiteration, Compiler, Compressed, Sparse, Tensor}
}

@software{10.5281/zenodo.7517506,
author = {Salvador Rohwedder, Caio and Henderson, Nathan and De Carvalho, Jo\~{a}o P. L. and Chen, Yufei and Amaral, Jos\'{e} Nelson},
title = {Artifact for "To Pack or Not to Pack: A Generalized Packing Analysis and Transformation"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7517506},
abstract = {
    <ul>
<li>docker-packing-artifact.tar.gz: docker image for the execution of experiments</li>
<li>llvm-packing-v0.5.zip: LLVM source code with packing implementation (binary in docker image)</li>
<li>logs-and-graphs.zip: Log files and graphs that were used in the paper</li>
<li>packing-scripts.zip: scripts used to run experiments and Dockerfile source&nbsp;(also provided in docker image) -&nbsp;polybench-c-4.2.1-plus-contract-3d.zip: Polybench 4.2 and running example of paper (also provided in docker image)</li>
</ul>

},
keywords = {Packing Optimization LLVM Compiler}
}

@software{10.5281/zenodo.7519936,
author = {Ben-Nun, Tal and Ates, Berke and Calotoiu, Alexandru and Hoefler, Torsten},
title = {Reproduction package for the paper Bridging Control-Centric and Data-Centric Optimization},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7519936},
abstract = {
    <p>Contains the benchmarking suite for the benchmarks shown in the paper as well as scripts and instructions on how to reproduce them.</p>

},
keywords = {DaCe, data-centric programming, MLIR}
}

@software{10.5281/zenodo.7521260,
author = {Mitenkov, George and Magkanaris, Ioannis and Awile, Omar and Kumbhar, Pramod and Sch\"{u}rmann, Felix and Donaldson, Alastair F.},
title = {Reproduction package for "MOD2IR: High-Performance Code Generation for a Biophysically Detailed Neuronal Simulation DSL"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7521260},
abstract = {
    <p>The artifact was created to complement the submission of the “MOD2IR: High-Performance Code Generation for a Biophysically Detailed Neuronal Simulation DSL” paper to the ACM SIGPLAN 2023 International Conference on Compiler Construction. It contains all the necessary source code, data and scripts to reproduce the results published in the paper.</p>

},
keywords = {Code Generation, Compiler, DSL, LLVM, NEURON, NMODL, Vectorization}
}

@software{10.5281/zenodo.7524279,
author = {Kandiah, Vijay and Lustig, Daniel and Villa, Oreste and Nellans, David and Hardavellas, Nikos},
title = {Artifact for CGO'23 paper titled "Parsimony: Enabling SIMD/Vector Programming in Standard Compiler Flows"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7524279},
abstract = {
    <p>Parsimony is a SPMD programming approach built with semantics designed to be compatible with multiple languages and to cleanly integrate into the standard optimizing compiler toolchains for those languages. This artifact is for our CGO’23 paper titled “Parsimony: Enabling SIMD/Vector Programming in Standard Compiler Flows” and includes a LLVM prototype of the Parsimony model along with a build and test framework for the Simd Library benchmarks and ispc benchmarks. It also includes scripts to build our prototype compiler, build and run the SimdLibrary and ispc benchmarks, and reproduce the figures 4 and 5 presented in our CGO’23 paper.</p>

},
keywords = {Code Transformation, Compiler Design, Single-instruction Multiple-data, Single-program Multiple-data, Vectorization}
}

@software{10.5281/zenodo.7533561,
author = {Mart\'{\i}nez, Pablo Antonio and Woodruff, Jackson and Armengol-Estap\'{e}, Jordi and Bernab\'{e}, Gregorio and Garc\'{\i}a, Jos\'{e} Manuel and O’Boyle, Michael F. P.},
title = {Reproduction package for 'Matching Linear Algebra and Tensor Code to Specialized Hardware Accelerators'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7533561},
abstract = {
    <p>The artifact contains the ATC compiler implemented with OCaml, the JIT compiler implemented in LLVM, the SVM classifier implemented with scikit-learn and the list of GEMM and convolution programs used in the paper. The artifact also contains other compilers used in the evaluation such as KernelFaRer, IDL and LLVM-Polly.</p>

},
keywords = {GEMM, JIT, LLVM, Program synthesis}
}

@software{10.5281/zenodo.7573782,
author = {Fried, Andreas and Stemmer-Grabow, Maximilian and Wachter, Julian},
title = {Register Allocation for Compressed ISAs in LLVM},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7573782},
abstract = {
    <p>We provide a Docker image to reproduce the central result of our work. Our artifact builds two versions of LLVM+Clang, with and without the compression-aware register allocator. It then compiles the SPEC CPU2000 and CPU2006 benchmarks with both compilers. The result of the experiment is a reproduction of figure 1 of our paper, along with other graphs not present in the paper.</p>
<p>Reviewers can also experiment with the parameters of the register allocator and observe their effect on the compression achieved.</p>

},
keywords = {compressed instruction sets, LLVM, register allocation, RISC-V}
}

@software{10.5281/zenodo.7574403,
author = {Matsumura, Kazuaki and De Gonzalo, Simon Garcia and Pe\~{n}a, Antonio J.},
title = {PTXASW},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7574403},
abstract = {
    <p>A symbolic emulator works for shuffle synthesis on the NVIDIA PTX code. Also, this artifact contains the benchmarks.</p>

},
keywords = {CUDA, NVIDIA PTX, OpenACC}
}

@software{10.5281/zenodo.7575072,
author = {VenkataKeerthy, S. and Jain, Siddharth and Kundu, Anilava and Aggarwal, Rohit and Cohen, Albert and Upadrasta, Ramakrishna},
title = {Artifacts for the paper "RL4ReAl: Reinforcement Learning for Register Allocation"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7575072},
abstract = {
    <p>This artifact corresponds to the publication “RL4ReAl: Reinforcement Learning for Register Allocation”, published in CC 2023. This artifact consists of a docker image submitted for the artifact evaluation.</p>

},
keywords = {Graph Coloring, Register Allocation, Reinforcement Learning}
}

@software{10.5281/zenodo.7584642,
author = {Mezdour, Lina and Kadem, Khadidja and Merouani, Massinissa and Haichour, Amina Selma and Amarasinghe, Saman and Baghdadi, Riyadh},
title = {Reproduction Artifact for Article: A Deep Learning Model for Loop Interchange},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7584642},
abstract = {
    <p>This artifact introduces the model presented in the paper: A Deep Learning Model for Loop Interchange, published in CC23 conference, dedicated to predicting the best loop interchange instance for a Tiramisu program given as input. It reproduces the model’s training using the provided datasets, as well as all tests, performed on both the test set and the benchmark. It uses Python and PyTorch mainly.</p>
<p>This tool is presented through python scripts and pickle/json datasets. We present the different scripts in the following: - Model_training.py: It requires no input, provided that all scripts and dataset files are in the same folder, locally, and all default values are being used. It outputs the model with a pickle format. It shows throughout execution the loss values that the model is getting in both the training and the validation set, as well as the accuracy of the resulting model on both sets by the end. - Model_tests.py: It uses the default name of the pickle model (produced in the precedent script) to perform the tests described in the paper. It outputs: the results of the tests (on both the synthetic test set and the benchmark): the accuracy and the search performance. Moreover, it outputs a text file presenting the results for the search performance. - Utils.py: Helper functions</p>

},
keywords = {automatic code optimization, compilers, cost model, deep learning, loop interchange, Tiramisu}
}

@software{10.5281/zenodo.7639153,
author = {Shin, Yongwon and Park, Juseong and Cho, Sungjun and Sung, Hyojin},
title = {Reproduction Package for Article " PIMFlow: Compiler and Runtime Support for CNN Models on Processing-in-Memory DRAM"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7639153},
abstract = {
    <p>Our artifact consists of four parts: (1) PIM-aware ONNX transformation passes, (2) hardware measurement scripts for execution mode and granularity search, (3) an extended TVM compiler with DRAM-PIM back-end, and (4) GPU and DRAM-PIM simulators. For pre-generated input data, we provide GPU traces for the CNN models evaluated in the paper. You can also generate these traces by using NVBit2. For the compiler, we provide modified binaries and source codes for the TVM compiler extended with DRAM-PIM back- end. Artifact evaluation and testing are streamlined with a top-level script (pimflow) that controls different features of PIMFlow with lower-level scripts (Details in Section A.5). The evaluation and reproduction of the results in the paper can be done on any platform with the simulators, as long as the traces are generated on NVIDIA GeForce RTX 2080 Ti GPU.</p>

},
keywords = {CNN models, Processing-in-memory}
}

@software{10.6084/m9.figshare.21964787.v1,
author = {Peng, Mai Jacob and Dubach, Christophe},
title = {Reproduction Package for Artifact "LAGrad: Statically Optimized Differentiable Programming in MLIR"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.21964787.v1},
abstract = {
    <p>This artifact contains the source code for LAGrad, pinned versions of LLVM and Enzyme, and the necessary scripts to reproduce the comparison against the state-of-the-art (Figures 7 and 8) in the CC ’23 paper “LAGrad: Statically Optimized Differentiable Programming in MLIR”.</p>

},
keywords = {automatic differentiation, differentiable programming, MLIR, sparsity, static analysis}
}

@software{10.6084/m9.figshare.21976358.v1,
author = {Rocha, Rodrigo C. O. and Saumya, Charitha and Sundararajah, Kirshanthan and Petoumenos, Pavlos and Kulkarni, Milind and O’Boyle, Michael F. P.},
title = {Artifact for "HyBF : A hybrid branch fusion strategy for code size reduction"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.21976358.v1},
abstract = {
    <p>This is the artifact of the paper</p>
<p>“HyBF : A hybrid branch fusion strategy for code size reduction” Rodrigo Rocha, Charitha Saumya, Kirshanthan Sundararajah, Pavlos Petoumenos, Milind Kulkarni, Michael O’Boyle</p>
<p>published at the Conference on Compiler Construction, 2023.</p>
<p>We provide scripts that automate the installation and use of this artifact. Read README.md for detailed instructions.</p>

},
keywords = {branch fusion, code size, compiler optimizations, compilers, function merging, llvm}
}

@software{10.5281/zenodo.7553144,
author = {Chen, Zhenpeng and Zhang, Jie M. and Sarro, Federica and Harman, Mark},
title = {Artifact for "MAAT: A Novel Ensemble Approach to Addressing Fairness and Performance Bugs for Machine Learning Software"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7553144},
abstract = {
    <p>This artifact is for the paper entitled “MAAT: A Novel Ensemble Approach to Addressing Fairness and Performance Bugs for Machine Learning Software”, which is accepted by ESEC/FSE 2022. MAAT is a novel ensemble approach to improving the fairness-performance trade-off for machine learning software. It outperforms state-of-the-art bias mitigation methods. In this artifact, we provide the source code of MAAT and other existing bias mitigation methods that we use in our study, as well as the intermediate results, the installation instructions, and a replication guideline (included in the README). The replication guideline provides detailed steps to replicate all the results for all the research questions.</p>

},
keywords = {bias mitigation, ensemble learning, fairness-performance trade-off, machine learning software, Software fairness}
}

@software{10.1145/3554339,
author = {Arrial, Victor and Guerrieri, Giulio and Kesner, Delia},
title = {An Implementation of the Quantitative Inhabitation for Different Lambda Calculi in a Unifying Framework},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3554339},
abstract = {
    <p>This artifact provides an implementation in OCaml of the inhabitation algorithm presented in the paper “Quantitative Inhabitation for Different Lambda Calculi in a Unifying Framework”.</p>

},
keywords = {call-by-push-value, inhabitation, lambda-calculus, ocaml, quantitative types}
}

@software{10.1145/3554340,
author = {Hou (Favonia), Kuen-Bang and Angiuli, Carlo and Mullanix, Reed},
title = {Artifact of “An Order-Theoretic Analysis of Universe Polymorphism”},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3554340},
abstract = {
    <p>An OCaml implementation of the paper and an Agda formalization of various parts of the paper.</p>

},
keywords = {type theory, universe polymorphism, universes}
}

@software{10.1145/3554341,
author = {Lemerre, Matthieu},
title = {Artifact for the paper "SSA Translation Is an Abstract Interpretation"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3554341},
abstract = {
    <p>The artifact contains the source code of a small plugin for the Frama-C platform (http://www.frama-c.com), which takes a C file (in the supported subset of C) and translate it to LLVM code, using a dataflow algorithm pass as described in the paper “SSA translation is an abstract interpretation”. The main entry point of the plugin is online_ssa_complete.ml, with okasakimap.ml (an implementation of Chris Okasaki’s Fast Mergeable Integer Maps) and fixpoint_wto.ml (an implementation of Bourdoncle’s Efficient chaotic iteration strategies with widenings) as support files.</p>
<p>The artifact also contains the csmith files generated for use in the experiments described in the paper; a result.org file containing the results of our run of evaluation; a Makefile to compile the plugin and run the experiments; a Dockerfile to recreate a working environment; and a README.org file further documenting the artifact.</p>

},
keywords = {abstract interpretation, dataflow analysis., SSA translation}
}

@software{10.1145/3554342,
author = {Gancher, Joshua and Sojakova, Kristina and Fan, Xiong and Shi, Elaine and Morrisett, Greg},
title = {Repository for Article 'A Core Calculus for Equational Proofs of Cryptographic Protocols'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3554342},
abstract = {
    <p>This repository contains the Coq proofs and technical information for our work. Installation instructions are in the README, while the protocols themselves are in theories/protocols.</p>

},
keywords = {cryptographic protocols, equational proof, multiparty computation, verification}
}

@software{10.1145/3554343,
author = {Zhou, Li and Barthe, Gilles and Strub, Pierre-Yves and Liu, Junyi and Ying, Mingsheng},
title = {Coq Development for Article `CoqQ: Foundational Verification of Quantum Programs`},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3554343},
abstract = {
    <p>CoqQ is a framework for reasoning about quantum programs in the Coq proof assistant. Its main components are: a deeply embedded quantum programming language, in which classic quantum algorithms are easily expressed, and an expressive program logic for proving properties of programs.</p>

},
keywords = {Mathematical Libraries, Program Logics, Proof Assistants, Quantum Programs}
}

@software{10.5281/zenodo.7120897,
author = {Cao, David and Kunkel, Rose and Nandi, Chandrakana and Willsey, Max and Tatlock, Zachary and Polikarpova, Nadia},
title = {Artifact for "babble: Learning Better Abstractions with E-Graphs and Anti-Unification"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7120897},
abstract = {
    <p>This is the artifact for the paper “babble: Learning Better Abstractions with E-Graphs and Anti-Unification”.</p>
<p>The canonical source for this artifact is the Github repo: https://github.com/dcao/babble/tree/popl23 An archival copy is on Zenodo with DOI: 10.5281/zenodo.7120897.</p>

},
keywords = {e-graphs, library learning, program synthesis}
}

@software{10.5281/zenodo.7129302,
author = {Moine, Alexandre and Chargu\'{e}raud, Arthur and Pottier, Fran\c{c}ois},
title = {A High-Level Separation Logic for Heap Space under Garbage Collection - Artifact},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7129302},
abstract = {
    <p>This is the artifact corresponding to&nbsp;the article entitled “A High-Level Separation Logic for Heap Space under Garbage Collection”, and its associated documentation.</p>

},
keywords = {Coq, Iris, live data, program verification, separation logic, tracing garbage collection}
}

@software{10.5281/zenodo.7130343,
author = {Smeding, Tom J. and V\'{a}k\'{a}r, Matthijs I. L.},
title = {Artifact for Efficient Dual-Numbers Reverse AD via Well-Known Program Transformations},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7130343},
abstract = {
    <p>Artifact for the POPL23 submission titled “Efficient Dual-Numbers Reverse AD via Well-Known Program Transformations”. Includes a VirtualBox virtual disk image (tested with VirtualBox 6.1.38), as well as a zip file with just the code. The artifact allows reproduction of the experimental results in the paper.</p>

},
keywords = {automatic differentiation, functional programming, source transformation}
}

@software{10.5281/zenodo.7144067,
author = {Antonopoulos, Timos and Koskinen, Eric and Le, Ton Chanh and Nagasamudram, Ramana and Naumann, David A. and Ngo, Minh},
title = {Mechanization of some results in: An Algebra of Alignment for Relational Verification},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7144067},
abstract = {
    <p>Relational verification encompasses information flow security, regression verification, translation validation for compilers, and more. Effective alignment of the programs and computations to be related facilitates use of simpler relational invariants and relational procedure specs, which in turn enables automation and modular reasoning. Alignment has been explored in terms of trace pairs, deductive rules of relational Hoare logics (RHL), and several forms of product automata. This article shows how a simple extension of Kleene Algebra with Tests (KAT), called BiKAT, subsumes prior formulations, including alignment witnesses for forall-exists properties, which brings to light new RHL-style rules for such properties. Alignments can be discovered algorithmically or devised manually but, in either case, their adequacy with respect to the original programs must be proved; an explicit algebra enables constructive proof by equational reasoning. Furthermore our approach inherits algorithmic benefits from existing KAT-based techniques and tools, which are applicable to a range of semantic models.</p>
<p>The artifact formalizes some results from the paper in Coq. These include constructions of models of BiKAT, general consequences of BiKAT axioms, and the encoding of forall-forall relational triples. In addition, the artifact proves soundness and completeness of a technique for establishing forall-exists properties using BiKAT.</p>

},
keywords = {hyperproperties, Kleene algebra with tests, program algebra, relational verification}
}

@software{10.5281/zenodo.7147007,
author = {Das, Ankush and Wang, Di and Hoffmann, Jan},
title = {Probabilistic Resource-Aware Session Types (Artifact)},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7147007},
abstract = {
    <p>This artifact accompanies the paper titled “Probabilistic Resource-Aware Session Types” appearing at POPL 2023. The artifact contains a VM (Virtual Machine) image that contains an implementation of the NomosPro core calculus (our main contribution) and benchmark examples to test the implementation.</p>

},
keywords = {Amortized Analysis, Markov Chains, Nested Multiverse Semantics, Probabilistic Concurrency, Probabilistic Programming, Randomized Distributed Protocols, Resource Analysis, Semantics, Session Types, Type Systems}
}

@software{10.5281/zenodo.7148055,
author = {Thokair, Mosaad Al and Zhang, Minjian and Mathur, Umang and Viswanathan, Mahesh},
title = {Artifact: Dynamic Race Detection With O(1) Samples},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7148055},
abstract = {
    <p>This document provides instructions on how to evaluate the implementation and reproduce the results from the POPL 2023 article titled “Dynamic Race Detection With O(1) Samples”</p>

},
keywords = {Concurrency, Dynamic program analysis, Happens-before, Property testing, Race detection}
}

@software{10.5281/zenodo.7149192,
author = {Barri\`{e}re, Aur\`{e}le and Blazy, Sandrine and Pichardie, David},
title = {Reproduction Package for "Formally Verified Native Code Generation in an Effectful JIT"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7149192},
abstract = {
    <p>A Virtual Machine Image where FM-JIT is installed (in /home/popl23/FM-JIT/coqjit) and ready to be run.</p>

},
keywords = {CompCert compiler, just-in-time compilation, verified compilation}
}

@software{10.5281/zenodo.7150549,
author = {Jacobs, Jules and Balzer, Stephanie},
title = {Higher-Order Leak and Deadlock Free Locks (Coq mechanization)},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7150549},
abstract = {
    <p>Coq mechanization for the paper “Higher-Order Leak and Deadlock Free Locks”.</p>

},
keywords = {Coq, deadlocks, locks, mechanization, proofs}
}

@software{10.5281/zenodo.7150677,
author = {Bembenek, Aaron and Greenberg, Michael and Chong, Stephen},
title = {From SMT to ASP: Solver-Based Approaches to Solving Datalog Synthesis-as-Rule-Selection Problems (POPL 2023 Artifact)},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7150677},
abstract = {
    <p>This artifact includes the application code, benchmarks, and scripts for reproducing the experiments in the POPL’23 paper “From SMT to ASP: Solver-Based Approaches to Solving Datalog Synthesis-as-Rule-Selection Problems” by Aaron Bembenek, Michael Greenberg, and Stephen Chong.</p>

},
keywords = {answer set programming, Datalog, inductive logic programming, program synthesis, satisfiability}
}

@software{10.5281/zenodo.7150943,
author = {Dash, Swaraj and Kaddar, Younesse and Paquet, Hugo and Staton, Sam},
title = {LazyPPL: Affine monads and lazy structures for Bayesian programming},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7150943},
abstract = {
    <p>A Haskell library for probabilistic programming with lazy structures, to accompany the paper “Affine monads and lazy structures for Bayesian programming”.</p>

},
keywords = {Probabilistic programming}
}

@software{10.5281/zenodo.7151663,
author = {Bowers, Matthew and Olausson, Theo X. and Wong, Lionel and Grand, Gabriel and Tenenbaum, Joshua B. and Ellis, Kevin and Solar-Lezama, Armando},
title = {Artifact for Reproducing Results From "Top-Down Synthesis for Library Learning"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7151663},
abstract = {
    <p>This Artifact is for reproducing the results of “Top-Down Synthesis for Library Learning” (POPL 2023). While this remains as the static version submitted to POPL, some small changes/fixes for broader OS compatibility were made during the evaluation process and are present in the GitHub repo https://github.com/mlb2251/stitch-artifact which will remain more up to date, so <strong>for most use-cases the GitHub version will be preferable</strong>. All instructions for installation, running, etc can be found in the ReadMe of the artifact.</p>

},
keywords = {Abstraction Learning, Library Learning, Program Synthesis}
}

@software{10.5281/zenodo.7151842,
author = {Kokologiannakis, Michalis and Lahav, Ori and Vafeiadis, Viktor},
title = {Reproduction package for article: "Kater: Automating Weak Memory Metatheory and Consistency Checking"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7151842},
abstract = {
    <p>The artifact comprises the version of Kater used for the paper benchmarks, as well as a version of GenMC that employs Kater-generated consistency checks.</p>

},
keywords = {declarative semantics, kleene algebra with tests, software model checking, weak memory models}
}

@software{10.5281/zenodo.7152484,
author = {Klimis, Vasileios and Clark, Jack and Baker, Alan and Neto, David and Wickerson, John and Donaldson, Alastair F.},
title = {Artifact for POPL 2023 Paper: Taking Back Control in an Intermediate Representation for GPU Computing},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7152484},
abstract = {
    <p>The artifact provides evidence to back up the claims made in our POPL 2023 Paper: “Taking Back Control in an Intermediate Representation for GPU Computing”. It is a Docker image that has all the necessary tooling/software pre-installed; this includes the tools produced by us for the paper and this artifact, as well as some third-party tooling for assembling, parsing, disassembling and validating SPIR-V modules.</p>

},
keywords = {Alloy, control flow, fuzz testing, GPU graphics, SPIR-V}
}

@software{10.5281/zenodo.7220452,
author = {Chen, Zilin and Lafont, Ambroise and O'Connor, Liam and Keller, Gabriele and McLaughlin, Craig and Jackson, Vincent and Rizkallah, Christine},
title = {Dargent: A Silver Bullet for Verified Data Layout Refinement (Artefact)},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7220452},
abstract = {
    <p>The artefact contains the source code of the Cogent compiler and its verification framework extended with Dargent, a test suite consisting of small Dargent programs, and the case studies presented in the paper.</p>

},
keywords = {certifying compiler, data layout description, data refinement, systems programming}
}

@software{10.5281/zenodo.7227966,
author = {Chappe, Nicolas and He, Paul and Henrio, Ludovic and Zakowski, Yannick and Zdancewic, Steve},
title = {Choice Trees: Representing Nondeterministic, Recursive, and Impure Programs in Coq},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7227966},
abstract = {
    <p>Snapshot of the “ctrees” library as per its description in the paper “Choice Trees: Representing Nondeterministic, Recursive, and Impure Programs in Coq”.</p>
<p>This library provides a constructive semantic model supporting native support for divergence and non-determinism, while being parameterized by a non-axiomatized signature of external interaction. It is shown to be a valid interpretation target from itrees, as well as to support further interpretation towards other iterative monads.</p>

},
keywords = {Concurrency, Formal Semantics, Interaction Trees, Nondeterminism}
}

@software{10.5281/zenodo.7246597,
author = {Lee, Wonyeol and Rival, Xavier and Yang, Hongseok},
title = {Artifact for the Paper "Smoothness Analysis for Probabilistic Programs with Application to Optimised Variational Inference"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7246597},
abstract = {
    <p>The artifact includes (i) our implementation of the static analysis for smoothness properties, (ii) the Pyro programs used in our experiments, and (iii) information on how to reproduce the results reported in the paper. For more details, please refer to `pyppai/README.txt’ in the artifact, and Section 7 of the paper.</p>

},
keywords = {probabilistic programming, smoothness, static analysis, variational inference}
}

@software{10.5281/zenodo.7260815,
author = {Palmkvist, Viktor and Castegren, Elias and Haller, Philipp and Broman, David},
title = {Implementation, Experiments, and Mechanization for 'Statically Resolvable Ambiguity'},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7260815},
abstract = {
    <p>This artifact contains all supplementary material for the ‘Statically Resolvable Ambiguity’ paper, including the modified OCaml compiler, the library implementing our grouper, the benchmarks and resulting data used in the paper, and the mechanized proof of static resolvability.</p>

},
keywords = {Coq, OCaml, Parsing}
}

@software{10.5281/zenodo.7305612,
author = {Abreu, Pedro and Delaware, Benjamin and Hubers, Alex and Jenkins, Christa and Morris, J. Garrett and Stump, Aaron},
title = {Artifact, Documentation, and Code for POPL'23 Paper &nbsp;"A Type-Based Approach to Divide-and-Conquer Recursion in Coq"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7305612},
abstract = {
    <p>Artifact for POPL’23 Paper “A Type-Based Approach to Divide-and-Conquer Recursion in Coq”. The paper describes a development in Coq for writing divide-and-conquer recursion with type-based termination checking. This artifact contains this development and many example applications.</p>

},
keywords = {Algebraic Semantics, Coq, Divide-and-Conquer Recursion, Mendler Algebras, Mergesort, Strong Normalization, Type-Based Termination Checking}
}

@software{10.5281/zenodo.7306313,
author = {Sammler, Michael and Spies, Simon and Song, Youngju and D'Osualdo, Emanuele and Krebbers, Robbert and Garg, Deepak and Dreyer, Derek},
title = {Artifact and Appendix of "DimSum: A Decentralized Approach to Multi-language Semantics and Verification"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7306313},
abstract = {
    <p>This is the artifact for the POPL’23 paper “DimSum: A Decentralized Approach to Multi-language Semantics and Verification”. It contains the Coq development and the appendix for the paper.</p>

},
keywords = {compilers, Coq, Iris, multi-language semantics, non-determinism, separation logic, verification}
}

@software{10.5281/zenodo.7308911,
author = {Popescu, Andrei and Traytel, Dmitriy},
title = {POPL'23 artifact for "Admissible Types-To-PERs Relativization in Higher-Order Logic"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7308911},
abstract = {
    <p>The artifact contains the tool support we developed to experiment with relativization in Isabelle/HOL.</p>

},
keywords = {higher-order logic (HOL), interactive theorem proving, Isabelle/HOL, partial equivalence relation, proof theory, relativization, type definition}
}

@software{10.5281/zenodo.7310633,
author = {Pitts, Andrew M.},
title = {Agda code accompanying the paper "Locally Nameless Sets"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7310633},
abstract = {
    <p>The zip archive locns-agda.zip contains code for Agda (version 2.6.2.2) that was used to develop the theory of locally nameless sets and to check some of the proofs in the paper: Andrew M. Pitts. 2023. Locally Nameless Sets. Proc. ACM Program. Lang. 7, POPL, Article 17 (January 2023), 27 pages. https://doi.org/10.1145/3571210. The code mainly targets proofs that involve equational reasoning combined with the use of atoms and indices that are sufficiently fresh (via cofinite quantification). Some of these proofs involve a lot of nested case analysis on elements of sets with decidable equality (atoms and indices); some of the equational axioms are unfamiliar-looking and combinatorially complicated; and it is easy to forget to check necessary freshness conditions are satisfied when doing informal proofs. For all these reasons the use of an interactive theorem prover to produce machine-checked proofs was essential to gain assurance that the results in the paper are correct. The Agda code is stand-alone: the root is the file Everything.agda (for browsable code start at html/Everything.html). Some standard definitions (that might otherwise be called from the Agda Standard Library) are collected in the file Prelude.agda. The last part of the development requires function extensionality, which we postulate in the file FunExt.agda.</p>

},
keywords = {Agda, category theory, cofinite quantification, initial algebra, locally nameless, metatheory of syntax, name binding}
}

@software{10.5281/zenodo.7315899,
author = {Bach Poulsen, Casper and van der Rest, Cas},
title = {Hefty Algebras -- the Artifact},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7315899},
abstract = {
    <p>This artifact contains the code accompanying the POPL 2023 paper Hefty Algebras: Modular Elaboration of Higher-Order Algebraic Effects.</p>

},
keywords = {Agda, Algebraic Effects, Dependent Types, Modularity, Reuse}
}

@software{10.5281/zenodo.7320806,
author = {Lee, Woosuk and Cho, Hangyeol},
title = {Artifacts for "Inductive Synthesis of Structurally Recursive Functional Programs from Non-recursive Expressions"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7320806},
abstract = {
    <p>This artifact includes all things necessary􏰛 for reproducing experimental results in the paper “Inductive Synthesis of Structurally Recursive Functional Programs from Non-recursive Expressions”. The source code for Trio, which is the tool presented in the paper, and the other baseline synthesizers (Burst and Smyth), and the scripts for running the experiments are contained.</p>

},
keywords = {Program synthesis, Programming-by-example, Recursive functional programs, Version space}
}

@software{10.5281/zenodo.7321183,
author = {Kincaid, Zachary and Koh, Nicolas and Zhu, Shaowei},
title = {Artifact for the article "When Less is More: Consequence Finding in a Weak Theory of Arithmetic"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7321183},
abstract = {
    <p>This is the artifact for the POPL 2023 paper, When Less is More: Consequence Finding in a Weak Theory of Arithmetic. The artifact is an OVA virtual machine that can be opened through VirtualBox. The artifact contains all necessary software and dependencies to reproduce the experimental results in Section 6 of the paper. The accompanying README file contains detailed instructions to reproduce the results and how to run the tool on new tasks.</p>

},
keywords = {computational commutative algebra, Groebner basis, invariants, monotone, non-linear invariant generation, predictable, program analysis, theory of arithmetics}
}

@software{10.5281/zenodo.7332066,
author = {Pujet, Lo\"{\i}c and Tabareau, Nicolas},
title = {CoqHott/logrel-mltt: POPL23 version},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7332066},
abstract = {
    <p>A Logical Relation for Impredicative Observational Equality in Agda.</p>
<p>This is a formalized proof of the decidability of conversion for an extension of the calculus of inductive constructions (CIC) with an equality satisfying UIP, function extensionality, and propositional extensionality.</p>

},
keywords = {Agda, Impredicativity, Logical Relation, Proof Irrelevance, Type Theory}
}

@software{10.5281/zenodo.7382711,
author = {Voichick, Finn and Li, Liyi and Rand, Robert and Hicks, Michael},
title = {Qunity: A Unified Language for Quantum and Classical Computing (Type Checker)},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7382711},
abstract = {
    <p>This code repository is designed to accompany the paper “Qunity: A Unified Language for Quantum and Classical Computing.” You can run the “make” command to compile our proofs. See the README.md file for more details.</p>

},
keywords = {programming languages, quantum computing, type checking}
}

@software{10.5281/zenodo.7409103,
author = {Rioux, Nick and Huang, Xuejing and Oliveira, Bruno C. d. S. and Zdancewic, Steve},
title = {A Bowtie for a Beast: Overloading, Eta Expansion, and Extensible Data Types in F⋈ (Artifact)},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7409103},
abstract = {
    <p>Our companion paper presents F⋈, a core language that demonstrates how unions, intersections, and overloading can all coexist with a tame merge operator. Merging values from overlapping types may be ambiguous, so disjointness relations have been introduced to rule out undesired nondeterminism and obtain a well-behaved semantics. Our design principle states that any two types can support either the deterministic merging of their values, or the ability to distinguish their values, but never both. To realize this invariant, We decompose previously studied notions of disjointness into two new, dual relations that permit the operation that best suits each pair of types. This artifact contains Coq code that formalizes certain type-level parts of the semantics of F⋈, including subtyping, dispatch, and some key properties of the two disjointness relations.</p>

},
keywords = {Coq, intersection types, subtyping, union types}
}

@software{10.5281/zenodo.7472859,
author = {Xu, Han and Huang, Xuejing and Oliveira, Bruno C. d. S.},
title = {Coq Formalization for "Making a Type Difference: Subtraction on Intersection Types as Generalized Record Operations"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7472859},
abstract = {
    <p>Coq formalization that contains the definitions and proves the claims in the paper. We provide the source code and a virtual machine image with all the dependencies installed. The appendix of the paper is also included.</p>

},
keywords = {Coq, functional programming, object-oriented programming, type systems}
}

@software{10.5281/zenodo.7491759,
author = {Lu, Sirui and Bod\'{\i}k, Rastislav},
title = {Reproduction Package for Article "Grisette: Symbolic Compilation as a Functional Programming Library"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7491759},
abstract = {
    <p>The artifact contains the Grisette library, a modified leanette POPL’22 artifact, and the reimplementation of some leanette benchmarks in Grisette.</p>

},
keywords = {State Merging, Symbolic Compilation}
}

@software{10.5281/zenodo.7492757,
author = {Fu, Peng and Kishida, Kohei and Ross, Neil J. and Selinger, Peter},
title = {An implementation for the paper "Proto-Quipper with Dynamic Lifting"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7492757},
abstract = {
    <p>It contains source code of an interpreter for Proto-Quipper-Dyn.</p>

},
keywords = {Proto-Quipper-Dyn, Quantum programming language}
}

@software{10.5281/zenodo.7493157,
author = {Song, Youngju and Cho, Minki and Lee, Dongjae and Hur, Chung-Kil and Sammler, Michael and Dreyer, Derek},
title = {Artifact Package for "Conditional Contextual Refinement"},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7493157},
abstract = {
    <p>This is the artifact for the paper “Conditional Contextual Refinement”. Please refer to the included “README.md” for more detailed instructions.</p>

},
keywords = {abstraction, CompCert, compiler verification, compositionality, Coq, interactive theorem proving, Iris, layered abstraction, modular reasoning principles, program logic, program verification, refinement, separation logic, specification}
}

@software{10.5281/zenodo.7495380,
author = {Zhou, Litao and Zhou, Yaoda and Oliveira, Bruno C. d. S.},
title = {Recursive Subtyping for All (Artifact)},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7495380},
abstract = {
    <p>This artifact contains the formalization of the <span class="math inline"><em>F</em><sub>≤</sub><sup><em>μ</em></sup></span> calculus (and its extension <span class="math inline"><em>F</em><sub> ≤ ≥</sub><sup><em>μ</em></sup></span>), together with its soundness, decidability, and conservativity proof in the Coq proof assistant. All definitions, lemmas and theorems with their proofs presented in the paper “Recursive Subtyping for All” can be found in the Coq.zip file. We show the correspondence between the paper and the proofs in the README file. The proof in Coq.zip can be built with Coq 8.13.1.</p>

},
keywords = {Bounded Polymorphism, Iso-Recursive Subtyping, Object Encodings}
}

@software{10.5281/zenodo.7188801,
author = {Chen, Zilin and Rizkallah, Christine and O'Connor, Liam and Susarla, Partha and Klein, Gerwin and Heiser, Gernot and Keller, Gabriele},
title = {Property-Based Testing: Climbing the Stairway to Verification (Artefact)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7188801},
abstract = {
    <p>In the artefact, we provide the source code of the Cogent compiler that has been extended with the property-based testing infrastructure, and the source code of the examples studied in the paper.</p>

},
keywords = {formal verification, functional programming, QuickCheck, systems programming}
}

@software{10.5281/zenodo.7211893,
author = {van der Storm, Tijs and Hermans, Felienne},
title = {Gradual Grammars: Syntax in Levels and Locales (artifact)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7211893},
abstract = {
    <p>The artifact contains the source code of the Fabric gradual grammar formalism, including its compiler to LARK. Additionally, it demonstrates the embedding of Fabric in the Rascal metaprogramming language. Both approaches are evaluated with case-studies. Finally, the artifact contains the scripts to reproduce the benchmark result about the performance overhead of <code>unravel</code>.</p>

},
keywords = {gradual languages, grammars, internationalization, modularity, parsing}
}

@software{10.5281/zenodo.7259115,
author = {Risberg Alak\"{u}la, Anton and Hedin, G\"{o}rel and Fors, Niklas and Pop, Adrian},
title = {Property Probe Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7259115},
abstract = {
    <p>Artifact and Docker images for the paper “Property Probes: Source Code Based Exploration of Program Analysis Results”, to appear in ACM SLE 2022.</p>
<p>Main instructions on how to evaluate this artifact can be found in the README.pdf inside the Artifact.zip file.</p>
<p>There are two prebuilt Docker images available, each with a different target Docker architecture. Make sure to download the one that matches your local architecture to get best performance while evaluating the artifact.</p>
<p>Version 1.1.0 of this artifact contains some updates to the README inside Artifact.zip.</p>

},
keywords = {programming language tools}
}

@software{10.5281/zenodo.7342082,
author = {Turcotte, Alexi and Donat-Bouillud, Pierre and K\v{r}ikava, Filip and Vitek, Jan},
title = {Artifact for signatr: A Data-Driven Fuzzing Tool for R},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7342082},
abstract = {
    <p>The artifact contains the signatr tool, and the pipelines to create an R value database and to fuzz R functions with the database to find type signatures. The pipeline to create a value database is in pipeline-dbgen. The fuzzing pipeline will generate the inputs for the sle.Rmd R markdown notebook. That notebook can then be rendered to get all the results (tables, figures) we use in the paper.</p>

},
keywords = {dynamic program analysis, dynamic programming languages, fuzzing, R}
}

@software{10.1145/3554336,
author = {Steinh\"{o}fel, Dominic and Zeller, Andreas},
title = {Replication Package for "Input Invariants"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3554336},
abstract = {
    <p>This artifact describes how to</p>
<ul>
<li><em>obtain</em> the ISLa and ISLearn tools for the paper “Input Invariants” (ESEC/FSE’22),</li>
<li><em>reproduce</em> the results reported in the paper, and</li>
<li><em>apply</em> the tools to your examples.</li>
</ul>
<p>We describe these aspects separately for the ISLa and ISLearn systems. Both tools are referred to with URLs and bundled in the artifact file.</p>

},
keywords = {constraint mining, fuzzing, grammars, specification language}
}

@software{10.5281/zenodo.6906415,
author = {Park, Jihyeok and An, Seungmin and Ryu, Sukyoung},
title = {JSAVER: JavaScript Static Analyzer via ECMAScript Representation},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6906415},
abstract = {
    <p>JSAVER is a JavaScript Static Analyzer via ECMAScript Representation. It is the first tool that automatically derives JavaScript static analyzers from language specifications using an interpreter-based approach called meta-level static analysis instead of a traditional compiler-based approach.</p>
<p>This artifact extends JISET to extract JavaScript definitional interpreters written in Intermediate Representations for ECMAScript Specifications (IRES) from diverse versions of ECMA-262.</p>

},
keywords = {definitional interpreter, JavaScript, meta-level static analysis}
}

@software{10.5281/zenodo.6941292,
author = {Martin-Lopez, Alberto and Segura, Sergio and Ruiz-Cort\'{e}s, Antonio},
title = {[Supplementary material] Online Testing of RESTful APIs: Promises and Challenges},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6941292},
abstract = {
    <p>This is the artifact for the paper entitled “Online Testing of RESTful APIs: Promises and Challenges”. This artifact comprises two main resources: 1) a ready-to-use testing ecosystem consisting of a multi-bot architecture for online testing of RESTful APIs; and 2) the dataset of test cases generated in our experiments. In addition, we provide instructions on how to use the testing ecosystem, how to replicate the results reported in the paper, and how our work could serve as the basis for multiple future research opportunities in varied scenarios.</p>

},
keywords = {black-box testing, bot, online testing, REST, web API}
}

@software{10.5281/zenodo.6975558,
author = {Dyer, Robert and Chauhan, Jigyasa},
title = {Replication package for "An Exploratory Study on the Predominant Programming Paradigms in Python Code"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6975558},
abstract = {
    <p>This dataset includes scripts and data files used to generate all analysis and results from the paper. A README.md file is included for details on using the scripts - though all of the data the scripts generate should already be cached and none of the scripts actually need run.</p>
<p>It also includes a spreadsheet containing the human judgements from Table 4 of the paper.</p>
<p>Always current source for the scripts is available on GitHub: https://github.com/psybers/python-paradigms</p>

},
keywords = {empirical study, programming paradigms, Python}
}

@software{10.5281/zenodo.6977413,
author = {Song, Yang and Mahmud, Junayed and Zhou, Ying and Chaparro, Oscar and Moran, Kevin and Marcus, Andrian and Poshyvanyk, Denys},
title = {A Replication Package for "Toward Interactive Bug Reporting for (Android App) End-Users"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6977413},
abstract = {
    <p>This is the replication package for our ESEC/ FSE’22 paper: “Toward Interactive Bug Reporting for (Android App) End-Users”. The package provides data, source code, and documentation that aims to enable verification/validation of our work and future research on the topic of bug reporting systems.</p>

},
keywords = {Android Apps, Bug Reporting, Task-Oriented Chatbots}
}

@software{10.5281/zenodo.7036047,
author = {Kim, Seulbae and Kim, Taesoo},
title = {Artifact of "RoboFuzz: Fuzzing Robotic Systems over Robot Operating System (ROS) for Finding Correctness Bugs"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7036047},
abstract = {
    <p>RoboFuzz is a fuzzing framework for testing Robot Operating System 2 (ROS 2), and robotic systems that are built using ROS 2. Any developer-defined prop- erties relating to the correctness of the robotic system under test, e.g., conformance to specification, can be tested using RoboFuzz.</p>
<p>The artifact (i.e., a docker image and a repository) contains the following: 1. Source code of RoboFuzz 2. Pre-compiled target sytstems and their code 3. Utilities for running experiments 4. Instructions on installing and executing RoboFuzz 5. Description of detected bugs and the links to the original bug reports</p>
<p>The six targets we tested with RoboFuzz are: * Two from the internal layers of ROS2 foxy: 1. Type system (ROSIDL) 2. ROS Client Library APIs (rclpy and rclcpp) * Four ROS-based robotic systems and libraries: 3. Turtlesim (apt package: ros-foxy-turtlesim) 4. Move It 2 + PANDA manipualtor 5. Turtlebot3 Burger (version foxy) 6. PX4 quadcopter (firmware v1.12 + fmu-v5)</p>
<p>Running RoboFuzz with the in-house oracles we built for each target, we discovered 30 new correctness bugs. We reported all bugs and 25 are acknowledged and 6 have been fixed so far.</p>

},
keywords = {Correctness bugs, Robot Operating System 2 (ROS 2), Semantic feedback-driven fuzzing}
}

@software{10.5281/zenodo.7036747,
author = {Luo, Chuan and Zhao, Qiyuan and Cai, Shaowei and Zhang, Hongyu and Hu, Chunming},
title = {Artifact for ESEC/FSE 2022 Article `SamplingCA: Effective and Efficient Sampling-based Pairwise Testing for Highly Configurable Software Systems'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7036747},
abstract = {
    <p>Combinatorial interaction testing (CIT) is a popular testing methodology for testing interactions of options of highly configurable systems. In the context of CIT, covering arrays are the test suites that can cover all such interactions, possibly under certain constraints. Particularly, pairwise covering arrays (PCAs) are widely employed, since they can achieve a good balance between testing costs and fault detection capability.</p>
<p>SamplingCA is a state-of-the-art algorithm for generating small-sized PCAs efficiently. In our implementation of SamplingCA, the input is a system under test (SUT) modeled as a Boolean formula in CNF. It outputs a PCA of the given SUT, where each line represents a valid configuration.</p>

},
keywords = {Covering Array, Pairwise Testing, Sampling, Satisfiability}
}

@software{10.5281/zenodo.7060209,
author = {Cao, Junming and Chen, Bihuan and Sun, Chao and Hu, Longjie and Wu, Shuaihong and Peng, Xin},
title = {Reproduction Package for Article "Understanding Performance Problems in Deep Learning Systems"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7060209},
abstract = {
    <p>In this document, we provide a detailed experiment reproduction of the paper. Each case has an independent directory, in which the Readme.md file that describes the environment required to run, the root cause of the bug, and how to reproduce the bug. It also provides a comparison of the running results of the two versions of the code on our machine. These results can show that the repaired code has better performance. DeepPerf is a rule-based static code checker capable of detecting Performance bugs in DL systems. Also, we provide code to test this tool.</p>

},
keywords = {Deep Learning, Deep Learning Bugs, Performance Problems}
}

@software{10.5281/zenodo.7080271,
author = {Fu, Michael and Tantithamthavorn, Chakkrit and Le, Trung and Nguyen, Van and Phung, Dinh},
title = {Reproduction Package for VulRepair: A T5-Based Automated Software Vulnerability Repair},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7080271},
abstract = {
    <p>The replication package of the VulRepair paper supports future research to reproduce the experiment results in the paper.</p>

},
keywords = {Automated Vulnerability Repair, Software Vulnerability Repair}
}

@software{10.5281/zenodo.7080369,
author = {Qin, Qi and JiYang, JulianAndres and Song, Fu and Chen, Taolue and Xing, Xinyu},
title = {DeJITLeak Tool Proposed in Article "DeJITLeak: Eliminating JIT-Induced Timing Side-Channel Leaks"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7080369},
abstract = {
    <p>This artifact contains the two main components of the DeJITLeak tool, the Joana-based type inference tool and the patched JVM for fine-grained JIT control. It also includes the dataset and evaluation results and all the scripts used in the evaluation.</p>

},
keywords = {detection, formal semantics, JIT compilation, mitigation, timing side-channel, type inference}
}

@software{10.5281/zenodo.7082252,
author = {Di Grazia, Luca and Pradel, Michael},
title = {Reproduction Package for Article 'The Evolution of Type Annotations in Python: An Empirical Study'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7082252},
abstract = {
    <p>The artifact contains script and data to reproduce all the results of the paper. Moreover, there are instructions to use the source code with a different dataset. The file README.md contains all the information to run the artifact.</p>

},
keywords = {artifact, empirical study, Python, Type annotations, type errors}
}

@software{10.5281/zenodo.7082407,
author = {Winter, Stefan and Timperley, Christopher S. and Hermann, Ben and Cito, J\"{u}rgen and Bell, Jonathan and Hilton, Michael and Beyer, Dirk},
title = {Reproduction Package (Docker container) for the FSE 2022 Article `A Retrospective Study of one Decade of Artifact Evaluations`},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7082407},
abstract = {
    <p>This is the artifact accompanying our study of artifact evaluations at SE/PL conferences and their effects, accepted for presentation at the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE) 2022. For ease of artifact evaluation and usage, we ship our artifact as a Docker container, which comprises our datasets, the tools we built to collect those datasets, and the scripts used to obtain the results presented in the paper. It also contains the Dockerfile to create the submitted image in order to make the software dependencies for our artifact explicit.</p>

},
keywords = {Artifact Evaluation, Reproducibility, Research Artifacts, Software Engineering}
}

@software{10.5281/zenodo.7088613,
author = {Tomy, Chris and Wang, Tingmao and Barr, Earl T. and Mechtaev, Sergey},
title = {Reproduction package for the article "Modus: A Datalog Dialect for Building Container Images"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7088613},
abstract = {
    <p>This software is an artifact used to reproduce the results of our paper. Below is the abstract of our paper.</p>
<p>Containers help share and deploy software by packaging it with all its dependencies. Tools, like Docker or Kubernetes, spawn containers from images as specified by a build system’s language, such as Dockerfile. A build system takes many parameters to build an image, including OS and application versions. These build parameters can interact: setting one can restrict another. Dockerfile lacks support for reifying and constraining these interactions, thus forcing developers to write a build script per workflow. As a result, developers have resorted to creating ad hoc solutions such as templates or domain-specific frameworks that harm performance and complicate maintenance because they are verbose and mix languages.</p>
<p>To address this problem, we introduce Modus, a Datalog dialect for building container images. Modus’ key insight is that container definitions naturally map to proof trees of Horn clauses. In these trees, container configurations correspond to logical facts, build instructions correspond to logic rules, and the build tree is computed as the minimal proof of the Datalog query specifying the target image. Modus relies on Datalog’s expressivity to specify complex workflows with concision and facilitate automatic parallelisation.</p>

},
keywords = {Build system, Containers, Datalog}
}

@software{10.5281/zenodo.7110095,
author = {Bittner, Paul Maximilian and Tinnes, Christof and Schulthei\ss{}, Alexander and Viegener, S\"{o}ren and Kehrer, Timo and Th\"{u}m, Thomas},
title = {Appendix and Replication Package for Article: Classifying Edits to Variability in Source Code},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7110095},
abstract = {
    <p>This replication package consists of four parts:</p>
<ol type="1">
<li><strong>DiffDetective</strong>: For our validation, we built <em>DiffDetective</em>, a java library and command-line tool to classify edits to variability in git histories of preprocessor-based software product lines.</li>
<li><strong>Appendix</strong>: The appendix of our paper is given in PDF format in the file <a href="https://github.com/VariantSync/DiffDetective/raw/esecfse22/appendix.pdf">appendix.pdf</a>.</li>
<li><strong>Haskell Formalization</strong>: We provide an extended formalization in the Haskell programming language as described in our appendix. Its implementation can be found in the Haskell project in the proofs directory.</li>
<li><strong>Dataset Overview</strong>: We provide an overview of the 44 inspected datasets with updated links to their repositories in the file <a href="https://github.com/VariantSync/DiffDetective/blob/esecfse22/docs/datasets.md">docs/datasets.md</a>.</li>
</ol>

},
keywords = {feature traceability, mining version histories, software evolution, software product lines, software variability}
}

@software{10.6084/m9.figshare.16528521.v1,
author = {Li, Wen and Li, Li and Cai, Haipeng},
title = {Reproduction Package for Article "On the Vulnerability Proneness of Multilingual Code"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.16528521.v1},
abstract = {
    <p>The artifact contains the tool–PolyFax and dataset for the paper “On the Vulnerability Proneness of Multilingual Code”. PolyFax can be applied for repository grabbing on GitHub, vulnerability-fixing commit classification and language interfacing mechanism identification.</p>

},
keywords = {language interface, multi-language, program analysis, vulnerability proneness}
}

@software{10.6084/m9.figshare.20448573.v1,
author = {Oh, Wonseok and Oh, Hakjoo},
title = {A Replication Package for PyTER: Python TypeError Repair by Type-Aware Generation},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.20448573.v1},
abstract = {
    <p>It can reproduce the result of PyTER’s main table using Docker container provided. In Docker container, our PyTER system and TypeBugs benchmark are provided. Moreover, the guide to run arbitrary test cases is also served. The detailed information is written on README in our artifact.</p>

},
keywords = {Debugging, Program Analysis, Program Repair}
}

@software{10.6084/m9.figshare.20748235.v1,
author = {Fregnan, Enrico and Braz, Larissa and D'Ambros, Marco and \c{C}al\i{}kl\i{}, G\"{u}l and Bacchelli, Alberto},
title = {Artefact Package - First come first served: the impact of file position on code review},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.20748235.v1},
abstract = {
    <p>Artifacts Package of the accepted FSE 22 paper: “First come first served: the impact of file position on code review”.</p>
<p>The “pr_data.zip” file contains the Json data of the mined Pull Requests. Given its size, we separated it from the rest of the replication package (contained in the fse22-fregnan.zip file).</p>
<p>Our artifact package contains the following material:</p>
<ul>
<li>Mining script. The script used to mine PRs from online repositories. The script is available in the folder ‘data-retrieval’.</li>
<li>Pull Requests dataset. The dataset of 219,476 PRs from 138 java-based open-source projects considered in our investigation. Repeating the mining process might lead to different results if, for instance, the projects have been updated. The dataset is contained in the pr_data.zip archive.</li>
<li>PRs analysis scripts. The Java script used to extract the metrics considered in our analysis from the PRs dataset (contained in the ‘metrics’ folder) and the R script used for the analysis of the result (in the ‘PR_analysis_script’ folder).</li>
<li>Experiment tool. The tool used for the online experiment. We extended CRExperiment, a publicly available tool to perform code review experiments. The tool is available in the folder ‘tool’. The subfolder ‘resources’ contains the object code snippets used in the experiment.</li>
<li>Experiment results and analysis script. The results from the valid participants are in the ‘validParticipantsPublic.csv’ file. Among the original 106 valid participants, four did not give their consent for their data to be shared publicly. For this reason, the provided dataset only contains the results of 102 participants. This leads to slightly different results than the ones in the paper but our findings are preserved.</li>
<li>The ‘results_analysis.R’ script contains the code used to analyze the collected experiment data.</li>
<li>Ethics authorization. The experiment approval by the Human Subjects Committee of the University of Zurich, Switzerland.</li>
</ul>
<p>See README.md for more information.</p>

},
keywords = {Code review, Empirical Software Engineering, Pull requests}
}

@software{10.1145/3554330,
author = {Ghica, Dan and Lindley, Sam and Bravo, Marcos Maro\~{n}as and Pir\'{o}g, Maciej},
title = {Cpp-effects: High-level effect handlers in C++},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3554330},
abstract = {
    <p>Effect handlers allow for programming with user-defined computational effects, with applications including custom lightweight concurrency (threads, async-await, actors, generators), error handling, dependency injection, etc. Effect handlers originate from the realm of functional programming, and the main goal of this experimental library is to explore how they fit in the more object-oriented setting of C++.</p>

},
keywords = {algebraic effects, control structures, Effect handlers, lightweight concurrency}
}

@software{10.5281/zenodo.6818171,
author = {Ritter, Fabian and Hack, Sebastian},
title = {AnICA: Analyzing Inconsistencies in Microarchitectural Code Analyzers (Artifact)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6818171},
abstract = {
    <p>This artifact consists of a Vagrant virtual machine providing a functional version of our software development with extensive documentation, the AnICA campaigns produced in our evaluation, as well as (where permitted by licenses) installed versions of the throughput predictors used in our evaluation. Its purpose is to demonstrate our approach (with the provided throughput predictors and the possibility to integrate new ones), to show AnICA’s results in more detail than possible in the paper, and to allow researchers to build upon our work.</p>

},
keywords = {Abstraction, Basic Blocks, Differential Testing, Throughput Prediction}
}

@software{10.5281/zenodo.6819031,
author = {Yuan, Charles and Carbin, Michael},
title = {Tower: Data Structures in Quantum Superposition},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6819031},
abstract = {
    <p>The artifact contains: README.md, a description document tower.tgz, a Docker image containing source code, pre-built binaries, and tests tower.dockerfile, a Dockerfile that generates the above image from scratch The directory oopsla22-artifact, a copy of the contents of the Docker image, containing the source code of the Tower language interpreter (src/) and the tests (tests/)</p>

},
keywords = {data structures, history independence, quantum programming, quantum random-access memory, reversible programming}
}

@software{10.5281/zenodo.6826341,
author = {Moiseenko, Evgenii and Kokologiannakis, Michalis and Vafeiadis, Viktor},
title = {Replication Package for "Model Checking for a Multi-Execution Memory Model},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6826341},
abstract = {
    <p>The artifact contains WMC, as well as the other tools and benchmarks used in the paper.</p>

},
keywords = {software verification, stateless model checking, weak memory models}
}

@software{10.5281/zenodo.7055010,
author = {Nieto, Abel and Gondelman, L\'{e}on and Reynaud, Alban and Timany, Amin and Birkedal, Lars},
title = {Modular Verification of Op-Based CRDTs in Separation Logic (Proof Artifact)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7055010},
abstract = {
    <p>Coq implementation of the libraries described in the paper, as well mechanized safety proofs.</p>

},
keywords = {causal broadcast, Coq, CRDT, distributed systems, Iris, separation logic, verification}
}

@software{10.5281/zenodo.7055030,
author = {Moosbrugger, Marcel and Stankovi\v{c}, Miroslav and Bartocci, Ezio and Kov\'{a}cs, Laura},
title = {This is the Moment for Probabilistic Loops - Artifact (Polar)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7055030},
abstract = {
    <p>The artifact contains the tool “Polar” together with scripts to reproduce all the scientific claims from the corresponding paper “This Is the Moment for Probabilistic Loops” published at OOPSLA 2022.</p>
<p>The artifact consists of a single ZIP-file. The ZIP-file comes with a Docker image and a README-file containing all information necessary to reproduce the results from the corresponding paper.</p>
<p>The tool “Polar” - central to the artifact and the paper - is a program analysis tool capable of exactly computing higher moments of program variables for a class of probabilistic loops.</p>

},
keywords = {Distribution
Recovery, Higher Moments, Linear Recurrences, Loops, Probabilistic Programs}
}

@software{10.5281/zenodo.7058421,
author = {Chen, Adam and Fathololumi, Parisa and Koskinen, Eric and Pincus, Jared},
title = {Veracity: Declarative Multicore Programming with Commutativity},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7058421},
abstract = {
    <p>Veracity is a c-like language that features the commute statement, which can describe conditional commutativity of sequential code. When such code’s commutativity condition is satisfied, and proper (scoped) serializability constraints are met, it may be run in parallel, benefiting from multi-core architecture.</p>
<p>Veracity is provided as an interpreter that is implemented in Multicore OCaml. The artifact contains a version of the interpreter, provided with Servois2 to drive the commutativity analysis. The benchmark suite used in the paper is provided, as well as the programs/scripts used to generate the benchmarks seen in the paper.</p>
<p>The extended technical report can be found of Arxiv and is linked at http://www.veracity-lang.org/.</p>

},
keywords = {commutativity analysis, commutativity conditions, parallelization, pre-condition synthesis, serializability}
}

@software{10.5281/zenodo.7062933,
author = {Xie, Ningning and Cong, Youyou and Ikemori, Kazuki and Leijen, Daan},
title = {OOPSLA'22 Paper Artifact: First Class Names for Effect Handlers},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7062933},
abstract = {
    <p>The artifact is a docker image that contains a Koka implementation of named handlers as well as examples in the paper. Also available at: https://hub.docker.com/repository/docker/daanx/oopsla22-namedh</p>

},
keywords = {Algebraic Effect Handlers, Koka, Named Handlers}
}

@software{10.5281/zenodo.7065424,
author = {Sun, Yaozhu and Dhandhania, Utkarsh and Oliveira, Bruno C. d. S.},
title = {Compositional Embeddings of Domain-Specific Languages (Artifact)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7065424},
abstract = {
    <p>This is the artifact of the OOPSLA’22 paper Compositional Embeddings of Domain-Specific Languages. The artifact contains an in-browser interpreter of the CP language with support for the ExT DSL. The code examples and applications mentioned in the paper are also included.</p>

},
keywords = {Domain-Specific Languages, Interpreter}
}

@software{10.5281/zenodo.7066264,
author = {Muduli, Sujit Kumar and Roy, Subhajit},
title = {Satisfiability Modulo Fuzzing: A Synergistic Combination of SMT Solving and Fuzzing (Artifact)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7066264},
abstract = {
    <p>This repository contains the artifact for the paper “Satisfiability Modulo Fuzzing: A Synergistic Combination of SMT Solving and Fuzzing” accepted at the OOPSLA’22 conference.</p>
<p>The docker image saadhak-image.tar.gz has the source code and executable of our tool Sundefineddhak installed. A manual README.pdf provides step-by-step instructions on how to evaluate our tool on the benchmarks. The license file LICENSE.txt provides permission to copy, modify and re-distribute Sundefineddhak.</p>

},
keywords = {Closed-Box Functions, Fuzzing, Program Verification, SMT Solver, Testing Conflict-Driven Fuzz Loop}
}

@software{10.5281/zenodo.7066401,
author = {Lei, Yuxiang and Sui, Yulei and Ding, Shuo and Zhang, Qirun},
title = {Artifact of "Taming Transitive Redundancy for Context-Free Reachability"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7066401},
abstract = {
    <p>This is the artifact of the paper “Taming Transitive Redundancy for Context-Free Reachability” accepted to OOPSLA 2022. The artifact is packaged as a Docker image “pocr-release.tar.gz”, which is to reproduce the experiment results of the paper. Please see README.pdf for detailed usage of the artifact.</p>

},
keywords = {CFL-reachability, performance, redundancy, transitive relation}
}

@software{10.5281/zenodo.7068972,
author = {Li, Liyi and Voichick, Finn and Hietala, Kesha and Peng, Yuxiang and Wu, Xiaodi and Hicks, Michael},
title = {Reproduction Package for "Verified Compilation of Quantum Oracles"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7068972},
abstract = {
    <p>This repository contains the code used in our paper “Verified Compilation of Quantum Oracles.” This includes OQASM, PQASM, and OQIMP. It includes programs implemented in these languages, Coq proofs, and QuickChick tests.</p>

},
keywords = {Compiler Verification, Programming Language Design, Quantum Oracle, Type System}
}

@software{10.5281/zenodo.7071281,
author = {Chaliasos, Stefanos and Gervais, Arthur and Livshits, Benjamin},
title = {Artifact: A Study of Inline Assembly in Solidity Smart Contracts},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7071281},
abstract = {
    <p>This is the artifact for the OOPSLA’22 paper “A Study of Inline Assembly in Solidity Smart Contracts”. You can also find the latest version of this artifact at https://github.com/StefanosChaliasos/solidity-inline-assembly.</p>

},
keywords = {Blockchain, Corpus Study, Ethereum, Inline Assembly, Solidity, YUL}
}

@software{10.5281/zenodo.7072457,
author = {Dardinier, Thibault and M\"{u}ller, Peter and Summers, Alexander J.},
title = {Fractional Resources in Unbounded Separation Logic (artifact)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7072457},
abstract = {
    <p>This artifact contains an Isabelle/HOL (version 2021-1) formalisation that proves the technical claims of the paper “Fractional Resources in Unbounded Separation Logic”.</p>

},
keywords = {(co)inductive predicates, automatic deductive verifiers, combinability, fractional permissions, Isabelle, magic
wands, separation logic}
}

@software{10.5281/zenodo.7074690,
author = {van der Rest, Cas and Poulsen, Casper Bach and Rouvoet, Arjen and Visser, Eelco and Mosses, Peter},
title = {Intrinsically-Typed Definitional Interpreters \`{a} la Carte (artifact)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7074690},
abstract = {
    <p>Formalization of the code shown/discussed in the paper + the case study discussed in Section 5.</p>

},
keywords = {Definitional Interpreters, Dependently Typed Programming, Modularity, Reuse, Type Safety}
}

@software{10.5281/zenodo.7079022,
author = {Zhu, Fengmin and Sammler, Michael and Lepigre, Rodolphe and Dreyer, Derek and Garg, Deepak},
title = {Artifact of "BFF: Foundational and Automated Verification of Bitfield-Manipulating Programs"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7079022},
abstract = {
    <p>This is the artifact for the OOPSLA’22 paper “BFF: Foundational and Automated Verification of Bitfield-Manipulating Programs”.</p>
<p>After unzipping the archive <code>bff_artifact.zip</code>, the <code>README.md</code> provides instructions on how to use this artifact.</p>

},
keywords = {bit vectors, bitfield manipulation, C programming language, Coq, Iris, proof automation, refinement types}
}

@software{10.5281/zenodo.7079463,
author = {Boruch-Gruszecki, Aleksander and Wa\'{s}ko, Rados\l{}aw and Xu, Yichen and Parreaux, Lionel},
title = {Mechanized proof of «A case for DOT: Theoretical Foundations for Objects With Pattern Matching and GADT-style Reasoning»},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7079463},
abstract = {
    <p>This artifact contains: - mechanized proofs of soundness for cDOT and our variant of λ2,Gµ - mechanized proofs of lemmas related to our translation from λ2,Gµ to cDOT</p>

},
keywords = {classes, Coq, DOT, GADT, pattern matching}
}

@software{10.5281/zenodo.7079830,
author = {Blaudeau, Cl\'{e}ment and Liu, Fengyun},
title = {Coq formalization of the Celsius language},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7079830},
abstract = {
    <p>This artifact contains the Coq project that supports the paper. The calculus is defined, semantics and typing rules are given. It contains all the results presented in the paper.</p>

},
keywords = {annotations, Celsius, Coq, initialization, object, soundness, typing}
}

@software{10.5281/zenodo.7079930,
author = {Abuah, Chik\'{e} and Darais, David and Near, Joseph P.},
title = {Implementation of the Solo Library},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7079930},
abstract = {
    <p>Solo is a Haskell library for static verification of differential privacy. Our paper makes the following claims supported by the artifact:</p>
<ul>
<li>Solo encodes sensitivity and privacy analysis in Haskell’s types</li>
<li>Solo can be used to write and verify useful differentially private programs</li>
<li>Solo does not impose significant annotation burden on the programmer</li>
</ul>

},
keywords = {differential privacy, Haskell, type system, verification}
}

@software{10.5281/zenodo.7079982,
author = {Sela, Gal and Petrank, Erez},
title = {Concurrent Size - Artifact for OOPSLA'22},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7079982},
abstract = {
    <p>Artifact for the paper Concurrent Size published in OOPSLA’22</p>

},
keywords = {Concurrent Size}
}

@software{10.5281/zenodo.7080459,
author = {Meyer, Roland and Wies, Thomas and Wolff, Sebastian},
title = {Artifact for "A Concurrent Program Logic with a Future and History"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7080459},
abstract = {
    <p>Experimental automatic verifier for lock-free data structures, accompanying the OOPSLA’22 paper “A Concurrent Program Logic with a Future and History” by Roland Meyer, Thomas Wies, and Sebastian Wolff. The artifact consists of the verifier’s source code and a virtual machine (VM) to reproduce the experiments from the paper.</p>

},
keywords = {Automated Verification, Linearizability, Lock-free Data Structures, Program Logic, Separation Logic}
}

@software{10.5281/zenodo.7082520,
author = {Atkinson, Eric and Yuan, Charles and Baudart, Guillaume and Mandel, Louis and Carbin, Michael},
title = {Semi-Symbolic Inference for Efficient Streaming Probabilistic Programming},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7082520},
abstract = {
    <p>This is an artifact accompanying the OOPSLA 2022 paper “Semi-Symbolic Inference for Efficient Streaming Probabilistic Programming”. It consists of a tarball containing the following components:</p>
<p>A Docker image that may be used to execute the artifact in the file semi-symbolic-artifact.tgz. We have tested the Docker image in Docker Engine version 20.10.17.</p>
<p>A directory of the source code located at source-code.</p>
<p>A PDF of this guide can be found at guide.pdf.</p>
<p>In both the docker file and the source code directory, the semi-symbolic-impl directory is the main package implementing semi-symbolic inference – with the source in semi-symbolic-impl/src – while semi-symbolic-probzelus contains the ProbZelus bindings.</p>

},
keywords = {probabilistic programming, streaming inference}
}

@software{10.5281/zenodo.7093079,
author = {Titzer, Ben L.},
title = {Artifact for "A Fast In-Place Interpreter for WebAssembly "},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.7093079},
abstract = {
    <p>This archive includes supplementary data and code for the OOPSLA 2022 paper entitled “A Fast In-Place Interpreter for WebAssembly”.</p>
<ul>
<li>source-code snapshots of 3 Web Engines for executing WebAssembly</li>
<li>3 non-Web engines: Wasm3, the WebAssembly Micro-Runtime, and the Wizard Research Engine</li>
<li>binary builds for Linux x86-64</li>
<li>build instructions</li>
<li>PolyBenchC benchmark Wasm binaries</li>
<li>benchmarking setup and scripts</li>
<li>data collected from experiments included in the OOPSLA 2022 paper</li>
<li>instructions for running the benchmarks on Linux systems</li>
</ul>

},
keywords = {interpreters, performance, virtual machines, WebAssembly}
}

@software{10.5281/zenodo.6928465,
author = {Maillard, Kenji and Lennon-Bertrand, Meven and Tabareau, Nicolas and Tanter, \'{E}ric},
title = {A Reasonably Gradual Type Theory – Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6928465},
abstract = {
    <p>Accompanying artifact to the article A Reasonably Gradual Type Theory.</p>
<p>It consists of two parts:</p>
<ul>
<li><p>a Coq formalization of the model described in the article,</p></li>
<li><p>a proof of concept using rewrite rules in Agda to present the source system of the article and the examples of usage of that source system.</p></li>
</ul>
<p>A virtual machine is also available, where all the necessary components needed to immediately check these two parts are installed. The artefact already available in the virtual machine is the one of the first uploaded version (with only minor differences with the post-reviewing one). If one wishes to check the newer version, they should simply upload this newer version into the virtual machine and build it.</p>

},
keywords = {Agda, Coq}
}

@software{10.5281/zenodo.6651953,
author = {Nguyen, Minh and Perera, Roly and Wang, Meng and Wu, Nicolas},
title = {Reproduction Package for Article: Modular Probabilistic Models via Algebraic Effects},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6651953},
abstract = {
    <p>This is the artifact for the probabilistic programming language ProbFX as described in the paper “Modular Probabilistic Models via Algebraic Effects”.</p>
<p>It contains:</p>
<ol type="1">
<li><p>A preprint of the paper “Modular Probabilistic Models via Algebraic Effects”.</p></li>
<li><p>A virtual image prepared with an executable script for running and visualising the example programs shown in the paper (and more).</p></li>
<li><p>The documented source code for the language implementation and example programs.</p></li>
</ol>

},
keywords = {effect handlers, embedded domain-specific languages, functional programming, modularity, probabilistic programming}
}

@software{10.5281/zenodo.6668446,
author = {Koppel, James and Guo, Zheng and de Vries, Edsko and Solar-Lezama, Armando and Polikarpova, Nadia},
title = {Artifact for "Searching Entangled Program Spaces"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6668446},
abstract = {
    <p>This artifact is to reproduce results reported in the paper “Searching Entangled Program Spaces”. It includes a virtual machine in <code>ecta-artifact.tar</code> and the source code in <code>icfp-artifact-source-code.*</code>. Run the virtual machine with the script <code>start.sh</code> and there is a README file inside, which tells you how to run the commands and reproduce our figures.</p>

},
keywords = {synthesis, tree automata}
}

@software{10.5281/zenodo.6671887,
author = {Westrick, Sam and Arora, Jatin and Acar, Umut A.},
title = {Entanglement Detection With Near-Zero Cost: Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6671887},
abstract = {
    <p>This artifact provides code and scripts for reproducing the empirical evaluation in the paper “Entanglement Detection with Near-Zero Cost” at ICFP’22. Running these experiments requires access to a modern multi-core x86_64 machine. The experiments in the paper use up to 72 cores and 110GB RAM, but partial results can be obtained using a smaller machine. In particular, 8 cores and 8 GB RAM is sufficient for a small set of experiments. A full set of experiments requires 110 GB RAM and a decent number of cores (preferably at least 32 cores).</p>

},
keywords = {disentanglement, functional programming, memory management, parallelism}
}

@software{10.5281/zenodo.6672939,
author = {Ho, Son and Protzenko, Jonathan},
title = {Aeneas: Rust Verification by Functional Translation},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6672939},
abstract = {
    <p>We present Aeneas, a new verification toolchain for Rust programs based on a lightweight functional translation. We leverage Rust’s rich region-based type system to eliminate memory reasoning for a large class of Rust programs, as long as they do not rely on interior mutability or unsafe code. Doing so, we relieve the proof engineer of the burden of memory-based reasoning, allowing them to instead focus on functional properties of their code.</p>
<p>The first contribution of Aeneas is a new approach to borrows and controlled aliasing. We propose a pure, functional semantics for LLBC, a Low-Level Borrow Calculus that captures a large subset of Rust programs. Our semantics is value-based, meaning there is no notion of memory, addresses or pointer arithmetic. Our semantics is also ownership-centric, meaning that we enforce soundness of borrows via a semantic criterion based on loans rather than through a syntactic type-based lifetime discipline. We claim that our semantics captures the essence of the borrow mechanism rather than its current implementation in the Rust compiler.</p>
<p>The second contribution of Aeneas is a translation from LLBC to a pure lambda-calculus. This allows the user to reason about the original Rust program through the theorem prover of their choice, and fulfills our promise of enabling lightweight verification of Rust programs. To deal with the well-known technical difficulty of terminating a borrow, we rely on a novel approach, in which we approximate the borrow graph in the presence of function calls. This in turn allows us to perform the translation using a new technical device called backward functions.</p>
<p>We implement our toolchain in a mixture of Rust and OCaml; our chief case study is a low-level, resizing hash table, for which we prove functional correctness, the first such result in Rust. Our evaluation shows significant gains of verification productivity for the programmer. This paper therefore establishes a new point in the design space of Rust verification toolchains, one that aims to verify Rust programs simply, and at scale.</p>
<p>Rust goes to great lengths to enforce static control of aliasing; the proof engineer should not waste any time on memory reasoning when so much already comes “for free”!</p>

},
keywords = {program verification, rust}
}

@software{10.5281/zenodo.6678339,
author = {Li, Yao and Weirich, Stephanie},
title = {Program Adverbs and Tl\"{o}n Embeddings (Artifact)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6678339},
abstract = {
    <p>This artifact contains the Coq formalization of the paper Program Adverbs and Tl\"{o}n Embeddings. It contains a Coq implementation of all the key definitions, theorems and proofs, as well as examples described in the paper.</p>

},
keywords = {Coq, embedding, formal verification, mechanized reasoning, program adverbs}
}

@software{10.5281/zenodo.6684085,
author = {Ullrich, Sebastian and de Moura, Leonardo},
title = {Supplement of "'do' Unchained: Embracing Local Imperativity in a Purely Functional Language"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6684085},
abstract = {
    <p>This supplement consists of a Lean 4 package containing translation rules and example proofs of equivalence as described in the paper. Each extension is declared in a separate <code>.lean</code> file in the <code>Do</code> directory. <code>Do/Formal.lean</code> contains the formalization of the equivalence proof written in a literate style explaining more details not mentioned in the paper. Each Lean file comes with a corresponding <code>.html</code> file rendered using Alectryon that allows for exploring the file including type and goal information in any browser without installing Lean. The directory <code>gh-survey</code> contains simple scripts for aggregating the use of extended <code>do</code> notation from Lean projects on GitHub.</p>

},
keywords = {formal verification, Lean, macros}
}

@software{10.5281/zenodo.6685674,
author = {Ostermann, Klaus and Binder, David and Skupin, Ingo and S\"{u}berkr\"{u}b, Tim and Downen, Paul},
title = {Introduction and Elimination, Left and Right - Coq Formalization},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6685674},
abstract = {
    <p>Coq formalization of the ICFP 2022 paper “Introduction and Elimination, Left and Right”.</p>

},
keywords = {Abstract machines, Duality, Lambda calculus, Linear logic, Natural Deduction, Proof theory, Sequent Calculus, Type theory}
}

@software{10.5281/zenodo.6689803,
author = {Koppel, James and Kearl, Jackson and Solar-Lezama, Armando},
title = {Automatically Deriving Control-Flow Graph Generators from Operational Semantics},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6689803},
abstract = {
    <p>This artifact contains information needed to evaluate all claims in the paper. Specifically, it contains a QEMU image and sources containing Mandate, along with instructions for running. It also features pre-generated control-flow graphs and generators.</p>

},
keywords = {control flow, haskell, program synthesis, term rewriting}
}

@software{10.5281/zenodo.6702804,
author = {Spies, Simon and G\"{a}her, Lennard and Tassarotti, Joseph and Jung, Ralf and Krebbers, Robbert and Birkedal, Lars and Dreyer, Derek},
title = {Coq development for "Later Credits: Resourceful Reasoning for the Later Modality"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6702804},
abstract = {
    <p>This is the artifact for the ICFP’22 paper “Later Credits: Resourceful Reasoning for the Later Modality”. It contains the Coq development mechanizing the results of the paper. The artifact contains the development both in a VM image (QEMU) with pre-built sources and as a .zip source archive. In addition, the technical appendix is included.</p>

},
keywords = {Iris, later modality, Separation logic, step-indexing, transfinite}
}

@software{10.5281/zenodo.6710298,
author = {Vasilenko, Elizaveta and Vazou, Niki and Barthe, Gilles},
title = {Library Implementation for Article "Safe Couplings: Coupled Refinement Types"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6710298},
abstract = {
    <p>This artifact includes an appendix with the soundness proof and source code of safe-coupling library and case studies.</p>

},
keywords = {Haskell, program verification, refinement types, relational types}
}

@software{10.5281/zenodo.6727752,
author = {Ramsey, Norman},
title = {Reproduction Package for Article "Beyond Relooper: Recursive Translation of Unstructured Control Flow to Structured Control Flow"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6727752},
abstract = {
    <p>A development branch of the Glasgow Haskell Compiler extended with a translation from arbitrary control flow to WebAssembly control flow. Includes source code, compiled binary, and test cases. Packaged as a QEMU virtual machine.</p>

},
keywords = {compilers, control-flow analysis, dominator
tree, functional languages, GHC, Glasgow Haskell Compiler, Haskell, reverse postorder numbering, WebAssembly}
}

@software{10.5281/zenodo.6757373,
author = {Kov\'{a}cs, Andr\'{a}s},
title = {Supplementary artifact for the paper "Staged Compilation with Two-Level Type Theory"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6757373},
abstract = {
    <p>A demo implementation of the type theory described in the titular paper.</p>

},
keywords = {staged compilation, two-level type theory, type theory}
}

@software{10.5281/zenodo.6767057,
author = {Escot, Lucas and Cockx, Jesper},
title = {Generics, a library for datatype-generic programming in Agda},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6767057},
abstract = {
    <p>This artifact contains the source code for the Generics library for safe, typed datatype-generic programming in Agda.</p>

},
keywords = {Agda, Datatype, Dependent, Generic Programming, Types, Universe}
}

@software{10.5281/zenodo.6778257,
author = {Hoang, Tram and Trunov, Anton and Lampropoulos, Leonidas and Sergey, Ilya},
title = {ICFP-2022 Artifact for the paper "Random Testing of a Higher-Order Blockchain Language (Experience Report)"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6778257},
abstract = {
    <p>The artifact contains Scilla-Chick – a QuickChick-based tool for property-based randomized testing of the Scilla smart-contract language.</p>
<p>The tool developed for the paper is located in the <code>~/scilla-chick</code> directory. The (pseudo)random type-and-term generator is located in the file <code>~/scilla-chick/src/scilla.v</code> and is written in Coq (see <code>gen_type</code> and <code>gen_term</code> functions) using the QuickChick framework. QuickChick works by translating Coq code into OCaml for the sake of performance (it runs compiled OCaml code). We translate between Coq and OCaml representations using some glue OCaml code in <code>~/scilla-chick/src/extr/extr.ml</code> file. Various kinds of tests are located in the <code>X_test.v</code> files: <code>gen_test.v</code>, <code>eval_test.v</code>, etc.</p>
<p>The rest of the files and directories in the home directory are used to pin particular dependency versions needed to build the Scilla-Chick project. In particular, we re-use the Scilla implementation as an OCaml library.</p>
<p>For more information, please see the <code>~/scilla-chick/README.md</code> file in the <code>master</code> branch of the <code>~/scilla-chick</code> repository (note that the other branches contain an outdated version of <code>README.md</code>).</p>

},
keywords = {definitional interpreters, functional languages, higher-order control-flow analysis, property-based testing, QuickChick, random testing, Scilla, smart contracts}
}

@software{10.5281/zenodo.6786796,
author = {Biernacka, Ma\l{}gorzata and Charatonik, Witold and Drab, Tomasz},
title = {Abstract Machines Workshop},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6786796},
abstract = {
    <p>This project contains the code accompanying the paper <em>A Simple and Efficient Implementation of Strong Call by Need by an Abstract Machine</em>.</p>
<p>This research is supported by the National Science Centre of Poland, under grant number 2019/33/B/ST6/00289.</p>

},
keywords = {Abstract Machines, Computational Complexity, Normalization by Evaluation, Reduction Strategies, λ-calculus}
}

@software{10.5281/zenodo.6794696,
author = {Bahr, Patrick and Hutton, Graham},
title = {Supplementary Material for "Monadic Compiler Calculation"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6794696},
abstract = {
    <p>This artifact includes Agda formalisations of all calculations in the paper. In addition, we also include Agda formalisations for calculations that were mentioned but not explicitly carried out in the paper.</p>

},
keywords = {bisimilarity, divergence, non-determinism, program calculation}
}

@software{10.5281/zenodo.6865817,
author = {Keuchel, Steven and Huyghebaert, Sander and Lukyanov, Georgy and Devriese, Dominique},
title = {Source Code, Case Study and Reproduction for 'Verified Symbolic Execution with Kripke Specification Monads (and No Meta-programming)'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6865817},
abstract = {
    <p>The provided artifact contains the source code for our verifier Katamaran and instructions how to reproduce and verify all claims of the paper. Furthermore, we provide a QEMU VM-image of Debian that comes with all dependencies preinstalled and that does not require any additional online resources.</p>

},
keywords = {coq, iris, logical relations, predicate transformers, program verification, refinement, separation logic, symbolic execution}
}

@software{10.5281/zenodo.6874025,
author = {Materzok, Marek},
title = {Reproduction Package for Article 'Generating Circuits with Generators'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6874025},
abstract = {
    <p>The artifact source archive contains four repositories:</p>
<ul>
<li><code>yieldfsm</code> – the implementation of the YieldFSM compiler.</li>
<li><code>yieldfsm-hd44780</code> – the implementation of the HD44780 display driver described in the paper.</li>
<li><code>yieldfsm-riscv</code> – the implementation of RISC-V cores described in the paper.</li>
<li><code>yieldfsm-icfp2022</code> – various examples from the paper and calculation of the data in Table 2.</li>
</ul>
<p>Each of the repositories contains its own README file. Building requires <code>stack</code> (https://haskellstack.org). When additional packages are needed, this is described in a README for a given repository.</p>
<p>The <code>stack.yaml</code> files in the <code>yieldfsm-hd44780</code> and <code>yieldfsm-riscv</code> repositories were modified to use the local version of <code>yieldfsm</code> rather than the version on Github.</p>

},
keywords = {generators, hardware description languages, haskell, yieldfsm}
}

@software{10.5281/zenodo.6884760,
author = {Jacobs, Jules and Balzer, Stephanie and Krebbers, Robbert},
title = {Multiparty GV: Functional Multiparty Session Types With Certified Deadlock Freedom (Coq mechanization)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6884760},
abstract = {
    <p>This artifact contains mechanized Coq proofs of the theorems in the associated paper.</p>

},
keywords = {concurrency, deadlocks, memory leaks, multi-party., Session types}
}

@software{10.5281/zenodo.6913915,
author = {Yoon, Irene and Zakowski, Yannick and Zdancewic, Steve},
title = {Artifact for "Formal Reasoning about Layered Monadic Interpreters"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6913915},
abstract = {
    <p>This is the artifact for the paper submission of “Formal Reasoning About Layered Monadic Interpreters”. We have mechanized and proved all claims made in the paper in Coq.</p>

},
keywords = {Coq (language), Functional Programming, Monads, Program Verification}
}

@software{10.5281/zenodo.6946310,
author = {Lorenzen, Anton and Leijen, Daan},
title = {Implementation and Benchmarks for "Reference Counting with Frame Limited Reuse"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6946310},
abstract = {
    <p>Contains the implementation of Koka with the new frame-limited reuse algorithm, and the various benchmarks and language implementations we compare against. All benchmark results in the paper were produced using this software.</p>

},
keywords = {frame-limited, koka, reference counting, reuse}
}

@software{10.5281/zenodo.6954977,
author = {Ko, Hsiang-Shang and Chen, Liang-Ting and Lin, Tzu-Chi},
title = {Repository and virutal machine image for paper "Datatype-Generic Programming Meets Elaborator Reflection"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6954977},
abstract = {
    <p>There are three files in the artifact package: The tarball “NDGP.tar.gz” consists of a patch for compiling Agda, necessary libraries, metaprograms, and examples mentioned in the main text; “vm-image.tar.gz” is a disk image file of a working operating system, on which a patched Agda is installed, and an exact same repository is presented in the home directory; “README.md” contains the documentation for patching and compiling Agda, as well as how to execute our proofs, metaprograms, and examples.</p>

},
keywords = {datatype-generic programming, dependently typed programming, elaborator reflection, inductive families, metaprogramming, universe polymorphism}
}

@software{10.5281/zenodo.6957191,
author = {Valliappan, Nachiappan and Ruch, Fabian and Tom\'{e} Corti\~{n}as, Carlos},
title = {Artifact for "Normalization for Fitch-Style Modal Calculi"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6957191},
abstract = {
    <p>The artifact contains the Agda mechanization of the normalization functions for the Fitch-style modal calculi λ<sub>IK</sub> and λ<sub>IS4</sub> as described in the article.</p>
<p>See <code>README.md</code> in <code>source.tar.xz</code> for details.</p>

},
keywords = {Fitch-style lambda calculi, Normalization by Evaluation, Possible-world semantics}
}

@software{10.5281/zenodo.6520942,
author = {Weiss, Michael and Tonella, Paolo},
title = {Reproduction Package for Paper `Simple Techniques Work Surprisingly Well for Neural Network Test Prioritization and Active Learning (Replicability Study)`},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6520942},
abstract = {
    <p>This is the reproduction package of the paper Simple Techniques Work Surprisingly Well for Neural Network Test Prioritization and Active Learning by M.Weiss and P.Tonella, published at ISSTA 2022.</p>
<p>For uses other than reproduction, we also extracted three standalone, general-purpose artifacts: - fashion-mnist-c dataset (Github: https://github.com/testingautomated-usi/fashion-mnist-c) - text corruptor (Github: https://github.com/testingautomated-usi/corrupted-text) - tip implementations (Github: https://github.com/testingautomated-usi/dnn-tip)</p>

},
keywords = {neural networks, Test prioritization, uncertainty quantification}
}

@software{10.5281/zenodo.6534062,
author = {Ghaleb, Asem and Rubin, Julia and Pattabiraman, Karthik},
title = {Reproduction Package for Article 'eTainter: Detecting Gas-Related Vulnerabilities in Smart Contracts'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6534062},
abstract = {
    <p>The execution of smart contracts on the Ethereum blockchain consumes gas paid for by users submitting contracts’ invocation requests. A contract execution proceeds as long as the users dedicate enough gas for execution and the total gas for the execution is under the block gas limit set by Ethereum. Otherwise, the contract execution halts, and changes made during execution get reverted. Unfortunately, smart contracts may contain code patterns that increase their execution gas cost, causing them to run out of gas. These patterns can be manipulated by malicious attackers to induce unwanted behavior in the targeted victim contracts, e.g., Denial-of-Service (DoS) attacks. We call these gas-related vulnerabilities. The paper proposes eTainter, a static analyzer for detecting gas-related vulnerabilities based on taint tracking in the bytecode of smart contracts.</p>
<p>In this artifact, we provide the implementation of the proposed approach and the scripts to reproduce results shown in the paper. Further, we provide 3 datasets we have used in our experiments, one of the datasets is annotated dataset.</p>

},
keywords = {Ethereum, security, Solidity, taint analysis}
}

@software{10.5281/zenodo.6534229,
author = {Lahiri, Sumit and Roy, Subhajit},
title = {Almost Correct Invariants: Synthesizing Inductive Invariants by Fuzzing Proofs},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6534229},
abstract = {
    <p>The artifact is a tar zip file containing the README along with install script to set the tool up and other assets which have been detailed in the README file.</p>

},
keywords = {fuzzing, inductive invariant synthesis, testing, verification}
}

@software{10.5281/zenodo.6534292,
author = {Liu, Ye and Li, Yi and Lin, Shang-Wei and Artho, Cyrille},
title = {Replication Data for: Finding Permission Bugs in Smart Contracts with Role Mining},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6534292},
abstract = {
    <p>Smart contracts deployed on permissionless blockchains, such as Ethereum, are accessible to any user in a trustless environment. Therefore, most smart contract applications implement access control policies to protect their valuable assets from unauthorized accesses. A difficulty in validating the conformance to such policies, i. e., whether the contract implementation adheres to the expected behaviors, is the lack of policy specifications. In this paper, we mine past transactions of a contract to recover a likely access control model, which can then be checked against various information flow policies and identify potential bugs related to user permissions. We implement our role mining and security policy validation in tool SPCon. The experimental evaluation on labeled smart contract role mining benchmark demonstrates that SPCon effectively mines more accurate user roles compared to the state-of-the-art role mining tools. Moreover, the experimental evaluation on real-world smart contract benchmark and access control CVEs indicates SPCon effectively detects potential permission bugs while having better scalability and lower false-positive rate compared to the state-of-the-art security tools, finding 11 previously unknown bugs and detecting six CVEs that no other tool can find.</p>

},
keywords = {access control, information flow policy, role mining, Smart contract}
}

@software{10.5281/zenodo.6534721,
author = {Zheng, Yingying and Dou, Wensheng and Wang, Yicheng and Qin, Zheng and Tang, Lei and Gao, Yu and Wang, Dong and Wang, Wei and Wei, Jun},
title = {ISSTA 22 Artifact for "Finding Bugs in Gremlin-Based Graph Database Systems via Randomized Differential Testing"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6534721},
abstract = {
    <p>Grand is a tool for finding logic bugs in Gremlin-Based Graph Database Systems (GDBs). We refer to logic bugs as those bugs that GDBs return an unexpected result (e.g., incorrect query result or unexpected error) without crashing the GDBs for a given query.</p>
<p>Grand operates in the following three phases: 1. Graph database generation: The goal of this phase is to generate a populated graph database for each target GDB. Specially, Grand first randomly generates the graph schema to define the types of vertices and edges. Then, the detailed vertices and edges can be randomly generated according to the generated graph schema. Finally, the generated database will be written into target GDBs. 2. Gremlin query generation: This phase is aimed to generate syntactically correct and valid Gremlin queries. We first construct a traversal model for Gremlin APIs, and then generate Gremlin queries based on the constructed traversal model. 3. Differential Testing: Grand executes the generated Gremlin queries and validates the query results by differential testing.</p>

},
keywords = {differential testing, Graph database systems, Gremlin}
}

@software{10.5281/zenodo.6535073,
author = {Guo, Wunan and Dong, Zhen and Shen, Liwei and Tian, Wei and Su, Ting and Peng, Xin},
title = {Reproduction Package for Article 'Detecting and Fixing Data Loss Issues in Android Apps'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6535073},
abstract = {
    <p>This tool(iFixDataloss) consists of three components: static analyzer, dynamic explorer and patch generator. It works as follows: In the first step, iFixDataloss uses the static analyzer to build an activity transition graph and get persistent data for the app under test; In the second step, iFixDataloss runs dynamic explorer to detect data loss issues in the app. The relevant data for the data loss issue is stored in a database. Lastly, iFixDataloss takes the source code of the app and the data obtained in the dynamic exploration to generate a patch.</p>

},
keywords = {dynamic analysis, mobile testing, patching}
}

@software{10.5281/zenodo.6535361,
author = {Zheng, Yaowen and Li, Yuekang and Zhang, Cen and Zhu, Hongsong and Liu, Yang and Sun, Limin},
title = {Reproduction Package for 'Efficient Greybox Fuzzing of Applications in Linux-Based IoT Devices via Enhanced User-Mode Emulation'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6535361},
abstract = {
    <p>To easily use our prototype, you can follow the README.md to run the docker images and perform the testing. Source code is also included in EQUAFL_code.zip, so that others can extend it for further research.</p>

},
keywords = {Enhanced User-mode Emulation, Greybox Fuzzing, Linux-based IoT Devices}
}

@software{10.5281/zenodo.6535557,
author = {Zhang, Yuntong and Gao, Xiang and Duck, Gregory J. and Roychoudhury, Abhik},
title = {Reproduction Package for Article `Program Vulnerability Repair via Inductive Inference'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6535557},
abstract = {
    <p>Contains source code, experimental subjects, and instructions to reproduce main results for the article `Program Vulnerability Repair via Inductive Inference’.</p>

},
keywords = {Automated program repair, Inductive inference, Snapshot fuzzing}
}

@software{10.5281/zenodo.6579248,
author = {Kim, Geunwoo and Hong, Sanghyun and Franz, Michael and Song, Dokyung},
title = {XBA},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6579248},
abstract = {
    <p>XBA is a deep learning tool for generating platform-agnostic binary code embeddings. XBA applies Graph Convolutional Network (GCN) on the graph representation of binary which we call Binary Disassembly Graph (BDG). XBA can learn semantic matchings of binary code compiled for different platforms that are not included in the training dataset. It outperformed prior works in aligning binary code blocks for different platforms, which shows the embeddings generated by XBA indeed are useful in the cross binary analysis. XBA is implemented with Python v3.8 and Tensorflow v2.7.0.</p>

},
keywords = {Binary analysis, Cross-platform, Graph alignment}
}

@software{10.1145/3462319,
author = {Baudart, Guillaume and Mandel, Louis and Tekin, Reyyan},
title = {Reproduction package for article JAX Based Parallel Inference for Reactive Probabilistic Programming},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462319},
abstract = {
    <p>This artifact supports the LCTES 2022 article <strong>JAX Based Parallel Inference for Reactive Probabilistic Programming</strong>. It contains:</p>
<ul>
<li><code>zelus</code>: a modified version of the <a href="https://zelus.di.ens.fr">Zelus</a> compiler with a new JAX backend</li>
<li><code>probzelus</code>: the original <a href="https://github.com/IBM/probzelus">ProbZelus</a> runtime for OCaml</li>
<li><code>zlax</code>: the new ProbZelus runtime for JAX</li>
<li><code>examples</code>: several examples of ProbZelus programs</li>
<li><code>zlax-benchmarks</code>: the benchmarks to compare the OCaml and JAX runtimes based on the original <a href="https://github.com/IBM/probzelus">ProbZelus benchmark</a></li>
<li><code>lctes22-zlax.pdf</code>: the <a href="https://pldi22.sigplan.org/track/LCTES-2022">LCTES 2022</a> paper.</li>
<li><code>lctes22-zlax-image.tar.gz</code>: the saved <a href="https://www.docker.com">Docker</a> image with everything installed.</li>
</ul>

},
keywords = {Compilation, Parallel Computing, Probabilistic Programming, Reactive Programming, Streaming Inference}
}

@software{10.5281/zenodo.6598647,
author = {Liu, Fengyun and Prokopec, Aleksandar},
title = {Artifact for paper implicit state machines LCTES 2022},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6598647},
abstract = {
    <p>This is the artefact for the paper “implicit state machines” at LCTES 2022.</p>
<p>Note that DSL is an old version and thus deprecated. We are working on a newer version with a better design.</p>

},
keywords = {digital design, DSL, implicit state machine}
}

@software{10.5281/zenodo.6326451,
author = {Zagieboylo, Drew and Sherk, Charles and Suh, Gookwon Edward and Myers, Andrew C.},
title = {Reproduction Package for 'PDL: A High-Level Hardware Design Language for Pipelined Processors'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6326451},
abstract = {
    <p>A Docker container which can be used to recreate the results from the PLDI ’22 paper, PDL: A High-Level Hardware Design Language for Pipelined Processors.</p>
<p>This includes:</p>
<ul>
<li>The source code of the PDL compiler and its test suite</li>
<li>A simulator for the baseline Chisel processor used in our evaluation</li>
<li>The PDL programs describing the RISC-V architectures described in our evaluation</li>
<li>A build system to generate the CPI results reported in the paper for the above architectures</li>
</ul>

},
keywords = {Computer Architecture, Language Design}
}

@software{10.5281/zenodo.6326513,
author = {Greenberg, Michael and Beckett, Ryan and Campbell, Eric},
title = {Implementation of the KMT framework in OCaml},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6326513},
abstract = {
    <p>Kleene algebra modulo theories (KMT) is a framework for deriving concrete Kleene algebras with tests (KATs)—an algebraic framework for While-like programs with decidable program equivalence.</p>
<p>More plainly: KMT is a framework for building simple programming languages with structured control (if, while, etc.) where we can algorithmically decide whether or not two programs are equivalent. You can use equivalence to verify programs. If a is a nice property to have after running your program, then if p;a == p, you know that p satisfies a. Kleene algebra with tests subsumes Hoare logic: if a;p;~b == 0 then all runs starting from a either diverge or end with b, i.e., that equation corresponds to the partial correctness specification {a} p {b}. While prior work on KAT often focuses on abstract properties, we write programs over theories that assign concrete meanings to primitive tests and actions.</p>
<p>In addition to providing an OCaml library for defining KMTs over your own theories, we offer a command-line tool for testing equivalence in a variety of pre-defined theories.</p>

},
keywords = {algebraic models, functors, kleene algebra, modules, program equivalence, tracing semantics, verification}
}

@software{10.5281/zenodo.6327186,
author = {Jones, Eddie and Ong, C.-H. Luke and Ramsay, Steven},
title = {CycleQ},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6327186},
abstract = {
    <p>CycleQ is an efficient basis for automatic equation reasoning with cyclic proofs, rather than traditional induction, that is aimed at verifying the behaviour of functional programs. Specifically, the tool is implemented as a plugin for GHC.</p>

},
keywords = {cyclic proofs, equational reasoning, program verification}
}

@software{10.5281/zenodo.6327595,
author = {Tang, Shizhi and Zhai, Jidong and Wang, Haojie and Jiang, Lin and Zheng, Liyan and Yuan, Zhenhao and Zhang, Chen},
title = {Artifact: FreeTensor: A Free-form DSL with Holistic Optimizations for Irregular Tensor Programs},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6327595},
abstract = {
    <p>Artifact for PLDI ’22 paper “FreeTensor: A Free-form DSL with Holistic Optimizations for Irregular Tensor Programs”. The tensor compiler described in the paper is included, and the performance number can be reproduced.</p>

},
keywords = {DSL, optimizing compilers, tensor computing}
}

@software{10.5281/zenodo.6327882,
author = {Crichton, Will and Patrignani, Marco and Agrawala, Maneesh and Hanrahan, Pat},
title = {Artifact for "Modular Information Flow through Ownership"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6327882},
abstract = {
    <p>This is a Docker image that contains the codebase and evaluation scripts for our PLDI 2022 paper “Modular Information Flow Through Ownership”.</p>

},
keywords = {information flow, modular program analysis, rust}
}

@software{10.5281/zenodo.6329754,
author = {Farzan, Azadeh and Lette, Danya and Nicolet, Victor},
title = {Software Artifact for "Recursion Synthesis with Unrealizability Witnesses" Paper},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6329754},
abstract = {
    <p>This software artifact is provided to support the experimental claims made in the PLDI’22 paper <em>Recursion Synthesis with Unrealizability Witnesses</em>. All the results given in the paper are reproducible modulo experimental error. The artifact also contains a reusable version of Synduce, the tool implementing the synthesis algorithms presented in the paper.</p>

},
keywords = {Abstraction, Functional Programming, Invariants, Program Synthesis, Recursion, Unrealizability}
}

@software{10.5281/zenodo.6330174,
author = {Milano, Mae and Turcotti, Joshua and Myers, Andrew C.},
title = {A Flexible Type System for Fearless Concurrency: Accompanying Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6330174},
abstract = {
    <p>An implementation of a type-checker (with efficient proof search/inference) for the language described in the PLDI 2022 paper “A Flexible Type System for Fearless Concurrency,” available with DOI 10.1145/3519939.3523443 at the The ACM DL in June of 2022. Includes an accompanying virtual machine, with all dependencies installed, capable of building the type checker.</p>

},
keywords = {aliasing, compiler, concurrency, coq, linear types, ocaml, regions, type systems}
}

@software{10.5281/zenodo.6330208,
author = {Briggs, Ian and Panchekha, Pavel},
title = {OpTuner Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6330208},
abstract = {
    <p>Instructions and a virtual machine image to verify the claims in the paper “Choosing Math Function Implementations for Speed and Accuracy”</p>

},
keywords = {accuracy, floating point, ILP, optimization}
}

@software{10.5281/zenodo.6330232,
author = {Zhou, Xiangyu and Bodik, Rastislav and Cheung, Alvin and Wang, Chenglong},
title = {Reproduction Package for Synthesizing Analytical SQL Queries from Computation Demonstration},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6330232},
abstract = {
    <p>In this artifact, we included implementations of an analytical query synthesizer that uses enumerative synthesis algorithm and provenance abstraction for pruning the search space. In addition, we included the implementation of baselines synthesizers that use value abstraction, and type abstraction for experiments. Running the experimental scripts reproduces graph results in Synthesizing Analytical SQL Queries from Computation Demonstration. We also included 80 real-world benchmarks on solving analytical SQL problems with synthesizer.</p>

},
keywords = {Program Synthesis, Query by Demonstration}
}

@software{10.5281/zenodo.6330573,
author = {Verbeek, Freek and Bockenek, Joshua and Fu, Zhoulai and Ravindran, Binoy},
title = {Artifact for Article `Formally Verified Lifting of C-compiled x86-64 Binaries'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6330573},
abstract = {
    <p>This artifact accompanies the PLDI’22 article `Formally Verified Lifting of C-compiled x86-64 Binaries’. It can be used to disassemble x86-64 binaries and export proofs of correctness to the Isabelle/HOL theorem prover.</p>

},
keywords = {binary verification, disassembly, formal methods}
}

@software{10.5281/zenodo.6330707,
author = {Tao, Runzhou and Shi, Yunong and Yao, Jianan and Li, Xupeng and Javadi-Abhari, Ali and Cross, Andrew W. and Chong, Frederic T. and Gu, Ronghui},
title = {Artifact for PLDI 2022 paper Giallar: Push-button Verification for the Qiskit Quantum Compiler},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6330707},
abstract = {
    <p>The artifact contains the docker image file needed to reproduce the results presented in the paper.</p>

},
keywords = {automated verification, compiler verification, quantum computing}
}

@software{10.5281/zenodo.6330740,
author = {Pit-Claudel, Cl\'{e}ment and Philipoom, Jade and Jamner, Dustin and Erbsen, Andres and Chlipala, Adam},
title = {Artifact for "Relational Compilation for Performance-Critical Applications"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6330740},
abstract = {
    <p>A virtual machine submitted to PLDI 2022’s artifact evaluation committee.</p>

},
keywords = {compilation, theorem proving, verification}
}

@software{10.5281/zenodo.6351111,
author = {Guo, Zheng and Cao, David and Tjong, Davin and Yang, Jean and Schlesinger, Cole and Polikarpova, Nadia},
title = {Reproduction package of "Type-Directed Program Synthesis for RESTful APIs"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6351111},
abstract = {
    <p>This package includes a VMware virtual machine to reproduce results reported in the paper “Type-Directed Program Synthesis for RESTful APIs”.</p>

},
keywords = {Program Synthesis, RESTful API, Type Inference}
}

@software{10.5281/zenodo.6354482,
author = {Doenges, Ryan and Kapp\'{e}, Tobias and Sarracino, John and Foster, Nate and Morrisett, Greg},
title = {Leapfrog: Certified Equivalence for Protocol Parsers},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6354482},
abstract = {
    <p>This is the artifact accompanying the paper “Leapfrog: Certified Equivalence for Protocol Parsers”, to appear at PLDI 2022. See the README.md file for more details and installation instructions.</p>

},
keywords = {automata, certified parsers, Coq, equivalence, foundational verification, network protocol parsers, P4}
}

@software{10.5281/zenodo.6366190,
author = {Fehr, Mathieu and Niu, Jeff and Riddle, River and Amini, Mehdi and Su, Zhendong and Grosser, Tobias},
title = {IRDL: An IR Definition Language for SSA Compilers - PLDI 2022 Artifact Evaluation},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6366190},
abstract = {
    <p>The artifact provides: * A python tool to extract an IRDL representation of the 28 dialects available in MLIR. Each dialect can be extracted in two variants: (1) contains constraints that can currently be enforced by our IRDL implementation, (2) contains additional IRDL constraints that demonstate the full expressiveness of IRDL. The reader can manually inspect the IRDL file of each dialect to get a visual impression of the IRDL files for typical MLIR dialects. * Scripts to reproduce all plots (except Figure 3) from the evaluation section of the paper. In particular, Figure 3 is not reproduced * An implementation of the key language constructs of IRDL for MLIR, which can be registered at runtime and supports the following constructs: * Definition of dialects * Operations with operands, results, and constraint variables * Types * The following type constraints: <code>Any</code>, <code>AnyOf</code>, equality constraint, base constraint, parametric constraint</p>

},
keywords = {Compilers, Intermediate Representation, MLIR}
}

@software{10.5281/zenodo.6366296,
author = {Ahrens, Willow and Kjolstad, Fredrik and Amarasinghe, Saman},
title = {Autoscheduling for Sparse Tensor Algebra with an Asymptotic Cost Model (The Artifact)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6366296},
abstract = {
    <p>An artifact to replicate the results of “Autoscheduling for Sparse Tensor Algebra with an Asymptotic Cost Model”, Willow Ahrens, Fredrik Kjolstad, and Saman Amarasinghe. PLDI 2022.</p>

},
keywords = {Asymptotic Analysis, Automatic Scheduling, Compilers, Conjunctive Query Containment, Query Optimization, Sparse Tensors}
}

@software{10.5281/zenodo.6374369,
author = {Dang, Hoang-Hai and Jung, Jaehwang and Choi, Jaemin and Nguyen, Duc-Than and Mansky, William and Kang, Jeehoon and Dreyer, Derek},
title = {Compass: Strong and Compositional Library Specifications in Relaxed Memory Separation Logic (Artifact)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6374369},
abstract = {
    <p>This contains a snapshot of the Compass development.</p>
<p>More updated information can be found at https://plv.mpi-sws.org/compass/.</p>

},
keywords = {C11, Coq, Iris, Linearizabliity, Logical Atomicity, Relaxed Memory, Separation Logic}
}

@software{10.5281/zenodo.6394618,
author = {Fl\"{u}ckiger, Olivier and Je\v{c}men, Jan and Krynski, Sebasti\'{a}n and Vitek, Jan},
title = {Artifact of "Deoptless: Speculation with Dispatched On-Stack Replacement and Specialized Continuations"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6394618},
abstract = {
    <p>This is the artifact to accompany our PLDI 2022 submission on “Deoptless: Speculation with Dispatched On-Stack Replacement and Specialized Continuations”. The artifact consists of a virtual machine for the R language, called \v{R}, a suite of benchmarks written in R, as well as R scripts to plot the results.</p>

},
keywords = {virtual machine}
}

@software{10.5281/zenodo.6395059,
author = {Gorjiara, Hamed and Luo, Weiyu and Lee, Alex and Xu, Guoqing Harry and Demsky, Brian},
title = {Replication Package for Article: Checking Robustness to Weak Persistency Models},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6395059},
abstract = {
    <p>This artifact contains a vagrant repository that downloads and compiles the source code for PSan(a plugin for Jaaru), its companion compiler pass, and benchmarks. The artifact enables users to reproduce the bugs that are found by PSan in PMDK and RECIPE (Table 2} in Evaluation Section) as well as comparing bug-finding capabilities and performance of PSan with Jaaru, a persistent memory model checker (Table 3 in the Evaluation Section). To simplify the evaluation process, we created an instance of VM that includes all the source code and corresponding binary files. This VM is fully set up and it is available on this artifact repository. This artifact also provides a guideline on how to setup the VM and use it to reproduce PSan’s evaluation results.</p>

},
keywords = {Crash Consistency Bugs, Jaaru, Persistency Bugs, Persistent Memory Model Checker, PMDK, PSan, RECIPE, Robustness Violations}
}

@software{10.5281/zenodo.6402134,
author = {Honor\'{e}, Wolf and Shin, Ji-Yong and Kim, Jieung and Shao, Zhong},
title = {Artifact For "Adore: Atomic Distributed Objects with Certified Reconfiguration"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6402134},
abstract = {
    <p>This is the Coq implementation of the Adore model, safety proof, and refinement described in the paper. It also includes an executable instantiation of the abstract model using OCaml extraction. Refer to the README for build instructions and additional details.</p>

},
keywords = {consensus protocols, Coq, distributed systems, formal verification, reconfiguration, refinement}
}

@software{10.5281/zenodo.6408463,
author = {Rocha, Rodrigo C. O. and Sprokholt, Dennis and Fink, Martin and Gouicem, Redha and Spink, Tom and Chakraborty, Soham and Bhatotia, Pramod},
title = {Lasagne: A Static Binary Translator for Weak Memory Model Architectures},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6408463},
abstract = {
    <p>Artifact for the paper titled “Lasagne: A Static Binary Translator for Weak Memory Model Architectures” published in the Conference on Programming Language Design and Implementation, 2022. It contains the automated proofs presented in the paper as well as the software for the Lasagne system and its evaluation.</p>

},
keywords = {LLVM, Memory Model, Static Binary Translation}
}

@software{10.5281/zenodo.6409577,
author = {Morelli, Canberk and Reineke, Jan},
title = {Replication Package for Warping Cache Simulation of Polyhedral Programs},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6409577},
abstract = {
    <p>This is the artifact of the conference paper “Warping Cache Simulation of Polyhedral Programs” at PLDI 2022.</p>
<p>The artifact structure is as follows: - <code>benchmark</code>: The <a href="https://web.cse.ohio-state.edu/~pouchet.2/software/polybench/">PolyBench</a> benchmark that is used in our experiments. - <code>data</code>: The data we obtained from our experiments (<code>data/existing</code>) which are presented in our paper as plots. The data that you will reproduce will also be available here (<code>data/reproduced</code>). - <code>haystack-artifact</code>: The <a href="https://dl.acm.org/do/10.1145/332599">artifact</a> provided by the related work <a href="https://dl.acm.org/doi/10.1145/3314221.3314606">HayStack</a>. - <code>plots</code>: The plots you will generate (<code>plots/from-existing-data</code> and <code>plots/from-reproduced-data</code>). - <code>scripts</code>: The scripts for repeating our experiments and generating our figures. - <code>warping-cache-simulation</code>: The source code of our cache simulation tool. - <code>d4-7.tar.gz</code>: DineroIV package, used only if the ftp server used in <code>haystack-artifact/Dockerfile</code> is down. - <code>Dockerfile</code>: File to build our Docker image, which will be used to repeat our experiments and generate our plots. - <code>README.md</code>: This file. We suggest using a “markdown capable” viewer to read the file. - <code>paper-submission-version.pdf</code>: The submission version of our accepted paper.</p>
<p>Please refer to the README.md for more information.</p>

},
keywords = {cache model, cache simulation, data independence, performance analysis, simulation}
}

@software{10.5281/zenodo.6410434,
author = {Chaliasos, Stefanos and Sotiropoulos, Thodoris and Spinellis, Diomidis and Gervais, Arthur and Livshits, Benjamin and Mitropoulos, Dimitris},
title = {Replication Package for Article: "Finding Typing Compiler Bugs"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6410434},
abstract = {
    <p>The purpose of this artifact is to reproduce the results presented in the PLDI 2022 paper titled “Finding Typing Compiler Bugs”. The artifact contains the instructions, tool, and scripts to re-run the evaluation described in the paper. The artifact has the following structure:</p>
<ul>
<li>scripts/: This directory contains the scripts needed to re-run the experiments presented in our paper.</li>
<li>data/: This is the directory that contains the precomputed results of our evaluation.</li>
<li>database/bug_schema.sql: This is the database schema that contains the bugs discovered by our approach.</li>
<li>database/bugdb.sqlite3: This is the sqlite3 database file corresponding to our bug database.</li>
<li>database/bugs.json: This JSON file contains the bugs of database/bugdb.sqlite.</li>
<li>hephaestus/: Contains the source code of the tool (provided as a git submodule) used for testing the compilers of Java, Kotlin, and Groovy. The name of our tool is Hephaestus.</li>
<li>installation_scripts/: Contains helper scripts used to install all dependencies (e.g., compiler versions from SDKMAN).</li>
<li>figures/: This directory will be used to save figure 8 of the paper.</li>
<li>Dockerfile: The Dockerfile used to create a Docker image of our artifact. This image contains all data and dependencies.</li>
</ul>

},
keywords = {compiler bugs, compiler testing, Groovy, Java, Kotlin, static typing}
}

@software{10.5281/zenodo.6412048,
author = {Guria, Sankha Narayan and Vazou, Niki and Guarnieri, Marco and Parker, James},
title = {Replication package for "ANOSY: Approximated Knowledge Synthesis with Refinement Types for Declassification"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6412048},
abstract = {
    <p>The artifact is a Docker image that contains all of the source code, benchmarks, and experiment harnesses used in the development of the paper (set-up and ready to run). The README contains instructions to reproduce results from the paper, as well as pointers for how to use, extend or modify the tool and benchmarks.</p>

},
keywords = {knowledge-based privacy, program synthesis, program verification, refinement types}
}

@software{10.5281/zenodo.6413018,
author = {Kortbeek, Vito and Ghosh, Souradip and Hester, Josiah and Campanoni, Simone and Pawe\l{}czak, Przemys\l{}aw},
title = {WARio: Efficient Code Generation for Intermittent Computing - PLDI 2022 Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6413018},
abstract = {
    <p>This is the PLDI 2022 artifact for WARio, a compiler-support runtime for intermittently-powered platforms with non-volatile main memory.</p>
<p>This artifact is separated into three downloadable objects: * docker.zip, which holds all the Dockerfiles and prebuilt Docker containers. * code.zip, which holds all the source code (also available at: https://github.com/TUDSSL/WARio) * README.md, a markdown file containing more details about this artifact and how to evaluate it properly.</p>
<p>The docker containers can go through all the steps required to reproduce WARio, from building WARio and its dependencies to generating the figures and tables presented in the paper (and more).</p>
<p>For more information, please download the README.md file in this artifact.</p>
<p>Accompanying GitHub repository: https://github.com/TUDSSL/WARio</p>
<p>Supporting grants: NWO: P15-06 NSF: CNS-1850496, CNS-2145584, CCF-1908488, CNS-1763743</p>

},
keywords = {ARM, battery-free, compiler-support, embedded, intermittent computing, mixed-memory architecture, non-volatile memory, PLDI}
}

@software{10.5281/zenodo.6414469,
author = {Grewal, Karuna and D'Antoni, Loris and Hsu, Justin},
title = {Reproduction Package for Article "P4BID: Information Flow Control in P4"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6414469},
abstract = {
    <p>The artifact contains the main Readme.txt describing how to reproduce the evaluation presented in the paper using the baseline original P4c compiler and its IFC extension.</p>

},
keywords = {IFC, P4}
}

@software{10.5281/zenodo.6414787,
author = {Mulder, Ike and Krebbers, Robbert and Geuvers, Herman},
title = {Artifact and Appendix of 'Diaframe: Automated Verification of Fine-Grained Concurrent Programs in Iris'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6414787},
abstract = {
    <p>This is the artifact for the PLDI ‘22 paper ’Diaframe: Automated Verification of Fine-Grained Concurrent Programs in Iris’. It contains the Diaframe source code, a VM containing a compiled version of this source code, the appendix for the paper, and instructions for evaluation.</p>

},
keywords = {Coq, fine-grained concurrency, Iris, proof automation, Separation logic}
}

@software{10.5281/zenodo.6416420,
author = {Paraskevopoulou, Zoe and Eline, Aaron and Lampropoulos, Leonidas},
title = {Artifact for Computing Correctly with Inductive Relations},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6416420},
abstract = {
    <p>VM containing ready-to-build experiments for the paper.</p>

},
keywords = {Coq, Inductive relations, QuickChick}
}

@software{10.5281/zenodo.6416442,
author = {Christensen, Michael and Tzimpragos, Georgios and Kringen, Harlan and Volk, Jennifer and Sherwood, Timothy and Hardekopf, Ben},
title = {Reproduction Package for Article "PyLSE: A Pulse-Transfer Level Language for Superconductor Electronics"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6416442},
abstract = {
    <p>PyLSE is a Python-embedded pulse-transfer level language for the design and simulation of superconductor electronics (SCE). The purpose of PyLSE is to make it easier to create precise and composable models of the basic SCE cells (i.e.&nbsp;gates), use these models to create larger systems, quickly get up and running in the built-in simulation framework, and finally prove various properties about these cells and systems using a state-of-the-art model checker. This artifact will show you how to do so, as well as show you how to get the results in the tables and figures found in the evaluation section of our paper.</p>

},
keywords = {hardware description language, superconductor electronics, timed automata}
}

@software{10.5281/zenodo.6416483,
author = {O'Connor, Liam and Wickstr\"{o}m, Oskar},
title = {Reproduction Package for 'Quickstrom: Property-based acceptance testing with LTL specifications'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6416483},
abstract = {
    <p>This artifact contains the software, source code, and experimental results for the paper ‘Quickstrom: Property-based acceptance testing with LTL specifications’ at PLDI 2022. See README.TXT for more details.</p>

},
keywords = {programming, property-based testing, results, software, web applications}
}

@software{10.5281/zenodo.6417959,
author = {Sammler, Michael and Hammond, Angus and Lepigre, Rodolphe and Campbell, Brian and Pichon-Pharabod, Jean and Dreyer, Derek and Garg, Deepak and Sewell, Peter},
title = {Artifact for "Islaris: Verification of Machine Code Against Authoritative ISA Semantics"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6417959},
abstract = {
    <p>This is the artifact for the PLDI’22 paper “Islaris: Verification of Machine Code Against Authoritative ISA Semantics”. It contains the Coq development for the paper.</p>

},
keywords = {Arm, assembly, Coq, Iris, Isla, proof automation, RISC-V, Sail, separation logic, verification}
}

@software{10.5281/zenodo.6419124,
author = {Ikarashi, Yuka and Bernstein, Gilbert Louis and Reinking, Alex and Genc, Hasan and Ragan-Kelley, Jonathan},
title = {Exocompilation for Productive Programming of Hardware Accelerators},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6419124},
abstract = {
    <p>This artifact consists of a Docker image capable of reproducing our AVX-512 benchmarks on compatible hardware (e.g.&nbsp;Skylake-X or Tiger Lake). To use the latest Exo system for practical development, we refer readers to our GitHub repository at: https://github.com/ChezJrk/exo and our Python package at: https://pypi.org/project/exo-lang/</p>

},
keywords = {Code optimization, Computer architecture, High performance computing, Language design}
}

@software{10.5281/zenodo.6450309,
author = {Farzan, Azadeh and Klumpp, Dominik and Podelski, Andreas},
title = {Artifact for PLDI'22 paper "Sound Sequentialization for Concurrent Program Verification"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6450309},
abstract = {
    <p>This artifact for the PLDI’22 paper “Sound Sequentialization for Concurrent Program Verification” consists of a docker image that contains source code for the evaluated verifiers, compiled binaries of the verifiers, benchmark programs to compare the verifiers, and the raw evaluation results that form the basis for the discussion in the paper.</p>

},
keywords = {Concurrency, Partial Order Reduction, Sequentialization}
}

@software{10.5281/zenodo.6460021,
author = {Bendrissou, Bachir and Gopinath, Rahul and Zeller, Andreas},
title = {Reproduction package for “Synthesizing Input Grammars”: A Replication Study},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6460021},
abstract = {
    <p>This is a virtual box image that contains all experiments necessary to reproduce the results of the paper “Synthesizing Input Grammars”: A Replication Study.</p>

},
keywords = {glade, grammar mining, replication}
}

@software{10.5281/zenodo.6466911,
author = {Dhulipala, Laxman and Blelloch, Guy E. and Gu, Yan and Sun, Yihan},
title = {CPAM (Compressed Parallel Augmented Maps), an implementation of "PaC-Trees: Supporting Parallel and Compressed Purely-Functional Collections"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6466911},
abstract = {
    <p>CPAM (Compressed Parallel Augmented Maps) is a parallel C++ library providing an implementation of the PaC-tree data structure, which is used to provide an interface for augmented maps that supports blocking of the nodes and applying user-defined compression schemes on the underlying data. CPAM’s interface is an extension of the interface from the PAM (Parallel Augmented Maps) library. CPAM is designed for maintaining ordered map data structures on potentially large and compressed datasets while efficiently answering queries (e.g., range queries) and performing dynamic updates on the data.</p>
<p>In the experiments, we use the interface in four examples: an inverted index, interval-queries, 2d range-queries, and graph processing. This artifact provides a self-contained docker image, includes examples and scripts for running the main experiments reported in the paper. It has also been designed to make it easy to try many other scenarios (e.g., different sizes, different datasets, different numbers of cores, and other operations described in the paper, but not reported in the experiments).</p>
<p>More details, examples, and discussion can be found in our paper.</p>

},
keywords = {parallel data structures, purely-functional data structures, space-efficient data structures}
}

@software{10.5281/zenodo.6468999,
author = {Anderson, Daniel and Blelloch, Guy E. and Wei, Yuanhao},
title = {Artifact for "Turning Manual Concurrent Memory Reclamation into Automatic Reference Counting"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6468999},
abstract = {
    <p>This artifact contains our code and experiments as they were at the time of <strong>submission</strong>, and hence, at the time that they were validated by the artifact evaluation comittee. The latest version of our code can always be obtained from <a href="https://github.com/cmuparlay/concurrent_deferred_rc">here</a>. If you wish to build on our code for your own research, we highly recommend obtaining the latest version.</p>
<p>Note that this artifact does not contain the commercial <a href="https://www.stdthread.co.uk/">just::threads</a> library, which we compare with in Figure 13 of our paper, due to copyright. This artifact is still able to plot Figure 13, but without the line for just::threads.</p>

},
keywords = {automatic memory reclamation, concurrency, lock-free, smart pointers}
}

@software{10.5281/zenodo.6470820,
author = {Beutner, Raven and Ong, C.-H. Luke and Zaiser, Fabian},
title = {Artifact for: Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming (PLDI 2022)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6470820},
abstract = {
    <p>This is the artifact for “Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming” (PLDI 2022). It contains the implementation of the GuBPI tool, which can compute Guaranteed Bounds for Posterior Inference. It also includes the benchmarks from the paper and scripts to reproduce the reported data. For convenience, Docker images are also provided to allow for quick experimentation.</p>

},
keywords = {abstract interpretation, Bayesian inference, interval arithmetic, operational semantics, probabilistic programming, symbolic execution, type system, verification}
}

@software{10.5281/zenodo.6501665,
author = {Matsushita, Yusuke and Denis, Xavier and Jourdan, Jacques-Henri and Dreyer, Derek},
title = {RustHornBelt: A Semantic Foundation for Functional Verification of Rust Programs with Unsafe Code, Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6501665},
abstract = {
    <p>It is the artifact for the PLDI 2022 paper “RustHornBelt: A Semantic Foundation for Functional Verification of Rust Programs with Unsafe Code”. It contains the Coq mechanization of RustHornBelt’s type-spec system and its semantic soundness proof, as well as the benchmarks that evaluate RustHornBelt’s specs using a semi-automated Rust verifier Creusot.</p>

},
keywords = {Coq mechanization, Iris, Rust, semi-automated verification, separation logic, Why3}
}

@software{10.5281/zenodo.6501899,
author = {Zhao, Wenyu and Blackburn, Stephen M. and McKinley, Kathryn S.},
title = {[PLDI'22 Artifact] #132 Low-Latency, High-Throughput Garbage Collection},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6501899},
abstract = {
    <p>Artifact for PLDI 2022 paper: Low-Latency, High-Throughput Garbage Collection</p>
<p>Please check https://github.com/wenyuzhao/lxr-pldi-2022-artifact/blob/main/README.md for instructions on building and evaluating the artifact.</p>
<p>Please refer to https://github.com/wenyuzhao/mmtk-core/tree/lxr for the latest implementation.</p>

},
keywords = {Garbage collection, Reference counting}
}

@software{10.5281/zenodo.6503142,
author = {Chen, Yanju and Yan, Xifeng and Feng, Yu},
title = {Research Artifact for PLDI'22 Paper: Visualization Question Answering Using Introspective Program Synthesis},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6503142},
abstract = {
    <p>Research Artifact for PLDI’22 Paper: Visualization Question Answering Using Introspective Program Synthesis</p>

},
keywords = {Machine Learning, Program Synthesis}
}

@software{10.5281/zenodo.6509997,
author = {Aanjaneya, Mridul and Lim, Jay P. and Nagarakatte, Santosh},
title = {Artifact for Progressive Polynomial Approximations for Fast Correctly Rounded Math Libraries},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6509997},
abstract = {
    <p>We present the artifact for the paper, “Progressive Polynomial Approximations for Fast Correctly Rounded Math Libraries.” We describe the list of claims made by the paper, evaluation instructions, and instructions on how to use RLIBM-PROG. To ease the installation effort, we provide a docker image with all but one required softwares installed already (with instructions on how to build the remaining required software in the docker image). Additionally, we provide complete instructions to manually install the artifact on Ubuntu 20.04.</p>

},
keywords = {Correct rounded elementary functions, progressive polynomials, RLIBM, RLIBM-PROG}
}

@software{10.48420/17041502.v1,
author = {Stirling, Sean and Rocha, Rodrigo C. O. and Hazelwood, Kim and Leather, Hugh and O'Boyle, Michael and Petoumenos, Pavlos},
title = {Artifact for F3M: Fast Focused Function Merging},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.48420/17041502.v1},
abstract = {
    <p>Evaluation Artifact for the CGO 2022 paper “F3M: Fast Focused Function Merging”.</p>
<p>This archive contains: 1) The scripts needed to setup the evaluation environment including pulling the Function Merging code and building it. 2) The scripts needed to reproduce the experiments in the paper. 3) Pre-compiled LLVM IR bitcode files on which we evaluate function merging.</p>

},
keywords = {code-size reduction, compiler optimization, function merging, LLVM}
}

@software{10.5281/zenodo.5703630,
author = {Vishwanathan, Harishankar and Shachnai, Matan and Narayana, Srinivas and Nagarakatte, Santosh},
title = {Artifact for submission "Sound, Precise, and Fast Abstract Interpretation with Tristate Numbers"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5703630},
abstract = {
    <p>In this artifact, we provide instructions to reproduce and validate the following claims in the paper.</p>
<ol type="1">
<li><p>Verification of tnum operations using the Z3 SMT solver</p></li>
<li><p>Precision improvements in our tnum multiplication algorithm compared to the Linux kernel’s tnum multiplication.</p></li>
<li><p>Performance improvements in our tnum multiplication algorithm compared to Linux kernel’s tnum multiplication.</p></li>
<li><p>Precision of tnum multiplication compared to the Linux kernel’s tnum multiplication as a function of increasing bitwidth of input tnums.</p></li>
</ol>

},
keywords = {Abstract domains, eBPF, Kernel extensions, Program verification, Static
analysis}
}

@software{10.5281/zenodo.5710526,
author = {Kallwies, Hannes and Leucker, Martin and Scheffel, Torben and Schmitz, Malte and Thoma, Daniel},
title = {Artifact (Docker Image) for paper "Aggregate Update Problem for Multi-Clocked Dataflow Languages"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5710526},
abstract = {
    <p>The artifact contains a TeSSLa to Scala compiler with the optimization described in the paper “Aggregate Update Problem for Multi-Clocked Dataflow Languages” and the benchmarks from the paper. The artifact is packaged as a Docker image for x86 64 Bit architectures. It provides shell scripts to compile and execute the synthetic as well as the real-world benchmarks described in the paper. The artifact further contains the source code of the implemented compiler phase and additional examples.</p>

},
keywords = {Aggregate Update Problem, Compiler Optimization, Dataflow Languages}
}

@software{10.5281/zenodo.5784251,
author = {Cummins, Chris and Wasti, Bram and Guo, Jiadong and Cui, Brandon and Ansel, Jason and Gomez, Sahir and Jain, Somya and Liu, Jia and Teytaud, Olivier and Steiner, Benoit and Tian, Yuandong and Leather, Hugh},
title = {CompilerGym Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5784251},
abstract = {
    <p>This is a supporting code artifact for the publication: “CompilerGym: Robust, Performant Compiler Optimization Environments for AI Research”. This is a snapshot of the CompilerGym repository, created at the time of publication.</p>
<p>For the most up-to-date release of CompilerGym, see GitHub: https://github.com/facebookresearch/CompilerGym.</p>
<p>For further information on CompilerGym, see our documentation site: https://compilergym.ai/.</p>

},
keywords = {compiler optimization, machine learning, reinforcement learning}
}

@software{10.5281/zenodo.5784768,
author = {Saumya, Charitha and Sundararajah, Kirshanthan and Kulkarni, Milind},
title = {Replication Package for Article: DARM: Control-Flow Melding for SIMT Thread Divergence Reduction},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5784768},
abstract = {
    <p>This artifact provides the source code that implements DARM, a compiler optimization technique for reducing SIMT thread divergence by control-flow melding. Our approach is implemented on top of the ROCm LLVM compiler. We also provide a benchmark suite to evaluate the effectiveness of our technique. This benchmark suite consists of well-known open-source GPGPU applications and optimized reference implementations of certain GPGPU applications. We provide a README file that describes how to build DARM and perform the experimental evaluation described in the initial version of our paper.</p>

},
keywords = {Compiler Optimizations, Control-Flow Divergence, GPGPUs}
}

@software{10.5281/zenodo.5787482,
author = {Wang, Xudong and Xu, Xuezheng and Li, Qingan and Yuan, Mengting and Xue, Jingling},
title = {Artifact for Article: Recovering Container Class Types in C++ Binaries},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5787482},
abstract = {
    <p>The artifact provides all non-proprietary components of TIARA.</p>

},
keywords = {Binary Code Analysis, Containers, Template Classes, Type Inference}
}

@software{10.5281/zenodo.5788581,
author = {Brahmakshatriya, Ajay and Amarasinghe, Saman},
title = {Replication Package for the paper 'GraphIt to CUDA Compiler in 2021 LOC: A Case for High-Performance DSL Implementation via Staging with BuilDSL'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5788581},
abstract = {
    <p>The artifact contains the source code and the evaluation scripts for the evaluations in the paper. The attached README has step-by-step instructions to clone, build and run BuilDSL. The README also has steps on how to obtain the dataset, build the comparison framework GraphIt and run the experiments that compare the performance of the generated code on 9 datasets and 5 applications.</p>
<p>The second part of the README provides step-by-step instructions to write a new DSL with BuilDSL for matrix multiplication and implement a simple analysis on top of it before generating CPU and GPU code.</p>

},
keywords = {code generation, data-flow analysis, domain-specific languages, meta-programming, multi-stage programming}
}

@software{10.5281/zenodo.5789242,
author = {Li, Ao and Zheng, Bojian and Pekhimenko, Gennady and Long, Fan},
title = {Replication Packet for Article: Automatic Horizontal Fusion for GPU Kernels},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5789242},
abstract = {
    <p>This replication package provides the source code for article: Automatic Horizontal Fusion for GPU Kernels.</p>

},
keywords = {CUDA, GPU, Kernel Fusion, LLVM}
}

@software{10.5281/zenodo.5792202,
author = {Rivera, Joao and Franchetti, Franz and P\"{u}schel, Markus},
title = {Artifact: A Compiler for Sound Floating-Point using Affine Arithmetic},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5792202},
abstract = {
    <p>The artifact is in the form of a virtual machine running Ubuntu 20.04. It contains source code of SafeGen, benchmarks and scripts for reproducing main experiments of the paper.</p>

},
keywords = {affine arithmetic, floating-point arithmetic, guaranteed computations, source-to-source compiler}
}

@software{10.5281/zenodo.5866935,
author = {Vesely, Jan and Pothukuchi, Raghavendra Pradyumna and Joshi, Ketaki and Gupta, Samyak and Cohen, Jonathan D. and Bhattacharjee, Abhishek},
title = {Distill: Domain-Specific Compilation for Cognitive Models Evaluation Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5866935},
abstract = {
    <p>This artifact contains an image with the environments and experiments presented in: “Distill: Domain-Specific Compilation for Cognitive Models” [CGO’22, Seoul, South Korea].</p>
<p>This artifact is based on an older version of PsyNeuLink (April 2021), and no longer represents the latest version. For up-to-date information on PsyNeuLink, as well as any support with developing cognitive models please visit https://github.com/PrincetonUniversity/PsyNeuLink.</p>

},
keywords = {cognitive models, Domain-specific compilation, human brain, JIT compilers, LLVM, PsyNeuLink, Python.}
}

@software{10.6084/m9.figshare.17048447.v1,
author = {Olabi, Mhd Ghaith and Luna, Juan G\'{o}mez and Mutlu, Onur and Hwu, Wen-mei and El Hajj, Izzat},
title = {A Compiler Framework for Optimizing Dynamic Parallelism on GPUs},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.17048447.v1},
abstract = {
    <p>Our artifact is a compiler implemented within Clang for optimizing applications that use dynamic parallelism. Since building the compiler requires building Clang/LLVM which can be time and resource consuming, we provide pre-built binaries in a Docker image, along with the required dependences and the benchmarks/datasets on which the compiler has been evaluated. Reviewers can use these binaries to transform the CUDA code with our optimizations, then compile and run the code on a CUDA-capable GPU. Scripts are provided to automate this process.</p>

},
keywords = {compiler, CUDA kernel, GPU computing}
}

@software{10.6084/m9.figshare.17263274.v1,
author = {Rocha, Rodrigo C. O. and Petoumenos, Pavlos and Franke, Bj\"{o}rn and Bhatotia, Pramod and O'Boyle, Michael},
title = {Replication Package for Article, "Loop Rolling for Code Size Reduction"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.17263274.v1},
abstract = {
    <p>Artifact for the CGO 2022 paper titled: “Loop Rolling for Code Size Reduction”.</p>

},
keywords = {Code Size Reduction, Compiler, Compiler Optimization, LLVM, Loop Optimization}
}

@software{10.5281/zenodo.5821862,
author = {Georges, A\"{\i}na Linn and Trieu, Alix and Birkedal, Lars},
title = {Le Temps des Cerises: Efficient Temporal Stack Safety on Capability Machines using Directed Capabilities (Artifact)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5821862},
abstract = {
    <p>This the artifact accompanying the article “Le Temps des Cerises: Efficient Temporal Stack Safety on Capability Machines using Directed Capabilities”.</p>
<p>The artifact contains the Coq proofs accompanying the paper. These proofs are built using the Iris framework.</p>
<p>These proofs are available either as a .tar.gz archive, which can then be checked and compiled following the instructions in the README within, or as a virtual machine image for VirtualBox containing the already compiled Coq proofs. The VM does not require any password and has emacs with Proof General already installed to browse the proofs.</p>
<p>html/index.html provides a description of the files and how they correspond to statements in the paper. (You need to run make html first if compiling by yourself).</p>

},
keywords = {capability machines, CHERI, compilation, Coq, full abstraction, Iris, logical relations, separation logic}
}

@software{10.5281/zenodo.5834281,
author = {Paltenghi, Matteo and Pradel, Michael},
title = {Reproduction Package for "Bugs in Quantum Computing Platforms: An Empirical Study"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5834281},
abstract = {
    <p>It contains the bugs inspected in the study together with the minimized bug-fixing commits and a jupyter notebook to reproduce the result of the analysis.</p>

},
keywords = {braket, bug patterns, bug study, c# bugs, c++ bugs, circ, commit, dwave-system, empirical study, github, mitiq, open source quantum platforms, open source software, openql, oss, pennylane, projectq, pyquil, python bugs, q#, qalcs, qdk, qiskit, qiskit-aer, qiskit-ignis, qiskit-terra, quantum bug, quantum computing, quantum computing platforms, quantum programming languages, quantum programs, quantum software, quantum-specific bugs, software bug, software engineering, strawberryfields, tequila, xacc}
}

@software{10.5281/zenodo.6329773,
author = {Jacobs, Koen and Devriese, Dominique and Timany, Amin},
title = {Artifact OOPSLA22 - Purity of an ST Monad - Full Abstraction by Semantically Typed Back-Translation},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6329773},
abstract = {
    <p>Coq formalization of the results presented in the paper.</p>

},
keywords = {Coq, full abstraction, Iris, semantic typing, ST}
}

@software{10.5281/zenodo.6341551,
author = {Labrada, Elizabeth and Toro, Mat\'{\i}as and Tanter, \'{E}ric and Devriese, Dominique},
title = {Plausible Sealing for Gradual Parametricity: Supporting Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6341551},
abstract = {
    <p>This is the artifact accompanying the paper “Plausible Sealing for Gradual Parametricity”, to be published at OOPSLA 2022.</p>
<p>Graduality and parametricity have proven to be extremely challenging notions to bring together. Intuitively, enforcing parametricity gradually requires possibly sealing values in order to detect violations of uniform behavior. Toro et al.&nbsp;(2019) argue that the two notions are incompatible in the context of System F, where sealing is transparently driven by potentially imprecise type information, while New et al.&nbsp;(2020) reconcile both properties at the cost of abandoning the syntax of System F and requiring user-provided sealing annotations, which are not subject to graduality guarantees. Furthermore, all current proposals rely on a global form of dynamic sealing in order to enforce parametric behavior at runtime, which weakens parametric reasoning and breaks equivalences in the static language. Based on the observation that the tension between graduality and parametricity comes from the early commitment to seal values based on type information, we propose plausible sealing as a new intermediate language mechanism that allows postponing such decisions to runtime. We propose an intermediate language for gradual parametricity, Funky, which supports plausible sealing in a simplified setting where polymorphism is restricted to instantiations with base and variable types. We prove that Funky satisfies both parametricity and graduality, mechanizing key lemmas in Agda. Additionally, we avoid global dynamic sealing and instead propose a novel lexically-scoped form of sealing realized using a representation of evidence inspired by the category of spans. As a consequence, Funky satisfies a standard formulation of parametricity that does not break System F equivalences. In order to show the practicality of plausible sealing, we describe a translation from Funk, a source language without explicit sealing, to Funky, that takes care of inserting plausible sealing forms. We establish graduality of Funk, subject to a restriction on type applications, and explain the source-level parametric reasoning it supports. Finally, we provide an interactive prototype along with illustrative examples both novel and from the literature.</p>

},
keywords = {gradual parametricity
plausible sealing
parametricity
gradual typing}
}

@software{10.5281/zenodo.6342311,
author = {Le, Quang Loc and Raad, Azalea and Villard, Jules and Berdine, Josh and Dreyer, Derek and O'Hearn, Peter W.},
title = {Artifact and Appendix of "Finding Real Bugs in Big Programs with Incorrectness Logic"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6342311},
abstract = {
    <p>This is the artifact for the OOPSLA’22 paper “Finding Real Bugs in Big Programs with Incorrectness Logic”. It contains the scripts reproducing the results and proofs of the paper.</p>

},
keywords = {bug catching, compositionality, incorrectness logic, incorrectness proving}
}

@software{10.5281/zenodo.6342476,
author = {Lesani, Mohsen and Xia, Li-yao and Kaseorg, Anders and Bell, Christian J. and Chlipala, Adam and Pierce, Benjamin C. and Zdancewic, Steve},
title = {Coq formalization of C4: Verified Transactional Objects},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6342476},
abstract = {
    <p>A framework for Verified Transactional Objects in Coq.</p>
<ul>
<li>Formalization of concurrent objects, linearizability, strict serializability, and associated proof techniques.</li>
<li>Verified linearizable concurrent hash map</li>
<li>Verified strictly serializable TML</li>
<li>Verified strictly serializable transaction-predicated map</li>
</ul>

},
keywords = {concurrency, coq, formal verification, library}
}

@software{10.5281/zenodo.6370152,
author = {Dyer, Tristan and Nelson, Tim and Fisler, Kathi and Krishnamurthi, Shriram},
title = {Applying Cognitive Principles to Model-Finding Output: The Positive Value of Negative Information (artifact)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6370152},
abstract = {
    <p>This artifact includes an experimental model-finder that demonstrates the “2+1-” visualization mode from the paper. Additionally, working versions of all user interfaces used in the studies are included, as well as the raw and anonymized data for all participants in the quantitative studies and the anonymized audio transcripts for participants in the qualitative studies. In-depth instructions for how to access and use the included items are included in the artifact README.</p>

},
keywords = {Alloy, cognitive science, formal methods, Human-centered computing, model finding, user studies}
}

@software{10.5281/zenodo.6371291,
author = {Liu, Jiawei and Wei, Yuxiang and Yang, Sen and Deng, Yinlin and Zhang, Lingming},
title = {Coverage-Guided Tensor Compiler Fuzzing with Joint IR-Pass Mutation},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6371291},
abstract = {
    <p>This artifact is for the paper “Coverage-Guided Tensor Compiler Fuzzing with Joint IR-Pass Mutation” accepted by OOPSLA’22. It contains the original experimental statistics presented in the paper and source code to reproduce it with guidance.</p>

},
keywords = {fuzzing, machine learning system, tensor compiler}
}

@software{10.5281/zenodo.6372033,
author = {Li, Jialin and Lattuada, Andrea and Zhou, Yi and Cameron, Jonathan and Howell, Jon and Parno, Bryan and Hawblitzel, Chris},
title = {Linear VeriBetrKV Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6372033},
abstract = {
    <p>This artifact includes the VeribetrKV-DF and VeriBetrKV-LT described in the case study of the paper. It also includes details for the formalization of Linear Dafny.</p>

},
keywords = {linear types, system verification}
}

@software{10.5281/zenodo.6372830,
author = {Brachth\"{a}user, Jonathan Immanuel and Schuster, Philipp and Lee, Edward and Boruch-Gruszecki, Aleksander},
title = {Artifact of the paper "Effects, Capabilities, and Boxes: From Scope-based Reasoning to Type-based Reasoning and Back"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6372830},
abstract = {
    <p>The artifact consists of two parts:</p>
<ol type="1">
<li>Coq proofs, proving soundness of the calculus System C.</li>
<li>A website featuring an implementation of System C with examples that can be typechecked, edited, and run.</li>
</ol>

},
keywords = {coq proofs, effect handlers, effect safety, type systems}
}

@software{10.5281/zenodo.6384379,
author = {Machiry, Aravind and Kastner, John and McCutchen, Matt and Eline, Aaron and Headley, Kyle and Hicks, Michael},
title = {Reproduction and Source Code for the paper "C to Checked C by 3C"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6384379},
abstract = {
    <p>This artifact contains all the necessary instructions and software to reproduce the results in the paper along with instructions to re-use/re-purpose the software.</p>

},
keywords = {C, Checked C, Rewriting, Type Inference}
}

@software{10.5281/zenodo.5988606,
author = {Peduri, Anurudh and Bhat, Siddharth and Grosser, Tobias},
title = {QSSA: An SSA-based IR for Quantum Computing - Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5988606},
abstract = {
    <p>This is the artifact for our CC’22 paper “QSSA: An SSA-based IR for Quantum Computing”. It consists of a docker image containing full source code of our compiler, benchmarks and scripts for reproducing main experiments of the paper. We supply instructions on how to run the artifact evaluation in the appendix of our paper.</p>

},
keywords = {compilers, intermediate representations, optimization, quantum circuits, SSA}
}

@software{10.5281/zenodo.6313660,
author = {Wang, Huanting and Tang, Zhanyong and Zhang, Cheng and Zhao, Jiaqi and Cummins, Chris and Leather, Hugh and Wang, Zheng},
title = {Reproduction Package for Article 'Automating Reinforcement Learning Architecture Design for Code Optimization'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6313660},
abstract = {
    <p>The research artifact enables the reproduction of the main results of the paper. It provides instructions to download and run a preconfigured Docker image to reproduce the results and customize the experiments.</p>

},
keywords = {code optimization, Compiler optimization, reinforcement learning}
}

@software{10.5281/zenodo.6330043,
author = {Xu, Yufan and Raje, Saurabh and Rountev, Atanas and Sabin, Gerald and Sukumaran-Rajam, Aravind and Sadayappan, P.},
title = {Reproduction package for "Training of Deep Learning Pipelines on Memory-Constrained GPUs via Segmented Fused-Tiled Execution"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6330043},
abstract = {
    <p>The artifact contains all the scripts and data required to reproduce the experimental results in the CC 2022 paper titled “ Training of Deep Learning Pipelines on Memory-Constrained GPUs via Segmented Fused-Tiled Execution”. The git repository contains: 1)The SFT source code; 2)The scripts to measure execution time of default PyTorch, PyTorch checkpoint, and SFT; 3)Raw data that we used to plot Fig. 8 (for comparison).</p>

},
keywords = {Checkpointing, DNN, Fusion, GPU, Large image training, Memory-constrained execution, Tiling}
}

@software{10.5281/zenodo.6330172,
author = {Sahebolamri, Arash and Gilray, Thomas and Micinski, Kristopher},
title = {Ascent},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6330172},
abstract = {
    <p>Source code of Ascent, a logic programming language (similar to Datalog) embedded in Rust via macros.</p>

},
keywords = {Datalog, Logic Programming, Program Analysis, Rust}
}

@software{10.5281/zenodo.6345727,
author = {Gerard, Blake and Grosser, Tobias and Kong, Martin},
title = {BlakeGerard/qrane-artifact:},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.6345727},
abstract = {
    <p>This artifact contains a version of our proposed tool, Qrane, along with all of the data and scripts needed to run each experiment in the paper. The artifact is presented as a public GitHub repository. It also comes with a Dockerfile to load the repository onto a Docker image with all dependencies installed, if the user wishes to take that route. Within the repository, you will find a README with instructions to run the one wrapper script that will automatically run all experiments. The wrapper script will invoke Qrane on the provided datasets used in the paper, and dump all intermediate files to a specified directory. It will then generate similar plots to those found in the Experiment and Supplemental sections of the paper (with some variation from machine thread-usage and optional tweaking of Qrane flags, if desired).</p>

},
keywords = {delinearization, polyhedral model, quantum affine computing., quantum assembly}
}

@software{10.6084/m9.figshare.19249817.v1,
author = {Mogers, Naums and Li, Lu and Radu, Valentin and Dubach, Christophe},
title = {Artifact for the paper "Mapping Parallelism in a Functional IR through Constraint Satisfaction"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.19249817.v1},
abstract = {
    <p>This artifact contains the parallel code generator Lift which is described in the CC 2022 paper “Mapping Parallelism in a Functional IR through Constraint Satisfaction”. Furthermore, this artifact contains the Docker image, scripts and best-found convolution kernels required to reproduce the performance and search efficiency results presented in the paper. To validate the results, build Lift, run the best-found VGG-16 convolution kernels on a Mali GPU board, and, finally use the plotting script to reproduce the results from Figure 4 in the paper. We also provide scripts to perform time-intensive parallel mapping space exploration and discover the best parallelizations for each layer of VGG-16 for a given Mali GPU board, as well as measure exploration duration to reproduce Figure 5 in the paper.</p>

},
keywords = {code generation, convolution, mobile GPU, parallelism}
}

@software{10.1145/3462303,
author = {Niu, Yue and Sterling, Jonathan and Grodin, Harrison and Harper, Robert},
title = {agda-calf},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462303},
abstract = {
    <p>The calf language is a cost-aware logical framework for studying quantitative aspects of (parallel) functional programs. agda-calf is the implementation of calf in the Agda proof assistant and comes bundled with the calf mechanization of various case studies.</p>

},
keywords = {algorithm analysis, amortized analysis, behavioral verification, cost models, equational reasoning, intensional property, mechanized proof, modal type theory, noninterference, parallel algorithms, phase distinction, proof assistants, recurrence relations}
}

@software{10.1145/3462304,
author = {Ciccone, Luca and Padovani, Luca},
title = {FairCheck},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462304},
abstract = {
    <p>FairCheck is a proof-of-concept implementation of the type system described in the paper Fair Termination of Binary Sessions in the proceedings of POPL 2022. FairCheck parses a distributed program modeled in a session-oriented variant of the π-calculus and verifies that: (1) There exists a typing derivation for each definition in the program using the algorithmic version of the type system; (2) Each process definition is action bounded, namely there exists a finite branch leading to termination; (3) Each process definition is session bounded, namely the number of sessions the process needs to create in order to terminate is bounded; (4) Each process definition is cast bounded, namely the number of casts the process needs to perform in order to terminate is bounded.</p>

},
keywords = {deadlock-freedom, fairness, liveness-checker, pi-calculus, session-types, type-checker}
}

@software{10.1145/3462305,
author = {Hou (Favonia), Kuen-Bang and Wang, Zhuyang},
title = {Replication Package for Article: Logarithm and Program Testing},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462305},
abstract = {
    <p>This artifact contains the our Haskell implementation and experiments on it for the article Logarithm and Program Testing. It contains the following components: 1. README.txt: instructions to build and run the experiments and evaluate claims in the article. 2. polycheck-qc: our library with the QuickCheck backend. 3. polycheck-sc: our library with the SmallCheck backend. 4. polycheck-qc-draw: scripts for the distribution figures. 5. Dockerfile, Dockerfile-draw: Dockerfiles to reproduce the results.</p>

},
keywords = {Haskell, property-based testing}
}

@software{10.1145/3462306,
author = {Castagna, Giuseppe and Laurent, Micka\"{e}l and Nguy\~{\^e}n, Kim and Lutze, Matthew},
title = {Prototype Typechecker for the Article 'On Type-Cases, Union Elimination, and Occurrence Typing'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462306},
abstract = {
    <p>The artifact is the prototype of the typechecker used to provide experimental results in the article ‘On Type-Cases, Union Elimination, and Occurrence Typing’. It features an implementation of the inference algorithm presented in the paper (as well as several extensions documented in the supplementary appendix).</p>

},
keywords = {Intersection Types, Occurrence Typing, Set-Theoretic Types, Type Inference., Type-Checking, Union Types}
}

@software{10.1145/3462308,
author = {M\"{u}ller, Mark Niklas and Makarchuk, Gleb and Singh, Gagandeep and P\"{u}schel, Markus and Vechev, Martin},
title = {Artifact for article: PRIMA: General and Precise Neural Network Certification via Scalable Convex Hull Approximations},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462308},
abstract = {
    <p>Codebase for the ERAN verification framework including the verifier PRIMA (domains “refinepoly” or “refinegpupoly”) and scripts to reproduce the results reported in “PRIMA: General and Precise Neural Network Certification via Scalable Convex Hull Approximations”.</p>

},
keywords = {Abstract Interpretation, Convexity, Polyhedra, Robustness}
}

@software{10.1145/3462309,
author = {Chen, Taolue and Flores-Lamas, Alejandro and Hague, Matthew and Han, Zhilei and Hu, Denghang and Kan, Shuanglong and Lin, Anthony W. and R\"{u}mmer, Philipp and Wu, Zhilin},
title = {String solver and benchmarks from 'Solving String Constraints with Regex-Dependent Functions through Transducers with Priorities and Variables'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462309},
abstract = {
    <p>Experiments in the article ‘Solving String Constraints with Regex-Dependent Functions through Transducers with Priorities and Variables’ were done using a version of the OSTRICH SMT solver, extended with support for PSSTs and the string functions described in the article. The artifact contains binaries (as Java bytecode) and sources (Scala) of this extended solver, in directory ostrich/, as well as benchmarks used in the evaluation.</p>

},
keywords = {String solving
SMT solver
Regular expressions}
}

@software{10.1145/3462311,
author = {Zhang, Yihong and Wang, Yisu Remy and Willsey, Max and Tatlock, Zachary},
title = {Artifact for "Relational E-matching"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462311},
abstract = {
    <p>https://github.com/yihozhang/relational-ematching-benchmark/commit/584156fe84b3862c862da6b3ee15320e8c8a7cf1</p>
<p>This is the artifact for the POPL 2022 paper “Relational E-matching”. A copy can be found on arXiv.</p>
<p>The paper introduces a new way to solve the e-matching problem using techniques from relational databases. In particular, our implementation uses an algorithm called generic join. The evaluation compares our approach (referred to in the paper and here as GJ) with a traditional e-matching algorithm (referred to as EM).</p>
<p>This artifact aims to reproduce Figure 9 and Table 1.</p>

},
keywords = {e-graphs, e-matching, generic join, relational database}
}

@software{10.1145/3462312,
author = {Raad, Azalea and Maranget, Luc and Vafeiadis, Viktor},
title = {X86_64 Memory Type Tests.},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462312},
abstract = {
    <p>This set of web pages explores the effect of X86_64 memory types on memory model. This is companion material to our article “Extending Intel-x86 Consistency and Persistency: Formalising the Semantics of Intel-x86 Memory Types and Non-Temporal Stores” by A. Raad, L. Maranget, V. Vafeiadis.</p>
<p>A dedicated section “Reproduce some experiments” describes two experiments to be performed on a Linux system: reproducing our main experiment and running our tests on hardware. This will demonstrate tools from the herdtools7 toolbox at work.</p>

},
keywords = {memory model, programming language semantics, shared memory concurrency., X86_64}
}

@software{10.1145/3462313,
author = {Miltner, Anders and Nu\~{n}ez, Adrian Trejo and Brendel, Ana and Chaudhuri, Swarat and Dillig, Isil},
title = {Replication Package for Artifact: Bottom-Up Synthesis of Recursive Functional Programs using Angelic Execution},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462313},
abstract = {
    <p>This archive contains the code and benchmarks for the paper Bottom-Up Synthesis of Recursive Functional Programs using Angelic Execution.</p>
<p>Instructions for installation and build, instructions for reproduction of the results, and a description of the structure of the repository, are all available in the file $/README.pdf.</p>

},
keywords = {finite tree automata, functional programming, program synthesis, recursion}
}

@software{10.5281/zenodo.5549765,
author = {Madiot, Jean-Marie and Pottier, Fran\c{c}ois},
title = {A Separation Logic for Heap Space under Garbage Collection - Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5549765},
abstract = {
    <p>This is the artifact corresponding to the article entitled A Separation Logic for Heap Space under Garbage Collection, and its associated documentation.</p>

},
keywords = {live data, program verification, separation logic, tracing garbage collection}
}

@software{10.5281/zenodo.5550765,
author = {Kokologiannakis, Michalis and Marmanis, Iason and Gladstein, Vladimir and Vafeiadis, Viktor},
title = {Replication Package for "Truly Stateless, Optimal Dynamic Partial Order Reduction"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5550765},
abstract = {
    <p>We consider our paper’s artifact to be the included version of TruSt, as well as the results we got by running the various tools on our benchmarks set. We stress that the results obtained for the same benchmarks by TruSt in the future might differ, as the tool will evolve.</p>
<p>We have made TruSt publicly available as part of GenMC: https://github.com/MPI-SWS/genmc. For any bugs, comments, or feedback regarding TruSt, please do not hesitate to contact us.</p>

},
keywords = {Dynamic Partial Order Reduction, Model Checking, Weak Memory Models}
}

@software{10.5281/zenodo.5553753,
author = {Wang, Yuting and Zhang, Ling and Shao, Zhong and Koenig, J\'{e}r\'{e}mie},
title = {Artifact: Verified Compilation of C Programs with a Nominal Memory Model},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5553753},
abstract = {
    <p>This is the artifact for the POPL 2022 paper “Verified Compilation of C Programs with a Nominal Memory Model”.</p>
<p>The artifact is a VM image in .ova format. We have tested the VM in VirtualBox 6.1.26 running on a host linux machine with 64-bit Ubuntu LTS 20.04. The source code can be found in the directory ‘/home/authors/nominal-compcert-popl22-artifact’. Follow the ‘READM.md’ file to evaluate the artifact. You can also open the README file with Firefox browser for improved readability.</p>
<p>If you prefer to compile from the source code on your local machine (Linux or Mac), please find the source code at the following address:</p>
<p>https://github.com/SJTU-PLV/nominal-compcert-popl22-artifact</p>
<p>The prerequisites are the same as for CompCert. You need to setup Coq 8.12, install necessary software (e.g., menhir), and run the configuration and make files in each directory as follows:</p>
<p>./configure x86_64-linux make</p>
<p>See CompCert’s user manual for more details.</p>

},
keywords = {Memory Models, Nominal Techniques, Verified Compilation}
}

@software{10.5281/zenodo.5553759,
author = {Li, Yuanbo and Satya, Kris and Zhang, Qirun},
title = {Implementation for "Efficient Algorithms for Dynamic Bidirected Dyck-Reachability"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5553759},
abstract = {
    <p>The artifact includes the implementation for the algorithm proposed in the paper “Efficient Algorithms for Dynamic Bidirected Dyck-Reachability”. It also include the necessary componenet of DDlog Data solver for the evaluation.</p>
<p>The artifact contains two main parts: The DynDyck implementation and the DDlog tool. We implement the dynamic Dyck-reachability algorithm for bidirected graphs in the directory <code>/root/popl_2022/dynamic</code>. The <code>/root/popl_2022/ddlog</code> directory contains the DDlog tool. The <code>/root/popl_2022/benchmark</code> directory contains the two benchmarks evaluated in our experiments.</p>

},
keywords = {bidirected graphs, Dyck-reachability, Dynamic graph algorithms, incremental analysis}
}

@software{10.5281/zenodo.5568850,
author = {Blanvillain, Olivier and Brachth\"{a}user, Jonathan Immanuel and Kjaer, Maxime and Odersky, Martin},
title = {Type-Level Programming with Match Types Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5568850},
abstract = {
    <p>This VM contains everything necessary to run the supplementary material of the “Type-Level Programming with Match Types” paper. To run this VM in VirtualBox:</p>
<ol type="1">
<li>Install Oracle VM VirtualBox (see instructions: Downloads – Oracle VM VirtualBox)</li>
<li>Click on the .ova file to import it into VirtualBox</li>
<li>Start the VM, then open the README.md file on the desktop for further instructions</li>
</ol>

},
keywords = {Match Types, Scala}
}

@software{10.5281/zenodo.5576388,
author = {Yuan, Charles and McNally, Christopher and Carbin, Michael},
title = {Artifact for Article: Twist: Sound Reasoning for Purity and Entanglement in Quantum Programs},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5576388},
abstract = {
    <p>This artifact supports the POPL’22 paper “Twist: Sound Reasoning for Purity and Entanglement in Quantum Programs” by Charles Yuan, Chris McNally, and Michael Carbin.</p>
<p>The artifact contains necessary materials to reproduce the evaluation of the paper, including sources of the interpreter for the Twist language, benchmark programs, and scripts to execute the evaluation.</p>

},
keywords = {entanglement, purity, quantum programming, type systems}
}

@software{10.5281/zenodo.5576679,
author = {Lim, Jay P. and Nagarakatte, Santosh},
title = {RLIBM-ALL: One Polynomial Approximation to Produce Correctly Rounded Results of an Elementary Function for Multiple Representations and Rounding Modes},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5576679},
abstract = {
    <p>We present the artifact for the accepted paper, One Polynomial Approximation to Produce Correctly Rounded Results of an Elementary Function for Multiple Representations and Rounding Modes. We describe the list of claims made by the paper, the installation instructions, and evaluation instructions. To ease the installation effort, we provide a docker image with all required softwares installed already. Additionally, we provide complete instructions to manually install the artifact on Ubuntu 20.04.</p>

},
keywords = {Correctly Rounded Elementary Functions, RLIBM, RLIBM-ALL, Round-to-odd}
}

@software{10.5281/zenodo.5586354,
author = {Hirsch, Andrew K. and Garg, Deepak},
title = {Coq Code for 'Pirouette: Higher-Order Typed Functional Choreographies'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5586354},
abstract = {
    <p>Coq code describing Pirouette, a higher-order typed functional choreography language. Contains code for all constructions in the paper along with formal proofs of every theorem in the paper. Pirouette is defined with reference to a local language, which can be given as a module.</p>

},
keywords = {choreographies, concurrent programming, coq, formal proofs, Functional languages}
}

@software{10.5281/zenodo.5598485,
author = {Tan, Bryan and Mariano, Benjamin and Lahiri, Shuvendu K. and Dillig, Isil and Feng, Yu},
title = {Replication Package for for SolType: Refinement Types for Arithmetic Overflow in Solidity},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5598485},
abstract = {
    <p>A collection of scripts and benchmarks for (partially) reproducing the results of the SolType evaluation.</p>

},
keywords = {automated verification, integer overflow, refinement type inference, smart contracts}
}

@software{10.5281/zenodo.5604551,
author = {Liu, Amanda and Bernstein, Gilbert Louis and Chlipala, Adam and Ragan-Kelley, Jonathan},
title = {Verified Scheduling Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5604551},
abstract = {
    <p>This artifact contains a virtual machine containing the source code and dependencies for building our Coq framework and running the tests and benchmarks as described in our accompanying paper. It also includes a README containing documentation and instructions for building and running components of this artifact.</p>

},
keywords = {Coq, formal verification, Halide, image processing, optimization, proof assistants}
}

@software{10.5281/zenodo.5628699,
author = {Ikebuchi, Mirai and Erbsen, Andres and Chlipala, Adam},
title = {Code Artifact for Certifying Derivation of State Machines from Coroutines},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5628699},
abstract = {
    <p>This artifact is for the paper “Certifying Derivation of State Machines from Coroutines” to appear at POPL 2022.</p>
<p>The code tarball includes our Coq development, the TLS case study, and supporting infrastructure for running extracted code using dependencies implemented in Haskell. The Virtual machine image also contains all dependencies for development and evaluation.</p>

},
keywords = {coroutines, cryptographic protocols, interaction trees, nested state machines, program derivation, proof assistants}
}

@software{10.5281/zenodo.5652106,
author = {Ye, Qianchuan and Delaware, Benjamin},
title = {Oblivious Algebraic Data Types: POPL22 Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5652106},
abstract = {
    <p>This artifact holds the Coq formalization of Oblivious Algebraic Data Types, a language for writing secure computation with recursive data types whose structures are protected. More specifically, it formalizes the two core calculi, λOADT and λOADT✚, from the POPL22 paper Oblivious Algebraic Data Types, and proves their soundness and obliviousness.</p>
<p>This artifact contains 3 files:</p>
<ul>
<li><p>oadt-pure-popl22.zip: λOADT formalization. It is a snapshot of tag pure-popl22 (commit b34546f).</p></li>
<li><p>oadt-tape-popl22.zip: λOADT✚ formalization. It is a snapshot of tag tape-popl22 (commit 32d8fc4).</p></li>
<li><p>oadt-popl22.ova: virtual machine image.</p></li>
</ul>

},
keywords = {algebraic data types, coq, dependent types, multiparty computation, oblivious computation}
}

@software{10.5281/zenodo.5652640,
author = {Jeon, Minseok and Oh, Hakjoo},
title = {Return of CFA: Call-Site Sensitivity Can Be Superior to Object Sensitivity Even for Object-Oriented Programs},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5652640},
abstract = {
    <p>This artifact aims to reproduce the results in Table 2~6, which experimentally show that call-site sensitivity is more precise than existing state-of-the-art object sensitivities. POPL_2022_paper586.ova is a bootable VirtualBox image with all of the necessary libraries installed. ArtifactManual.pdf provides instructions to check whether the artifact is installed correctly (Section 1). Section 2 presents how to reproduce the results in our paper. Section 3 illustrates how to analyze other programs with our artifact and how to analyze a program with a user-defined tunneling abstraction.</p>

},
keywords = {Context sensitivity, Machine learning for program analysis, Pointer analysis}
}

@software{10.5281/zenodo.5655530,
author = {Heunen, Chris and Kaarsgaard, Robin},
title = {Artifact for 'Quantum Information Effects'},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5655530},
abstract = {
    <p>This is an implementation of the languages UPi, UPi_a, and UPi^chi_a and all related constructions, described in the paper Quantum Information Effects by Chris Heunen and Robin Kaarsgaard.</p>
<p>This artifact contains the implementation of the constructions and translations relating to UPi, UPi_a, and UPi^chi_a. These languages are implemented as eDSLs in (heavily extended Glasgow) Haskell. They have been tested to work with the GHC Haskell compilation system version 8.10.1 on macOS 11.6 Big Sur, as well as 8.6.5 on Ubuntu 20.04.</p>
<p>Though Haskell supports arrows via the Arrow type class, the implementation in Haskell only permits arrows over Haskell functions (i.e., over the type a -&gt; b) rather than over an arbitrary Category instance. For this reason, though the and constructions are arrows, they cannot be implemented as such. Instead, we have chosen to name the arrow combinators with suggestive but non-conflicting names, such as arr’, first’, left’, and so forth.</p>
<p>The code is structured as follows:</p>
<p>UPiBase.hs: Contains the data type declaration for UPi combinators. UPi.hs: Implementation of all (derived) UPi combinators, including the quantum gates described in Section 3.2. UPiaBase.hs: Contains the data type declaration for UPi_a combinators, as well as the declaration of the type classes Cloneable and Inhabited used to define the clone and inhab combinators respectively. Since all UPi_a types have a Cloneable instance, the Cloneable constraint is trivial (but Haskell doesn’t know that). UPia.hs: Contains the implementation of all (derived) combinators of UPi_a, as described in Section 3.3. UPichiaBase.hs: Contains the data type declaration for UPi^chi_a combinators, as well as the declaration of the Discardable type class used to handle projections. Again, all UPi^chi_a types have Discardable instances, so the constraint is trivial, but Haskell doesn’t know that. UPichia.hs: Contains the implementation of all (derived) combinators relating to UPi^chi_a, see Section 3.4. QFC.hs: Contains the translation from quantum flow charts to UPi^chi_a as described in Section 6.2.</p>

},
keywords = {arrows, information effects, quantum computing, reversible computing}
}

@software{10.5281/zenodo.5662349,
author = {Lepigre, Rodolphe and Sammler, Michael and Memarian, Kayvan and Krebbers, Robbert and Dreyer, Derek and Sewell, Peter},
title = {Artifact and Appendix of "VIP: Verifying Real-World C Idioms with Integer-Pointer Casts"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5662349},
abstract = {
    <p>This is the artifact for the POPL’22 paper “VIP: Verifying Real-World C Idioms with Integer-Pointer Casts”. It contains an extended version of the RefinedC and Cerberus tools with the presented VIP memory model, as well as examples, evaluation data, and the technical appendix for the paper.</p>

},
keywords = {C programming language, Coq, Iris, memory model, pointer provenance, proof automation, separation logic}
}

@software{10.5281/zenodo.5662717,
author = {Loehr, Devon and Walker, David},
title = {POPL22 Pipe AEC Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5662717},
abstract = {
    <p>This artifact contains a copy of the source code for the Lucid executable, as of POPL22’s AEC evaluation period. It also contains a vagrant box with the necessary tools to build the executable, as well as instructions for running the artifact and a link to the github repo containing the most up-to-date source code. Full instructions are contained in the README file included with the artifact.</p>

},
keywords = {Network programming languages, P4, PISA, type and effect systems}
}

@software{10.5281/zenodo.5662934,
author = {Porncharoenwase, Sorawee and Nelson, Luke and Wang, Xi and Torlak, Emina},
title = {"A formal foundation for symbolic evaluation with merging" Artifact},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5662934},
abstract = {
    <p>The artifact contains: - mechanization of our symbolic semantics and proof of its correctness - a reference interpreter named Leanette, which is proven correct. - solver-aided differential testing setup to test that Leanette agrees with Rosette 4 (https://github.com/emina/rosette), a new Rosette system that implements the symbolic semantics with an optimized symbolic factory - tools that test performance and compare interface of Rosette 4 vs Rosette 3 (the previous Rosette system)</p>

},
keywords = {state merging, symbolic evaluation}
}

@software{10.5281/zenodo.5667545,
author = {G\"{a}her, Lennard and Sammler, Michael and Spies, Simon and Jung, Ralf and Dang, Hoang-Hai and Krebbers, Robbert and Kang, Jeehoon and Dreyer, Derek},
title = {Coq development and technical documentation for "Simuliris: A Separation Logic Framework for Verifying Concurrent Program Optimizations"},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5667545},
abstract = {
    <p>This is the artifact for the paper “Simuliris: A Separation Logic Framework for Verifying Concurrent Program Optimizations”. It contains the Coq mechanization of Simuliris, in particular the logic, its soundness proof, and the examples described in the paper. The artifact contains the Simuliris development both in a VM image with pre-built sources and as a .zip source archive. In addition, the technical appendix is included.</p>

},
keywords = {Coq, data races, Iris, program optimizations, separation logic}
}

@software{10.5281/zenodo.5668206,
author = {Fiore, Marcelo and Szamozvancev, Dmitrij},
title = {Source code repository for article: Formal Metatheory of Second-Order Abstract Syntax},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5668206},
abstract = {
    <p>GitHub repository for the Agda source of the language-formalisation framework. Includes the formalisation of the abstract metatheory along with initiality proofs, the Python code generation script, and a wide range of examples.</p>

},
keywords = {abstract syntax, Agda, category theory, language formalisation}
}

@software{10.5281/zenodo.5668357,
author = {Pujet, Lo\"{\i}c and Tabareau, Nicolas},
title = {A Logical Relation for Setoid Type Theory in Agda},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5668357},
abstract = {
    <h2 id="a-logical-relation-for-setoid-type-theory-in-agda">A Logical Relation for Setoid Type Theory in Agda</h2>
<p>This is a formalized proof of the decidability of conversion for an extension of Martin L\"{o}f type theory with an equality satisfying UIP, function extensionality, and propositional extensionality.</p>
<p>The source code can be browsed in HTML <a href="https://htmlpreview.github.io/?https://github.com/CoqHott/logrel-mltt/blob/setoid-universes-hierarchy/html/README.html">here</a>.</p>
<p>The companion paper can be found <a href="https://hal.inria.fr/hal-03367052">here</a></p>
<h4 id="setoid-type-theory">Setoid Type Theory</h4>
<p>The type theory under scrutiny is a simplified version of TT<sup>obs</sup>, as described in the companion paper. It features: - A hierarchy of universes for proof-relevant types, and one for proof-irrelevant types, - dependent products, with domain and codomain in any universe, - dependent pairs with proof-irrelevant domain and codomain (“existential types”), - proof-irrelevant identity types and type casting along equalities in the universes, - natural numbers and a proof-irrelevant empty type. However, it is subject to the following restrictions: - The universe hierarchies are restricted to two levels, - no general inductive types, - no equality types \`{a} la Swan, - no quotient types.</p>
<p>The interested reader is invited to consult either the companion paper or the formalized definitions for a more detailed account of TT<sup>obs</sup>.</p>
<h4 id="structure-of-the-proof">Structure of the proof</h4>
<p>The raw, untyped syntax is defined inductively, followed by an inductive definition of the typing derivations of TT<sup>obs</sup>.</p>
<p>The proof then relies on Agda’s implementation of induction-recursion to define a logical relation that characterizes the computational behaviour of the typing judgments. Some basic properties of this logical relation are then established, in order to prove the <em>fundamental lemma</em>, which states that any derivable judgement satisfies the logical relation.</p>
<p>Once the fundamental lemma has been proven, it entails several fundamental properties of the type theory, such as the termination of the weak-head reduction strategy, the canonicity of the integers, typing inversion results, etc.</p>
<p>This first part lays the foundation necessary to the definition of an algorithmic equality relation on types and terms. We can prove that this algorithmic equality is decidable, and, using the fundamental lemma, that it coincides with the judgmental equality. It follows that the judgmental equality of terms and types is decidable.</p>
<p>A more detailed, but still high-level overview of the proof is provided in the companion paper.</p>
<h4 id="files">Files</h4>
<p>A more detailed description of the role of each file can be found in README.agda</p>
<h4 id="dependencies">Dependencies</h4>
<p>This project is written in Agda. It has been tested to be working with Agda version 2.6.3.</p>
<h4 id="warning">Warning</h4>
<p>The reader who wishes to type-check the entire proof should be warned that the files Defintion/LogicalRelations/Substitution/Introductions/Cast.agda and Conversion/Decidable.agda may be quite resource-intensive (Type-checking the latter seems to take at least 10 min on a higher-end laptop).</p>

},
keywords = {Agda, Logical Relations, Type Theory}
}

@software{10.5281/zenodo.5668384,
author = {Perera, Roly and Nguyen, Minh and Petricek, Tomas and Wang, Meng},
title = {Implementation for article: Linked Visualisations via Galois Dependencies},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5668384},
abstract = {
    <p>Proof-of-concept implementation of data-linked visualisations.</p>

},
keywords = {data visualisation, dependency analysis, program slicing, provenance}
}

@software{10.5281/zenodo.5671746,
author = {Choudhury, Vikraman and Karwowski, Jacek and Sabry, Amr},
title = {Artifact for Symmetries in Reversible Programming},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5671746},
abstract = {
    <p>This artifact contains the accompanying formalisation for the POPL’22 paper “Symmetries in Reversible Programming: From Symmetric Rig Groupoids to Reversible Programming Languages”.</p>
<p>The purpose of this artifact is to:</p>
<ul>
<li><p>Provide a partial formalisation of the semantics presented in the paper and related results.</p></li>
<li><p>Show applications of the semantics, using a collection of examples showing normalisation-by-evaluation, synthesis, and equivalence of reversible circuits written in the Pi language.</p></li>
</ul>

},
keywords = {categorical semantics, computational group theory, denotational semantics, homotopy type theory, reversible computing, reversible programming languages}
}

@software{10.5281/zenodo.5675249,
author = {Jacobs, Jules and Balzer, Stephanie and Krebbers, Robbert},
title = {Connectivity Graphs: A Method for Proving Deadlock Freedom Based on Separation Logic (Artifact)},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5675249},
abstract = {
    <p>The artifact for the paper “Connectivity Graphs: A Method for Proving Deadlock Freedom Based on Separation Logic”. It contains the Coq sources for the connectivity graph framework and a mechanisation of the deadlock freedom property of a binary session typed lambda calculus. The file readme.pdf contains a full description.</p>

},
keywords = {Coq, deadlock freedom, formal proof, graphs., mechanised proof, separation logic, Session types}
}

@software{10.5281/zenodo.5676412,
author = {K, Hari Govind V and Shoham, Sharon and Gurfinkel, Arie},
title = {Replication Instructions for paper: CHCs modulo ADTs and RF},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5676412},
abstract = {
    <p>The artifact contains instructions to replicate results from the paper titled Constrained Horn Clauses modulo Algebraic Data Types and Recursive Functions. It also contains links to the source code, a docker image will all necessary executables, and benchmarks.</p>

},
keywords = {Algebraic Data Types, Formal verification, Model Checking, Recursive Functions}
}

@software{10.5281/zenodo.5707114,
author = {Kjelstr\o{}m, Adam Husted and Pavlogiannis, Andreas},
title = {Replication package for article: The Decidability and Complexity of Interleaved Bidirected Dyck Reachability},
year = {2022},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5707114},
abstract = {
    <p>Paper : The Decidability and Complexity of Interleaved Bidirected Dyck Reachability, POPL’22</p>
<p>Artifact Outline - In the above paper, we present an algorithm for solving interleaved, bidirected <span class="math inline"><em>D</em><sub>1</sub> ⊙ <em>D</em><sub>1</sub></span> reachability in <span class="math inline"><em>O</em>(<em>n</em><sup>3</sup><em>α</em>(<em>n</em>))</span>, where a is the inverse Ackermann function. We have implemented this algorithm along with techniques for pre-processing and simplifying input graphs and run it on Dacapo Benchmarks.</p>
<p>We also present an algorithm for solving interleaved, bidirected <span class="math inline"><em>D</em><sub>1</sub> ⊙ <em>D</em><sub><em>k</em></sub></span> reachability in <span class="math inline"><em>O</em>(<em>n</em><sup>2</sup><em>α</em>(<em>n</em>))</span> with <span class="math inline"><em>O</em>(<em>n</em>)</span> bounded counters. We have also implemented this algorithm along with pre-processing and simplification and run it on Dacapo Benchmarks.</p>
<p>We have implemented the algorithms in C++.</p>

},
keywords = {bidirected graphs, CFL/Dyck reachability, complexity, static analysis}
}

@software{10.1145/3506805,
author = {Kaiser, Magdalena and Roy, Rishiraj Saha and Weikum, Gerhard},
title = {Reinforcement Learning from Reformulations in Conversational Question Answering over Knowledge Graphs},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3506805},
abstract = {
    <p>The rise of personal assistants has made conversational question answering (ConvQA) a very popular mechanism for user-system interaction. State-of-the-art methods for ConvQA over knowledge graphs (KGs) can only learn from crisp question-answer pairs found in popular benchmarks. In reality, however, such training data is hard to come by: users would rarely mark answers explicitly as correct or wrong. In this work, we take a step towards a more natural learning paradigm - from noisy and implicit feedback via question reformulations. A reformulation is likely to be triggered by an incorrect system response, whereas a new follow-up question could be a positive signal on the previous turn's answer. We present a reinforcement learning model, termed CONQUER, that can learn from a conversational stream of questions and reformulations. CONQUER models the answering process as multiple agents walking in parallel on the KG, where the walks are determined by actions sampled using a policy network. This policy network takes the question along with the conversational context as inputs and is trained via noisy rewards obtained from the reformulation likelihood. To evaluate CONQUER, we create and release ConvRef, a benchmark with about 11k natural conversations containing around 205k reformulations. Experiments show that CONQUER successfully learns to answer conversational questions from noisy reward signals, significantly improving over a state-of-the-art baseline.</p>
},
keywords = {Explanations, Influence functions, Recommendation Systems}
}

@software{10.1145/3506802,
author = {Draws, Tim Draws and Tintarev, Nava and Gadiraju, Ujwal and Bozzon, Alessandro and Timmermans, Benjamin},
title = {This Is Not What We Ordered: Exploring Why Biased Search Result Rankings Affect User Attitudes on Debated Topics},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3506802},
abstract = {
    In web search on debated topics, algorithmic and cognitive biases strongly influence how users consume and process information. Recent research has shown that this can lead to a search engine manipulation effect (SEME): when search result rankings are biased towards a particular viewpoint, users tend to adopt this favored viewpoint. To better understand the mechanisms underlying SEME, we present a pre-registered, 5 \texttimes{} 3 factorial user study investigating whether order effects (i.e., users adopting the viewpoint pertaining to higher-ranked documents) can cause SEME. For five different debated topics, we evaluated attitude change after exposing participants with mild pre-existing attitudes to search results that were overall viewpoint-balanced but reflected one of three levels of algorithmic ranking bias. We found that attitude change did not differ across levels of ranking bias and did not vary based on individual user differences. Our results thus suggest that order effects may not be an underlying mechanism of SEME. Exploratory analyses lend support to the presence of exposure effects (i.e., users adopting the majority viewpoint among the results they examine) as a contributing factor to users’ attitude change. We discuss how our findings can inform the design of user bias mitigation strategies.
},
keywords = {HCI design and evaluation methods, Human-centered computing, Information systems, User studies, Web searching and information discovery}
}

@software{10.1145/3506803,
author = {Ghosh, Avijit and Dutt, Ritam and Wilson, Christo},
title = {When Fair Ranking Meets Uncertain Inference},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3506803},
abstract = {
    <p>Existing fair ranking systems, especially those designed to be demographically fair, assume that accurate demographic information about individuals is available to the ranking algorithm. In practice, however, this assumption may not hold --- in real-world contexts like ranking job applicants or credit seekers, social and legal barriers may prevent algorithm operators from collecting peoples' demographic information. In these cases, algorithm operators may attempt to infer peoples' demographics and then supply these inferences as inputs to the ranking algorithm. <br> In this study, we investigate how uncertainty and errors in demographic inference impact the fairness offered by fair ranking algorithms. Using simulations and three case studies with real datasets, we show how demographic inferences drawn from real systems can lead to unfair rankings. Our results suggest that developers should not use inferred demographic data as input to fair ranking algorithms, unless the inferences are extremely accurate.</p>

},
keywords = {algorithmic fairness, demographic inference, ethical ai, noisy protected attributes, ranking algorithms, uncertainty}
}

@software{10.1145/3506804,
author = {Hiep Tran, Khanh and Ghazimatin, Azin and Roy, Rishiraj Saha},
title = {Counterfactual Explanations for Neural Recommenders},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3506804},
abstract = {
    <p>While neural recommenders have become the state-of-the-art in recent years, the complexity of deep models still makes the generation of tangible explanations for end users a challenging problem. Existing methods are usually based on attention distributions over a variety of features, which are still questionable regarding their suitability as explanations, and rather unwieldy to grasp for an end user. Counterfactual explanations based on a small set of the user's own actions have been shown to be an acceptable solution to the tangibility problem. However, current work on such counterfactuals cannot be readily applied to neural models. In this work, we propose ACCENT, the first general framework for finding counterfactual explanations for neural recommenders. It extends recently-proposed influence functions for identifying training points most relevant to a recommendation, from a single to a pair of items, while deducing a counterfactual set in an iterative process. We use ACCENT to generate counterfactual explanations for two popular neural models, Neural Collaborative Filtering (NCF) and Relational Collaborative Filtering (RCF), and demonstrate its feasibility on a sample of the popular MovieLens 100K dataset.</p>

},
keywords = {Explanations, Influence functions, Recommendation Systems}
}

@software{10.1145/3506572,
author = {Ca\~{n}amares, Roc\'{\i}o and Castells, Pablo},
title = {Should I Follow the Crowd?: A Probabilistic Analysis of the Effectiveness of Popularity in Recommender Systems},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3506572},
abstract = {
    <p>The use of IR methodology in the evaluation of recommender systems has become common practice in recent years. IR metrics have been found however to be strongly biased towards rewarding algorithms that recommend popular items "the same bias that state of the art recommendation algorithms display. Recent research has confirmed and measured such biases, and proposed methods to avoid them. The fundamental question remains open though whether popularity is really a bias we should avoid or not; whether it could be a useful and reliable signal in recommendation, or it may be unfairly rewarded by the experimental biases. We address this question at a formal level by identifying and modeling the conditions that can determine the answer, in terms of dependencies between key random variables, involving item rating, discovery and relevance. We find conditions that guarantee popularity to be effective or quite the opposite, and for the measured metric values to reflect a true effectiveness, or qualitatively deviate from it. We exemplify and confirm the theoretical findings with empirical results. We build a crowdsourced dataset devoid of the usual biases displayed by common publicly available data, in which we illustrate contradictions between the accuracy that would be measured in a common biased offline experimental setting, and the actual accuracy that can be measured with unbiased observations.</p>

},
keywords = {accuracy, bias, collaborative filtering, evaluation, non-random missing data, popularity, recommender systems}
}

@software{10.5281/zenodo.5531242,
author = {Jouneaux, Gwendal and Barais, Olivier and Combemale, Benoit and Mussbacher, Gunter},
title = {SEALS: A Framework for Building Self-Adaptive Virtual Machines},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5531242},
abstract = {
    <p>In this artifact, we provide the implementation of the three SEALS-based Self-Adaptive Virtual Machines and the three handcrafted Self-Adaptive Virtual Machines (HTML, RobLANG and MiniJava).</p>
<p>This artifact provides a Maven-based build for the artifact as well as scripts to reproduce the benchmarking experiment and the lines of code count. Additionally, we provide a Jupyter notebook to analyze the results of the benchmarking experiments.</p>

},
keywords = {framework, self-adaptation, software language}
}

@software{10.5281/zenodo.5534113,
author = {Verano Merino, Mauricio and Beckmann, Tom and van der Storm, Tijs and Hirschfeld, Robert and Vinju, Jurgen J.},
title = {Skogi},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5534113},
abstract = {
    <p>S/Kogi is an extension of Kog that implements some simplification rules of context-free grammars as described in the SLE paper Getting Grammars into Shape for Block-based Editors. This tool allows users to derive block-based environments from a context-free grammar specification. S/Kogi uses on Google Blockly for rendering block-based environments, and Squeak/Smalltalk</p>

},
keywords = {app inventor, blockly, grammars, kogi, language workbench, rascal, scratch, smalltalk, snap}
}

@software{10.5281/zenodo.5572916,
author = {Leroy, Dorian and Lelandais, Beno\^{\i}t and Oudot, Marie-Pierre and Combemale, Benoit},
title = {Artifact for Article: Monilogging for Executabel DSLs},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5572916},
abstract = {
    <p>The artifact is a Vagrant script building a VM that runs NabLab with MoniLog, allowing to instrument the execution of NabLab models with moniloggers. The resulting VM provides a NabLab workspace with 6 MoniLog specifications illustrating the different ways MoniLog can be used to perform logging and monitoring.</p>

},
keywords = {executable DSLs, logging, runtime monitoring}
}

@software{10.5281/zenodo.5573543,
author = {Yedidia, Zachary and Chong, Stephen},
title = {Artifact for Fast Incremental PEG Parsing},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5573543},
abstract = {
    <p>This artifact contains the source code for our GPeg incremental parser, the Flare syntax highlighting engine, an example text editor that uses both libraries, and our benchmarks and experiments from the paper, along with scripts to auto-generate the figures.</p>

},
keywords = {incremental parsing, packrat parsing, parsing expression grammars}
}

@software{10.6084/m9.figshare.16825933.v1,
author = {Farooq, Aamir and Zaytsev, Vadim},
title = {Supporting Code for Article "There Is More Than One Way to Zen Your Python"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.16825933.v1},
abstract = {
    <p>This archive contains the supporting code for the paper “There Is More Than One Way to Zen Your Python”. - catalogue_website_code/ contains the code for the website for our list of pythonic idioms. It can be viewed either by: - installing <code>docsify-cli</code> using: <code>npm i docsify-cli -g</code> and then running <code>docsify serve</code> in the <code>catalogue_website_code</code> folder. - using something like the Live Server extension for VSCode: https://marketplace.visualstudio.com/items?itemName=ritwickdey.LiveServer - deploying it to Github Pages - or visiting the live version of the website here: https://slimshadyiam.github.io/ZenYourPython/#/ - idiom_detection_code/ contains the code used to detect idioms in open source Python projects. A detailed setup guide and overview of the contents can be found in the README.md file in that directory, as well as the raw data collected from using the detection tool.</p>

},
keywords = {Python, pythonic idioms, pythonicity}
}

@software{10.5281/zenodo.5090141,
author = {Dura, Alexandru and Reichenbach, Christoph and S\"{o}derberg, Emma},
title = {Replication Package for Article: 'JavaDL: Automatically Incrementalizing Java Bug Pattern Detection'},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5090141},
abstract = {
    <p>The artifact contains the implementation of the JavaDL language and the evaluation setup that reproduces the claims regarding: - the precision of the JavaDL analyses relative to state-of-the-practice tools; - the performance comparison between JavaDL and state-of-the-practice tools.</p>

},
keywords = {Datalog, Software Bugs, Static Analysis Frameworks, Syntactic Patterns}
}

@software{10.5281/zenodo.5093839,
author = {Herklotz, Yann and Pollard, James D. and Ramanathan, Nadesh and Wickerson, John},
title = {Vericert},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5093839},
abstract = {
    <p>A formally verified high-level synthesis (HLS) tool written in Coq, building on top of CompCert. The implementation and proofs are described in the paper “Formal Verification of High-Level Synthesis”.</p>

},
keywords = {C, CompCert, Coq, high-level synthesis, Verilog}
}

@software{10.5281/zenodo.5130646,
author = {Zhou, Zhe and Dickerson, Robert and Delaware, Benjamin and Jagannathan, Suresh},
title = {OOPSLA2021 Artifact: Data-Driven Abductive Inference of Library Specifications},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5130646},
abstract = {
    <p>OOPSLA2021 Artifact: Data-Driven Abductive Inference of Library Specifications</p>

},
keywords = {data-driven inference, oopsla, specifications, verification}
}

@software{10.5281/zenodo.5139390,
author = {Park, Jiwon and Winterer, Dominik and Zhang, Chengyu and Su, Zhendong},
title = {OOPSLA 2021 Artifact for "Generative Type-Aware Mutation for Testing SMT Solvers"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5139390},
abstract = {
    <p>Software artifact for the paper Generative Type-Aware Mutation for Testing SMT Solvers, in a VirtualBox image. The artifact is realized as a single VirtualBox image of three main components: (1) yinyang, the tool which we created and extended, and in which we integrated TypeFuzz. TypeFuzz realizes generative type-aware mutation to find all reported bugs in the paper, (2) A database with statistics on the bugs and Coverage data.</p>

},
keywords = {SMT solving
Fuzzing
Formal methods}
}

@software{10.5281/zenodo.5141479,
author = {Phipps-Costin, Luna and Anderson, Carolyn Jane and Greenberg, Michael and Guha, Arjun},
title = {TypeWhich},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5141479},
abstract = {
    <p>See Zenodo for a description of the artifact.</p>

},
keywords = {typed, untyped}
}

@software{10.5281/zenodo.5394235,
author = {Goel, Aviral and Je\v{c}men, Jan and Krynski, Sebasti\'{a}n and Fl\"{u}ckiger, Olivier and Vitek, Jan},
title = {Replication Package for Article: "Promises Are Made to Be Broken: Migrating R to Strict Semantics"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5394235},
abstract = {
    <p>The artifact is a ZIP file containing code that analyzes R packages to migrate them from lazy to strict semantics. Details can be found in the README.pdf file accompanying the artifact.</p>

},
keywords = {Code Migration, Corpus Analysis, Delayed Or Lazy Evaluation, Empirical Study, R Language}
}

@software{10.5281/zenodo.5400508,
author = {Malewski, Stefan and Greenberg, Michael and Tanter, \'{E}ric},
title = {Gradually Structured Data: Typechecker and Interpreter},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5400508},
abstract = {
    <p>GSD is an interpreter for a gradually typed language with Gradually Structured Data.</p>
<p>It’s main features are the following: - It can typecheck and evaluate programs with different levels of datatype definitions. From no definitions at all (for dynamic programs) to fully defined static programs, and the levels in between those two extremes. - It works with three different matching strategies: sound, exact and complete.</p>

},
keywords = {algebraic datatypes, gradual typing, semi-structured data}
}

@software{10.5281/zenodo.5411667,
author = {Chaliasos, Stefanos and Sotiropoulos, Thodoris and Drosos, Georgios-Petros and Mitropoulos, Charalambos and Mitropoulos, Dimitris and Spinellis, Diomidis},
title = {Replication Package for Article: "Well-Typed Programs Can Go Wrong: A Study of Typing-Related Bugs in JVM Compilers"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5411667},
abstract = {
    <p>The purpose of this artifact is (1) to reproduce the results presented in the OOPSLA 2021 paper titled “Well-Typed Programs Can Go Wrong: A Study of Typing-Related Bugs in JVM Compilers”, and (2) to document the dataset and the proposed categorization in order to facilitate further research. Specifically, the artifact has the following structure:</p>
<ul>
<li><p><code>scripts/</code>: This is the directory that contains the scripts needed to reproduce the results, the figures, and the tables presented in the paper.</p></li>
<li><p><code>scripts/fetch/</code>: This is the directory that contains the scripts needed to construct the dataset of typing-related bugs as described in Section 2.1 of the main paper.</p></li>
<li><p><code>data/</code>: This is the “pre-baked” dataset of the 320 typing-related bugs under study.</p></li>
</ul>

},
keywords = {bug, compiler, Groovy, Java, Kotlin, Scala, static typing, study, testing}
}

@software{10.5281/zenodo.5415230,
author = {Goel, Aviral and Donat-Bouillud, Pierre and K\v{r}ikava, Filip and Kirsch, Christoph M. and Vitek, Jan},
title = {Replication Package for Article: "What We Eval in the Shadows: A Large-Scale Study of Eval in R Programs"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5415230},
abstract = {
    <p>The artifact is a ZIP file containing code that performs dynamic analysis of R programs to study the use of eval. The insights yielded by this analysis are reported in the OOPSLA’21 paper - What We Eval in the Shadows: A Large-Scale Study of Eval in R Programs. The details can be found in the README.pdf file accompanying the artifact.</p>

},
keywords = {Dynamic Analysis, Empirical Studies, Eval, R, Scripting Languages}
}

@software{10.5281/zenodo.5415274,
author = {Br\"{a}m, Christian and Eilers, Marco and M\"{u}ller, Peter and Sierra, Robin and Summers, Alexander J.},
title = {Artifact of the paper "Rich Specifications for Ethereum Smart Contract Verification"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5415274},
abstract = {
    <p>This is the artifact accompanying the OOPSLA 2021 paper “Rich Specifications for Ethereum Smart Contract Verification”.</p>
<p>The artifact comes in the form of a VirtualBox VM image (2vyper-artifact.ova) and contains the paper’s implementation in the tool 2vyper as well as the benchmarks used in the evaluation. Instructions for running the VM image and using the artifact can be found in the README.</p>

},
keywords = {Ethereum, resources, smart contracts, software verification, specification}
}

@software{10.5281/zenodo.5421762,
author = {Ishimwe, Didier and Nguyen, KimHao and Nguyen, ThanhVu},
title = {Software Artifact for the OOPSLA'21 Paper Titled "Dynaplex: Analyzing Program Complexity using Dynamically Inferred Recurrence Relations"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5421762},
abstract = {
    <p>This artifact contains an implementation of the dynaplex algorithm and benchmark programs, as described in the paper: <em>Dynaplex: Analyzing Program Complexity using Dynamically Inferred Recurrence Relations</em>.</p>
<p>The development and experiment environment is provided as a single Docker image at <code>unsatx/dynaplex:oopsla21</code>. In addition to the image a <code>Dockerfile</code> as well as a zip containing the github repository are also provided as alternative source of the artifact. We recommend using the provided Docker image as it is self-contained with all the dependencies installed. A guide to set up and use this artifact from the docker image is provided in file <code>dynaplex.pdf</code>.</p>

},
keywords = {complexity analysis, dynamic analysis, invariants, recurrence relations}
}

@software{10.5281/zenodo.5449078,
author = {Kazerounian, Milod and Foster, Jeffrey S. and Min, Bonan},
title = {Replication Package for Paper "SimTyper: Sound Type Inference for Ruby using Type Equality Prediction"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5449078},
abstract = {
    <p>This artifact can be used to reproduce the results presented in the paper “SimTyper: Sound Type Inference for Ruby using Type Equality Prediction.” It includes the type inference system SimTyper, and the eight programs which it is run on to produce results.</p>

},
keywords = {dynamic languages, machine learning, ruby, type inference}
}

@software{10.5281/zenodo.5459312,
author = {Nandi, Chandrakana and Willsey, Max and Zhu, Amy and Wang, Yisu Remy and Saiki, Brett and Anderson, Adam and Schulz, Adriana and Grossman, Dan and Tatlock, Zachary},
title = {Artifact for article: &nbsp;Rewrite Rule Inference Using Equality Saturation},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5459312},
abstract = {
    <p>This is the artifact for our paper “Rewrite Rule Inference Using Equality Saturation”. In our paper, we presented a framework, Ruler, that uses equality saturation to automatically infer small, expressive rulesets for a domain, given an interpreter. The artifact reproduces the following quantitative evaluations from the paper:</p>
<ul>
<li><p>Comparing with CVC4 (Section 4): We show that Ruler can infer smaller, powerful rulesets faster by comparing the rules inferred for bool, bv4, and bv32 with varying expression sizes (2, 3). The results are in Table 1.</p></li>
<li><p>Integrating with Herbie (Section 5): We show that Ruler’s rules can be used to replace human-written rules by comparing the Herbie tool’s results in fours different configurations: <code>None</code>, <code>Herbie</code>, <code>Ruler</code>, <code>Both</code>. The results are in Figure 7.</p></li>
<li><p>Search Parameter Analysis (Section 6.1): We profiled Ruler’s search algorithm to measure how much time is spent in each phase. Figure 8 shows the results for bv4, bv32, and rationals domains. We also compared different variations of <code>choose_eqs</code> by varying n in Figure 5, Line 3, whose default value is infinity. The results are shown in Figure 9a for bv4, bv32, and rationals. Importantly, we measure both running time and the number of rules learned. We also measured running time, number of rules learned, and number of e-classes in the egraph with and without invoking <code>run_rewrites</code> (Figure 4, Line 9) to study its effect. The results are shown in Figure 9b for bv4, bv32, and rationals.</p></li>
<li><p>Validation Analysis (Section 6.2): We compared different rule validation methods for bv4, bv32, and rationals. The results are shown in Table 2.</p></li>
</ul>

},
keywords = {e-graphs, equality saturation, program synthesis, rewrite rules}
}

@software{10.5281/zenodo.5476274,
author = {Honor\'{e}, Wolf and Kim, Jieung and Shin, Ji-Yong and Shao, Zhong},
title = {Artifact for "Much ADO about Failures: A Fault-Aware Model for Compositional Verification of Strongly Consistent Distributed Systems"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5476274},
abstract = {
    <p>This artifact includes the Coq source files for the Advert distributed system verification framework as well as the examples from the paper, a C implementation of multi-Paxos verified with CCAL, and the C source code for the multi-Paxos, Chain Replication, and Two-Phase Commit protocols used for the performance evaluations. Source files are included in artifact.tgz. See the README for build instructions.</p>

},
keywords = {Coq, distributed systems, formal verification, proof assistants}
}

@software{10.5281/zenodo.5482251,
author = {Xu, Haoran and Kjolstad, Fredrik},
title = {Artifact for Paper "Copy-and-Patch Compilation: A fast compilation algorithm for high-level languages and bytecode"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5482251},
abstract = {
    <p>This is the artifact corresponding to paper</p>
<pre><code>Copy-and-Patch Compilation: A fast compilation algorithm for high-level languages and bytecode</code></pre>
<p>to be published in OOPSLA 2021.</p>
<p>This artifact is judged by the Artifact Evaluation Committee as functional and reusable.</p>
<p>List of Files</p>
<pre><code> 'instruction.pdf' contains all instructions on how to use this artifact.
 'artifact_vm_image.ova' is the Virtual Box VM image containing the artifact.
 'artifact_vm_image.ova.md5sum' is the MD5 checksum for file 'artifact_vm_image.ova'.
 'draft_paper.pdf' is the paper referred to by 'instruction.pdf'. It is NOT the camera-ready version of the paper:  for camera-ready version, please check the OOPSLA 2021 publication website. This draft version is included only for consistency of this artifact.
 'LICENSE.txt' is the license of this artifact.</code></pre>
<p>How to Use this Artifact</p>
<p>Please refer to ‘instruction.pdf’ for all instructions on how to use this artifact.</p>

},
keywords = {Artifact}
}

@software{10.5281/zenodo.5483138,
author = {Lanzinger, Florian and Weigl, Alexander and Ulbrich, Mattias and Dietl, Werner},
title = {Property Checker -- Scalability and Precision by Combining Expressive Type Systems and Deductive Verification},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5483138},
abstract = {
    <p>The Property Checker is a checker developed using the Checker Framework for Java. The Checker Framework allows programmers to leverage Java annotations to create pluggable Java type systems. Unlike other checkers in the CF, the Property Checker allows users to specify their own type qualifiers and qualifier hierarchies using a simple definition language.</p>
<p>If the Property Checker is not able to completely prove a program’s correctness, it outputs a JML translation, in which all property qualifiers are translated into specification clauses in the Java Modeling Language (JML). This translation can be given to a deductive verification tool like KeY or OpenJML to prove the parts of the program which the checker was not able to prove. This approach combines the scalability and easy-of-use of pluggable type system with the power of deductive verification.</p>
<p>This artifact includes the Property Checker itself and the JML deductive verification tools KeY and OpenJML. The example project in the directory property-checker-tutorial illustrates how the Property Checker can be run on your own projects; see that project’s readme for details. See this file for information on how to run KeY and OpenJML. In addition, there are some premade bash scripts to help you re-run the evaluation described in the paper; see the artifact documentation for more details.</p>

},
keywords = {Object-oriented languages, Program specification, Program verification, Type systems}
}

@software{10.5281/zenodo.5484436,
author = {Popescu, Natalie and Xu, Ziyang and Apostolakis, Sotiris and August, David I. and Levy, Amit},
title = {Artifact for 'Safer at Any Speed: Automatic Context-Aware Safety Enhancement for Rust'},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5484436},
abstract = {
    <p>This artifact is responsible for reproducing the experiments in the article “Safer at Any Speed: Automatic Context-Aware Safety Enhancement for Rust”. We populate a docker image with the open-source libraries, applications, and application-specific data that we eventually use for running experiments, as well as a driver and supporting scripts that instantiates each experiment. The experiments help support the claims we make in the paper.</p>

},
keywords = {bounds checks, Rust, safety-performance trade-off}
}

@software{10.5281/zenodo.5494504,
author = {Yamaguchi, Masaomi and Matsuda, Kazutaka and David, Cristina and Wang, Meng},
title = {Synbit: Synthesizing Bidirectional Programs using Unidirectional Sketches (Implementation)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5494504},
abstract = {
    <p>This is the artifact of a paper “Synbit: Synthesizing Bidirectional Programs using Unidirectional Sketches”. This artifact includes the implementation of Synbit and scripts for reproducing the experiments in the paper.</p>

},
keywords = {Bidirectional Transformation, Program Synthesis}
}

@software{10.5281/zenodo.5494813,
author = {Smaragdakis, Yannis and Grech, Neville and Lagouvardos, Sifis and Triantafyllou, Konstantinos and Tsatiris, Ilias},
title = {Symbolic Value-Flow Static Analysis: Deep, Precise, Complete Modeling of Ethereum Smart Contracts (Artifact)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5494813},
abstract = {
    <p>This artifact can be used to support all claims made in the evaluation section of the corresponding paper. In particular it can be used to reproduce the results of the Controlled Evaluation Section of the paper (Section 7). These examples require running 3 analysis tools: our proposed Symvalic analysis, Manticore, and Mythril on two sets of smart contracts.</p>

},
keywords = {ethereum, EVM, static analysis, symbolic execution}
}

@software{10.5281/zenodo.5496104,
author = {Patel, Nisarg and Krishna, Siddharth and Shasha, Dennis and Wies, Thomas},
title = {Replication Package for Article: Verifying Concurrent Multicopy Search Structures},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5496104},
abstract = {
    <p>Artifact for OOPSLA’21 paper: Verifying Concurrent Multicopy Search Structures</p>
<p>The artifact is packaged as a VirtualBox Image based on Ubuntu 20.04.2. The login is <code>templates:templates</code>.</p>
<p>This artifact relies on two tools: Iris (a high-order concurrent separation logic built on top of Coq) and GRASShopper (a program verification tool). The artifact is packaged with these software preinstalled and the necessary files precompiled.</p>
<p>See README for further information on how to use the artifact. See LICENSE for the license-related information.</p>

},
keywords = {concurrent data structures, flow framework, log-structured merge trees, logic and verification, separation logic, shared memory algorithms, template-based verification, theory of computation}
}

@software{10.5281/zenodo.5497628,
author = {Fu, Weili and Krause, Fabian and Thiemann, Peter},
title = {Artifact for Label Dependent Lambda Calculus and Gradual Typing},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5497628},
abstract = {
    <p>This artifact contains two parts corresponding to our claim at the end of section 1 in the paper “Label Dependent Lambda Calculus and Gradual Typing” appearing in OOPSLA 2021.</p>
<ol type="1">
<li>An implementation of the type checker for LDLC corresponding to section 3.2 from the paper and its gradual extension for GLDLC described in section 5.1. It does <em>not</em> contain the translation described in section 5.2.</li>
<li>A formalization of the cast calculus CCLDLC (a proper extension of LDLC) described in section 4 and an implementation of the progress proof of theorem 4.6 in Agda.</li>
</ol>

},
keywords = {dependent types, gradual types, subtyping}
}

@software{10.5281/zenodo.5500548,
author = {Pelenitsyn, Artem and Belyakova, Julia and Chung, Benjamin and Tate, Ross and Vitek, Jan},
title = {Type Stability in Julia: Avoiding Performance Pathologies in JIT Compilation (Artifact)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5500548},
abstract = {
    <p>This artifact aims to give exact directions on how to reproduce experiments reported in Section 5 (Empirical Study) of the Type Stability in Julia paper presented at OOPSLA ’21; in particular: Tables 1 and 2, Figure 11.</p>
<p>The artifact consists of a number of scripts in Bash and Julia and have instructional comments inside. We submit the Git history of the project: the submitted version lives on the artifact branch. The same repository is available on Github (prl-julia/julia-type-stability).</p>

},
keywords = {compilation, dynamic languages, method dispatch, type inference}
}

@software{10.5281/zenodo.5501650,
author = {Jaber, Nouraldin and Wagner, Christopher and Jacobs, Swen and Kulkarni, Milind and Samanta, Roopsha},
title = {QuickSilver},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5501650},
abstract = {
    <p>This artifact contains a VirtualBox VM that can be used to replicate the results in “QuickSilver: Modeling and Parameterized Verification for Distributed Agreement-Based Systems”. It includes the source code of the QuickSilver tool.</p>

},
keywords = {modular verification., parameterized verification, QuickSilver}
}

@software{10.5281/zenodo.5502210,
author = {Gokhale, Satyajit and Turcotte, Alexi and Tip, Frank},
title = {Automatic Migration from Synchronous to Asynchronous JavaScript APIs (Artifact)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5502210},
abstract = {
    <p>This artifact contains information on setting up and evaluating the results for Desynchronizer, a tool for automatic refactoring of Synchronous Javascript API to their Asynchronous equivalents. The entire source code for the tool is also included.</p>

},
keywords = {async/await, JavaScript, promises, refactoring, static analysis}
}

@software{10.5281/zenodo.5504159,
author = {Atkinson, Eric and Baudart, Guillaume and Mandel, Louis and Yuan, Charles and Carbin, Michael},
title = {Statically Bounded-Memory Delayed Sampling for Probabilistic Streams},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5504159},
abstract = {
    <p>This artifact accompanies the paper “Statically Bounded-Memory Delayed Sampling for Probabilistic Streams” from OOPSLA 2021. It contains the code of the implementation and benchmarks, as well as a virtual machine that can be used to run the implementation.</p>

},
keywords = {Probabilistic programming, program analysis, reactive programming, semantics, streaming inference}
}

@software{10.5281/zenodo.5504362,
author = {Verbruggen, Gust and Le, Vu and Gulwani, Sumit},
title = {Replication Package for Article: "Semantic programming by example with pre-trained models"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5504362},
abstract = {
    <p>This archive contains the code for our paper “Semantic programming by example with pre-trained models”. It contains the code and data required to execute the experiments, as well as cached GPT-3 output in case no key is available.</p>

},
keywords = {flashfill, gpt-3, programming by example}
}

@software{10.5281/zenodo.5507442,
author = {Barbar, Mohamad and Sui, Yulei},
title = {Compacting Points-To Sets through Object Clustering (Artifact)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5507442},
abstract = {
    <p>Artifact packaged as a Docker image for reproducing the evaluation of “Compacting Points-To Sets Through Object Clustering” by Mohamad Barbar and Yulei Sui published at OOPSLA ’21.</p>

},
keywords = {bit-vectors, hierarchical clustering., points-to sets, staged points-to analysis}
}

@software{10.21979/N9/JKYYUD,
author = {Wu, Xiuheng and Zhu, Chenguang and Li, Yi},
title = {Replication Data for: DIFFBASE: A Differential Factbase for Effective Software Evolution Management},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.21979/N9/JKYYUD},
abstract = {
    <p>Numerous tools and techniques have been developed to extract and analyze information from software development artifacts. Yet, there is a lack of effective method to process, store, and exchange information among different analyses. DiffBase provides a uniform exchangeable representation supporting efficient querying and manipulation, based on the existing concept of program facts. We consider program changes as first-class objects, which establish links between intra-version facts of single program snapshots and provide insights on how certain artifacts evolve over time via inter-version facts. DiffBase includes a series of differential fact extractors and multiple software evolution management tasks have been implemented with DiffBase, demonstrating its usefulness and efficiency.</p>

},
keywords = {Program facts, Software evolution, Software maintenance}
}

@software{10.5281/zenodo.4818970,
author = {Maltbie, Nicholas and Niu, Nan and Van Doren, Matthew and Johnson, Reese},
title = {CSO Dataset Analysis for Article: XAI Tools in the Public Sector: A Case Study on Predicting Combined Sewer Overflows},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4818970},
abstract = {
    <p>This repository is provided as supplementary material for the paper “XAI Tools in the Public Sector: A Case Study on Predicting Combined Sewer Overflows” by Nicholas Maltbie, Nan Niu, Reese Johnson, and Matthew VanDoren.</p>
<p>These are the notes for the CSO case study, how the data is prepared, ML models are tuned and created, and the final interpretability analysis.</p>
<p>This repository contains instructions on how to use the code required to create models for the dataset and then how to apply these models to a sample dataset and gather expandability results for our research.</p>

},
keywords = {AI, Explainability, Goal Question Metric, LSTM, Machine Learning, Requirements Engineering}
}

@software{10.5281/zenodo.4888908,
author = {Sokolowski, Daniel and Weisenburger, Pascal and Salvaneschi, Guido},
title = {Automating Serverless Deployments for DevOps Organizations: Root Artifact},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4888908},
abstract = {
    <p>This artifact bundles all material supplementing:</p>
<p>[1] Daniel Sokolowski, Pascal Weisenburger, and Guido Salvaneschi. 2021. Automating Serverless Deployments for DevOps Organizations. In Proceedings of the 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE ’21), August 23–28, 2021, Athens, Greece. ACM, New York, NY, USA, 13 pages. https://doi.org/10.1145/3468264.3468575</p>
<ol type="1">
<li>Dependencies in DevOps Survey 2021</li>
</ol>
<p>https://doi.org/10.5281/zenodo.4873909 provides the dataset, a detailed report, and all analysis and content creation scripts for the contained technical report and all survey-related content in [1]. It supplements Section 2 in [1].</p>
<ol start="2" type="1">
<li>µs Infrastructure as Code</li>
</ol>
<p>https://doi.org/10.5281/zenodo.4902323 is the implementation of µs. It is reusable for IaC deployments and sets the base for future research on reactive IaC deployments. We suggest looking at the contained webpage example project and running it using the provided mjuz/mjuz Docker image. For this, follow the instructions in the README in the webpage’s subdirectory, showcasing an example setup using µs and plain Pulumi with both a centralized and a decentralized deployment. The “decentralized-mjuz” version uses the automated deployment coordination proposed in [1]. The Docker image is available on Docker Hub, but for long-term archiving, it is also included in this root artifact in mjuz-mjuz-docker-image.tar.zip. You can load and register it locally with the tags mjuz/mjuz:latest and mjuz/mjuz:1.0.0 by unzipping the file and running docker load -i mjuz-mjuz-docker-image.tar.</p>
<p>The µs implementation uses – and its Docker image builds upon – the Pulumi for µs CLI: https://doi.org/10.5281/zenodo.4902319. Its demonstration is already covered by the µs artifact in the previous paragraph; still, we include it here for completeness. Its Docker image is available on Docker Hub, too, and included in this artifact in mjuz-pulumi-docker-image.tar.zip. You can load and register it locally with the tags mjuz/pulumi:latest and mjuz/pulumi:1.0.0 by unzipping the file and running docker load -i mjuz-pulumi-docker-image.tar.</p>
<ol start="3" type="1">
<li>µs Performance Evaluation</li>
</ol>
<p>http://doi.org/10.5281/zenodo.4902330 contains the materials used for the performance evaluation of µs in Subsection 8.2 in [1]. It includes the deployment definitions, the measurement scripts, the measured data, and the scripts to generate the paper’s plots from the data.</p>
<ol start="4" type="1">
<li>Pulumi TypeScript Projects using Stack References</li>
</ol>
<p>https://doi.org/10.5281/zenodo.4878577 is the dataset of public GitHub repositories that contain Pulumi TypeScript projects using stack references. It supplements Subsection 8.3 in [1].</p>
<ol start="5" type="1">
<li>Pulumi TypeScript Stack References to µs Converter</li>
</ol>
<p>https://doi.org/10.5281/zenodo.4902171 converts existing stack references and outputs in Pulumi TypeScript projects to µs remotes, wishes, and offers. It supplements Subsection 8.3 in [1], where it is applied to the Pulumi TypeScript Projects using Stack References dataset.</p>

},
keywords = {DevOps, Infrastructure as Code, Software Dependencies, Software Engineering}
}

@software{10.5281/zenodo.4902179,
author = {Luo, Yicheng and Filieri, Antonio and Zhou, Yuan},
title = {Replication Package for Paper: Symbolic Parallel Adaptive Importance Sampling for Probabilistic Program Analysis},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4902179},
abstract = {
    <p>Replication package and reference implementation for</p>
<p>Yicheng Luo, Antonio Filieri, and Yuan Zhou. Symbolic Parallel Adaptive Importance Sampling for Probabilistic Program Analysis. In Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2021). arXiv:2010.05050.</p>

},
keywords = {importance sampling, JAX, MCMC, probabilistic programming, symbolic execution}
}

@software{10.5281/zenodo.4902383,
author = {Su, Ting and Wang, Jue and Su, Zhendong},
title = {Replication Package for Article: Benchmarking Automated GUI Testing for Android against Real-World Bugs},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4902383},
abstract = {
    <p>Our artifact is named Themis. Themis is a collection of real-world, reproducible crash bugs (collected from open-source Android apps) and a unified, extensible infrastructure for benchmarking automated GUI testing for Android and beyond. Themis now contains 52 critical crash bugs and integrates six state-of-the-art/practice GUI testing tools.</p>

},
keywords = {Android apps, Benchmarking, Crash bugs, GUI testing}
}

@software{10.5281/zenodo.4902728,
author = {Zhang, Changjian and Wagner, Ryan and Orvalho, Pedro and Garlan, David and Manquinho, Vasco and Martins, Ruben and Kang, Eunsuk},
title = {Benchmark for Paper: AlloyMax: Bringing Maximum Satisfaction to Relational Specifications},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4902728},
abstract = {
    <p>This is the reproduction package of the benchmarks used in the work AlloyMax: Bringing Maximum Satisfaction to Relational Specifications. This package contains AlloyMax executable, the necessary libraries, the models used in the paper, and the scripts for running the benchmark.</p>

},
keywords = {Alloy, MaxSAT, Model synthesis, Relational specifications, SAT}
}

@software{10.5281/zenodo.4970239,
author = {B\"{o}hme, Marcel and Liyanage, Danushka and W\"{u}stholz, Valentin},
title = {Estimating Residual Risk in Greybox Fuzzing - Artifacts},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4970239},
abstract = {
    <p>We make publicly available the tool used to produce the data, the data used to validate the claims made in the paper, and the simulation+evaluation scripts to produce from the data the figures shown in the paper. In the context of our paper, we conducted several simulation studies and evaluated the performance of the classical and proposed estimators of residual risk in the presence of adaptive bias in greybox fuzzing.</p>
<p>The data for the empirical evaluation were generated through fuzzing campaigns with a modified version of LibFuzzer. In this experimental setup, we establish ground truth for discovery probability to evaluate estimator performance with respect to the ground truth.</p>
<p>The workbooks and source code for experimental setup are available at https://github.com/Adaptive-Bias/fse21_paper270.</p>

},
keywords = {estimation, fuzzing, probability, software testing, statistics}
}

@software{10.5281/zenodo.5081240,
author = {Zhang, Minjian and Mathur, Umang and Viswanathan, Mahesh},
title = {Replication of checking LTL[F,G,X] on compressed traces in polynomial time},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5081240},
abstract = {
    <p>The artifact contains all tools to reproduce the experiment result of the corresponding paper, which includes the algorithm introduced, manually encoded automata, graphs and formal descriptions of tested properties, and the compressed, uncompressed traces.</p>

},
keywords = {Model checking, software engineering, verification}
}

@software{10.5281/zenodo.5084000,
author = {Song, Dowon and Lee, Woosuk and Oh, Hakjoo},
title = {Replication Package for Article: Context-Aware and Data-Driven Feedback Generation for Programming Assignments},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5084000},
abstract = {
    <p>It is an artifact to reproduce the experimental results of the paper “Context-Aware and Data-Driven Feedback Generation for Programming Assignments”. The artifact contains the codes, benchmarks, and python scripts to reproduce the results easily.</p>
<p>The detailed description (e.g., Install, Usage) of the tool is available on the public repository: https://github.com/kupl/LearnML</p>

},
keywords = {Program Repair, Program Synthesis}
}

@software{10.5281/zenodo.5086293,
author = {Pei, Kexin and Guan, Jonas and Broughton, Matthew and Chen, Zhongtian and Yao, Songchen and Williams-King, David and Ummadisetty, Vikas and Yang, Junfeng and Ray, Baishakhi and Jana, Suman},
title = {Code for Article: StateFormer: Fine-Grained Type Recovery from Binaries using Generative State Modeling},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5086293},
abstract = {
    <p>StateFormer is a tool that aims to recover source-level type information from stripped binary executable based on transfer learning. Inspired by how human analyzer reason about the program, we propose a pretraining task called Generative State Modeling (GSM) to teach an ML model assembly code operational semantics, and then transfer the learned knowledge for type inference. See our paper for details.</p>

},
keywords = {Machine Learning for Program Analysis, Reverse Engineering, Transfer Learning, Type Inference}
}

@software{10.5281/zenodo.5088948,
author = {Hu, Yang and Wang, Wenxi and Hunger, Casen and Wood, Riley and Khurshid, Sarfraz and Tiwari, Mohit},
title = {Software tools for the paper - ACHyb: A Hybrid Analysis Approach to Detect Kernel Access Control Vulnerabilities},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5088948},
abstract = {
    <p>The artifact includes four software tools developed in our work: 1) a cve analysis tool to conduct our KACV study 2) a static analysis tool to detect potentially vulnerable paths, 3) a clustering-base seed distillation tool to generate high-quality seed programs, and 4) a kernel fuzzer to reduce false positives of the potential paths reported our static analysis tool. For each tool, we document setup procedures and usage, and provide the corresponding datasets.</p>

},
keywords = {Access Control, Operating System, Program Analysis}
}

@software{10.5281/zenodo.5089077,
author = {Park, Joonyoung and Park, Jihyeok and Youn, Dongjun and Ryu, Sukyoung},
title = {Accelerating JavaScript Static Analysis via Dynamic Shortcuts (Artifact Evaluation)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5089077},
abstract = {
    <p>We present dynamic shortcuts, a new technique to flexibly switch between abstract and concrete execution during JavaScript static analysis in a sound way. SAFEDS is the actual instance of dynamic shortcuts (DS) based on Jalangi2 in order to accelerate the static analyzer SAFE. It can significantly improve the analysis performance and precision by using highly-optimized commercial JavaScript engines (V8 in Node.js in our setting) and lessen the modeling efforts for opaque code. We apply our artifact for the Reusable badge and Artifacts Available badge. Our artifact provides the reproducible experimental environment, the full results of the experiments presented in the paper, and the commands of SAFEDS to analyze a new input program. A user can reproduce the experiments presented in the paper that is the comparison of analysis performances of SAFE and SAFEDS on Lodash4 tests. There are script files to juxtapose experimental results for each RQs with numbers in the paper. The README file on the root directory describes the above in detail. This package is forked from SAFE and imports Jalangi2 as a git submodule. The license of this package is under the BSD license. We added the option “ds” to the original SAFE to trigger dynamic shortcuts. When the option is turned on, SAFEDS communicates with the Node.js server in the dynamic-shortcut directory and the server runs Jalangi2 for dynamic analysis of functions in the target program on the concrete engine. The requirements of SAFEDS are inherited from SAFE and Jalangi2 and specified in the REQUIREMENTS file. The INSTALL file will guide to initialize the submodule, SAFE, and Jalangi2.</p>

},
keywords = {dynamic analysis, dynamic shortcut, JavaScript, sealed execution, static analysis}
}

@software{10.5281/zenodo.5091384,
author = {He, Hao and He, Runzhi and Gu, Haiqiao and Zhou, Minghui},
title = {Replication Package for ESEC/FSE 2021 Paper "A Large-Scale Empirical Study of Java Library Migrations: Prevalence, Trends, and Rationales"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5091384},
abstract = {
    <p>This is the replication package for our ESEC/FSE 2021 paper A Large-Scale Empirical Study on Java Library Migrations: Prevalence, Trends, and Rationales. It can be used to replicate all three research questions in the paper using our preprocessed and manually labeled data. Please refer to this GitHub repository (https://github.com/hehao98/LibraryMigration) or the git repository archive (gitrepo.zip) in this package for detailed documentation about how to use this replication package.</p>
<p>It consists of the following files:</p>
<p>cache.zip: This file contains some most important datasets used in this paper, including the GitHub repositories and Maven libraries used, the set of all dependency changes, and the migration graph. Data related to thematic analysis can be found in the git repository. dbdata.tar.xz: This file contains the raw MongoDB data folder that will be used if you choose to install the required environment using Docker. dbdump.zip: This file contains the MongoDB data dump which will be used if you choose to manually install the required environment. gitrepo.zip: A git repository archive for the scripts, notebooks, and spreadsheets we used for this paper. Note that this archive may be somewhat older than the GitHub repository (https://github.com/hehao98/LibraryMigration). We recommend referring to the latest version at GitHub and only resort to this archive if the GitHub repository becomes unavailable in the unforeseeable future. We hope the provided scripts and dataset can be used to facilitate further research.</p>

},
keywords = {empirical software engineering, evolution and maintenance, library migration, mining software repositories}
}

@software{10.5281/zenodo.5109338,
author = {Wang, Bo and Baluta, Teodora and Kolluri, Aashish and Saxena, Prateek},
title = {SynGuar: Guaranteeing Generalization in Programming by Example (Artifact)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5109338},
abstract = {
    <p>This is the artifact accompanying the paper SynGuar: Guaranteeing Generalization in Programming by Example accepted by the conference ESEC/FSE 2021. It is a framework for PBE synthesizers that guarantees to achieve low generalization error with high probability. It contains a tool named SynGuar that dynamically calculates how many additional examples suffice to theoretically guarantee generalization. It also contains two string program synthesizers StrPROSE and StrSTUN to show how SynGuar can be used in well-known program synthesis approaches such as the PROSE framework and STUN (synthesis through unification).</p>

},
keywords = {Program Synthesis, Programming by Example}
}

@software{10.5281/zenodo.5109867,
author = {Bittner, Paul Maximilian and Schulthei\ss{}, Alexander and Th\"{u}m, Thomas and Kehrer, Timo and Young, Jeffrey M. and Linsbauer, Lukas},
title = {Library and Demo for Article: Feature Trace Recording},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5109867},
abstract = {
    <p>The artefact mainly consists of a library written in the Haskell language that implements feature trace recording. The library is accompanied with a demo application that uses the library to reproduce our motivating example (Alice and Bob using feature trace recording in Section 2 in our paper) as well as examples of the edit patterns we used to evaluate feature trace recording (Section 5).</p>

},
keywords = {clone-and-own, feature location, feature traceability, software evolution, software product lines, variability mining}
}

@software{10.5281/zenodo.5111654,
author = {Shen, Bo and Zhang, Wei and K\"{a}stner, Christian and Zhao, Haiyan and Wei, Zhao and Liang, Guangtai and Jin, Zhi},
title = {Artifact for Article: SmartCommit: A Graph-Based Interactive Assistant for Activity-Oriented Commits},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5111654},
abstract = {
    <p>This artifact is the core algorithm of SmartCommit—an assistant tool to lead and help developers follow the best practice of cohesive commits, which is advocated by many companies (like Google and Facebook) and open source communities (like Git and Angular). A cohesive commit should specifically focus on a development or maintenance activity, such as feature addition, bugfix or refactoring. Cohesive commits form a clear change history that facilitates software maintenance and team collaboration. To help the developer make cohesive commits, SmartCommit can suggest a decomposition (groups of related and self-contained code changes) to the code changes, and allows the developer to interactively adjust the suggested decomposition, until it reaches a state that the developer feels reasonable to submit code change groups as commits.</p>

},
keywords = {changes decomposition, code commit, collaboration in software development, revision control system}
}

@software{10.5281/zenodo.5112878,
author = {Lukes, Dylan and Sarracino, John and Coleman, Cora and Peleg, Hila and Lerner, Sorin and Polikarpova, Nadia},
title = {Replication package for FSE '21, Synthesis of Web Layouts from Examples},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.5112878},
abstract = {
    <p>Contains all code, experiments, and data, as well as instructions for installation, usage and replication of our experiments.</p>
<p>This package contains:</p>
<p>In ./implementation:</p>
<ul>
<li>mockdown, Our main tool, written in Python.</li>
<li>mockdown-client, A JavaScript client for mockdown, intended for use in writing benchmarks, or integrating mockdown into web applications. Used by auto-mock.</li>
<li>auto-mock (placed in implementation/web), Evaluation for the web backend (RQ1-RQ3).</li>
<li>inferui-eval (placed in implementation/android), Evaluation for the Android backend (RQ4).</li>
<li>flightlessbird.js, A fork of the kiwi.js constraint solver, with some bug fixes and changes to facilitate adding multiple constraints at once. Used by mockdown-client.</li>
</ul>
<p>In ./layouts, there is a variety of JSON files. These correspond to our scraped websites (input data).</p>
<p>In ./experiments/, there is the data and scripts for our experiments:</p>
<ul>
<li>overall, CSV files and Excel spreadsheets for our RQ1 trials.</li>
<li>noise, CSV files and plotting scripts for our RQ2 trials. There are two subfolders, 3/ and 10/ which correspond to the 3 and 10 training examples.</li>
<li>scaling, a CSV file, Excel spreadsheet, and helper python script for RQ3.</li>
<li>android, a CSV file for RQ4.</li>
</ul>

},
keywords = {cassowary, constraint-based layout, constraints, layout, linear constraints, program synthesis, synthesis}
}

@software{10.6084/m9.figshare.14724453.v4,
author = {Trabish, David and Itzhaky, Shachar and Rinetzky, Noam},
title = {Replication package for the paper: A Bounded Symbolic-Size Model for Symbolic Execution},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.14724453.v4},
abstract = {
    <p>The package contains: - Source code for our tool (including all the required compiled binaries) - Benchmarks used in the experiments - Scripts for running the experiments</p>

},
keywords = {Symbolic Execution}
}

@software{10.1145/3462277,
author = {Renner, John and Sanchez-Stern, Alex and Brown, Fraser and Lerner, Sorin and Stefan, Deian},
title = {Source Code and Case Studies for Scooter \&amp; Sidecar: A Domain-Specific Approach to Writing Secure Database Migrations},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462277},
abstract = {
    <p>The artifact contains the full source code for scooter and sidecar as they were originally submitted to artifact evaluation. Furthermore, the artifact contains several case studies which are discussed in the paper.</p>

},
keywords = {database migration, scooter, sidecar, SMT, verification}
}

@software{10.5281/zenodo.4697392,
author = {Schuster, Simon and W\"{a}gemann, Peter and Ulbrich, Peter and Schr\"{o}der-Preikschat, Wolfgang},
title = {PragMetis Source Code},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4697392},
abstract = {
    <p>This is the source code of the paper “Annotate Once - Analyze Anywhere: Context-Aware WCET Analysis by User-Defined Abstractions” [1]. Contains the modified T-Crest toolchain (llvm, clang, the platin WCET-analyzer and annotation language interpreter), distirbuted as a single derived work available under the GPLv3.</p>
<p>[1] Simon Schuster, Peter W\"{a}gemann, Peter Ulbrich, Wolfgang Schr\"{o}der-Preikschat. Annotate Once - Analyze Anywhere: Context-Aware WCET Analysis by User-Defined Abstractions. (to appear) In Proceedings of the 22nd International Conference on Languages, Compilers, and Tools for Embedded Systems (LCTES 2021)</p>

},
keywords = {annotations, pragmetis, source code, toolchain, wcet analysis}
}

@software{10.5281/zenodo.4698901,
author = {Pusz, Oskar and Dietrich, Christian and Lohmann, Daniel},
title = {Source Code and Evaluation Data for the Paper: Data-Flow–Sensitive Fault-Space Pruning for the Injection of Transient Hardware Faults},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4698901},
abstract = {
    <p>We provide the data-flow pruner (DFP) presented in our paper. First, we would like to describe the concrete evaluation scenario shortly. We use the fault-injection tool FAIL* (https://github.com/danceos/fail) and have extended it with our pruner. To evaluate DFP we ran FAIL* with a generic experiment after pruning the fault space with the well-known def-use pruner which is already implemented in FAIL<em>. After the execution of the campaign, FAIL</em> created a database with all relevant information about the programs under investigation as well as the results of the fault-injection campaign. The databases are the baseline of our evaluation and can be found in the database-dump/ directory.</p>

},
keywords = {bit flip, fault injection, fault-space pruning, functional correctness, reliability, single event upset}
}

@software{10.5281/zenodo.4737731,
author = {Monniaux, David and Six, Cyril},
title = {Replication package for "Simple, Light, Yet Formally Verified, Global Common Subexpression Elimination and Loop-Invariant Code Motion"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4737731},
abstract = {
    <p>A virtual machine in OVA (Open Virtualization) format containing * The version of CompCert used to perform the experiments, for compiling to x86-64, AArch64, Risc-V and Kalray KV3. * The benchmarks. * Scripts to recreate the tables and figures of the paper.</p>

},
keywords = {AArch64, common subexpression elimination, KV3, Polybench, Risc-V, verified compilation, x86-64}
}

@software{10.5281/zenodo.4740299,
author = {Cai, Xuyi and Wang, Ying and Zhang, Lei},
title = {Replication Package for Article: Optimus: Towards Optimal Layer-Fusion on Deep Learning Processors},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4740299},
abstract = {
    <p>This is the implementation of the paper “Optimus: Towards Optimal Layer-Fusion on Deep Learning Processors”</p>

},
keywords = {embedded processor, layer fusion, memory, neural network}
}

@software{10.1145/3410284,
author = {Szab\'{o}, Tam\'{a}s and Erdweg, Sebastian and Bergmann, G\'{a}bor},
title = {Replication Package for Article: Incremental Whole-Program Analysis in Datalog with Lattices},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410284},
abstract = {
    <p>This is an Ubuntu-based virtual machine with the IncA program analysis framework and benchmark Java programs already set up on it. The artifact can be used to execute the incremental static analyses described in the paper “Incremental Whole-Program Analysis in Datalog with Lattices” and to reproduce the presented measurement results.</p>

},
keywords = {Datalog, Incremental Computing, Static Analysis}
}

@software{10.1145/3410285,
author = {Guria, Sankha Narayan and Foster, Jeffrey S. and Van Horn, David},
title = {Replication Package for Article: RbSyn: Type- and Effect-Guided Program Synthesis},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410285},
abstract = {
    <p>The artifact is a Docker image that contains all of the source code, benchmarks, and experiment harnesses used in the development of the paper (set-up and ready to run). The README contains instructions to reproduce results from the paper, as well as pointers for how to extend or modify the tool and benchmarks.</p>

},
keywords = {program synthesis, Ruby, type and effect systems}
}

@software{10.1145/3410286,
author = {Erdweg, Sebastian and Szab\'{o}, Tam\'{a}s and Pacak, Andr\'{e}},
title = {Artifact: Concise, Type-Safe, and Efficient Structural Diffing},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410286},
abstract = {
    <p>Implementation of the algorithm in Scala; benchmark code and data.</p>

},
keywords = {incremental computing, tree diffing}
}

@software{10.1145/3410288,
author = {Montagu, Beno\^{\i}t and Jensen, Thomas},
title = {Static Control-Flow Analyzers for the Article: Trace-Based Control-Flow Analysis},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410288},
abstract = {
    <p>The artifact contains prototype implementations of the static analyzers for control-flow analysis (CFA) described in the PLDI’21 article “Trace-Based Control-Flow Analysis”, a collection of program examples, and a procedure to reproduce the experimental results presented in the article. The artifact is a TAR.XZ archive, that contains a README file, a LICENSE file and two components. The first component is the OCaml source code of the analyzers. We also provide a version of the analyzers that runs in a web browser directly. The second component is a docker container that embeds the same sources and a minimal Linux environment so that you can compile the sources and execute the analyzers. The README file describes with details the procedure to build and run the artifact using the docker container.</p>

},
keywords = {CFA, control-flow analysis, lambda-calculus, static analysis, widening}
}

@software{10.1145/3410289,
author = {Baudart, Guillaume and Burroni, Javier and Hirzel, Martin and Mandel, Louis and Shinnar, Avraham},
title = {Replication package for the article: Compiling Stan to Generative Probabilistic Languages and Extension to Deep Probabilistic Programming},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410289},
abstract = {
    <p>This artifact contains the <a href="https://mc-stan.org">Stan</a> (+ extensions) to Pyro and NumPyro compiler presented in the paper, and the code to reproduce the evaluation.</p>
<p>The artifact comprises 3 main parts corresponding to the 3 top-level directories. - <code>stanc3</code>: the fork of the <a href="https://github.com/stan-dev/stanc3">Stanc3 compiler</a> with two new backends targeting <a href="http://pyro.ai/">Pyro</a> and <a href="https://github.com/pyro-ppl/numpyro">NumPyro</a> (clone of https://github.com/deepppl/stanc3) - <code>stan-num-pyro</code>: the Pyro and NumPyro runtime libraries to execute the program (clone of https://github.com/deepppl/stan-num-pyro) - <code>evaluation</code>: code and data to reproduce the evaluation section of the paper (clone of https://github.com/deepppl/evaluation)</p>
<p>In addition the artifact also contains: - <code>README.md</code>: this file - <code>deepstan.tar.gz</code>: a Docker image with the compiler and runtime installed - <code>pldi2021.pdf</code>: the paper - <code>coin.stan</code>: a simple Stan program - <code>coin_infer.py</code>: a Python script to compile and execute <code>coin.stan</code> - <code>requirements.txt</code>: the list of Python dependencies - <code>deepstan.docker</code>: the docker file used to build the image.</p>
<p>To summarize this artifact: - Demonstrates that it is possible to compile Stan programs to generative probabilistic programming languages by providing a modified version of the Stanc3 compiler with two new backends targeting Pyro and NumPyro. - Demonstrates the extension of Stan with deep probabilistic programming and variational inference with explicit guides. - Provides the code used in the evaluation section of the paper to answer the following research questions: - RQ1: Can we compile and run all Stan models? - RQ2: What is the impact of the compilation on accuracy? - RQ3: What is the impact of the compilation on speed? - RQ4: Are explicit variational guides useful? - RQ5: For deep probabilistic models, how does DeepStan compare to hand-written Pyro code?</p>

},
keywords = {Compilation, Deep probabilistic programming, NumPyro, Probabilistic programming, Pyro, Stan, Variational inference}
}

@software{10.1145/3410290,
author = {Anderson, Daniel and Blelloch, Guy E. and Wei, Yuanhao},
title = {Artifact for "Concurrent Deferred Reference Counting with Constant-Time Overhead"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410290},
abstract = {
    <p>This artifact contains a preliminary version of our C++ library for atomic reference-counted pointers and a benchmark suite that evaluates its performance against existing reference-counted pointers and manual SMR techniques.</p>

},
keywords = {automatic memory management, concurrent algorithms, memory reclamation, reference counting}
}

@software{10.1145/3410291,
author = {Yu, Nengkun and Palsberg, Jens},
title = {Software artifact for the paper "Quantum Abstract Interpretation"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410291},
abstract = {
    <p>The artifact allows a user to reproduce the experimental results in the paper “Quantum Abstract Interpretation”.</p>

},
keywords = {abstract interpretation., Quantum programming, scalability}
}

@software{10.1145/3410292,
author = {Cho, Kyeongmin and Lee, Sung-Hwan and Raad, Azalea and Kang, Jeehoon},
title = {Mechanized Proof and Model Checker for Article: Revamping Hardware Persistency Models},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410292},
abstract = {
    <h2 id="revamping-hardware-persistency-models-view-based-and-axiomatic-persistency-models-for-intel-x86-and-armv8">Revamping Hardware Persistency Models: View-Based and Axiomatic Persistency Models for Intel-x86 and Armv8</h2>
<p>This is the artifact for the following paper:</p>
<p>Kyeongmin Cho, Sung-Hwan Lee, Azalea Raad, and Jeehoon Kang. Revamping Hardware Persistency Models: View-Based and Axiomatic Persistency Models for Intel-x86 and Armv8. PLDI 2021.</p>
<h3 id="contributions-paper-1">Contributions (paper §1)</h3>
<ul>
<li>We discuss the shortcomings of the existing persistency models of Intel-x86/Armv8 and present an intuitive account of our solution as view-based models (§2).</li>
<li>We develop x86_view, a new view-based model for Intelx86 concurrency (§3).</li>
<li>We develop Px86_view (§3.5) and PArmv8_view (§6.2), respectively extending the x86_view and Armv8_view models to account for persistent memory.</li>
<li>We present Px86_axiom (§4) and PArmv8_axiom (§6.3), our axiomatic models of Intel-x86 and Armv8 persistency that simplify and repair the state-of-the-art models of the respective architectures. We prove that our axiomatic models are equivalent to the authoritative semantics reviewed by Intel and Arm engineers, modulo our proposed fixes (§4.4 and §6.3). Our proposed fix in PArmv8_axiom has been reviewed by Arm engineers.</li>
<li>We prove that Px86_view and PArmv8_view are equivalent to Px86_axiom and PArmv8_axiom, respectively. The equivalence proof is mechanized in Coq (§5 and §6.4).</li>
<li>We develop a model checker for persistency and use it to verify several representative examples under PArmv8view (§7). We conclude with related and future work (§8).</li>
</ul>
<h3 id="artifacts">Artifacts</h3>
<ul>
<li>Coq formalization (§2-6) of the hardware persistency models (Px86-{view, axiom}, PArmv8-{view, axiom}) and their equivalence proofs</li>
<li>Model checker (§7) for Armv8 persistency</li>
</ul>
<h3 id="getting-started-guide">Getting Started Guide</h3>
<p>Each of Coq formalization and model checker has its own repository: - Coq formalization’s <a href="https://github.com/kaist-cp/view-hw/blob/master/README.md">repository</a> - Model checker’s <a href="https://github.com/kaist-cp/rmem-persistency">repository</a>.</p>
<p>These repositories are forks of <a href="https://github.com/snu-sf/promising-arm">snu-sf/promising-arm</a> and <a href="https://github.com/rems-project/rmem">rems-project/rmem</a>, respectively.</p>
<p>For each repository, you can either manually build it or reuse docker images in which the projects are already built.</p>
<h4 id="manual-build">Manual build</h4>
<p>Please read each repository’s README:</p>
<ul>
<li>Coq formalization’s <a href="https://github.com/kaist-cp/view-hw/blob/master/README.md#installation">README</a></li>
<li>Model checker’s <a href="https://github.com/kaist-cp/rmem-persistency#build">README</a></li>
</ul>
<h4 id="docker-image">Docker image</h4>
<p>Each repository contains a <code>Dockerfile</code>:</p>
<ul>
<li>Coq formalization’s <a href="https://github.com/kaist-cp/view-hw/blob/master/Dockerfile">Dockerfile</a></li>
<li>Model checker’s <a href="https://github.com/kaist-cp/rmem-persistency/blob/master/Dockerfile">Dockerfile</a></li>
</ul>
<p>You can download the prebuilt docker images <a href="https://drive.google.com/drive/folders/1HCojYdChl1qsSTHDrjWdAzS8SE2NRuLC?usp=sharing">here</a>.</p>
<h3 id="step-by-step-instructions">Step-by-Step Instructions</h3>
<ul>
<li>Coq formalization’s <a href="https://github.com/kaist-cp/view-hw/blob/master/README.md#our-results">README</a> explains which part of codes matches one of definitions, lemmas and theorems in the paper.</li>
<li>Model checker’s <a href="https://github.com/kaist-cp/rmem-persistency#run-an-example">README</a> exlains how to run the program to verify each example in the paper. It’s expected that all results come out within 1 second as mentioned in the paper.</li>
</ul>

},
keywords = {Armv8, mechanized proof, model checker, non-volatile random-access memory, NVRAM, persistency semantics, persistent memory, x86}
}

@software{10.1145/3410293,
author = {Wang, Di and Hoffmann, Jan and Reps, Thomas},
title = {Replication Package for Article: Central Moment Analysis for Cost Accumulators in Probabilistic Programs},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410293},
abstract = {
    <p>This artifact provides an implementation of a static analyzer for higher (raw or central) moments of cost accumulators (e.g., running time) in probabilistic programs.</p>

},
keywords = {central moments, cost analysis, Probabilistic programs, tail bounds}
}

@software{10.1145/3410294,
author = {Sotoudeh, Matthew and Thakur, Aditya V.},
title = {Replication Package for Article: Provable Repair of Deep Neural Networks},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410294},
abstract = {
    <p>The zip file contains our artifact as a virtual machine as well as a README with instructions. An updated version of this artifact is stored at https://github.com/95616ARG/PRDNN</p>

},
keywords = {deep learning, machine learning, program repair}
}

@software{10.1145/3410295,
author = {Erbsen, Andres and Gruetter, Samuel and Choi, Joonwon and Wood, Clark and Chlipala, Adam},
title = {Replication Package for Article: Integration Verification across Software and Hardware for a Simple Embedded System},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410295},
abstract = {
    <p>This artifact includes the Coq development described in the paper and all dependencies for generating the FPGA bitstream. All this is packaged as a .vdi disk image that boots into a Linux terminal environment accessible over SSH. The artifact was evaluated by running it in VirtualBox as described in README.txt.</p>

},
keywords = {Embedded Systems, Formal Verification, Hardware-Software Interface, Proof Assistants, RISC-V Instruction-Set Family}
}

@software{10.1145/3410297,
author = {Hu, Xiaowen and Zhao, David and Jordan, Herbert and Scholz, Bernhard},
title = {Artifact for Paper: An Efficient Interpreter for Datalog by De-specializing Relations},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410297},
abstract = {
    <p>The artifact provides source code, experiments input and necessary instructions for reproducing the primary results in the paper “An Efficient Interpreter for Datalog by De-specializing Relations”.</p>

},
keywords = {Datalog, interpreter, static analysis}
}

@software{10.1145/3410298,
author = {Koenig, Jason R. and Padon, Oded and Aiken, Alex},
title = {Replication Package for Article: Adaptive Restarts for Stochastic Synthesis},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410298},
abstract = {
    <p>This artifact contains the synthesis evaluation program and Superoptimization Benchmark of synthesis problems, experimental data, code for scraping new synthesis problems, input binaries for scraping, chart generating scripts, and other support scripts.</p>

},
keywords = {binary code, program synthesis, restart algorithms, superoptimization}
}

@software{10.1145/3410299,
author = {Acay, Co\c{s}ku and Recto, Rolph and Gancher, Joshua and Myers, Andrew C. and Shi, Elaine},
title = {Replication Package for Viaduct: An Extensible, Optimizing Compiler for Secure Distributed Programs},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410299},
abstract = {
    <p>This artifact contains code and instructions necessary to replicate experimental results in the article “Viaduct: An Extensible, Optimizing Compiler for Secure Distributed Programs.” We provide a Docker image with the Viaduct compiler and all its dependencies installed, as well as the code samples used in the evaluation. The image also includes scripts for running the experiments from the paper.</p>

},
keywords = {information flow, multiparty computation, zero knowledge}
}

@software{10.1145/3410300,
author = {Wang, Di and Hoffmann, Jan and Reps, Thomas},
title = {Replication Package for Article: Sound Probabilistic Inference via Guide Types},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410300},
abstract = {
    <p>This artifact provides an implementation of a probabilistic programming language that (i) features a coroutine-based paradigm for implementing generative models and custom inference guides (e.g., proposals for importance sampling), and (ii) uses a novel guide-type system to ensure that the distributions specified by a model and its guide have the same support; as a consequence, the model-guide pair is provably sound for probabilistic inference.</p>

},
keywords = {Bayesian inference, coroutines, Probabilistic programming, type systems}
}

@software{10.1145/3410301,
author = {Saad, Feras A. and Rinard, Martin C. and Mansinghka, Vikash K.},
title = {System Implementation and Experiments for SPPL: Probabilistic Programming with Fast Exact Symbolic Inference},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410301},
abstract = {
    <p>This artifact contains an implementation of the SPPL programming language (version 2.0.0), as well as code for experimental results and tutorial figures described in the paper.</p>

},
keywords = {probabilistic programming, symbolic execution}
}

@software{10.1145/3410302,
author = {Ellis, Kevin and Wong, Catherine and Nye, Maxwell and Sabl\'{e}-Meyer, Mathias and Morales, Lucas and Hewitt, Luke and Cary, Luc and Solar-Lezama, Armando and Tenenbaum, Joshua B.},
title = {DreamCoder software and data},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410302},
abstract = {
    <p>Source code for DreamCoder, pretrained checkpoints, and documentation</p>

},
keywords = {artificial intelligence, deep learning, program synthesis}
}

@software{10.1145/3410303,
author = {Nikolaev, Ruslan and Ravindran, Binoy},
title = {Replication Package for Article: Snapshot-Free, Transparent, and Robust Memory Reclamation for Lock-Free Data Structures},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410303},
abstract = {
    <p>The artifact contains a VM image (VirtualBox) with preinstalled Ubuntu 18.04 and the (precompiled) benchmark. The artifact also contains source code and instructions for manual (bare-metal) installations. The artifact also includes our data measurements and scripts for generating plots. Please see README.txt for more details.</p>

},
keywords = {epoch-based reclamation, hazard pointers, lock-free, memory reclamation, non-blocking}
}

@software{10.1145/3410304,
author = {Chatterjee, Krishnendu and Goharshady, Ehsan Kafshdar and Novotn\'{y}, Petr and \v{Z}ikeli\'{c}, undefinedor\dj{}e},
title = {RevTerm},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410304},
abstract = {
    <p>RevTerm is a static analysis tool for proving non-termination of integer C programs (possibly with non-determinism). RevTerm is an implementation of our method for non-termination proving presented in the paper “Proving Non-termination by Program Reversal”.</p>

},
keywords = {Program Termination, Static Analysis}
}

@software{10.1145/3410306,
author = {Koenig, J\'{e}r\'{e}mie and Shao, Zhong},
title = {Source code and virtual machine image for CompCertO: Compiling Certified Open C Components},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410306},
abstract = {
    <p>This artifact contains the source code for CompCertO v0.1 and a virtual machine image where all required dependencies have been installed on a Debian GNU/Linux system. The virtual machine image also contains a pre-built version of CompCertO and its documentation, which can immediately be browsed in CoqIDE and Firefox.</p>

},
keywords = {CompCert, Compilers, Compositional compiler correctness, Game semantics, Language interface, Simulation convention, Software verification}
}

@software{10.1145/3410307,
author = {Thakkar, Aalok and Naik, Aaditya and Sands, Nathaniel and Alur, Rajeev and Naik, Mayur and Raghothaman, Mukund},
title = {Example-Guided Synthesis of Relational Queries},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410307},
abstract = {
    <p>Tool for end-to-end automated synthesis of relational queries from input-output examples.</p>

},
keywords = {Program Synthesis, Programming-by-example}
}

@software{10.1145/3410310,
author = {Wang, Jinyi and Sun, Yican and Fu, Hongfei and Chatterjee, Krishnendu and Goharshady, Amir Kafshdar},
title = {Replication Package for Article: Quantitative Analysis of Assertion Violations in Probabilistic Programs},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410310},
abstract = {
    <p>This artifact contains our implementation of three synthesis algorithms as described in the paper. Algorithm 1&amp;2 are listed in section 5.1 \&amp; 5.2 and Algorithm 3 is in section 6.</p>

},
keywords = {Assertion, Automated Verification, Probabilistic Programs}
}

@software{10.1145/3410311,
author = {Basu, Nilanjana and Montanari, Claudio and Eriksson, Jakob},
title = {Replication Package for Frequent Background Polling on a Shared Thread, using Light-Weight Compiler Interrupts},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410311},
abstract = {
    <p>The artifact contains the libraries for a Compiler Interrupt pass, \&amp; the code for all experiments reported in the paper.</p>

},
keywords = {Compiler Interrupts, interrupt accuracy and overhead}
}

@software{10.1145/3410313,
author = {Zhu, Shaowei and Kincaid, Zachary},
title = {Replication Package for Article: Termination Analysis without the Tears},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410313},
abstract = {
    <p>The artifact is a virtual machine that contains ComPACT, a compositional and monotone termination analysis for C programs. The virtual machine also contains all softwares and their dependencies required to replicate the experimental results of PLDI 2021 paper “Termination Analysis without the Tears”.</p>

},
keywords = {algebraic path problems, Algebraic program analysis, loop summarization, termination analysis}
}

@software{10.1145/3462276,
author = {Omar, Cyrus and Moon, David and Blinn, Andrew and Voysey, Ian and Collins, Nick and Chugh, Ravi},
title = {Evaluted Artifact for: Filling Typed Holes with Live GUIs},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3462276},
abstract = {
    <p>Agda proofs and snapshot of Hazel implementation described in the paper.</p>

},
keywords = {GUIs, live programming, macros, typed holes}
}

@software{10.1184/R1/14356976,
author = {Takashima, Yoshiki and Martins, Ruben and Jia, Limin and P\u{a}s\u{a}reanu, Corina S.},
title = {SyRust Artifact: PLDI2021 Artifact},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1184/R1/14356976},
abstract = {
    <p>This artifact contains software required to replicate the results of the paper “SyRust: Automatic Testing of Rust Libraries with Semantic-Aware Program Synthesis” published at PLDI 2021.</p>
<p>The artifact consists of SyRust source code, configuration files to fully replicate our experiments, post-processing scripts to summarize data, and docker images for maintaining and environment for replicability.</p>

},
keywords = {API Testing, Rust, Security, Software Engineering, Synthesis}
}

@software{10.5281/zenodo.4649822,
author = {Sammler, Michael and Lepigre, Rodolphe and Krebbers, Robbert and Memarian, Kayvan and Dreyer, Derek and Garg, Deepak},
title = {Artifact and Appendix of "RefinedC: Automating the Foundational Verification of C Code with Refined Ownership Types"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4649822},
abstract = {
    <p>This is the artifact for the PLDI’21 paper “RefinedC: Automating the Foundational Verification of C Code with Refined Ownership Types”. It contains the RefinedC tool including its Coq development and the appendix for the paper.</p>

},
keywords = {C programming language, Coq, Iris, ownership types, proof automation, refinement types, separation logic}
}

@software{10.5281/zenodo.4663292,
author = {Stein, Benno and Chang, Bor-Yuh Evan and Sridharan, Manu},
title = {Artifact for Article: Demanded Abstract Interpretation},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4663292},
abstract = {
    <p>The artifact is a docker image containing source code and binaries needed to reproduce the paper’s experiments.</p>

},
keywords = {Abstract interpretation, demand-driven analysis, incremental analysis}
}

@software{10.5281/zenodo.4665859,
author = {Paradis, Anouk and Bichsel, Benjamin and Steffen, Samuel and Vechev, Martin},
title = {Replication Package for Article: Unqomp: Synthesizing Uncomputation in Quantum Circuits},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4665859},
abstract = {
    <p>This is a snapshot of Unqomp, providing the artifact for the PLDI’21 paper “Unqomp: Synthesizing Uncomputation in Quantum Circuits”. For the latest version of Unqomp, refer to https://github.com/eth-sri/Unqomp.</p>
<p>It contains the implementation of Unqomp for Qiskit, as well as all the necessary material to reproduce the evaluation of our paper.</p>

},
keywords = {Quantum Circuits, Synthesis, Uncomputation}
}

@software{10.5281/zenodo.4668317,
author = {Shariffdeen, Ridwan and Noller, Yannic and Grunske, Lars and Roychoudhury, Abhik},
title = {Replication Package for: Concolic Program Repair},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4668317},
abstract = {
    <p>This is the artifact for the PLDI’2021 submission “Concolic Program Repair”. It includes the following content: * the tool CPR, which implements our concolic program repair concept, * all benchmark subjects and scripts to reproduce our evaluation, and * additional documentation to allow the re-usage of CPR, as well as helpful examples.</p>

},
keywords = {patch overfitting, program repair, program synthesis, symbolic execution}
}

@software{10.5281/zenodo.4671078,
author = {Ringer, Talia and Porter, RanDair and Yazdani, Nathaniel and Leo, John and Grossman, Dan},
title = {PUMPKIN Pi},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4671078},
abstract = {
    <p>This is the artifact for the PLDI 2021 paper “Proof Repair Across Type Equivalences.” The anonymized version has been vetted by AEC as functional and reusable. A deanonymized version corresponding to the links in the paper has been uploaded as a second version (version “deanonymized”).</p>

},
keywords = {Coq, interactive theorem provers, proof assistants, proof engineering, proof evolution, proof repair}
}

@software{10.5281/zenodo.4674301,
author = {P\^{\i}rlea, George and Kumar, Amrit and Sergey, Ilya},
title = {CoSplit (PLDI 2021 Artefact)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4674301},
abstract = {
    <p>Virtual machine: The CoSplit.ova file is a virtual machine image containing the full artefact, including the CoSplit static analysis, its integration with the Zilliqa blockchain, the benchmark suite used for evaluation, the Ethereum dataset, and the Jupyter notebook used to analyse the dataset. This is the artefact that was evaluated during the PLDI 2021 Artifact Evaluation process.</p>
<p>The virtual machine image was generated using Virtual Box Version 6.1.18 r142142 and is known to work with that version of the software.</p>
<p>Source code: Please download cosplit-artefact-archive.zip. This includes the full source code, including dependencies, and the Ethereum dataset. The archive produced by GitHub (dranov/cosplit-artefact-v0.1-beta.zip) does not include the dependencies and dataset.</p>

},
keywords = {automatic parallelisation, blockchain, sharding, smart contracts, static analysis}
}

@software{10.5281/zenodo.4679316,
author = {Kalhauge, Christian Gram and Palsberg, Jens},
title = {Artifact from "Logical Bytecode Reduction"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4679316},
abstract = {
    <p>The artifact is a Virtual Box containing the results and everything to reproduce the results of the paper. Furthermore, it contains the source code of jreduce.</p>
<p>More information can be found in the REAMDE file in the artifact or at https://github.com/ucla-pls/pldi21-artifact/blob/master/README.md</p>

},
keywords = {input reduction}
}

@software{10.5281/zenodo.4679743,
author = {Itzhaky, Shachar and Peleg, Hila and Polikarpova, Nadia and Rowe, Reuben N. S. and Sergey, Ilya},
title = {Cypress (PLDI 2021 Artifact): Code and Benchmarks},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4679743},
abstract = {
    <p>Artifact accompanying the the paper Cyclic Program Synthesis published in proceedings of PLDI 2021.</p>

},
keywords = {cyclic proofs, program synthesis, program verification, separation logic}
}

@software{10.5281/zenodo.4679983,
author = {Christensen, Michael and Sherwood, Timothy and Balkind, Jonathan and Hardekopf, Ben},
title = {Replication Package for Artifact: "Wire Sorts: A Language Abstraction for Safe Hardware Composition"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4679983},
abstract = {
    <p>This artifact contains the code for reproducing the results in the paper “Wire Sorts: A Language Abstraction for Safe Hardware Composition.” Its purpose is to demonstrate how our tool can analyze and annotate hardware modules in order to determine their input and output wire sorts (and check these sorts against any user ascriptions), as well as use these sorts to improve intermodular connection checks.</p>

},
keywords = {combinational cycle detection, composition, hardware description languages, modules}
}

@software{10.5281/zenodo.4680045,
author = {Vega, Luis and McMahan, Joseph and Sampson, Adrian and Grossman, Dan and Ceze, Luis},
title = {Replication package for Reticle: A Virtual Machine for Programming Modern FPGAs},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4680045},
abstract = {
    <p>Virtual machine image containing all necessary dependencies for running the evaluation in the paper</p>

},
keywords = {compilers, FPGAs}
}

@software{10.5281/zenodo.4680470,
author = {Donaldson, Alastair F. and Thomson, Paul and Teliman, Vasyl and Milizia, Stefano and Maselco, Andr\'{e} Perez and Karpi\'{n}ski, Antoni},
title = {Artifact for "Test-Case Reduction and Deduplication Almost for Free with Transformation-Based Compiler Testing", PLDI 2021},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4680470},
abstract = {
    <p>Artifact associated with PLDI paper, providing the version of the spirv-fuzz tool that was used for evaluation in the paper, together with the ability to reproduce a number of results using the SwiftShader implementation of SPIR-V, as well as data sets associated with the full set of experiments reported in the paper.</p>

},
keywords = {Compilers, metamorphic testing, SPIR-V}
}

@software{10.5281/zenodo.4680746,
author = {Spies, Simon and G\"{a}her, Lennard and Gratzer, Daniel and Tassarotti, Joseph and Krebbers, Robbert and Dreyer, Derek and Birkedal, Lars},
title = {Coq Development for "Transfinite Iris: Resolving an Existential Dilemma of Step-Indexed Separation Logic"},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4680746},
abstract = {
    <p>This is the artifact for the paper “Transfinite Iris: Resolving an Existential Dilemma of Step-Indexed Separation Logic”. It contains the Coq mechanization of Transfinite Iris, in particular its soundness proof, program logics, and the examples presented in the paper. The artifact contains the Transfinite Iris development both in a VM image with pre-built sources and as a .zip source archive.</p>

},
keywords = {Coq, Iris, mechanized proofs, separation logic, transfinite step-indexing}
}

@software{10.5281/zenodo.4681027,
author = {Castro-Perez, David and Ferreira, Francisco and Gheri, Lorenzo and Yoshida, Nobuko},
title = {Zooid: a DSL for Certified Multiparty Computation},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4681027},
abstract = {
    <p>This is the implementation and Coq mechanisation of the metathory of Multiparty Session Types (MPST) as described on the paper.</p>

},
keywords = {concur- rent processes, Coq, deadlock freedom, liveness, mechanisation, multiparty session types, protocol compliance}
}

@software{10.5281/zenodo.4681598,
author = {Lasser, Sam and Casinghino, Chris and Fisher, Kathleen and Roux, Cody},
title = {CoStar parser implementation, correctness proofs, and performance evaluation},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4681598},
abstract = {
    <p>Artifact submitted for evaluation along with the PLDI 2021 paper "CoStar: A Verified ALL(*) Parser."</p>

},
keywords = {interactive theorem proving, parsing}
}

@software{10.5281/zenodo.4682172,
author = {Bruno, Rodrigo and Jovanovic, Vojin and Wimmer, Christian and Alonso, Gustavo},
title = {Compiler-Assisted Object Inlining with Value Fields},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4682172},
abstract = {
    <p>Object Oriented Programming has flourished in many areas ranging from web-oriented microservices, data processing, to databases. However, while representing domain entities as objects is appealing to developers, it leads to high data fragmentation as data is loaded into applications as large collections of data objects, resulting in high memory footprint and poor locality.</p>
<p>To minimize memory footprint and increase memory locality, embedding the payload of an object into another object (object inlining) has been considered before but existing techniques present severe limitations that prevent it from becoming a widely adopted technique. We argue that object inlining is mostly useful to optimize the application data-path and that objects in the data-path have value semantics, which unlocks great potential for inlining objects. We therefore propose value fields, an abstraction which allows fields to be marked as having value semantics.</p>
<p>We implement value fields for GraalVM Native Image. Object inlining is implemented as a compiler pipeline phase that mutates both object layouts and application code to access inlined fields. Experimental evaluation shows that applying value fields in real-world frameworks such as Apache Spark, Spring Boot, and Micronaut, requires minimal or even no effort at all from developers. Results show improvements in throughput of up to 3x, memory footprint reduction of up to 40\% and reduced GC pause times of up to 35\%.</p>

},
keywords = {Compiler Optimization, Language Implementation, Memory Management, Object Oriented, Programming Runtime Systems}
}

@software{10.5281/zenodo.4682681,
author = {Prabhu, Sumanth and Fedyukovich, Grigory and Madhukar, Kumar and D'Souza, Deepak},
title = {Artifact for the paper Specification Synthesis with Constrained Horn Clauses},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4682681},
abstract = {
    <p>The artifact is a zip file consisting of: pldi21.ova - a VirtualBox image consisting of tools to reproduce the data from the paper pldi21.md5 - md5sum of pldi21.ova README - instructions on how to use the artifact</p>

},
keywords = {automated verification, inductive invariants, SMT solvers, specification synthesis}
}

@software{10.5281/zenodo.4682811,
author = {Beutner, Raven and Ong, Luke},
title = {Probabilistic Termination Analysis Tools for: On Probabilistic Termination of Functional Programs with Continuous Distributions},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4682811},
abstract = {
    <p>Tools for computing lower bounds on the probability of termination (called LowerBound) and verification of AST of non-affine recursive programs (called astnar) for programs with continuous distributions. The tools build upon the theoretical results in the PLDI paper “On Probabilistic Termination of Functional Programs with Continuous Distributions”.</p>

},
keywords = {almost-sure termination, functional programs, lower bounds, Probabilistic programs, termination}
}

@software{10.5281/zenodo.4685966,
author = {Lim, Jay P. and Nagarakatte, Santosh},
title = {High Performance Correctly Rounded Math Libraries for 32-bit Floating Point Representations},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4685966},
abstract = {
    <p>RLIBM-32 is both a math library that provides correctly rounded result for all inputs and tools used to generate the correct polynomials. The techniques behind the tools will be appearing at PLDI 2021. Currently, RLIBM-32 supports a number of elementary functions for float and posit32 representations.</p>
<h4 id="list-of-float-functions-supported-by-rlibm-32">List of float functions supported by RLIBM-32</h4>
<ol type="1">
<li><p>log(x), log2(x), log10(x)</p></li>
<li><p>exp(x), exp2(x), exp10(x)</p></li>
<li><p>sinh(x), cosh(x)</p></li>
<li><p>sinpi(x), cospi(x)</p></li>
</ol>
<h4 id="list-of-posit32-functions-supported-by-rlibm-32">List of posit32 functions supported by RLIBM-32</h4>
<ol type="1">
<li><p>log(x), log2(x), log10(x)</p></li>
<li><p>exp(x), exp2(x), exp10(x)</p></li>
<li><p>sinh(x), cosh(x)</p></li>
</ol>

},
keywords = {correctly rounded results, elementary functions, floating point, posits}
}

@software{10.5281/zenodo.4763118,
author = {Farzan, Azadeh and Nicolet, Victor},
title = {Phased Synthesis of Divide and Conquer Programs (Software Artifact)},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4763118},
abstract = {
    <p>This software artifact implements the automatic methodology described in the paper. A README.md file has been provided with instructions on how to reproduce the results presented in the paper, as well as instructions on how to build the software from the provided sources.</p>

},
keywords = {Divide-And-Conquer Algorithms, Program Synthesis}
}

@software{10.5281/zenodo.1419788,
author = {Valiev, Marat and Vasilescu, Bogdan and Herbsleb, James},
title = {Ecosystem-Level Determinants of Sustained Activity in Open-Source Projects: A Case Study of the PyPI Ecosystem},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.1419788},
abstract = {
    <p>Replication pack, FSE2018 submission #164</p>

},
keywords = {Software Engineering}
}

@software{10.5281/zenodo.3907232,
author = {Sharma, Vaibhav and Hussein, Soha and Whalen, Michael W. and McCamant, Stephen and Visser, Willem},
title = {java-ranger: v1.0.0},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3907232},
abstract = {
    <p>This is the version of Java Ranger that was used in the evaluation accepted to FSE 2020.</p>

},
keywords = {Java, Software Engineering, Software Verification}
}

@software{10.1145/3373095,
author = {Maillard, Kenji and Hri\c{t}cu, C\u{a}t\u{a}lin and Rivas, Exequiel and Van Muylder, Antoine},
title = {Coq development for The Next 700 Relational Program Logics},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373095},
abstract = {
    <p>This artifact contains the Coq development supporting the paper “The Next 700 Relational Program Logics” with a formalization of relative monads enriched over orders and relational program logics for state, exception, Imp instantiating the general framework.</p>

},
keywords = {category theory, Coq, relational program logics, relative monad, side-effects}
}

@software{10.5281/zenodo.4399900,
author = {Miu, Anson and Ferreira, Francisco and Yoshida, Nobuko and Zhou, Fangyi},
title = {Communication-Safe Web Programming in TypeScript with Routed Multiparty Session Types},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4399900},
abstract = {
    <p>Our paper presents STScript, a toolchain that generates TypeScript APIs for communication-safe web development over WebSockets, and RouST, a new session type theory that supports multiparty communications with routing mechanisms.</p>

},
keywords = {API generation, deadlock freedom, session types, TypeScript, web programming, WebSocket}
}

@software{10.5281/zenodo.4416117,
author = {Silva, Anderson Faustino da and de Lima, Bernardo N. B. and Pereira, Fernando Magno Quint\~{a}o},
title = {Replication Package for Article: Exploring the Space of Optimization Sequences for Code-Size Reduction: Insights and Tools},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4416117},
abstract = {
    <p>Predictive compilation is the problem of determining good sequences of analyses and optimizations for particular programs. Although predictive compilers have enjoyed much progress in recent years, their development still faces a difficult challenge: the vastness of the space of possible optimizations that can be matched with each program. The effective exploration of this space is a community task that must be carried out gradually and systematically. Towards this vision, this artifact provides an Docker image that contains an optimization cache for research on code-size reduction. In addition, it provides a set of building blocks so that the user can build his/her own application.</p>

},
keywords = {code size, Compiler, sequence}
}

@software{10.5281/zenodo.4456774,
author = {Merigoux, Denis and Monat, Rapha\"{e}l and Protzenko, Jonathan},
title = {A Modern Compiler for the French Tax Code - Artifact},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4456774},
abstract = {
    <p>In France, income tax is computed from taxpayers’ individual returns, using an algorithm that is authored, designed and maintained by the French Public Finances Directorate (DGFiP). This algorithm relies on a legacy custom language and compiler originally designed in 1990, which unlike French wine, did not age well with time. Owing to the shortcomings of the input language and the technical limitations of the compiler, the algorithm is proving harder and harder to maintain, relying on ad-hoc behaviors and workarounds to implement the most recent changes in tax law. Competence loss and aging code also mean that the system does not benefit from any modern compiler techniques that would increase confidence in the implementation.</p>
<p>We overhaul this infrastructure and present Mlang, an open-source compiler toolchain whose goal is to replace the existing infrastructure. Mlang is based on a reverse-engineered formalization of the DGFiP’s system, and has been thoroughly validated against the private DGFiP test suite. As such, Mlang has a formal semantics; eliminates previous hand-written workarounds in C; compiles to modern languages (Python); and enables a variety of instrumentations, providing deep insights about the essence of French income tax computation. The DGFiP is now officially transitioning to Mlang for their production system.</p>
<p>This is the artifact accompanying the published paper at Compiler Construction 2021.</p>

},
keywords = {compiler, legal expert system, tax code}
}

@software{10.5281/zenodo.4458159,
author = {Palmkvist, Viktor and Castegren, Elias and Haller, Philipp and Broman, David},
title = {Resolvable Ambiguity - CC Artifact},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4458159},
abstract = {
    <p>This Docker image contains the software required to reproduce the results in the paper “Resolvable Ambiguity: Principled Resolution of Syntactically Ambiguous Programs” to be published in ACM SIGPLAN 2021 International Conference on Compiler Construction (CC 2021).</p>
<p>Note that as there is an element of randomness in the composition of language fragments, we include the same configuration used for Section 6, but also allow selecting new random combinations. For completeness, we also include the source code of our tool, but as it is not the main focus, it will not be as approachable as running the experiments.</p>

},
keywords = {Ambiguity, Syntax}
}

@software{10.5281/zenodo.4471345,
author = {Abella-Gonz\'{a}lez, Miguel \'{A}. and Carollo-Fern\'{a}ndez, Pedro and Pouchet, Louis-No\"{e}l and Rastello, Fabrice and Rodr\'{\i}guez, Gabriel},
title = {PolyBench/Python},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4471345},
abstract = {
    <p>PolyBench/Python is the reimplementation of PolyBench in the Python programming language. It is a benchmark suite of 30 numerical computations with static control flow, extracted from operations in various application domains (linear algebra computations, image processing, physics simulation, dynamic programming, statistics, etc.).</p>

},
keywords = {Benchmarking, Polyhedral Compilation, Python}
}

@software{10.1145/3410260,
author = {de Vilhena, Paulo Em\'{\i}lio and Pottier, Fran\c{c}ois},
title = {Artifact for A Separation Logic for Effect Handlers},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410260},
abstract = {
    <p>This artifact contains the Coq/Iris proofs that accompany the paper “A Separation Logic for Effect Handlers”.</p>

},
keywords = {Coq, effect handlers, Iris, program verification, separation logic}
}

@software{10.1145/3410262,
author = {Doenges, Ryan and Arashloo, Mina Tahmasbi and Bautista, Santiago and Chang, Alexander and Ni, Newton and Parkinson, Samwise and Peterson, Rudy and Solko-Breslin, Alaia and Xu, Amanda and Foster, Nate},
title = {Artifact for "Petr4: Formal Foundations for P4 Data Planes"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410262},
abstract = {
    <p>This artifact includes source code and tests for Petr4. For more information visit https://cornell-netlab.github.io/petr4/, where a full VM is also available, or check out the gh-pages branch of the artifact.</p>

},
keywords = {p4}
}

@software{10.1145/3410263,
author = {Barri\`{e}re, Aur\`{e}le and Blazy, Sandrine and Fl\"{u}ckiger, Olivier and Pichardie, David and Vitek, Jan},
title = {CoreJIT: a Replication Package for Article "Formally Verified Speculation and Deoptimization in a JIT Compiler "},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410263},
abstract = {
    <p>This is the development of CoreJIT, a formally verified JIT compiler.</p>

},
keywords = {just-in-time compilation, verified compilation}
}

@software{10.1145/3410264,
author = {Vassena, Marco and Disselkoen, Craig and Gleissenthall, Klaus von and Cauligi, Sunjay and K\i{}c\i{}, Rami G\"{o}khan and Jhala, Ranjit and Tullsen, Dean and Stefan, Deian},
title = {Replication package for article: Automatically Eliminating Speculative Leaks from Cryptographic Code with Blade},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410264},
abstract = {
    <p>See README.pdf included in the artifact for reviewer instructions. Included are the instructions and the VM image representing the artifact. Alternately, to set up the software on your own machine, see https://github.com/PLSysSec/blade-benchmarks/blob/master/README.md.</p>

},
keywords = {Constant-time, Lucet, Spectre, Speculative execution, WebAssembly}
}

@software{10.1145/3410265,
author = {Choudhury, Pritam and Eades III, Harley and Eisenberg, Richard A. and Weirich, Stephanie},
title = {Artifact for "A Graded Dependent Type System with a Usage-Aware Semantics"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410265},
abstract = {
    <p>This artifact contains Coq proofs for the type soundness proof described in Section 7.2.</p>

},
keywords = {dependent types, graded modal types, type soundness}
}

@software{10.1145/3410266,
author = {Sherman, Benjamin and Michel, Jesse and Carbin, Michael},
title = {Implementation of $\lambda_S$: Computable Semantics for Differentiable Programming with Higher-Order Functions and Datatypes},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410266},
abstract = {
    <p>This is the artifact for the paper “<span class="math inline"><em>λ</em><sub><em>S</em></sub></span>: Computable semantics for differentiable programming with higher-order functions and datatypes”. This repository contains the implementation of <span class="math inline"><em>λ</em><sub><em>S</em></sub></span> as an embedded language within Haskell. We name this library “smooth”.</p>

},
keywords = {Automatic Differentiation, Constructive Analysis, Diffeological Spaces}
}

@software{10.1145/3410267,
author = {Margalit, Roy and Lahav, Ori},
title = {Rocker},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410267},
abstract = {
    <p>Robustness Checker</p>

},
keywords = {C++11, C/C++11, C11, D, RC20, robustness, weak memory models}
}

@software{10.5281/zenodo.4067194,
author = {Lim, Jay P. and Aanjaneya, Mridul and Gustafson, John and Nagarakatte, Santosh},
title = {Artifact for the paper: An Approach to Generate Correctly Rounded Math Libraries for New Floating Point Variants},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4067194},
abstract = {
    <p>RLibm is a math library generator and a library that provides the correctly rounded result for all inputs. Currently, RLibm supports a number of elementary functions for bfloat16, posit16, and float representations.</p>

},
keywords = {elementary functions, floating point, polynomial approximation, posits}
}

@software{10.5281/zenodo.4068078,
author = {Gregersen, Simon Oddershede and Bay, Johan and Timany, Amin and Birkedal, Lars},
title = {Mechanized Logical Relations for Termination-Insensitive Noninterference (Artifact)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4068078},
abstract = {
    <p>A mechanized logical relations model for an expressive information-flow control type system with recursive types, existential types, label polymorphism, and impredicative type polymorphism for a higher-order programming language with higher-order state. The semantic model of the type system can be used to show that well-typed programs satisfy termination-insensitive noninterference but also to show that composing syntactically well-typed and syntactically ill-typed—but semantically sound—components is secure.</p>
<p>The model is defined using the Iris program logic framework. To capture termination-insensitivity, we make us of our theory of Modal Weakest Precondition. All of the theory and examples are formalized in the Coq proof assistant.</p>

},
keywords = {Coq, Information-Flow Control, Iris, Logical Relations, Program Logics}
}

@software{10.5281/zenodo.4071954,
author = {Rouvoet, Arjen and Krebbers, Robbert and Visser, Eelco},
title = {Intrinsically Typed Compilation with Nameless Labels: Virtual Machine},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4071954},
abstract = {
    <p>We present the library for separation logic, the model of nameless labels, and the implementation of the compiler backend in Agda.</p>

},
keywords = {Agda, Co-de-Bruijn, Compilation, Intrinsically-Typed, Labels, Proof relevant, Separation Logic}
}

@software{10.5281/zenodo.4072013,
author = {Willsey, Max and Nandi, Chandrakana and Wang, Yisu Remy and Flatt, Oliver and Tatlock, Zachary and Panchekha, Pavel},
title = {Artifact for "Fast and Extensible Equality Saturation"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4072013},
abstract = {
    <p>https://zenodo.org/record/4072013</p>

},
keywords = {e-graphs, equality saturation}
}

@software{10.5281/zenodo.4074932,
author = {Moy, Cameron and Nguy\~{\^e}n, Ph\'{u}c C. and Tobin-Hochstadt, Sam and Van Horn, David},
title = {Artifact: Corpse Reviver},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4074932},
abstract = {
    <p>This artifact contains a virtual machine appliance containing the SCV-CR tool and accompanying utilities for reproducing the experimental results reported in the paper.</p>

},
keywords = {contract verification, gradual typing, Typed Racket}
}

@software{10.5281/zenodo.4118715,
author = {Farka, Franti\v{s}ek and Nanevski, Aleksandar and Banerjee, Anindya and Delbianco, Germ\'{a}n Andr\'{e}s and F\'{a}bregas, Ignacio},
title = {On Algebraic Abstractions for Concurrent Separation Logics (artefact)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4118715},
abstract = {
    <p>The artefact contains Coq sources of the developments presented in the paper. The artefact supports the developments in both a theoretical and practical way. First, it provides a complete bottom-up mechanization of partial commutative monoids (PCM), separating relations, PCM morphisms, and the related constructions. The artefact formalizes all the concepts defined in the paper, Secondly, the artifact demonstrate practical utilisation of the theory of PCMs. Using FCSL (Nanevski et al, 2019) as the opaque type theory, the artefact provides mechanical verification of Ticket lock, the running example developed in the paper. The artefact also contains additional examples that the main body submission does not discuss.</p>

},
keywords = {Coq, Hoare/Separation Logics, Program Logics for Concurrency}
}

@software{10.5281/zenodo.4123035,
author = {Kokologiannakis, Michalis and Kaysin, Ilya and Raad, Azalea and Vafeiadis, Viktor},
title = {Replication Package for "PerSeVerE: Persistency Semantics for Verification under Ext4"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4123035},
abstract = {
    <p>This is the artifact accompanying the paper “PerSeVerE: Persistency Semantics for Verification under Ext4” which is accepted in POPL’21.</p>
<p>We consider our paper’s artifact to be the set of benchmarks and stress tests we used in the paper, as well as the results we got by running a particular version of Persevere (and its naive counterparts) on the benchmarks set. We do not consider the artifact of the paper to be Persevere itself, as it will evolve over time, and the results obtained by running the same benchmarks may differ in the future.</p>
<p>We have made Persevere publicly available on Github (https://github.com/MPI-SWS/genmc), as part of the GenMC tool. For any bugs, comments, or feedback regarding Persevere, please do not hesitate to contact us.</p>

},
keywords = {Filesystems, Persistency, Software Model Checking, Weak Memory Models}
}

@software{10.5281/zenodo.4139601,
author = {Gondelman, L\'{e}on and Gregersen, Simon Oddershede and Nieto, Abel and Timany, Amin and Birkedal, Lars},
title = {Distributed Causal Memory: Modular Specification and Verification in Higher-Order Distributed Separation Logic (Artifact)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4139601},
abstract = {
    <p>A specification and verification of an implementation of a causally-consistent distributeddatabase that supports modular verification of full functional correctness properties of clients and servers. We specify and reason about the causally-consistent distributed database in Aneris, a higher-order distributed separation logic for an ML-like programming language with network primitives for programming distributed systems. We demonstrate that our specifications are useful, by proving the correctness of small, but tricky,synthetic examples involving causal dependency and by verifying a session manager library implemented on top of the distributed database. We use Aneris’s facilities for modular specification and verification to obtain a highly modular development, where each component is verified in isolation, relying only on the specifications(not the implementations) of other components. We have used the Coq formalization of the Aneris logic to formalize all the results presented in the paper in the Coq proof assistant.</p>

},
keywords = {causal consistency, concurrency, Coq, Distributed systems, formal verification, higher-order logic, Iris, separation logic}
}

@software{10.5281/zenodo.4141684,
author = {Jones, Eddie and Ramsay, Steven},
title = {Intensional Datatype Refinement Checker},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4141684},
abstract = {
    <p>The Intensional Datatype Refinement tool is a GHC plugin that checks whether it is possible to type the program according to the refinement type system specified in our paper. This provides a guarantee of pattern-match safety but the complexity of inference is only linear in the size of the program. In addition to reporting a yes/no-instance, it also enable the user to explore a set-constraint style analysis of their program.</p>

},
keywords = {higher-order program verification, refinement types}
}

@software{10.5281/zenodo.4246174,
author = {Jacobs, Koen and Timany, Amin and Devriese, Dominique},
title = {Artifact POPL21 - Fully Abstract from Static to Gradual},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4246174},
abstract = {
    <p>This artifact contains a Coq/Iris proof of the fact that the embedding of STLCmu (the simply typed lambda calculus with equirecursive types) into GTLCmu (its gradualization) is fully abstract. It accompanies the paper “Fully abstract from Static to Gradual”.</p>

},
keywords = {Coq, full abstraction, gradual typing, GTLC}
}

@software{10.5281/zenodo.4265963,
author = {Ahman, Danel and Pretnar, Matija},
title = {Software artefact for the POPL 2021 paper "Asynchronous Effects"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4265963},
abstract = {
    <p>This is a software artefact for the POPL 2021 paper:</p>
<p>Danel Ahman and Matija Pretnar. 2021. Asynchronous Effects. Proc. ACM Program. Lang. 5, POPL, Article 24 (January 2021), 28 pages.</p>
<p>This software artefact comprises:</p>
<ul>
<li>an Agda formalisation of the core calculus presented in the POPL submission;</li>
<li>a prototype implementation of the core calculus in OCaml, called \AE{}ff; and</li>
<li>a Docker image that includes all necessary dependencies to use the artefact.</li>
</ul>
<p>For more information about the artefact and how to use it, see the README.md file in the attached archive.</p>

},
keywords = {Algebraic effects, Asynchrony, Concurrency, Interrupt handling, Signals}
}

@software{10.5281/zenodo.4268852,
author = {Arora, Jatin and Westrick, Sam and Acar, Umut A.},
title = {Replication Instructions for Article: Provably Space Efficient Parallel Functional Programming},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4268852},
abstract = {
    <p>Replication of the results presented in the article: Provably Space Efficient Parallel Functional Programming</p>

},
keywords = {disentanglement, functional programming, memory management, parallel computing}
}

@software{10.5281/zenodo.4269171,
author = {Lee, Woosuk},
title = {Artifacts for "Combining the Top-down Propagation and Bottom-up Enumeration for Inductive Program Synthesis"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4269171},
abstract = {
    <p>This artifact includes all things necessary􏰛 for reproducing experimental results in the paper “Combining the Top-down Propagation and Bottom-up Enumeration for Inductive Program Synthesis”. The source code for Duet, which is the tool presented in the paper, and the other baseline synthesizers (EUSolver, CVC4, and Euphony), and the scripts for running the experiments are contained.</p>

},
keywords = {Programming-by-example, Syntax-guided synthesis}
}

@software{10.5281/zenodo.4270313,
author = {Chen, Chao-Hong and Sabry, Amr},
title = {Artifact for A Computational Interpretation of Compact Closed Categories: Reversible Programming with Negative and Fractional Types},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4270313},
abstract = {
    <p>This artifact contains formalization of the abstract machines, interpreters, examples and proof of theorems in the paper.</p>

},
keywords = {Agda}
}

@software{10.5281/zenodo.4273768,
author = {Reynaud, Alban and Scherer, Gabriel and Yallop, Jeremy},
title = {Artifact accompanying the paper "A practical mode system for recursive definitions".},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4273768},
abstract = {
    <p>The paper studies a specific feature of some functional programming languages, namely recursive definitions of things that are not immediate functions (recursive records, functions preceded by local declarations or various other language constructs, etc.). We propose a new system of inference rules to characterize valid definitions, to avoid runtime errors when evaluating the definitions. An algorithm can be directly derived from our inference rules to check the validity of recursive definitions. The check has been integrated in the OCaml compiler – more precisely, the implementation work for the OCaml compiler led to the present paper.</p>
<p>The artifact provides evidence for the claims in the paper, principally:</p>
<p>Do the formal system presented in the paper and the implementation in OCaml compiler correspond to each other?</p>
<p>The artifact contains various versions of the OCaml compiler (and compilers for some other languages discussed in the paper), instructions for confirming that our system fixes the bugs claimed in the paper, examples that illustrate how the system works, references to the parts of the implementation that correspond to parts of the formal system, and evidence for the empirical claims that the paper makes about the prevalence and character of recursive value definitions in existing programs.</p>

},
keywords = {call-by-value, functional programming, ML, OCaml, recursion, semantics, types}
}

@software{10.5281/zenodo.4284088,
author = {Silver, Lucas and Zdancewic, Steve},
title = {Dijkstra Monads Forever: Termination-Sensitive Specifications for Interaction Trees},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4284088},
abstract = {
    <p>This artifact contains formal definitions and machine checked proofs for the objects and theorems presented in the paper.</p>

},
keywords = {Algebraic Effects, Coinduction, Coq, Monads, Specifications}
}

@software{10.5281/zenodo.4323505,
author = {Muller, Stefan K. and Hoffmann, Jan},
title = {RaCUDA software and Coq Proofs for "Modeling and Analyzing Evaluation Cost of CUDA Kernels"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4323505},
abstract = {
    <p>Software and proof artifacts for the POPL 2021 paper “Modeling and Analyzing Evaluation Cost of CUDA Kernels”. The artifact is packaged as a virtual machine image in ova format.</p>

},
keywords = {CUDA, performance analysis, program logics, resource-aware type system, thread-level parallelism}
}

@software{10.1145/3410252,
author = {Fritsche, Lars and Kosiol, Jens and M\"{o}ller, Adrian and Sch\"{u}rr, Andy and Taentzer, Gabriele},
title = {Artifact Evaluation for 'A Precedence-Driven Approach for Concurrent Model Synchronization Scenarios using Triple Graph Grammars'},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410252},
abstract = {
    <p>This artifact contains the evaluation of our paper ‘A Precedence-Driven Approach for Concurrent Model Synchronization Scenarios using Triple Graph Grammars’ in the form of a virtual machine and a step-by-step guide.</p>

},
keywords = {concurrent model synchronization, eMoflon, model-driven engineering, triple graph grammar}
}

@software{10.5281/zenodo.4032185,
author = {Urban, Caterina and Christakis, Maria and W\"{u}stholz, Valentin and Zhang, Fuyuan},
title = {Perfectly Parallel Fairness Certification of Neural Networks - Artifact},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4032185},
abstract = {
    <p>This is the artifact accompanying the published paper.</p>

},
keywords = {Abstract Interpretation, Fairness, Neural Networks, Static Analysis}
}

@software{10.5281/zenodo.4032401,
author = {Rigger, Manuel and Su, Zhendong},
title = {OOPSLA 20 Artifact for "Finding Bugs in Database Systems via Query Partitioning"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4032401},
abstract = {
    <p>The artifact consists of two main components:</p>
<ol type="1">
<li>SQLancer, the tool which we created and extended, and in which we implemented Ternary Logic Partitioning (TLP), to find all bugs reported in the paper.</li>
<li>A SQLite database with a list of bugs that we reported and additional meta information.</li>
</ol>

},
keywords = {Query Partitioning, SQLancer, Ternary Logic Partitioning}
}

@software{10.5281/zenodo.4032454,
author = {Zhou, Fangyi and Ferreira, Francisco and Hu, Raymond and Neykova, Rumyana and Yoshida, Nobuko},
title = {Statically Verified Refinements for Multiparty Protocols},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4032454},
abstract = {
    <p>Our paper presents Session<em>, a toolchain for specifying message passing protocols using Refined Multiparty Session Types and safely implementing the distributed endpoint programs in F</em>. This is the accompanying artifact containing the toolchain sources, and examples and sources used in the evaluation of the paper. For a more detailed description, see https://github.com/sessionstar/oopsla20-artifact/blob/master/README.md</p>

},
keywords = {Code Generation, F*, Multiparty Session Types (MPST), Refinement Types}
}

@software{10.5281/zenodo.4033001,
author = {Kallas, Konstantinos and Niksic, Filip and Stanford, Caleb and Alur, Rajeev},
title = {Artifact for DiffStream: Differential Output Testing for Stream Processing Programs},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4033001},
abstract = {
    <p>A differential testing library for Apache Flink programs. This artifact is provided as a VM.</p>
<p>The tool and the underlying methodology are described in the OOPSLA paper: DiffStream: Differential Output Testing for Stream Processing Programs</p>
<p>For further information and instructions, see the README after opening the VM.</p>

},
keywords = {Apache Flink, Differential Testing, Runtime Verification, Stream Processing}
}

@software{10.5281/zenodo.4033626,
author = {Pit-Claudel, Cl\'{e}ment},
title = {Artifact for Alectryon paper at SLE 2020 (Untangling Mechanized Proofs)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4033626},
abstract = {
    <p>A virtual machine submitted to SLE 2020’s artifact evaluation committee. Includes a snapshot of the Alectryon repository and datasets and scripts to reproduce the paper’s listings and figures.</p>

},
keywords = {formal verification, literate programming, proof presentation, proofbrowsing}
}

@software{10.5281/zenodo.4034438,
author = {Zhou, Yaoda and Oliveira, Bruno C. d. S. and Zhao, Jinxu},
title = {Revisiting Iso-Recursive Subtyping},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4034438},
abstract = {
    <p>This artifact contains the Coq formulation associated with the paper “Revisiting Iso-Recursive Subtyping”. For details, please refer to readme.</p>

},
keywords = {Coq, Formulation, Iso-recursive types}
}

@software{10.5281/zenodo.4034724,
author = {Zhang, Hengchu and Roth, Edo and Haeberlen, Andreas and Pierce, Benjamin C. and Roth, Aaron},
title = {Replication Package for Article: Testing Differential Privacy with Dual Interpreters},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4034724},
abstract = {
    <p>This package contains the Haskell implementation of DPCheck — an automated testing framework for differential privacy.</p>

},
keywords = {differential privacy, symbolic execution}
}

@software{10.5281/zenodo.4035150,
author = {Coblenz, Michael and Aldrich, Jonathan and Myers, Brad A. and Sunshine, Joshua},
title = {Replication Package for Article: Can Advanced Type Systems Be Usable? An Empirical Study of Ownership, Assets, and Typestate in Obsidian},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4035150},
abstract = {
    <p>The artifact consists of all the materials one would need to replicate the experiment in the paper. It includes a copy of the Obsidian repository as well as all of the materials the experiment participants received. It also includes the data generated by the participants during the study.</p>

},
keywords = {assets, blockchain, empirical studies of programming languages, linear types, Obsidian, ownership, permissions, smart contracts, typestate}
}

@software{10.5281/zenodo.4036303,
author = {Brody, Shaked and Alon, Uri and Yahav, Eran},
title = {A Structural Model for Contextual Code Changes articat},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4036303},
abstract = {
    <p>This artifact contains the PyTorch implementation of the neural network C3PO, along with all the required code and data to reproduce our results of the paper. Our code can be easily extended to other programming languages since the PyTorch network is agnostic to the input programming language. We also provide a with C# extractor for preprocessing the (raw) input code and explain how to implement such an extractor for other input programming languages.</p>

},
keywords = {Edit Completions, Machine Learning, Neural Models of Code}
}

@software{10.5281/zenodo.4037278,
author = {Turcotte, Alexi and Goel, Aviral and K\v{r}ikava, Filip and Vitek, Jan},
title = {Designing Types for R, Empirically (Data, Software, and Experiment Artifact)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4037278},
abstract = {
    <p>This artifact supports the paper “Designing Types for R, Empirically”, which appears at OOPSLA’20. The purpose of this artifact is to showcase the tools used to infer R function types, to showcase contractr, our function-types-as-contracts assertion package for R, and detail and replicate the experiments from the paper. In the artifact, you’ll find a “Getting Started Guide” to quickly sanity check the installation, and a detailed set of instructions on how to use our tracer (Typetracer), contractr, and how to replicate the experiments at whichever scale you like.</p>

},
keywords = {contracts, corpus analysis, dynamic analysis, empirical study, language design, R, type systems, types}
}

@software{10.5281/zenodo.4038334,
author = {Peleg, Hila and Gabay, Roi and Itzhaky, Shachar and Yahav, Eran},
title = {Artifact for: Programming with a Read-Eval-Synth Loop},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4038334},
abstract = {
    <p>Contains the RESL tool and reproduction of empirical experiments.</p>

},
keywords = {program synthesis, resl}
}

@software{10.5281/zenodo.4039085,
author = {Bembenek, Aaron and Greenberg, Michael and Chong, Stephen},
title = {Formulog: Datalog for SMT-Based Static Analysis (OOPSLA 2020 Artifact)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4039085},
abstract = {
    <p>This artifact corresponds to the paper “Formulog: Datalog for SMT-Based Static Analysis” by Aaron Bembenek, Michael Greenberg, and Stephen Chong, which has been accepted at OOPSLA 2020. It includes the Formulog runtime and material for running the empirical experiments described in the paper.</p>

},
keywords = {Datalog, Formulog, SMT solving}
}

@software{10.5281/zenodo.4039826,
author = {Sprenger, Christoph and Klenze, Tobias and Eilers, Marco and Wolf, Felix A. and M\"{u}ller, Peter and Clochard, Martin and Basin, David},
title = {Artifact for "Igloo: Soundly Linking Compositional Refinement and Separation Logic for Distributed System Verification"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4039826},
abstract = {
    <p>This artifact contains the entire Igloo framework formalized in Isabelle/HOL 2020 as well as our case studies (in Isabelle/HOL, VeriFast and Nagini). All necessary tools are pre-installed in the virtual machine.</p>

},
keywords = {distributed systems, formal methods, modeling, program verification, proof assistants}
}

@software{10.5281/zenodo.4043041,
author = {Mukherjee, Suvam and Deligiannis, Pantazis and Biswas, Arpita and Lal, Akash},
title = {Learning-Based Controlled Concurrency Testing},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4043041},
abstract = {
    <p>Concurrency bugs are notoriously hard to detect and reproduce. Controlled concurrency testing (CCT) techniques aim to offer a solution, where a scheduler explores the space of possible interleavings of a concurrent program looking for bugs. Since the set of possible interleavings is typically very large, these schedulers employ heuristics that prioritize the search to “interesting” subspaces. However, current heuristics are typically tuned to specific bug patterns, which limits their effectiveness in practice.</p>
<p>In this artifact, we present QL, a learning-based CCT framework where the likelihood of an action being selected by the scheduler is influenced by earlier explorations. We leverage the classical Q-learning algorithm to explore the space of possible interleavings, allowing the exploration to adapt to the program under test, unlike previous techniques. We have implemented and evaluated QL on a set of microbenchmarks, complex protocols, as well as production cloud services. In our experiments, we found QL to consistently outperform the state-of-the-art in CCT.</p>

},
keywords = {concurrency, model checking, reinforcement learning, testing}
}

@software{10.5281/zenodo.4043646,
author = {Marntirosian, Koar and Schrijvers, Tom and Oliveira, Bruno C. d. S. and Karachalias, Georgios},
title = {Resolution as Intersection Subtyping via Modus Ponens},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4043646},
abstract = {
    <p>This artifact consists of supplementary material for the article “Resolution as Intersection Subtyping via Modus Ponens”.</p>
<p>It contains a prototype implementation of λiMP, a mechanization of the metatheory of our calculus (declarative) and a mechanization of the metatheory for the subtyping algorithm of our calculus.</p>

},
keywords = {coherence, family polymorphism, intersection types, modus ponens, nested composition, resolution}
}

@software{10.5281/zenodo.4046893,
author = {Castro-Perez, David and Yoshida, Nobuko},
title = {CAMP: Cost-Aware Multiparty Session Protocols (artifact)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4046893},
abstract = {
    <p>This is the artifact for the paper ‘CAMP: Cost-Aware Multiparty Session Protocols’. The artifact comprises:</p>
<ul>
<li>A library for specifying cost-aware multiparty protocols.</li>
<li>The raw data used for comparing the cost models with real execution costs.</li>
<li>The cost-aware protocol specifications of the benchmarks that we studied.</li>
</ul>
<p>The library for specifying cost-aware protocols also provides functions for extracting cost equations from them, and for estimating recursive protocol latencies (i.e.&nbsp;average cost per protocol iteration). We provide a script for extracting cost equations, and instantiating them using the parameters used in the paper.</p>

},
keywords = {cost models, message optimisations, parallel programming, session types}
}

@software{10.5281/zenodo.4048298,
author = {Griesemer, Robert and Hu, Raymond and Kokke, Wen and Lange, Julien and Taylor, Ian Lance and Toninho, Bernardo and Wadler, Philip and Yoshida, Nobuko},
title = {Featherweight Go (Artifact)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4048298},
abstract = {
    <p>This paper presents Featherweight Go (FG) and Featherweight Generic Go (FGG), a core calculus of Go and a proposal for extending it with generics. The calculi are in the same vein as Featherweight Java (FJ), but where Featherweight Generic Java (FGJ) was translated into FJ via erasure, FGG translates into FG via monomorphisation (which is also formalised). The two calculi are proven sound using the normal progress and preservation arguments. Additionally a bisimulation is shown to exist between a FGG program and its monomorphisation (if it exists); in other words that monomorphisation preserves the semantics of the program.</p>
<p>The artifact consists of an implementation of type checkers and interpreters for FG and FGG, as well as a monomorphisation procedure (including the check if it is possible). It includes the examples from the paper, and a comparison using the Go compiler as reference. Type preservation and bisimulation for these programs are tested dynamically. Additionally, the same is tested for all well-typed programs up to a certain size (which are generated in a manner similar to property-based testing).</p>

},
keywords = {Generics, Go, Monomorphisation}
}

@software{10.5281/zenodo.4060109,
author = {Kabir, Ifaz and Li, Yufeng and Lhot\'{a}k, Ond\v{r}ej},
title = {ιDOT: A DOT Calculus with Object Initialization (Coq Formalization)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4060109},
abstract = {
    <p>This is the artifact for our OOPSLA’20 paper that presents ιDOT, a Dependent Object Types calculus with a type and effect system to ensure safe initialization of objects. This artifact contains the proof of type safety for the ιDOT calculus, formalized in the Coq proof assistant.</p>

},
keywords = {Coq, dependent object types, DOT, effect systems, iDOT, initialization, Scala, type safety, type soundness, type systems}
}

@software{10.5281/zenodo.4060132,
author = {Holtzen, Steven and Van den Broeck, Guy and Millstein, Todd},
title = {Software Artifact for: Scaling Exact Inference for Discrete Probabilistic Programs},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4060132},
abstract = {
    <p>This artifact contains a working copy of the software described in the paper, along with a guide for reproducing the key experimental results.</p>

},
keywords = {probabilistic programming}
}

@software{10.5281/zenodo.4060186,
author = {Bartell, Sean and Dietz, Will and Adve, Vikram S.},
title = {Artifact for Guided Linking: Dynamic Linking Without the Costs},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4060186},
abstract = {
    <p>Artifact for the paper “Guided Linking: Dynamic Linking Without the Costs”, conditionally accepted to OOPSLA 2020. This is the accepted version of the artifact, but the final version of the paper will include major terminology changes and improvements to the evaluation (such as Profile-Guided Optimization). An updated artifact, suitable for reproducing the results in the final paper, will be available at a later date.</p>

},
keywords = {compiler, dynamic linking, guided linking, ld.so, llvm, nixos, nixpkgs, optimization, shared libraries}
}

@software{10.5281/zenodo.4063694,
author = {Sotiropoulos, Thodoris and Chaliasos, Stefanos and Mitropoulos, Dimitris and Spinellis, Diomidis},
title = {Replication Package for Article: A Model for Detecting Faults in Build Specifications},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4063694},
abstract = {
    <p>This artifact contains the source code of the system, namely BuildFS, described in the article “A Model for Detecting Faults in Build Specifications”. BuildFS was designed to detect faults in Make and Gradle build specifications. In addition to that, the artifact includes all the scripts used to re-run the evaluation of BuildFS as described in the article. Specifically, these scripts apply BuildFS to 612 open-source Make and Gradle projects taken from the Github and Debian ecosystems, and evaluate BuildFS in terms of</p>
<ul>
<li>Effectiveness</li>
<li>Efficiency</li>
<li>Comparison with the-state-of-the-art</li>
</ul>

},
keywords = {Build, Fault, Gradle, Make}
}

@software{10.5281/zenodo.4088252,
author = {Atkinson, Eric and Carbin, Michael},
title = {Artifact for "Programming and Reasoning with Partial Observability"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4088252},
abstract = {
    <p>This is the artifact that accompanies the OOPSLA 2020 paper “Programming and Reasoning with Partial Observability”.</p>

},
keywords = {partial observability, uncertainty}
}

@software{10.1145/3410246,
author = {Trabish, David and Kapus, Timotej and Rinetzky, Noam and Cadar, Cristian},
title = {Replication Package for Article: Past-Sensitive Pointer Analysis for Symbolic Execution},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410246},
abstract = {
    <p>The artifact contains the docker image with the source code and the evaluation-related data, and instructions for replicating the experiments.</p>

},
keywords = {Pointer Analysis, Symbolic Execution}
}

@software{10.1145/3410247,
author = {Babakol, Timur and Canino, Anthony and Mahmoud, Khaled and Saxena, Rachit and Liu, Yu David},
title = {Experimental Replication of Experiments for Article: Calm Energy Accounting for Multithreaded Java Applications},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410247},
abstract = {
    <p>Contained in this artifact is a Docker image that reproduces the data with instructions for usage and a link to our public repository where our source and data are stored.</p>

},
keywords = {Concurrency, Energy Accounting, Energy Profiling, Power Disturbance, Software Performance}
}

@software{10.1145/3410251,
author = {She, Dongdong and Krishna, Rahul and Yan, Lu and Jana, Suman and Ray, Baishakhi},
title = {Replication package for MTFuzz: Fuzzing with a Multi-Task Neural Network},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3410251},
abstract = {
    <p>We provide source code for MTFuzz to foster further research in this area. We also provide 10 tested programs to reproduce results reported in our paper.</p>

},
keywords = {Fuzzing, Machine learning, Mutli-task learning}
}

@software{10.1184/R1/12543308.v1,
author = {Zhang, Changjian and Garlan, David and Kang, Eunsuk},
title = {Software for Paper: A Behavioral Notion of Robustness for Software Systems},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1184/R1/12543308.v1},
abstract = {
    <p>The prototype implementation for FSE 2020 paper: A Behavioral Notion of Robustness for Software Systems.</p>

},
keywords = {Formal methods, Software modeling and design, Software robustness, Specification and modeling languages}
}

@software{10.5281/zenodo.3843611,
author = {Zhang, Yuhao and Ren, Luyao and Chen, Liqian and Xiong, Yingfei and Cheung, Shing-Chi and Xie, Tao},
title = {DEBAR: Detecting Numerical Bugs in Neural Network Architectures},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3843611},
abstract = {
    <p>This artifact contains the implementation of DEBAR and the evaluation in our ESEC/FSE 2020 paper: Detecting Numerical Bugs in Neural Network Architectures.</p>

},
keywords = {Neural Network, Numerical Bugs, Static Analysis}
}

@software{10.5281/zenodo.3872848,
author = {Helm, Dominik and K\"{u}bler, Florian and Reif, Michael and Eichberg, Michael and Mezini, Mira},
title = {Artifact for Modular Collaborative Program Analysis in OPAL},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3872848},
abstract = {
    <p>This is the artifact that was used to obtain the results of “Modular Collaborative Program Analysis in OPAL”, published at ESEC/FSE 2020.</p>
<p>The Docker container contains the necessary tools (OPAL and DOOP), benchmarks (XCorpus, DoopBenchmarks), scripts to run the tools for the experiments performed in the paper and scripts to clean up the output of these experiments to reproduce the tables from the paper.</p>
<p>Please note that the artifact refers to OPAL as ‘BlaSt’ as this name was used during double-blind review.</p>

},
keywords = {Blackboard System, Composition, Modularization, Parallelization, Static Analysis}
}

@software{10.5281/zenodo.3872902,
author = {Gaaloul, Khouloud and Menghi, Claudio and Nejati, Shiva and Briand, Lionel C. and Wolfe, David},
title = {Replication Package for Article: Mining Assumptions for Software Components using Machine Learning},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3872902},
abstract = {
    <p>EPIcuRus (assumPtIon geneRation approach for CPS) automatically synthesizes environment assumptions for a component under analysis. EPIcuRus combines search-based testing, machine learning, and model checking. The core of EPIcuRus is a decision tree algorithm that infers environment assumptions from a test suite including test cases and their verdicts. The test cases are generated using search-based testing, and the assumptions inferred by decision trees are validated through model checking. To improve the efficiency and effectiveness of the assumption generation process, EPIcuRus implements a novel test case generation technique, namely Important Features Boundary Test (IFBT), that guides the test generation based on the feedback produced by machine learning.</p>

},
keywords = {Decision trees, Environment assumptions, Machine learning, Model checking, Search-based software testing}
}

@software{10.5281/zenodo.3876048,
author = {Ben Khadra, M. Ammar and Stoffel, Dominik and Kunz, Wolfgang},
title = {Supplemental artifacts of the paper: Efficient Binary-Level Coverage Analysis},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3876048},
abstract = {
    <p>The archive contains the artifacts accompanying the paper: “Efficient Binary-Level Coverage Analysis”. The artifacts are organized as follows:</p>
<ul>
<li><p><code>sample-binaries</code>. Folder that contains sample binaries patched with bcov.</p></li>
<li><p><code>dataset.tar.gz</code>. Package that contains experimental data in csv format.</p></li>
<li><p><code>figures</code>. Folder that contains the python script used to generate the figures of our paper. It assumes that the dataset was first extracted to the folder <code>dataset</code>.</p></li>
<li><p><code>install.sh</code>. This script builds and installs bcov together with its dependencies.</p></li>
<li><p><code>experiment-01.sh</code>. This script patches our sample binaries and shows how coverage data can be collected. It assumes that bcov was installed using the previous script.</p></li>
<li><p><code>bcov.tar.gz</code>. Source code of the first public version of <code>bcov</code>. The tool is distributed under an MIT license.</p></li>
</ul>

},
keywords = {code coverage analysis, experimental dataset, jump table analysis, reverse engineering, static binary instrumentation, supplemental artifacts}
}

@software{10.5281/zenodo.3876969,
author = {Gopinath, Rahul and Mathis, Bj\"{o}rn and Zeller, Andreas},
title = {Replication package for Mining Input Grammars from Dynamic Control Flow},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3876969},
abstract = {
    <p>A vagrant virtual box that is sufficient for reproduction of the results in Mining Input Grammars from Dynamic Control Flow</p>

},
keywords = {context-free grammar, fuzzing, mining, software testing}
}

@software{10.5281/zenodo.3877079,
author = {Terragni, Valerio and Jahangirova, Gunel and Tonella, Paolo and Pezz\`{e}, Mauro},
title = {Gassert: Evolutionary Improvement of Assertion Oracles},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3877079},
abstract = {
    <p>Gassert tool, presented in the paper “Evolutionary Improvement of Assertion Oracles” published at ESEC/FSE 2020.</p>

},
keywords = {esec-fse2020, gasser, oracle improvement, software testing, test generation}
}

@software{10.5281/zenodo.3877326,
author = {Chen, Qingrong and Wang, Teng and Legunsen, Owolabi and Li, Shanshan and Xu, Tianyin},
title = {Artifacts of Paper "Understanding and Discovering Software Configuration Dependencies in Cloud and Datacenter Systems"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3877326},
abstract = {
    <p>This package contains all the artifacts (i.e.&nbsp;codes \&amp; datasets) we use in our paper “Understanding and Discovering Software Configuration Dependencies in Cloud and Datacenter Systems” accepted to FSE 2020.</p>

},
keywords = {configuration dependencies, Hadoop, OpenStack, static analysis tools}
}

@software{10.5281/zenodo.3878164,
author = {Vassallo, Carmine and Proksch, Sebastian and Jancso, Anna and Gall, Harald C. and Di Penta, Massimiliano},
title = {Replication Package for "Configuration Smells in Continuous Delivery Pipelines: A Linter and A Six-Month Study on GitLab"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3878164},
abstract = {
    <p>This is the replication package of the paper “Configuration Smells in Continuous Delivery Pipelines: A Linter and A Six-Month Study on GitLab” accepted for publication at ESEC/FSE 2020. We describe the artifacts of our paper and how to use them to replicate the results of our study. When appropriate, we also link the description of the artifacts to relevant sections in the paper.</p>

},
keywords = {Anti-patterns, Configuration, Continuous Delivery, Continuous Integration, DevOps, GitLab, Linter}
}

@software{10.5281/zenodo.3895761,
author = {Shanker, Kripa and Joseph, Arun and Ganapathy, Vinod},
title = {Replication package for "An evaluation of methods to port legacy code to SGX enclaves"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3895761},
abstract = {
    <p>This artifact contains the code of the benchmarks used in the evaluation, as well as the source code of Porpoise, the instruction wrapper prototype used in the experiments reported in the paper.</p>

},
keywords = {enclaves, Porpoise, porting, programming, SGX}
}

@software{10.5281/zenodo.3896795,
author = {Mandrioli, Claudio and Maggio, Martina},
title = {Replication package for article: Testing Self-Adaptive Software with Probabilistic Guarantees on Performance Metrics},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3896795},
abstract = {
    <p>The artifact contains the code to replicate the experiments from the paper “Testing Self-Adaptive Software with Probabilistic Guarantees on Performance Metrics”. The experiments concerns two different adaptive softwre: Self -Adaptive Video Encoder, and Tele-Assistance System. The two subdirectories of the repository contain the code for the two artifacts.</p>

},
keywords = {Self-Adaptive Software, Testing}
}

@software{10.5281/zenodo.3902978,
author = {Cha, Sooyoung and Oh, Hakjoo},
title = {Replication Package for Article: Making Symbolic Execution Promising by Learning Aggressive State-Pruning Strategy},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3902978},
abstract = {
    <p>This is an artifact for the paper “Making Symbolic Execution Promising by Learning Aggressive State-Pruning Strategy” submitted to FSE 2020. It provides a VirtualBox image containing all resources to reproduce the main experimental results in our paper.</p>

},
keywords = {Online Learning, Symbolic Execution}
}

@software{10.5281/zenodo.3908793,
author = {Yan, Shenao and Tao, Guanhong and Liu, Xuwei and Zhai, Juan and Ma, Shiqing and Xu, Lei and Zhang, Xiangyu},
title = { 'Replication Package for Article: Correlations between Deep Neural Network Model Coverage Criteria and Model Quality'},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3908793},
abstract = {
    <p>This artifact includes two parts: ‘all-data.zip’ and ‘DNN/Testing/CovTesting-v1.1.zip’. ‘all-data.zip’ contains the data used for the experiments. ‘DNN/Testing/CovTesting-v1.1.zip’ contains the necessary codes. Please refer to the ‘README.md’ in ‘DNN/Testing/CovTesting-v1.1.zip’ to use this software. You can also refer to https://github.com/RU-System-Software-and-Security/CovTesting for more information.</p>

},
keywords = {Deep Neural Networks, Software Testing}
}

@software{10.5281/zenodo.3911750,
author = {Uesbeck, P. Merlin and Peterson, Cole S. and Sharif, Bonita and Stefik, Andreas},
title = {A Randomized Controlled Trial on the Effects of EmbeddedComputer Language Switching Replication Packet},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3911750},
abstract = {
    <p>A replication packet for the paper “A Randomized Controlled Trial on the Effects of Embedded Computer Language Switching” please review the README inside the zip archive.</p>

},
keywords = {analysis, computer language switching, data, database programming, experience, experiment software, polyglot programming, productivity, programming languages, randomized controlled trial, software}
}

@software{10.5281/zenodo.3912064,
author = {Biswas, Sumon and Rajan, Hridesh},
title = {Accepted Artifact Package for ESEC/FSE 2020 paper: Do the Machine Learning Models on a Crowd Sourced Platform Exhibit Bias? An Empirical Study on Model Fairness},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3912064},
abstract = {
    <p>The artifact contains code and data for the machine learning models used to analyze fairness.</p>

},
keywords = {fairness, machine learning, models}
}

@software{10.5281/zenodo.3947858,
author = {Rigger, Manuel and Su, Zhendong},
title = {ESEC/FSE 20 Artifact for "Detecting Optimization Bugs in Database Engines via Non-Optimizing Reference Engine Construction"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3947858},
abstract = {
    <p>The artifact consists of two main components:</p>
<ol type="1">
<li>SQLancer, the tool which we created, and in which we implemented NoREC, to find all bugs reported in the associated paper.</li>
<li>A SQLite database with a list of bugs that we reported and additional meta information.</li>
</ol>

},
keywords = {NoREC, SQLancer}
}

@software{10.5281/zenodo.3949286,
author = {Zhao, Yixue and Chen, Justin and Sejfia, Adriana and Schmitt Laser, Marcelo and Zhang, Jie and Sarro, Federica and Harman, Mark and Medvidovic, Nenad},
title = {FrUITeR's artifacts},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3949286},
abstract = {
    <p>FrUITeR’s artifacts accepted at ESEC/FSE 2020 for the paper “FrUITeR: A Framework for Evaluating UI Test Reuse”</p>

},
keywords = {Mobile Application, Open Science, Software Testing, Test Reuse}
}

@software{10.5281/zenodo.3949340,
author = {Wang, Zan and Yan, Ming and Chen, Junjie and Liu, Shuang and Zhang, Dongdi},
title = {Replication Packages for Article &nbsp;"Deep Learning Library Testing via Effective Model Generation"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3949340},
abstract = {
    <p>This artifact includes the code and datasets of LEMON. File named LEMON-V1.0.0.zip includes all the scripts in LEMON, and file named LEMON_datasets_models.zip includes datasets sampled from ImageNet or collected from GitHub by authors. More details can be seen in https://github.com/Jacob-yen/LEMON</p>

},
keywords = {Deep Learning Testing, Library Testing, Model Generation, Mutation, Search-based Software Testing}
}

@software{10.5281/zenodo.3951724,
author = {Hermann, Ben and Winter, Stefan and Siegmund, Janet},
title = {Community Expectations for Research Artifacts and Evaluation Processes (Additional Material)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3951724},
abstract = {
    <p>Raw and derived data on calls for artifacts and a survey conducted with artifact reviewers. The purpose of the artifact is to support the replicability of the conducted study, but also to allow for future studies in the same area.</p>

},
keywords = {Artifact Evaluation, Replicability, Reproducibility, Study}
}

@software{10.5281/zenodo.3966486,
author = {Trimananda, Rahmadi and Aqajari, Seyed Amir Hossein and Chuang, Jason and Demsky, Brian and Xu, Guoqing Harry and Lu, Shan},
title = {IoTCheck},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3966486},
abstract = {
    <p>IoTCheck is a framework that model-checks smart home apps. Please see https://github.com/uci-plrg/iotcheck for further instructions for downloads and installation.</p>

},
keywords = {concurrency, model checking, program analysis, smart home apps}
}

@software{10.5281/zenodo.4021473,
author = {Harel-Canada, Fabrice and Wang, Lingxiao and Gulzar, Muhammad Ali and Gu, Quanquan and Kim, Miryung},
title = {Replication Package for Article: Is Neuron Coverage a Meaningful Measure for Testing Deep Neural Networks?},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4021473},
abstract = {
    <p>This artifact contains the code which generates adversarial test suites and measures its attack success, naturalness (IS + FID), and output impartiality. It also includes the notebooks used to generate figures and the correlations, which were then extracted into a google sheet. The MNIST and CIFAR10 data can be easily downloaded from source, but the udacity driving dataset was included as it may not always be available through the original competition github repo.</p>
<p>Any potential updates will be maintained here: https://github.com/fabriceyhc/nc_diversity_attacks</p>

},
keywords = {Adversarial Attack, Machine Learning, Neuron Coverage, Software Engineering, Testing}
}

@software{10.5281/zenodo.4023299,
author = {Cha, Alan and Wittern, Erik and Baudart, Guillaume and Davis, James C. and Mandel, Louis and Laredo, Jim A.},
title = {A Principled Approach to GraphQL Query Cost Analysis Research Paper Artifact},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4023299},
abstract = {
    <p>The artifact contains 1) a GraphQL query-response corpus, containing 10,000 anonymized query and response pairs against the GitHub and Yelp APIs that were used in our experiments, 2) a randomized GraphQL query generator that was used to create the corpus, 3) configurations for the static analyses (ours as well as those we compared against) that were used in our experiments, 4) experiment data and the scripts that were used to create our plots, 5) scripts to fetch the GraphQL schemas that were used in our experiments, and 6) scripts that will use the aforementioned components to rerun our experiments.</p>

},
keywords = {API management, cost estimation, GraphQL, query complexity, random query generation}
}

@software{10.5281/zenodo.4028454,
author = {Baranov, Eduard and Legay, Axel and Meel, Kuldeep S.},
title = {Baital},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4028454},
abstract = {
    <p>Baital is a sampler generator for configurable systems. It generates a set of testing samples for large configurable systems with high t-wise coverage. The tool takes a set of constraints on features of the configurable system represented as a CNF formula in Dimacs format and provides a set of configurations of a specified size and computes their t-wise coverage.</p>

},
keywords = {Configurable software, t-wise coverage, Weighted sampling}
}

@software{10.5281/zenodo.4031225,
author = {Cambronero, Jos\'{e} P. and Cito, J\"{u}rgen and Rinard, Martin C.},
title = {AMS Artifact},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.4031225},
abstract = {
    <p>Software artifact for AMS (Generating AutoML Search Spaces from Weak Specifications), camera-ready modifications incorporated.</p>

},
keywords = {automated machine learning, search-based software engineering, software engineering}
}

@software{10.5522/04/11927208.v2,
author = {Guizzo, Giovani and Sarro, Federica and Harman, Mark},
title = {Replication package for "Cost Measures Matter for Mutation Testing Study Validity", accepted at FSE 2020},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5522/04/11927208.v2},
abstract = {
    <p>This is a replication package for the experiments reported in 2020 FSE paper “Cost Measures Matter for Mutation Testing Study Validity”.</p>
<p>It contains all the subject programs, experimental scripts, and results data.</p>

},
keywords = {Cost Reduction, Execution Time, Mutant Reduction, Mutation Analysis, Mutation Testing, Number of Mutants, Software Testing}
}

@software{10.6084/m9.figshare.12415622.v2,
author = {B\"{o}hme, Marcel and Man\`{e}s, Valentin J. M. and Cha, Sang Kil},
title = {Source and Results of "Boosting Fuzzer Efficiency An Information-Theoretic Perspective"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.12415622.v2},
abstract = {
    <p>Entropic is an information-theoretic power schedule implemented into LibFuzzer. It boosts performance by changing how weights are assigned to the seeds in the corpus. Seeds revealing more ‘‘information’’ about globally rare features are assigned a higher weight.</p>

},
keywords = {efficiency, entropy, fuzzing, information theory, software testing}
}

@software{10.5281/zenodo.3742225,
author = {Chowdhary, Sangeeta and Lim, Jay P. and Nagarakatte, Santosh},
title = {PositDebug Artifact: Debugging and Detecting Numerical Errors in Computation with Posits},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3742225},
abstract = {
    <p>This artifact contains a shadow execution framework for finding numerical errors in applications using both posits and floating point. The prototype for posits is called PositDebug and the prototype for floating point programs is called FPSsanitizer.</p>

},
keywords = {cancellation, CORDIC, floating point, FPSanitizer, numerical errors, PositDebug, posits}
}

@software{10.5281/zenodo.3751586,
author = {Apostolakis, Sotiris and Xu, Ziyang and Tan, Zujun and Chan, Greg and Campanoni, Simone and August, David I.},
title = {SCAF: A Speculation-Aware Collaborative Dependence Analysis Framework},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3751586},
abstract = {
    <p>Artifact archive for the artifact evaluation of the PLDI 2020 paper, titled "SCAF: A Speculation-Aware Collaborative Dependence Analysis Framework". It contains a Dockerfile along with relevant to this paper software to create a docker image used to reproduce the evaluation results presented in this PLDI 2020 paper.</p>

},
keywords = {compilers, program analysis, speculation}
}

@software{10.5281/zenodo.3753963,
author = {Huang, Kangjing and Qiu, Xiaokang and Shen, Peiyuan and Wang, Yanjun},
title = {DryadSynth: Release as PLDI 2020 Artifact: Reconciling Enumerative and Deductive Program Synthesis},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3753963},
abstract = {
    <p>DryadSynth: A syntax-guided synthesizer</p>

},
keywords = {deductive synthesis, divide-and-conquer, enumerative synthesis, syntax-guided synthesis}
}

@software{10.5281/zenodo.3754772,
author = {Kragl, Bernhard and Enea, Constantin and Henzinger, Thomas A. and Mutluergil, Suha Orhun and Qadeer, Shaz},
title = {Inductive Sequentialization of Asynchronous Programs (Evaluated Artifact)},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3754772},
abstract = {
    <p>Inductive sequentialization is implemented as an extension of the CIVL verifier. This implementation and all examples listed in Table 1 of the paper are part of the open-source project Boogie. This artifact is for long-term archiving purposes and contains a snapshot of Boogie version 2.6.4. Since the project is under active development, we recommend to obtain the most recent version from https://github.com/boogie-org/boogie.</p>
<p>For further information and instructions, see the included README.md file.</p>

},
keywords = {abstraction, asynchrony, concurrency, induction, invariants, layers, movers, reduction, refinement, verification}
}

@software{10.5281/zenodo.3756301,
author = {Qin, Boqin and Chen, Yilun and Yu, Zeming and Song, Linhai and Zhang, Yiying},
title = {Replication Package for Article: Understanding Memory and Thread Safety Practices and Issues in Real-World Rust Programs},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3756301},
abstract = {
    <p>The artifact is to support the data in our paper with programs. It contains five directories related to the corresponding sections in the paper. section-2-background-and-related-work contains scripts and raw data to plot Fig. 1 and Fig. 2. section-4-unsafe-usages contains a bench testing for safe and unsafe code, and a script to count unsafe statistics. section-5-memory-safety-issues contains the fix commits of our studied memory bugs, and our reproduced memory bugs. section-6-thread-safety-issues contains the fix commits of our studied blocking and non-blocking bugs, our reproduced blocking and non-blocking bugs, and the code to count cases where locks are manually dropped. section-7-bug-detection contains our detection tools for use-after-free and double-lock.</p>

},
keywords = {Bug Study, Concurrency Bug, Memory Bug, Rust}
}

@software{10.5281/zenodo.3764961,
author = {Bichsel, Benjamin and Baader, Maximilian and Gehr, Timon and Vechev, Martin},
title = {silq-artifact},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3764961},
abstract = {
    <p>Artifact for PLDI'20 paper "Silq: A High-level Quantum Programming Language with Safe Uncomputation and Intuitive Semantics".</p>

},
keywords = {Quantum Language, Semantics, Uncomputation}
}

@software{10.5281/zenodo.3765314,
author = {Gehr, Timon and Steffen, Samuel and Vechev, Martin},
title = {lpsi-artifact},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3765314},
abstract = {
    <p>Artifact for PLDI'20 paper "λPSI: Exact Inference for Higher-Order Probabilistic Programs".</p>

},
keywords = {Exact, Higher-order, Probabilistic Programming}
}

@software{10.5281/zenodo.3862978,
author = {Vanover, Jackson and Deng, Xuan and Rubio-Gonz\'{a}lez, Cindy},
title = {FPDiff: Discvovering Discrepancies in Numerical Libraries},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3862978},
abstract = {
    <p>FPDiff is a tool for automated, end-to-end differential testing that, given only library source code as input, extracts numerical function signatures, synthesizes drivers, creates equivalence classes of functions that are synonymous, and executes differential tests over these classes to detect meaningful numerical discrepancies between implementations. FPDiff's current scope covers special functions across numerical libraries written in different programming languages. This artifact in particular includes the following libraries: the C library GSL (The GNU Scientific Library, version 2.6), the Python libraries SciPy (version 1.3.1) and mpmath (version 1.1.0), and the JavaScript library jmat (commit 21d15fc3eb5a924beca612e337f5cb00605c03f3).</p>

},
keywords = {correctness, differential testing, floating point, numerical libraries, numerical methods, software testing}
}

@software{10.5281/zenodo.3895271,
author = {Busse, Frank and Nowack, Martin and Cadar, Cristian},
title = {Replication package for: Running Symbolic Execution Forever},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3895271},
abstract = {
    <p>The artefact contains a Docker image with MoKlee, our memoization extension of KLEE, all benchmarks in LLVM bitcode format, the raw experiment results and scripts to re-create our evaluation and to re-run all experiments.</p>

},
keywords = {binutils, coreutils, findutils, grep, KLEE, libspng, memoization, MoKlee, software testing, symbolic execution, tcpdump}
}

@software{10.5281/zenodo.3895414,
author = {Fang, Chunrong and Liu, Zixi and Shi, Yangyang and Huang, Jeff and Shi, Qingkai},
title = {Replication Package for Article: Functional Code Clone Detection with Syntax and Semantics Fusion Learning},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3895414},
abstract = {
    <p>The FCDetector is a functional code clone detection tool with syntax and semantics fusion learning.</p>

},
keywords = {code clone detection, code representation, functional clone detection}
}

@software{10.5281/zenodo.3895797,
author = {Gopinath, Rahul and Kampmann, Alexander and Havrikov, Nikolas and Soremekun, Ezekiel O. and Zeller, Andreas},
title = {Replication package for Abstracting Failure Inducing Inputs},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3895797},
abstract = {
    <p>This artifact contains the implementation of the algorithm in the paper "Abstracting Failure Inducing Inputs". The artifact is a Vagrant box (a virtual machine) that contains the complete implementation and the subjects that can be evaluated directly. A complete worked out example in a Jupyter notebook is included in the VM along with a complete Jupyter installation so that the notebook can be viewed directly.</p>

},
keywords = {debugging, error diagnosis, failure-inducing inputs, grammars}
}

@software{10.5281/zenodo.3897315,
author = {Riganelli, Oliviero and Mottadelli, Simone Paolo and Rota, Claudio and Micucci, Daniela and Mariani, Leonardo},
title = {DLD: Data Loss Detector},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3897315},
abstract = {
    <p>Android apps must work correctly even if their execution is interrupted by external events. For instance, an app must work properly even if a phone call is received, or after its layout is redrawn because the smartphone has been rotated. Since these events may require destroying, when the execution is interrupted, and recreating, when the execution is resumed, the foreground activity of the app, the only way to prevent the loss of state information is to save and restore it. This behavior must be explicitly implemented by app developers, who often miss to implement it properly, releasing apps affected by data loss problems, that is, apps that may lose state information when their execution is interrupted. Although several techniques can be used to automatically generate test cases for Android apps, the obtained test cases seldom include the interactions and the checks necessary to exercise and reveal data loss faults. Data Loss Detector (DLD) is a test case generation technique that integrates an exploration strategy, data-loss-revealing actions, and two customized oracle strategies for the detection of data loss failures.</p>

},
keywords = {Android, Data Loss, Mobile Apps, Test Case Generation, Validation}
}

@software{10.5281/zenodo.3901626,
author = {Hildebrandt, Carl and Elbaum, Sebastian and Bezzo, Nicola and Dwyer, Matthew B.},
title = {Feasible and Stressful Trajectory Generation for Mobile Robots - Artifact},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3901626},
abstract = {
    <p>This artifact can be used to replicate the results found in the paper: "Feasible and Stressful Trajectory Generation for Mobile Robots". For more information on the content consult the readme file.</p>

},
keywords = {Kinematic and Dynamic Models, Robotics, Stress Testing, Test Generation}
}

@software{10.1145/3406886,
author = {Li, Hui and Wang, Dong and Huang, Tianze and Gao, Yu and Dou, Wensheng and Xu, Lijie and Wang, Wei and Wei, Jun and Zhong, Hua},
title = {Replication Package for Article: Detecting Cache-Related Bugs in Spark Applications},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3406886},
abstract = {
    <p>This artifact contains the source code of CacheCheck. It provides general instructions to use CacheCheck and evaluates experimental results in our paper. More details and newest version is provided on Github (https://github.com/Icysandwich/cachecheck).</p>

},
keywords = {bug detection, cache, performance, Spark}
}

@software{10.1145/3406888,
author = {Lee, Seokhyun and Cha, Sooyoung and Lee, Dain and Oh, Hakjoo},
title = {Replication Package for Article: Effective White-box Testing of Deep Neural Networks with Adaptive Neuron-Selection Strategy},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3406888},
abstract = {
    <p>This article contains source codes and data for the paper "Effective White-box Testing of Deep Neural Networks with Adaptive Neuron-Selection Strategy". It also contains experiment scripts that can reproduce the results in the paper.</p>

},
keywords = {Deep neural networks, Online learning, White-box testing}
}

@software{10.1145/3406889,
author = {Lou, Yiling and Ghanbari, Ali and Li, Xia and Zhang, Lingming and Zhang, Haotian and Hao, Dan and Zhang, Lu},
title = {Tool Package for paper "Can Automated Program Repair Refine Fault Localization? A Unified Debugging Approach "},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3406889},
abstract = {
    <p>The package includes the tool in the paper "Can Automated Program Repair Refine Fault Localization? A Unified Debugging Approach ", including the installation and execution document. More updates please refer to the tool homepage "https://github.com/yilinglou/proFL"</p>

},
keywords = {Automated Debugging Tool, Automated Program Repair, Fault Localization, Unified Debugging}
}

@software{10.1145/3395630,
author = {Kang, Jeehoon and Jung, Jaehwang},
title = {Implementation and Benchmark suite for Article: A Marriage of Pointer- and Epoch-Based Reclamation},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395630},
abstract = {
    <h2 id="a-marriage-of-pointer--and-epoch-based-reclamation">A Marriage of Pointer- and Epoch-Based Reclamation</h2>
<p>This is the artifact for</p>
<p>Jeehoon Kang and Jaehwang Jung, A Marriage of Pointer- and Epoch-Based Reclamation, PLDI 2020.</p>
<p>The latest developments are on <a href="https://github.com/kaist-cp/pebr-benchmark" class="uri">https://github.com/kaist-cp/pebr-benchmark</a>.</p>
<h3 id="summary">Summary</h3>
<p>On Ubuntu 18.04,</p>
<pre><code>sudo apt install build-essential python3-pip
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
pip3 install --user pandas plotnine
python3 bench.py
python3 plot.py</code></pre>
<h3 id="dependencies">Dependencies</h3>
<ul>
<li>Linux &gt;= 4.14 for <a href="http://man7.org/linux/man-pages/man2/membarrier.2.html"><code>MEMBARRIER_CMD_PRIVATE_EXPEDITED</code> and <code>MEMBARRIER_CMD_REGISTER_PRIVATE_EXPEDITED</code></a>, used in the implementation of PEBR.
<ul>
<li><strong>IMPORTANT</strong>: Docker disables this feature by default. To enable, please use <code>--security-opt seccomp:unconfined</code> option when launching Docker.</li>
</ul></li>
<li><a href="https://rustup.rs/"><code>rustup</code></a> for building the implementation of NR, EBR, PEBR and data structures
<ul>
<li>Rust requires GCC for linking in Linux.</li>
</ul></li>
<li>Python &gt;= 3.6, pandas and plotnine for benchmark runner and plotting scripts</li>
</ul>
<h3 id="usage">Usage</h3>
<p>To build the benchmark,</p>
<pre><code>git submodule update --init --recursive # not needed if you got the archived source code
cargo build --release                   # remove --release for debug build</code></pre>
<p>To run a single test,</p>
<pre><code>./target/release/pebr-benchmark -d &lt;data structure&gt; -m &lt;reclamation scheme&gt; -t &lt;threads&gt;</code></pre>
<p>where</p>
<ul>
<li>data structure: HList, HMList, HHSList, HashMap, NMTree, BonsaiTree</li>
<li>reclamation scheme: NR, EBR, PEBR</li>
</ul>
<p>For detailed usage information,</p>
<pre><code>./target/release/pebr-benchmark -h</code></pre>
<p>To run the entire benchmark,</p>
<pre><code>python3 bench.py</code></pre>
<p>This takes several hours and creates raw CSV data under <code>./results/</code>.</p>
<p>To generate plots,</p>
<pre><code>python3 plot.py</code></pre>
<p>This creates plots presented in the paper under <code>./results/</code>.</p>
<h3 id="debug">Debug</h3>
<p>We used <code>./sanitize.sh</code> to debug our implementation. This script runs the benchmark with <a href="https://github.com/japaric/rust-san">LLVM address sanitizer for Rust</a> and uses parameters that impose high stress on PEBR by triggering more frequent ejection.</p>
<p>Note that sanitizer may report memory leaks when used against <code>-m EBR</code>. This is because of a minor bug in original Crossbeam but it doesn't affect performance of our benchmark.</p>
<h3 id="project-structure">Project structure</h3>
<ul>
<li><p><code>./crossbeam-pebr</code> is the fork of <a href="https://github.com/crossbeam-rs/crossbeam">Crossbeam</a> that implements PEBR. The main implementation of PEBR lies under <code>./crossbeam-pebr/crossbeam-epoch</code>.</p></li>
<li><p><code>./crossbeam-ebr</code> is the original Crossbeam source code.</p></li>
<li><p><code>./src</code> contains the benchmark driver (<code>./src/main.rs</code>) and the implementation of data structures based on PEBR (<code>./src/pebr/</code>) and original Crossbeam (<code>./src/ebr/</code>).</p></li>
</ul>
<h3 id="results">Results</h3>
<p><code>./paper-results</code> contains the raw results and graphs used in the paper.</p>
<h3 id="note">Note</h3>
<ul>
<li><p>On Windows, the benchmark uses the default memory allocator instead of jemalloc since <a href="https://crates.io/crates/jemallocator">the Rust library for jemalloc</a> does not support Windows.</p></li>
<li><p>The benchmark run by <code>./sanitize.sh</code> will generate inaccurate memory usage report since it uses the default memory allocator instead of jemalloc. The memory tracker relies on jemalloc's functionalities which doesn't keep track of allocations by the default allocator.</p></li>
</ul>

},
keywords = {epoch-based reclamation, garbage collection, hazard pointer, pointer-based reclamation, safe memory reclamation}
}

@software{10.1145/3395632,
author = {Flatt, Matthew and Dybvig, R. Kent},
title = {Replication Package for Article: Compiler and Runtime Support for Continuation Marks},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395632},
abstract = {
    <p>The artifact contains the full source code for Racket and Chez Scheme and variants as described in the paper, and it provides benchmarks that can be used to support the following claims:</p>
<ul>
<li><p>The implementation of continuation marks is compatible with a high-performance implementation of first-class, delimited continuations.</p></li>
<li><p>Compiler and runtime support for continuation marks can improve the performance of applications.</p></li>
<li><p>Specific optimizations described in the paper improve the performance of continuation marks and applications that use them.</p></li>
</ul>

},
keywords = {context inspection, Dynamic binding}
}

@software{10.1145/3395634,
author = {Berry, G\'{e}rard and Serrano, Manuel},
title = {Replication package for: HipHop.js: (A)Synchronous Reactive Web Programming},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395634},
abstract = {
    <p>Our artifact consists of:</p>
<ul>
<li><p>The current HipHop.js implementation, which you can either download fully constructed in the docker file available from the PLDI artifact site (see Part 1 below) or entirely rebuild from the public Hop/HipHop sources files (see Part 3) if you find the 1.3 GB docker file too big or if you want to do it yourself. Once the docker image is downloaded or built, you can validate it by running the standard HipHop implementation test suite (see Part 4).</p></li>
<li><p>The implementation and step-by-step simulation of our Lisinopril medical prescription application described in the paper (Part 2 below). The main Lisinopril HipHop reactive module is exacly the one in the paper. The complete source files can be accessed within the docker image or dowloaded from the web.</p></li>
</ul>

},
keywords = {JavaScript, Reactive Programming, Synchronous Programming, Web Programming}
}

@software{10.1145/3395635,
author = {Phulia, Ankush and Bhagee, Vaibhav and Bansal, Sorav},
title = {Replication package for OOElala: Order-of-Evaluation Based Alias Analysis for Compiler Optimization},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395635},
abstract = {
    <p>This artifact contains the implementation for the algorithm described in the paper, <em>OOElala: Order-of-Evaluation Based Alias Analysis for Compiler Optimization</em>, accepted at PLDI 2020.</p>
<h3 id="terminology">Terminology</h3>
<ul>
<li>We use <code>OOElala</code>, <code>ooelala</code> and <code>clang-unseq</code> interchangeably to refer to the tool/binary which we have implemented and produced as a part of this work.</li>
<li><code>&lt;artifact-home&gt;</code> refers to <code>/home/$USER/ooelala-project</code></li>
</ul>
<h3 id="structure-of-the-artifact">Structure of the artifact</h3>
<p>This artifact directory is structured into the following subdirectories, each of which is described subsequently:</p>
<ul>
<li><em>litmus_tests</em> - This directory contains the implementation of the two examples, which have been introduced in Section 1.1 of the paper, to spearhead the discussion about the key idea of the paper. The makefile is used to run these two examples, as described in detail in the later sections.
<ul>
<li><em>array_min_max</em> - This subdirectory contains the code, for the first example, on the left of the figure.</li>
<li><em>nested_loop</em> - This subdirectory contains the code for an example, which isolates the kernel initialization code described in the second image on the right. The implementation captures the basic idea for the SPEC 2017 example, as discussed in section 1.1 of the paper.</li>
</ul></li>
<li><em>ooelala</em> - This directory contains the source code for our tool, OOELala, which has been implemented over clang/llvm 8.0.0.
<ul>
<li><em>src</em> - This sub-directory contains the source code for the optimizing compiler implementation which includes the AST analysis to identify the must-not-alias predicates and the Alias Analysis which utilises the must-not-alias information to enable further optimisations. This has been added as a sub-module and the specific implementation details can be found in the commit history and commit messages of this sub-module.</li>
<li><em>ubsan</em> - This sub-directory contains the source code for the implementation of the UB Sanitizer which uses the must-not-alias predicates generated after the AST analysis to implement the runtime checks. This has been added as a sub-module and the specific implementation details can be found in the commit history and commit messages of this sub-module.</li>
</ul></li>
<li><em>spec</em> - This directory contains the resources which we use to run the SPEC CPU 2017 benchmarks, with clang and OOELala.
<ul>
<li><em>configs</em> - This subdirectory contains the config files <code>clang-unseq.cfg</code> and <code>clang.cfg</code>, which are used when we build and run the SPEC CPU 2017 suite with OOELala and clang respectively. Additionally, this directory also contains config files <code>clang-ubsan.cfg</code> and <code>clang-ubsan-unseq.cfg</code>, which are used to specify that SPEC should be built and run with clang and OOELala respectively, with UB Sanitizer checks enabled and no optimisations.</li>
<li><em>makefiles</em> - This subdirectory contains the makefiles, which are used to compile and run specific SPEC benchmarks or generate object/LLVM files for some specific source files, in some specific benchmarks. These have been used to identify the patterns discussed in figure 2 of the paper. For running these on SPEC refrate inputs refer to <code>Readme.md</code> in the subdirectory.</li>
<li><em>scripts</em> - This subdirectory contains the scripts which are used to build and run the SPEC 2017 benchmarks and generate the performance numbers presented in table 6 of the paper. This also contains the post processing python script which is used to generate the summary of the aliasing stats, which are presented in Table 5 of the paper. The list of scripts and their functionality is described in the Readme.md file present in this subdirectory.</li>
</ul></li>
<li><em>polybench</em> - This directory contains the resources which we use to run the Polybench benchmark suite, with clang and OOELala
<ul>
<li><em>common</em> - This subdirectory contains the Polybench header file which needs to be included in the benchmarks.</li>
<li><em>scripts</em> - This subdirectory contains the scripts used to build and run the Polybench benchmarks to obtain the speedups listed in Table 4 of the paper. Comparisons between various compilers have been drawn.</li>
<li><em>selected_benchmarks</em> - This represents the selected subset of benchmarks which we have annotated with custom <code>RESTRICT</code> macro predicates (corresponding to <code>CANT_ALIAS</code> used in the paper), used to provide the additional aliasing information, but in no way modifying the behaviour of the program</li>
</ul></li>
<li><em>sample_outputs</em> - This directory contains a set of sample outputs which are obtained on running the SPEC CPU 2017 and the polybench benchmarks. These can be used by the developers to verify the output format
<ul>
<li><em>spec</em> - This contains the results and stats obtained for a sample run of SPEC CPU 2017, with clang and clang-unseq</li>
<li><em>polybench</em> - This contains the results and stats obtained for a sample run of Polybench, with clang and clang-unseq</li>
</ul></li>
<li><em>CANT_ALIAS.md</em> - This is a tutorial which discusses the <em>CANT_ALIAS</em> predicate described in the paper. It outlines the use of the macro and the subtleties associated with that.</li>
</ul>

},
keywords = {Alias Analysis, Clang, Compiler Optimization, LLVM, Polybench, SPEC CPU 2017, Undefined behaviour}
}

@software{10.1145/3395636,
author = {Farvardin, Kavon and Reppy, John},
title = {Replication Package for Article: From Folklore to Fact: Comparing Implementations of Stacks and Continuations},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395636},
abstract = {
    <p>This artifact contains all materials needed to reproduce or extend the results of this work. It includes the raw data and plots corresponding to the results presented in the paper, the full source code of Manticore \&amp; LLVM (plus the benchmark programs and plotting scripts), a Docker image that contains the entire system pre-built, and an extensive README that describes how to build and run our benchmark suite to replicate the experiments in the paper.</p>

},
keywords = {Call stacks, Compilers, Concurrency, Continuations, Functional Programming}
}

@software{10.1145/3395638,
author = {Miltner, Anders and Padhi, Saswat and Millstein, Todd and Walker, David},
title = {Replication Package for Artifact: Data-Driven Inference of Representation Invariants},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395638},
abstract = {
    <p>This archive contains the code and benchmarks for the paper Data-Driven Inference of Representation Invariants.</p>
<p>Instructions for installation and build, instructions for reproduction of the results, and a description of the structure of the repository, are all available in the file $/README.pdf.</p>

},
keywords = {Abstract Data Types, Logical Relations, Type-Directed Synthesis}
}

@software{10.1145/3395644,
author = {Zhu, Shaopeng and Hung, Shih-Han and Chakrabarti, Shouvanik and Wu, Xiaodi},
title = {Replication Package for: On the Principles of Differentiable Quantum Programming Languages},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395644},
abstract = {
    <p>The artifact includes two parts: (1) A parser and compiler that implements the rules for autodifferentiaton; (2) A simulation that demonstrates the advantage of differentiating quantum programs with control flow. Classical simulation of quantum programs is used in this part for evaluation.</p>

},
keywords = {autodifferentiation, differentiable programming, quantum computing, quantum machine learning, quantum programming languages}
}

@software{10.1145/3395647,
author = {Usman, Muhammad and Wang, Wenxi and Vasic, Marko and Wang, Kaiyuan and Vikalo, Haris and Khurshid, Sarfraz},
title = {Replication Package for Article: A Study of the Learnability of Relational Properties: Model Counting Meets Machine Learning (MCML) - PLDI 2020},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395647},
abstract = {
    <p>The artifact contains datasets and code which were used to compute results for this paper (A Study of the Learnability of Relational Properties: Model Counting Meets Machine Learning (MCML) - PLDI 2020). Detailed instructions can be found in README.txt file.</p>

},
keywords = {Alloy, ApproxMC, machine learning, model counting, ProjMC, Relational Properties, SAT solving}
}

@software{10.1145/3395648,
author = {He, Jingxuan and Singh, Gagandeep and P\"{u}schel, Markus and Vechev, Martin},
title = {Reproduction Package for Article: Learning Fast and Precise Numerical Analysis},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395648},
abstract = {
    <p>This material is the artifact for paper "Learning Fast and Precise Numerical Analysis" at PLDI 2020. It contains raw data for main experiments, benchmarks, full source code, and scripts for reproducing main experiments.</p>

},
keywords = {Abstract interpretation, Machine learning, Numerical domains, Performance optimization.}
}

@software{10.1145/3395650,
author = {Koenig, Jason R. and Padon, Oded and Immerman, Neil and Aiken, Alex},
title = {Artifact for Article: First-Order Quantified Separators},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395650},
abstract = {
    <p>This artifact contains implementations of the separation algorithm from Section 5, the IC3/PDR implementation from Section 6.3, and the evaluation data from Section 7. This artifact can be used to both reproduce the results of the article as well as run these algorithms on novel distributed protocols.</p>

},
keywords = {first-order logic, invariant inference, software verification}
}

@software{10.1145/3395653,
author = {Lorch, Jacob R. and Chen, Yixuan and Kapritsos, Manos and Parno, Bryan and Qadeer, Shaz and Sharma, Upamanyu and Wilcox, James R. and Zhao, Xueyuan},
title = {Replication Package for Article "Armada: Low-Effort Verification of High-Performance Concurrent Programs"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395653},
abstract = {
    <p>This artifact contains the materials necessary for replication of the paper "Armada: Low-Effort Verification of High-Performance Concurrent Programs". It contains a Docker image containing the source code, executables, external dependencies, and examples. It also contains documentation of the artifact and a description of the Armada language.</p>

},
keywords = {refinement, weak memory models, x86-TSO}
}

@software{10.1145/3395654,
author = {Schuiki, Fabian and Kurth, Andreas and Grosser, Tobias and Benini, Luca},
title = {Replication Package for Paper: LLHD: A Multi-level Intermediate Representation for Hardware Description Languages},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395654},
abstract = {
    <p>A Docker image with the necessary toolchains pre-installed and source codes pre-loaded to reproduce the main results of the LLHD paper, and to serve as a starting point for individual exploration.</p>

},
keywords = {domain-specific languages, hardware, language design, language implementation, new programming models or languages, parallelism}
}

@software{10.1145/3395655,
author = {Krishna, Siddharth and Patel, Nisarg and Shasha, Dennis and Wies, Thomas},
title = {Mechanized proofs accompanying paper: Verifying Concurrent Search Structure Templates},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395655},
abstract = {
    <p>Our artifact consists of two parts: the proofs of template algorithms, to be verified by Iris/Coq, and the proofs of implementations, to be verified by GRASShopper.</p>

},
keywords = {concurrent search structures, Coq, functional correctness, Grasshopper, Iris, mechanized proofs, memory safety}
}

@software{10.1145/3395656,
author = {Breck, Jason and Cyphert, John and Kincaid, Zachary and Reps, Thomas},
title = {Artifact for "Templates and Recurrences: Better Together"},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395656},
abstract = {
    <p>This is the artifact for the PLDI 2020 paper, "Templates and Recurrences: Better Together." The artifact is a virtual machine in OVA (Open Virtualization Archive) format. Its operating system is Ubuntu 18. The virtual machine contains an installation of the CHORA static analysis tool, which is the implementation of the technique described by the associated paper. The virtual machine also contains the benchmark programs that were used in the experiments of the associated paper, along with a script that is designed to replicate the paper's experimental results. The virtual machine has a user account with name "chorauser" and password "chorapassword", and allows login via graphical user interface, or via SSH on port 22.</p>

},
keywords = {Invariant generation, Recurrence relation}
}

@software{10.1145/3395657,
author = {Nigam, Rachit and Atapattu, Sachille and Thomas, Samuel and Li, Zhijing and Bauer, Theodore and Ye, Yuwei and Koti, Apurva and Sampson, Adrian and Zhang, Zhiru},
title = {Replication Package for Article: Predictable Accelerator Design with Time-Sensitive Affine types},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395657},
abstract = {
    <p>Contains the following repositories: - Dahlia (v0.0.1): The reference compiler built for the paper. - Dahlia-evaluation: The data and the evaluation scripts. - Dahlia-spatial-comparison: Repository to reproduce Dahlia's Spatial evaluation. - Polyphemus: Server framework used to run FPGA experiments on AWS.</p>

},
keywords = {affine types, high-level synthesis}
}

@software{10.1145/3395658,
author = {Boehm, Hans-J.},
title = {Real arithmetic package and code to check floating point precision},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395658},
abstract = {
    <p>Source code and instructions to run the floating point accuracy test described in the paper. This includes the real arithmetic package, with the described comparison support, and an updated version of the previously described underlying recursive reals package (which diverges on exact comparison of equal real numbers). The real arithmetic package is very similar to that currently used by Google's Android calculator.</p>

},
keywords = {accuracy checking, comparison, decidability, floating point, real numbers}
}

@software{10.1145/3395659,
author = {Yang, Albert Mingkun and \"{O}sterlund, Erik and Wrigstad, Tobias},
title = {Replication Package for Article: Improving Program Locality in the GC using Hotness},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3395659},
abstract = {
    <p>It includes our implementation, benchmarks used, and scripts for running benchmarks and collecting/visualizing results.</p>

},
keywords = {garbage collection, load barrier, openjdk, program locality}
}

@software{10.1145/3373123,
author = {Serrano, Manuel and Findler, Robert Bruce},
title = {Replication package for: Dynamic Property Caches, A Step towards Faster JavaScript Proxy Objects},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373123},
abstract = {
    <p>The artifact associated with the submission Dynamic Property Caches is the Hop JavaScript static native compiler and the test suite that is described and used in the paper. The compiler and the tests are packaged in a way that facilitates the reproduction of the experimental results of the paper. The artifact contains two automatic procedures. One that re-runs the portion of the performance evaluation for Hop and V8 and one that re-runs the full experiment.</p>
},
keywords = {ahead-of-time compilation., AOT, compiler, compiler optimization, dynamic languages, JavaScript, runtime representation}
}

@software{10.1145/3373124,
author = {Castro-Perez, David and Yoshida, Nobuko},
title = {Tool and Benchmarks for Article: Compiling First-Order Functions to Session-Typed Parallel Code},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373124},
abstract = {
    <p>This is the artifact for the paper 'Compiling First-Order Functions to Session-Typed Parallel Code'. It contains a prototyle EDSL for the language described in the paper, as well as the benchmarks that we used for its evaluation.</p>
},
keywords = {arrows, Haskell, multiparty session types, parallel programming}
}

@software{10.5281/zenodo.3579301,
author = {L\'{o}pez-G\'{o}mez, Javier and Fern\'{a}ndez, Javier and Astorga, David del Rio and Vassilev, Vassil and Naumann, Axel and Garc\'{\i}a, J. Daniel},
title = {Replication Package for Article: Relaxing the One Definition Rule in Interpreted C++},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3579301},
abstract = {
    <p>This package contains the required scripts and source code to run the required evaluation tests -both, those included in the paper, and additional tests-. For convenience, we provide a VM image in OVA format that contains all the required dependencies. Users should import the image and see the README file for further instructions. Alternatively, the `master' branch can be built from sources in the Cling repository.</p>
},
keywords = {C++, Cling, interpreter, One-Definition-Rule}
}

@software{10.5281/zenodo.3607141,
author = {Chida, Nariyoshi and Kawakoya, Yuhei and Ikarashi, Dai and Takahashi, Kenji and Sen, Koushik},
title = {PoC Implementation of parser generators based on existing/SG/CM-stateful packrat parsing},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3607141},
abstract = {
    <p>This is an artifact of the paper titled "Is Stateful Packrat Parsing Really Linear in Practice  -- A Counter-Example, an Improved Grammar, and Its Parsing Algorithms --".</p>
},
keywords = {Parser Generator, Parsing Expression Grammar, Stateful Packrat Parser}
}

@software{10.5281/zenodo.3608382,
author = {Chen, Hanfeng and Krolik, Alexander and Kemme, Bettina and Verbrugge, Clark and Hendren, Laurie},
title = {Replication Package for Article: Improving Database Query Performance with Automatic Fusion},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3608382},
abstract = {
    <p>This artifact is created for showing the reproducibility of our experiments in the paper. We provide the details of scripts and original data used in the experiments. There are mainly two systems: HorsePower and RDBMS MonetDB. We supply step-by-step instructions to configure and deploy both systems in the experiments.</p>
},
keywords = {Array programming, Compiler optimizations, IR, Loop fusion, SQL database queries}
}

@software{10.1145/3373121,
author = {Ismail, Mohamed and Suh, G. Edward},
title = {Artifact for Article: Efficient Nursery Sizing for Managed Languages on Multi-core Processors with Shared Caches},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373121},
abstract = {
    <p>Our artifact provides a full framework to evaluate the performance of our Dynamic Nursery Allocator. The framework is provided as a Docker image to ensure repeatability and to make setup and running it easy on any platform. Our framework consists of: (1) The compiled PyPy binary that supports DNA along with the PyPy source code and the DNA source code, (2) The Python and PyPy benchmark suite programs used in the evaluation, (3) Scripts to setup the experiments and automate running the benchmarks, (4) An analysis script to summarize the results as CSV files, and (5) Graphing scripts to generate graphs from the CSV files. We additionally provide reference CSV files with the results presented in the paper for inspection and comparison.</p>
},
keywords = {automatic memory management, managed languages, PyPy, Python, shared caches}
}

@software{10.1145/3373122,
author = {Taneja, Jubi and Liu, Zhengyang and Regehr, John},
title = {Replication Package for Article: Testing Static Analyses for Precision and Soundness},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373122},
abstract = {
    <p>This artifact provides the source code that implements our work on testing precision and soundness of LLVM s dataflow analyses. Our work builds on the open source superoptimizer, Souper and evaluates LLVM 8.0. We use SPEC CPU 2017 benchmarks version 1.0.1 to evaluate the precision and soundness, and measure the impact of maximal precision on code generation by testing some open source applications like, Gzip, Bzip2, Stockfish, and SQLite . We provide a Dockerfile in our artifact to automatically build the Docker image, which takes care of installing all required dependencies, benchmark suite, and Souper for the experimental evaluation.</p>
},
keywords = {Dataflow analysis, Precision, Soundness}
}

@software{10.1145/3373120,
author = {Haj-Ali, Ameer and Ahmed, Nesreen K. and Willke, Ted and Shao, Yakun Sophia and Asanovic, Krste and Stoica, Ion},
title = {GitHub Version 0.0.1: NeuroVectorizer: End-to-End Vectorization with Deep Reinforcement Learning},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373120},
abstract = {
    <p>This artifact can be used to produce similar results to ours. It runs training of our NeuroVectorizer framework that trains end-to-end from the code to the optimal factors. Data is provided in the README. It is best if you keep using the updated github repo for fixes/updates.</p>
},
keywords = {Automatic Vectorization., Code Optimization, Deep Reinforcement Learning, LLVM}
}

@software{10.5281/zenodo.3542289,
author = {Cheng, Lin and Ilbeyi, Berkin and Bolz-Tereick, Carl Friedrich and Batten, Christopher},
title = {Replication package for Type Freezing: Exploiting Attribute Type Monomorphism in Tracing JIT Compilers},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3542289},
abstract = {
    <p>In this artifact we provide the source code of type freezing equipped PyPy, our microbenchmarks, and PyPy benchmarks we used in our paper -- Type Freezing: Exploiting Attribute Type Monomorphism in Tracing JIT Compilers. Along with the source code, we also provide a prebuilt Docker image. Be noted that running performance experiments inside Docker can have unexpected behaviors. Please refer to the README file for how to import the docker image, translate PyPy from source code, and run the experiments we did in this paper.</p>
},
keywords = {dynamic languages, just-in-time compiler, PyPy, type monomorphism}
}

@software{10.17863/CAM.46071,
author = {Savage, Joe and Jones, Timothy M.},
title = {Research data supporting "HALO: Post-Link Heap-Layout Optimisation"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.17863/CAM.46071},
abstract = {
    <p>Source code for the HALO optimisation pipeline. This includes a client for the Pin binary instrumentation framework, a patch for the BOLT binary optimiser, a custom memory allocator, and scripts to assist in applying our optimisations and extracting performance results. See the README.md file within the repository for a more detailed description and usage instructions.</p>
},
keywords = {binary analysis, binary optimisation, data layout optimisation}
}

@software{10.5281/zenodo.3572539,
author = {Mackay, Julian and Potanin, Alex and Aldrich, Jonathan and Groves, Lindsay},
title = {Proof of Decidable Subtyping for Path Dependent Types},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3572539},
abstract = {
    <p>A proof of subtype decidability for the Wyv_self and Wyv_fix variants of Wyvern, formalised in Coq. The associated type systems are described in greater detail in the associated paper: Decidable Subtyping for Path Dependent Types.</p>
},
keywords = {Formal Methods, Functional Programming Languages, Object Oriented Lanaguages, Programming Languages, Proofs, Scala, Type Systems, Type Theory, Wyvern}
}

@software{10.5281/zenodo.3543712,
author = {Chang, Stephen and Ballantyne, Michael and Turner, Milo and Bowman, William J.},
title = {Artifact for: Dependent Type Systems as Macros},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3543712},
abstract = {
    <p>Implementation of the Turnstile+ framework, and the Cur proof assistant</p>
},
keywords = {dependent types, macros, proof assistants, type systems}
}

@software{10.1145/3373101,
author = {Song, Youngju and Cho, Minki and Kim, Dongjoo and Kim, Yonghyun and Kang, Jeehoon and Hur, Chung-Kil},
title = {Replication Package for Article: "CompCertM: CompCert with C-Assembly Linking and Lightweight Modular Verification"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373101},
abstract = {
    <p>This artifact is a replication package for the article "CompCertM: CompCert with C-Assembly Linking and Lightweight Modular Verification".</p>
},
keywords = {CompCert, Compositional Compiler Correctness, Coq, Verified Compilation}
}

@software{10.1145/3373096,
author = {Hinrichsen, Jonas Kastberg and Bengtson, Jesper and Krebbers, Robbert},
title = {Coq Mechanisation of Actris: Session-Type Based Reasoning in Separation Logic},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373096},
abstract = {
    <p>This artifact concerns a Coq development, which is based on the Iris framework for concurrent separation logic. The artifact consists of a zip file that contains: - A virtual machine with the artifact installed. - The sources of the artifact that one can build locally. - A link to the git repository of the current version of the artifact.</p>
},
keywords = {actor model, concurrency, Coq, Iris, Message passing, session types}
}

@software{10.1145/3373100,
author = {Kim, Sung Kook and Venet, Arnaud J. and Thakur, Aditya V.},
title = {Replication Package for Article: Deterministic Parallel Fixpoint Computation},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373100},
abstract = {
    <p>The main purpose of this artifact is to share the implementation of algorithms in the paper. The paper describes how the fixpoint computation in abstract interpretation can be parallelized without non-determinism. The provided implementation is a fully functioning end-to-end static analysis tool. The artifact also contains data and figures in the paper, and scripts to reconstruct them.</p>
},
keywords = {abstract interpretation, chaotic iteration, concurrency, concurrent iteration strategy, program analysis, weak partial order}
}

@software{10.5281/zenodo.3544373,
author = {Sozeau, Matthieu and Boulier, Simon and Forster, Yannick and Tabareau, Nicolas and Winterhalter, Th\'{e}o},
title = {Snapshot of MetaCoq associated to the article},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3544373},
abstract = {
    <p>This archive contains the whole development of MetaCoq. If you only want to browse the files a "light" documentation is available in html/toc.html which provides access to all the development files. Otherwise, to run interactively, the development can be compiled with Coq 8.9.1 and Equations 1.2. Detailed installation instructions for the version of the package on opam are below, what follows is a short summary of the development and installation instructions for the popl artifact sources version.</p>
},
keywords = {Metatheory
Type-checking
Proof Assistants}
}

@software{10.1145/3373099,
author = {Farzan, Azadeh and Vandikas, Anthony},
title = {Replication Package for Article: Reductions for Safety Proofs},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373099},
abstract = {
    <p>Contains a tool implementing the verification algorithm described in the paper, as well as a script for reproducing the benchmark times presented in Section 9 of the paper.</p>
},
keywords = {Automata, Automated Verification, Concurrency, Reductions}
}

@software{10.1145/3373102,
author = {Handley, Martin A. T. and Vazou, Niki and Hutton, Graham},
title = {RTick library and proofs described in the paper},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373102},
abstract = {
    <p>This artifact includes: - Source files for the RTick library - The source code for the examples presented throughout the paper, in particular, those summarised in Table 1; - Formalised proofs of the functor, applicative, and monad laws for the Tick datatype; - Formalised proofs of the relationships between the cost relations shown in Figure 2.</p>
},
keywords = {Liquid Haskell, refinement types, resource analysis, static verification}
}

@software{10.1145/3373097,
author = {Barthe, Gilles and Blazy, Sandrine and Gr\'{e}goire, Benjamin and Hutin, R\'{e}mi and Laporte, Vincent and Pichardie, David and Trieu, Alix},
title = {Supplementary material for Article: Formal Verification of a Constant-Time Preserving C Compiler},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373097},
abstract = {
    <p>Supplementary material for Article: Formal Verification of a Constant-Time Preserving C Compiler Contains a modified version of the CompCert 3.4 C compiler for which cryptographic constant-time security has been proved to be preserved as described in the article.</p>
},
keywords = {CompCert compiler, Coq, timing side-channels, verified compilation}
}

@software{10.1145/3373098,
author = {Hu, Jason Z. S. and Lhot\'{a}k, Ond?ej},
title = {Undecidability of D&lt;: and Its Decidable Fragments},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373098},
abstract = {
    <p>The home page of the artifact: https://hustmphrrr.github.io/popl20-artifact/ This artifact formalizes the theorems in our paper, Undecidability of D&lt;: and Its Decidable Fragments. The formalization is done in a combination of Coq 8.8.2 and Agda 2.5.4.2. The artifact ships with 1. the Agda code for undecidability analysis, 2. the Coq code for algorithmic analysis, 3. the HTML files generated from the previous two components, and 4. a VM file with environment set up. The artifact contains necessary instructions on how to install binaries and reproduce our results.</p>
},
keywords = {Agda, algorithmic subtyping, Coq, undecidability}
}

@software{10.1145/3373104,
author = {Migeed, Zeina and Palsberg, Jens},
title = {What Is Decidable about Gradual Types?},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373104},
abstract = {
    <p>In this artifact, we verify the results of the paper "What is Decidable about Gradual Types ". In particular, we verify the results of four algorithmic problems. 1- Singleton 2- Top Choice 3- Finitness 4- Maximality We provide a Haskell implementation for the above problems. In particular, we implement the decision procedures for the first three problems and the semi algorithm for the fourth problem. The results are given by figures 4,6 and 7 while figure 5 contains scalability and performance results. We first verify the results in figures 4,6, and 7 and finally figure 5.</p>
},
keywords = {Algorithms and Complexity, Gradual typing, Type inference, Type theory}
}

@software{10.1145/3373105,
author = {Mathur, Umang and Murali, Adithya and Krogmeier, Paul and Madhusudan, P. and Viswanathan, Mahesh},
title = {Replication Package for Article: Deciding Memory-Safety for Single-Pass Heap Manipulating Programs},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373105},
abstract = {
    <p>Proof of concept implementation of the streaming congruence closure algorithm from Deciding Memory-Safety for Single-Pass Heap Manipulating Programs.</p>
},
keywords = {decidable, memory safety, uninterpreted programs, verification}
}

@software{10.1145/3373107,
author = {Greenberg, Michael and Blatt, Austin J.},
title = {Replication Package for Article: Executable Formal Semantics for the POSIX Shell},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373107},
abstract = {
    <p>A Vagrant box containing a Linux image which has Smoosh installed in /bin/smoosh. Other shells discussed in the paper are installed, as well. The Smoosh test suites is available, as is modernish.</p>
},
keywords = {executable formal semantics, POSIX shell, Smoosh}
}

@software{10.1145/3373115,
author = {Meyer, Roland and Wolff, Sebastian},
title = {seal},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373115},
abstract = {
    <p>Verification tool for lock-free data structures with safe memory reclamation.</p>
},
keywords = {data-structures, epoch-based-reclamation, garbage collection, hazard-pointer, linearizability, lock-free, memory-management, memory-reclamation, static analysis, type-system, verification}
}

@software{10.5281/zenodo.3539237,
author = {Dang, Hoang-Hai and Jourdan, Jacques-Henri and Kaiser, Jan-Oliver and Dreyer, Derek},
title = {RustBelt Meets Relaxed Memory (Artifact)},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3539237},
abstract = {
    <p>This is a virtual machine that contains a snapshot of the RustBelt Relaxed Coq development. In our repository, the snapshot has the tag "RBrlx-POPL20-artifact". More updated information can be found at http://plv.mpi-sws.org/rustbelt/rbrlx/.</p>
},
keywords = {Coq, Iris, relaxed memory model, Rust, RustBelt, semantic soundness}
}

@software{10.5281/zenodo.3544697,
author = {Guo, Zheng and James, Michael and Justo, David and Zhou, Jiaxiao and Wang, Ziteng and Jhala, Ranjit and Polikarpova, Nadia},
title = {Hoogle Plus},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3544697},
abstract = {
    <p>Hoogle Plus implements our Type-Guided Abstraction Refinement technique. It includes two binaries: `hplus`, which serves as a CLI to our synthesis engine; and `webapp`, which serves a basic web interface to our default parameters. There are two scripts to re-run the evaluation, either in part or in full (evaluation-short.sh and evaluation.sh)</p>
},
keywords = {Functional Programming, Haskell, Program Synthesis, Type Systems}
}

@software{10.5281/zenodo.3545194,
author = {Lee, Wonyeol and Yu, Hangyeol and Rival, Xavier and Yang, Hongseok},
title = {Artifact for Article: Towards Verified Stochastic Variational Inference for Probabilistic Programs},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3545194},
abstract = {
    <p>The artifact includes (i) our implementation of the static analysis for model-guide support match, and (ii) the Pyro model-guide pairs used in our experiments. For more details, please refer to `README.txt' in the artifact, and Section 8 of the paper.</p>
},
keywords = {correctness, Probabilistic programming, semantics, static analysis, variational inference}
}

@software{10.5281/zenodo.3570660,
author = {Jung, Ralf and Lepigre, Rodolphe and Parthasarathy, Gaurav and Rapoport, Marianna and Timany, Amin and Dreyer, Derek and Jacobs, Bart},
title = {The Future is Ours: Prophecy Variables in Separation Logic -- Artifact},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3570660},
abstract = {
    <p>This is the artifact accompanying the POPL20 paper "The Future is Ours: Prophecy Variables in Separation Logic". For more information about that paper, see https://plv.mpi-sws.org/prophecies/.</p>
},
keywords = {Iris, linearizability, logical atomicity, Prophecy variables, separation logic}
}

@software{10.1145/3373110,
author = {Xia, Li-yao and Zakowski, Yannick and He, Paul and Hur, Chung-Kil and Malecha, Gregory and Pierce, Benjamin C. and Zdancewic, Steve},
title = {Library presented in the paper: Interaction Trees},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373110},
abstract = {
    <p>Interaction Trees is a Coq library, defining a structure for representing recursive and impure programs, featuring an equational theory for reasoning about monadic programs.</p>
},
keywords = {coq, denotational semantics, formal verification, monads}
}

@software{10.1145/3373112,
author = {Raghothaman, Mukund and Mendelson, Jonathan and Zhao, David and Naik, Mayur and Scholz, Bernhard},
title = {Replication Package for Article: Provenance-Guided Synthesis of Datalog Programs},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373112},
abstract = {
    <p>This is the artifact package accompanying our POPL 2020 submission titled Provenance-Guided Synthesis of Datalog Programs. The paper presents a new algorithm to synthesize Datalog programs from input-output examples. We have implemented this algorithm in a tool named ProSynth, and benchmarked them against the existing solvers, ALPS and Difflog. This artifact contains all three tools (ProSynth, ALPS, and Difflog), benchmark files, and scripts to reproduce the experiments described in the paper. In this document, we will describe the outline of these experiments, how to run them, and also describe how one may use ProSynth to solve Datalog synthesis problems of their own.</p>
},
keywords = {Counter-Example Guided Inductive Synthesis (CEGIS), data provenance, Datalog, Program synthesis, SAT solvers, Syntax-Guided Synthesis (SyGuS)}
}

@software{10.5281/zenodo.3541779,
author = {Jung, Ralf and Dang, Hoang-Hai and Kang, Jeehoon and Dreyer, Derek},
title = {Stacked Borrows: An Aliasing Model for Rust -- Artifact},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3541779},
abstract = {
    <p>This is the artifact accompanying the POPL20 paper "Stacked Borrows: An Aliasing Model for Rust". It consists of a Coq mechanization of the simulation proof sketches that were made in the paper. For more information about that paper, see https://plv.mpi-sws.org/rustbelt/stacked-borrows/.</p>
},
keywords = {alias analysis, Coq, operational semantics, program transformation, Rust, simulation proof}
}

@software{10.5281/zenodo.3533037,
author = {Sammler, Michael and Garg, Deepak and Dreyer, Derek and Litak, Tadeusz},
title = {Coq development for "The High-Level Benefits of Low-Level Sandboxing"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3533037},
abstract = {
    <p>This is the artifact for the POPL'20 paper "The High-Level Benefits of Low-Level Sandboxing". It contains the Coq development formalizing the results of the paper.</p>
},
keywords = {Coq, Iris, language-based security, logical relations, robust safety, sandboxing, type systems}
}

@software{10.1145/3373103,
author = {Forster, Yannick and Kunze, Fabian and Roth, Marc},
title = {Mechanisation of "The Weak Call-By-Value ?-Calculus is Reasonable for Both Time and Space"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373103},
abstract = {
    <p>This Coq development contains the mechanised parts of the paper "The Weak Call-By-Value  -Calculus is Reasonable for Both Time and Space". The mechanisation defines two abstract machines that evaluate call by value lambda calculus and analyses the sizes of the states during a machine run and the lengths of the runs, both in relation to the semantics on terms.</p>
},
keywords = {abstract machines, invariance thesis, lambda calculus, time and space complexity, weak call-by-value reduction}
}

@software{10.1145/3373108,
author = {Bourke, Timothy and Brun, L\'{e}lio and Pouzet, Marc},
title = {Models, Algorithms, and Proofs for "Mechanized Semantics and Verified Compilation for a Dataflow Synchronous Language with Reset"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3373108},
abstract = {
    <p>These source files contain the implementation, models, and proof of correctness of a formally verified Lustre compiler. The compiler supports the reset construct which is presented in the POPL 2020 paper. The examples/ subdirectory contains several example programs that can be used to test the compiler. We build on earlier work together with Pierre- variste Dagand, Xavier Leroy, and Lionel Rieg.</p>
},
keywords = {interactive theorem proving (Coq), stream languages, synchronous languages (Lustre), verified compilation}
}

@software{10.5281/zenodo.3369436,
author = {K?ikava, Filip and Miller, Heather and Vitek, Jan},
title = {Artifact for Scala Implicits are Everywhere},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3369436},
abstract = {
    <p>Code and data for the OOPLSA 2019 paper.</p>
},
keywords = {analysis, Scala}
}

@software{10.5281/zenodo.3362696,
author = {Song, Dowon and Lee, Myungho and Oh, Hakjoo},
title = {Automatic and Scalable Detection of Logical Errors in Functional Programming Assignments},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3362696},
abstract = {
    <p>This is an artifact for the paper "Automatic and Scalable Detection of Logical Errors in Functional Programming Assignments" submitted to OOPSLA 2019. It provides VM and documentation for reproducing the evaluation results in the paper. The VM contains source codes for implementing the algorithm, benchmarks used in evaluation, and a python script for reproducing the Table 1 and Table 2 in the paper. Specially, you can see that the main parts of our algorithm are implemented in the following files: 1. engine/TestML/testGenerator.ml: Our overall algorithm and symbolic test case generation 2. engine/TestML/sym_exec.ml: Symbolic verification</p>
},
keywords = {Automated Test Case Generation, Program Synthesis, Symbolic Execution}
}

@software{10.5281/zenodo.3369573,
author = {Goel, Aviral and Vitek, Jan},
title = {Replication Package for Article: On the Design, Implementation and Use of Laziness in R},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3369573},
abstract = {
    <p>The artifact is a Docker image. It performs a dynamic analysis on packages written in the R language, and analyzes the generated data. The artifact uses this data to generate an HTML report containing the graphs and data appearing in our paper. The report is served by the Docker container on localhost:8000.</p>
},
keywords = {Corpus Analysis, Delayed or Lazy Evaluation, Empirical Study, Large-scale, R Language}
}

@software{10.5281/zenodo.3374835,
author = {Yamazaki, Tetsuro and Nakamaru, Tomoki and Ichikawa, Kazuhiro and Chiba, Shigeru},
title = {Generating a fluent API with syntax checking from an LR grammar (Artifact)},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3374835},
abstract = {
    <p>The artifact for "Generating a fluent API with syntax checking from an LR grammar", which will be published in OOPSLA 2019. "artifact.pdf" mentions the usage of typelevelLR, a fluent-API-style library-skeleton generator, which we implemented for the experiments presented in the paper. This artefact contains all the programs that can be used to reproduce the evaluation of our paper. You can find the instructions in the README.pdf file.</p>
},
keywords = {artifact, fluent API, library skeleton generator, OOPSLA 2019}
}

@software{10.5281/zenodo.3364114,
author = {Mastrangelo, Luis and Hauswirth, Matthias and Nystrom, Nathaniel},
title = {Casting about in the Dark - Artifact Evaluation},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3364114},
abstract = {
    <p>Companion dataset artifact used in the paper "Casting about in the Dark".</p>
},
keywords = {cast, Java, type safety}
}

@software{10.5281/zenodo.3366212,
author = {Adams, Ulf},
title = {Implementations of Ryu \&amp; Ryu Printf},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3366212},
abstract = {
    <p>A set of C and Java libraries implementing Ryu and Ryu Printf.</p>
},
keywords = {c, conversion, float, java, printf, string}
}

@software{10.5281/zenodo.3368188,
author = {Vukotic, Ivana and Rahli, Vincent and Esteves-Ver\'{\i}ssimo, Paulo},
title = {Asphalion: Trustworthy Shielding Against Byzantine Faults},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3368188},
abstract = {
    <p>Asphalion is a Coq-based framework for verifying the correctness of implementations of fault-tolerant systems. It especially provides features to verify the correctness of hybrid fault-tolerant systems (such as the MinBFT protocol http://www.di.fc.ul.pt/~bessani/publications/tc11-minimal.pdf), where normal components (that can for example fail arbitrarily) trust some special components (that can for example only crash on failure) to provide properties in a trustworthy manner. Asphalion allows running such trusted-trustworthy components inside Intel SGX enclaves. More details are provided here: https://vrahli.github.io/articles/asphalion.pdf and here: https://vrahli.github.io/articles/asphalion-long.pdf</p>
},
keywords = {Byzantine fault-tolerance, Compositional reasoning, Coq, Crash fault-tolerance, Distributed systems, Fault-tolerance, Formal verification, Hybrid fault-tolerance, Intel SGX, Knowledge calculus, MinBFT, State machine replication, Trusted components}
}

@software{10.5281/zenodo.3370063,
author = {Konnov, Igor and Kukovec, Jure and Tran, Thanh-Hai},
title = {Artifact - TLA+ Model Checking Made Symbolic},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3370063},
abstract = {
    <p>This artifact version, named "25_ae", contains the same materials which we submitted in the artifact evaluation, and two new files README, and LICENSE. Our artifact comes in the form of a virtual machine (user: oopsla19, pass: ae). Our model checker v0.5.0 is already installed on the VM. After the rebuttal, we agreed with the reviewers to add new optimizations in our model checker, and new benchmarks in the second submission. However, these changes are included only in the later version of our artifact, named "25_v2". Please follow the link 10.5281/zenodo.3370071 for the new version called "25_v2", which contains updates in our second submission.</p>
},
keywords = {artifact, model checking, SMT, TLA+}
}

@software{10.5281/zenodo.3363988,
author = {Marcozzi, Micha\"{e}l and Tang, Qiyi and Donaldson, Alastair F. and Cadar, Cristian},
title = {Replication Package for "Compiler Fuzzing: How Much Does It Matter?"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3363988},
abstract = {
    <p>This artifact provides the bug impact measurement infrastructure and the experimental data presented in the following paper: Micha l Marcozzi, Qiyi Tang, Alastair F. Donaldson, and Cristian Cadar. 2019. Compiler Fuzzing: How Much Does It Matter . Proc. ACM Program. Lang. 3, OOPSLA, Article 155 (October 2019), 29 pages. https://doi.org/10.1145/3360581 The paper introduces the first quantitative and qualitative study of the tangible impact of fuzzer-found compiler bugs. It follows a novel methodology where the impact of a miscompilation bug is evaluated based on (1) whether the bug appears to trigger during compilation; (2) the extent to which generated assembly code changes syntactically due to triggering of the bug; and (3) how likely such changes are to cause runtime divergences during execution. The study is conducted with respect to the compilation of more than 10 million lines of C/C++ code from 309 Debian packages, using 12\% (27) of the historical and now fixed miscompilation bugs found by four state-of-the-art fuzzers in the Clang/LLVM compiler, as well as 18 other bugs found by the Alive formal verification tool or human users. This artifact provides the necessary software and data to replicate this study for the 45 Clang/LLVM miscompilation bugs over the 309 Debian packages. In addition to enabling the easy replication of the paper results, the provided bug impact measurement infrastructure can also be used to measure the impact of miscompilation bugs over Debian packages that have not been considered in the paper. It can also be extended to perform differential testing for multiple compilers or optimisation options of a compiler.</p>
},
keywords = {bug impact, Clang, compilers, fuzzing, LLVM, software testing}
}

@software{10.5281/zenodo.3366234,
author = {Rapoport, Marianna and Lhot\'{a}k, Ond?ej},
title = {Coq type soundness proof for 'A Path to DOT: Formalizint Fully Path-Dependent Types'},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3366234},
abstract = {
    <p>Our paper presents pDOT, a generalization of the Dependent Object Types (DOT) calculus that formalizes Scala. The pDOT calculus extends DOT with support for path-dependent types on paths of arbitrary length. This artifact presents the Coq formalization of the pDOT type-safety proof as presented in Section 5 of the paper.</p>
},
keywords = {Coq, DOT, paths, Scala, type safety}
}

@software{10.5281/zenodo.3366904,
author = {Siraichi, Marcos Yukio and Santos, Vin\'{\i}cius Fernandes dos and Collange, Caroline and Pereira, Fernando Magno Quint\~{a}o},
title = {Experiment and Software to Reproduce: Qubit Allocation as a Combination of Subgraph Isomorphism and Token Swapping},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3366904},
abstract = {
    <p>This artifact is composed of mainly scripts, benchmarks, and configuration data used to generate the data of this paper. The scripts set up the environment, downloading the necessary software and dependencies using Git and APT (since package managers are specific for different distros, it may not work on all of them), and compiling them all. In the end, you will have in hands: (i) "enfield", an OpenQASM source-to-source compiler; (ii) all the benchmarks used; (iii) helper scripts. Ideally, you would run the script for reproducing the experiments as is, but you may also change the configuration data for custom experiments.</p>
},
keywords = {Compilers, Quantum Computing, Qubit Allocation}
}

@software{10.5281/zenodo.3368504,
author = {Sergey, Ilya and Nagaraj, Vaivaswatha and Johannsen, Jacob and Kumar, Amrit and Trunov, Anton and Hao, Ken Chan Guan},
title = {Benchmarks accompanying the OOPSLA 2019 paper Safer Smart Contract Programming with Scilla},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3368504},
abstract = {
    <p>This is the artefact accompanying the OOPSLA 2019 paper entitled "Safer Smart Contract Programming with Scilla". The artefact contains scripts for reproducing the quantitative comparison with Ethereum Virtual Machine, reported in the paper.</p>
},
keywords = {Benchmarks, EVM, Scilla, Smart Contracts, Zilliqa}
}

@software{10.5281/zenodo.3362424,
author = {Caires, Lu\'{\i}s and Toninho, Bernardo},
title = {Refinement Kinds: Type-safe Programming with Practical Type-level Computation (Artifact)},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3362424},
abstract = {
    <p>This is the artifact for the paper Refinement Kinds: Type-safe Programming with Practical Type-level Computation. The artifact consists of a prototype kind and type-checker (which also includes an evaluator) for the language described in the paper. The artifact is distributed as a Docker image that bundles the source code, all its dependencies, the code examples from the paper and various additional examples. See the README for a getting started and syntax guides.</p>
},
keywords = {Refinement Kinds, Type Theory, Type-level Computation, Typed Meta-Programming}
}

@software{10.5281/zenodo.3365412,
author = {Bender, John and Palsberg, Jens},
title = {JAM Model: Herd and Coq Instantiations},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3365412},
abstract = {
    <p>The artifact is a virtual machine image with all necessary dependencies to use the Herd and Coq models and reproduce the results of our paper.</p>
},
keywords = {coq, herd, mechanized, memory models}
}

@software{10.5281/zenodo.3368627,
author = {Antonopoulos, Timos and Koskinen, Eric and Le, Ton Chanh},
title = {Knotical: An Inference System of Trace Refinement Relations},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3368627},
abstract = {
    <p>This is an artifact for the paper "Specification and Inference of Trace Refinement Relations", which is accepted to OOPSLA 2019. The artifact is licensed under the MIT license. The development repository is located at https://github.com/knotical/knotical.</p>
},
keywords = {Kleene Algebra with Tests, program refinement, relational reasoning, trace refinement}
}

@software{10.5281/zenodo.3363914,
author = {Astrauskas, Vytautas and M\"{u}ller, Peter and Poli, Federico and Summers, Alexander J.},
title = {Software Artefact for the OOPSLA'19 Paper Titled "Leveraging Rust Types for Modular Specification and Verification"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3363914},
abstract = {
    <p>This artefact contains a virtual machine that can be used to reproduce the evaluation of our paper. You can find the instructions in the README.pdf file. If you are interested in building on top of our research results, you can find the latest version of Prusti in our GitHub repository: https://github.com/viperproject/prusti-dev.</p>
},
keywords = {Rust, verification, Viper}
}

@software{10.5281/zenodo.3369233,
author = {Keidel, Sven and Erdweg, Sebastian},
title = {Artifact: Sound and Reusable Components for Abstract Interpretation},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3369233},
abstract = {
    <p>The artifact contains the library of analysis components (Section 6) and the code of the case studies (Section 7).</p>
},
keywords = {Abstract Interpretation, Soundness, Static Analysis}
}

@software{10.1145/3345840,
author = {Kapus, Timotej and Cadar, Cristian},
title = {Replication package for Segmented Memory Model},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3345840},
abstract = {
    <p>The artefact consists of a dokcer image that has the experiments described in the paper set-up and ready to run. In addition we provide the raw data and plotting utilities to get the graphs in the paper. See the README file for further details.</p>
},
keywords = {KLEE, m4, make, memory model, SQLite, symbolic execution}
}

@software{10.5281/zenodo.3262095,
author = {Menghi, Claudio and Nejati, Shiva and Gaaloul, Khouloud and Briand, Lionel C.},
title = {Replication Package for Article: Generating Automated and Online Test Oracles for Simulink Models with Continuous and Uncertain Behaviors},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3262095},
abstract = {
    <p>SOCRaTeS automatically converts functional requirements into oracles specified in Simulink. The oracles evaluate test outputs of the CPS model in an automated and online manner and generate fitness values that provide engineers with a degree of satisfaction or failure for each test input. Engineers can stop running a test in the middle when SOCRaTeS concludes that the test fitness is going to remain below a given threshold for the rest of its execution.</p>
},
keywords = {Formal language definitions., Software and its engineering, Software verification and validation}
}

@software{10.1145/3345842,
author = {Rigger, Manuel and Marr, Stefan and Adams, Bram and M\"{o}ssenb\"{o}ck, Hanspeter},
title = {Artifact: Understanding GCC Builtins to Develop Better Tools},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3345842},
abstract = {
    <p>This artifact is associated with the paper "Understanding GCC Builtins to Develop Better Tools" and provides the builtin raw data, the preprocessed data, and aggregated data of builtin usages. It also contains a record of the manual decisions made as part of this study. Furthermore, it contains all the scripts and applications to reproduce the paper's results.</p>
},
keywords = {C GitHub projects, compiler intrinsics, GCC builtins}
}

@software{10.5281/zenodo.3257172,
author = {Koyuncu, Anil and Liu, Kui and Bissyand\'{e}, Tegawend\'{e} F. and Kim, Dongsun and Monperrus, Martin and Klein, Jacques and Le Traon, Yves},
title = {iFixR a patch generation system for user-reported bugs},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3257172},
abstract = {
    <p>Dataset and code to run iFixR</p>
},
keywords = {bug-report.program-repair}
}

@software{10.5281/zenodo.3262201,
author = {Kalhauge, Christian Gram and Palsberg, Jens},
title = {Artifact from "Binary Reduction of Dependency Graphs"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3262201},
abstract = {
    <p>This is the artifact is supplementing the "Binary Reduction of Dependency Graphs" paper by Christian Gram Kalhauge and Jens Palsberg ESCE/FSE 2019. It contains the source code for tool, the evaluation procedure, and the benchmarks.</p>
},
keywords = {debugging, dependencies, reduction}
}

@software{10.5281/zenodo.3334854,
author = {Durieux, Thomas and Madeiral, Fernanda and Martinez, Matias and Abreu, Rui},
title = {RepairThemAll},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3334854},
abstract = {
    <p>RepairThemAll is a framework to execute 11 automatic repair tools on 5 benchmarks of Java Bugs.</p>
},
keywords = {Automatic Program Repair, Benchmark of bugs, Patch Generation}
}

@software{10.5281/zenodo.3336282,
author = {Bui, Nghi D. Q. and Yu, Yijun and Jiang, Lingxiao},
title = {SAR: Learning Cross-Language API Mappings with Little Knowledge},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3336282},
abstract = {
    <p>Providing the 2 corpus of the 2 languages, the tool will automatically infer the API mappings.</p>
},
keywords = {adversarial learning, API mapping, code learning, cross language, generative adversarial networks, program representation learning}
}

@software{10.6084/m9.figshare.7749356,
author = {He, Sen and Manns, Glenna and Saunders, John and Wang, Wei and Pollock, Lori and Soffa, Mary Lou},
title = {Code and Dataset for PT4Cloud},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.7749356},
abstract = {
    <p>This artifact contain code and data used to generate the data in the paper, which are the evaluation results of PT4Cloud. The code can be resused for other functions. The main componnent of the code include the function for KL-Divergence and multinomial likelihood, implemented in PT4CloudArtifacts.py in function "DistSimilarity"", and the function for bootstrapping the confidence band is implemented in "pt4cloud_figures.py" in function "bootstrap_conf_band."</p>
},
keywords = {cloud computing, non-parametric statistics, performance testing, resource contention}
}

@software{10.6084/m9.figshare.8242877,
author = {Cotroneo, Domenico and De Simone, Luigi and Liguori, Pietro and Natella, Roberto and Bidokhti, Nematollah},
title = {Replication Package for Article: How Bad Can a Bug Get? An Empirical Analysis of Software Failures in the OpenStack Cloud Computing Platform},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.8242877},
abstract = {
    <p>The artifact includes tools to repeat the fault-injection experiments presented in the paper "How Bad Can a Bug Get  An Empirical Analysis of Software Failures in the OpenStack Cloud Computing Platform" (ESEC/FSE '19). Please note that this artifact does not include a fault injection tool since we transferred the ownership of the tool to our industry partners. Therefore, the artifact includes pre-injected source-code files. Before every fault injection test, an original source-code file is replaced with a pre-injected file, and it is restored after the test.</p>
},
keywords = {Cloud computing, Fault injection, Software fault tolerance}
}

@software{10.6084/m9.figshare.8753420,
author = {DeFreez, Daniel and Baldwin, Haaken Martinson and Rubio-Gonz\'{a}lez, Cindy and Thakur, Aditya V.},
title = {EESI},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.6084/m9.figshare.8753420},
abstract = {
    <p>This repository contains the tool EESI. This is the software artifact that accompanies the paper "Effective Error-Handling Specification Inference via Domain Knowledge Expansion" by Daniel DeFreez, Haaken Martinson Baldwin, Cindy Rubio-Gonz lez, and Aditya V. Thakur.</p>
},
keywords = {bug finding, error handling, static analysis}
}

@software{10.1145/3339072,
author = {Sharma, Aman and Nasre, Rupesh},
title = {QADroid: Regression Event Selection for Android Applications},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3339072},
abstract = {
    <p>We present here the artifacts that supports our ISSTA 19 paper. We proposed QADroid. We implemented QaDroid using Soot and FlowDroid, and tested it over multiple versions of Android apps. We compared the regression selection of events in QADroid against the total number of events. The artifacts provides the experimental setup used and the steps to run QADroid on Android apps.</p>
},
keywords = {Android apps, Regression Analysis, Software Engineering}
}

@software{10.5281/zenodo.3267950,
author = {Banerjee, Subarno and Clapp, Lazaro and Sridharan, Manu},
title = {NullAway: Practical Type-Based Null Safety for Java},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3267950},
abstract = {
    <p>NullAway is a tool to help eliminate NullPointerExceptions (NPEs) in your Java code. To use NullAway, first add @Nullable annotations in your code wherever a field, method parameter, or return value may be null. Given these annotations, NullAway performs a series of type-based, local checks to ensure that any pointer that gets dereferenced in your code cannot be null. NullAway is similar to the type-based nullability checking in the Kotlin and Swift languages, and the Checker Framework and Eradicate null checkers for Java. NullAway is fast. It is built as a plugin to Error Prone and can run on every single build of your code. In our measurements, the build-time overhead of running NullAway is usually less than 10\%. NullAway is also practical: it does not prevent all possible NPEs in your code, but it catches most of the NPEs we have observed in production while imposing a reasonable annotation burden.</p>
},
keywords = {java, null safety, pluggable type systems, static code analysis}
}

@software{10.5281/zenodo.3262370,
author = {Mordahl, Austin and Oh, Jeho and Koc, Ugur and Wei, Shiyi and Gazzillo, Paul},
title = {Artifacts for: An Empirical Study of Real-World Variability Bugs Detected by Variability-Oblivious Tools},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3262370},
abstract = {
    <p>This repository provides the implementation of the final three steps of the automated framework presented in our FSE'2019 paper (included as ./PDF). The first step, Sample Generation, relies on the work done by Jeho et al. [31], so we do not include it here. Instead, we provide the results of that step in ./cases, and provide the rest of the framework, which runs off-the-shelf bug detectors, deduplicates their results, automatically extracts relevant features, and outputs those results in a unified format. See INSTALL.md for instructions on running the experiments. This is a single version uploaded for archival purposes, but refer to https://github.com/paulgazz/kconfig_case_studies for the most current version, with any necessary bug fixes.</p>
},
keywords = {configurable C software, static analysis, variability bugs}
}

@software{10.1145/3339069,
author = {Padhye, Rohan and Lemieux, Caroline and Sen, Koushik and Papadakis, Mike and Le Traon, Yves},
title = {Replication Package for "Semantic Fuzzing with Zest"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3339069},
abstract = {
    <p>The artifact is a Docker image that contains the Zest fuzzing engine, benchmark programs evaluated in the paper, scripts to run all the experiments described in the paper, and a data-set containing the results of the experiments when they were run on the authors' machine.</p>
},
keywords = {property-based testing, random testing, Structure-aware fuzzing}
}

@software{10.1145/3339070,
author = {Kechagia, Maria and Devroey, Xavier and Panichella, Annibale and Gousios, Georgios and van Deursen, Arie},
title = {Replication Package for Article: Effective and Efficient API Misuse Detection via Exception Propagation and Search-Based Testing},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3339070},
abstract = {
    <p>Effective and efficient detection of API misuses in Java client programs by combining static exception propagation and search-based testing. The artifact includes the main components for the exception propagation and the search-based testing. A tutorial is also provided for running the experiments.</p>
},
keywords = {API misuse, search-based software testing, software crash, static exception propagation}
}

@software{10.1145/3339067,
author = {Schwahn, Oliver and Coppik, Nicolas and Winter, Stefan and Suri, Neeraj},
title = {Artifact for Article: Assessing the State and Improving the Art of Parallel Testing for C},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3339067},
abstract = {
    <p>This is the artifact for the paper "Assessing the State and Improving the Art of Parallel Testing for C" by Oliver Schwahn, Nicolas Coppik, Stefan Winter, and Neeraj Suri. The provided artifact contains the prototype implementations and raw data used for the paper packaged as a Docker image. The ZIP file includes our Docker image along with a more detailed README.txt and some utility shell scripts to simplify Docker handling and package installation. The Docker image contains a complete setup for building and executing our tools as well as the repository study and library raw data and scripts. Please refer to the aforementioned README.txt for the full documentation and detailed instructions. The Docker image and its contents are provided as is without any warranty for academic purposes. The user-space included in the Docker image was installed from the Ubuntu software repository. The source code for the Debian repository study and the libraries was downloaded from the Debian software repository. The source code for additional third-party tools, libraries, and programs was downloaded from their respective distribution archives or GitHub, e.g., llvm.org, https://github.com/coccinelle/coccinelle, https://github.com/AlDanial/cloc, https://cran.r-project.org, https://pypi.org/, https://www.rust-lang.org, https://crates.io Note that all included third-party software is subject to their respecive licenses.</p>
},
keywords = {Parallel Test Execution, Parallel Testing, Software Repository Analysis, Static Analysis, Static Dependency Detection}
}

@software{10.1145/3339068,
author = {Li, Xia and Li, Wei and Zhang, Yuqun and Zhang, Lingming},
title = {Replication Package for Article: "DeepFL: Integrating Multiple Fault Diagnosis Dimensions for Deep Fault Localization"},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3339068},
abstract = {
    <p>This artifact is used to implement our fault localization technique "DeepFL". It includes two main components: (1) DeepFL execution and (2) Result analysis.</p>
},
keywords = {Deep learning, Fault localization, Mutation testing}
}

@software{10.5281/zenodo.3239998,
author = {Lee, Sungho and Ryu, Sukyoung},
title = {Adlib: Static Analyzer to Detect Vunlerable Patterns in AdSDKs},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.3239998},
abstract = {
    <p>Adlib is a static analyzer for AdSDKs. AdSDKs have powerful APIs, but the APIs may open to the malicious advertisements. Using predefined vulnerable patterns, Adlib constructs callgraphs and performs data flow analysis to find the vulnerable APIs that open to and can be abused by advertisements.</p>
},
keywords = {AdSDKs, Advertising Platform Vulnerabilities, Hybrid Applications, Malicious Advertisements}
}

@software{10.5281/zenodo.2669678,
author = {Hsiao, Luke and Wu, Sen and Chiang, Nicholas and R\'{e}, Christopher and Levis, Philip},
title = {Software for Automating the Generation of Hardware Component Datasheets},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.2669678},
abstract = {
    <p>This artifact provides a Python package and datasets which can be used to replicate our methodology for automating the generation of hardware component knowledge bases. We describe how the software and datasets can be obtained, how the software and dependencies can be installed, and how the software can be used to run our experiments. Our artifact outlines the workflow from the input data (PDF and HTML documents, along with gold labels) to the final quality metrics we used to evaluate the approach. We also include scripts used for our analysis and performance experiments.</p>
},
keywords = {design tools, hardware components, knowledge base construction}
}

@software{10.1145/3300175,
author = {Wang, Qingsen and Su, Pengfei and Chabbi, Milind and Liu, Xu},
title = {Software for Lightweight Hardware Transactional Memory Profiling},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3300175},
abstract = {
    
},
keywords = {Hardware Transactional Memory, optimization, profiling}
}

@software{10.5281/zenodo.2240193,
author = {Qiao, Bo and Reiche, Oliver and Hannig, Frank and Teich, J\"{u}rgen},
title = {From Loop Fusion to Kernel Fusion: A Domain-specific Approach to Locality Optimization},
year = {2019},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.2240193},
abstract = {
    <p>This artifact describes the steps to reproduce the results for the CUDA code generation with kernel fusion in Hipacc (an image processing DSL and source-to-source compiler embedded in C++), as presented in the CGO19 paper “From Loop Fusion to Kernel Fusion: A Domain-specific Approach to Locality Optimization”. We provide the original binaries as well as the source code to regenerate the binaries, which can be executed on x86_64 Linux system with CUDA enabled GPUs. Furthermore, we include two python scripts to run the application and compute the statistics as depicted in Figure 6 in the paper.</p>
<p>Hardware Dependencies: CUDA enabled GPUs are required. We used three Nvidia cards, as discussed in Section 5.1 in the paper: (a) Geforce GTX 745 facilitates 384 CUDA cores with a base clock of 1,033 MHz and 900 MHz memory clock. (b) Geforce GTX 680 has 1,536 CUDA cores with a base clock of 1,058 MHz and 3,004 MHz memory clock. (c) Tesla K20c has 2,496 CUDA cores with a base clock of 706 MHz and 2,600 MHz memory clock. For all three GPUs, the total amount of shared memory per block is 48 Kbytes, the total number of registers available per block is 65,536. GPUs with similar configurations are expected to generate comparable results.</p>
<p>Software Dependencies: Clang/LLVM (6.0), compiler_rt and libcxx for Linux (6.0). CMake (3.4 or later), Git (2.7 or later). Nvidia CUDA Driver (9.0 or later). OpenCV for producing visual output in the samples.</p>

},
keywords = {DSL, Image Processing, Kernel Fusion}
}

@software{10.1145/3291638,
author = {Scalas, Alceste and Yoshida, Nobuko},
title = {mpstk: the Multiparty Session Types Toolkit},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291638},
abstract = {
    <p>mpstk is a toolkit for specifying multiparty protocols and verifying their properties (e.g., deadlock-freedom and liveness). This artifact contains the mpstk source code, its documentation, and a ready-to-use virtual machine. They include instructions to replicate the examples and tables in the companion paper. For the latest version of mpstk, visit: https://alcestes.github.io/mpstk</p>
},
keywords = {mcrl2, model checking, session types}
}

@software{10.1145/3291628,
author = {Miyazaki, Yusuke and Sekiyama, Taro and Igarashi, Atsushi},
title = {lambda-dti},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291628},
abstract = {
    <p>lambda-dti is an interpreter of the implicitly typed gradual language (ITGL) which uses dynamic type inference for evaluating programs. This implementation consists of: - Garcia and Cimini's type inference algorithm; - a cast-inserting translator from the ITGL to the blame calculus; - an evaluator of the blame calculus with dynamic type inference; and - some extensions (recursion, operators, and libraries) to the ITGL. The artifact helps to understand the ideas from the paper by trying examples.</p>
},
keywords = {dynamic type inference, functional programming language, gradual typing, operational semantics, polymorphism}
}

@software{10.1145/3291648,
author = {Gilbert, Ga\"{e}tan and Cockx, Jesper and Sozeau, Matthieu and Tabareau, Nicolas},
title = {Coq and Agda with proof irrelevance, plus examples},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291648},
abstract = {
    <p>Sources for versions of the proof assistants Coq and Agda which have a proof irrelevant universe (respectively SProp and Prop)</p>
},
keywords = {proof assistants, proof irrelevance, type theory}
}

@software{10.1145/3291622,
author = {Omar, Cyrus and Voysey, Ian and Chugh, Ravi and Hammer, Matthew A.},
title = {Agda Mechanization and Implementation Snapshot for Article: Live Functional Programming with Typed Holes},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291622},
abstract = {
    <p>This artifact contains: 1. The Agda mechanization of Hazelnut Live, as described in Sec. 3.4. 2. A snapshot of the Hazel implementation at the time of submission, which supports the user interface features described in Sec. 2.</p>
},
keywords = {contextual modal type theory, gradual typing, live programming, structured editing, typed holes}
}

@software{10.1145/3291625,
author = {Florence, Spencer P. and You, Shu-Hung and Tov, Jesse A. and Findler, Robert Bruce},
title = {Artifact for A Calculus for Esterel},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291625},
abstract = {
    <p>This virtual machine is the artifact for the paper "A Calculus for Esterel". This is a machine that contains all of the publicly available support for the git repository `https://github.com/florence/esterel-calculus ` already installed and configured. This README explains how the machine is set up; see the git repositories s README for the actually interesting content: Installation instructions (which have already been performed), dependencies, the project layout, the `make` targets, and examples of how to modify the code base in various ways. The git repository is cloned to `~/Desktop/esterel-calculus`. This machine's user is `user`, and the the users password is `password`. The user has sudo access. The machine has Agda version 2.5.2 installed via stack. The stack global project is configured to point at the `lts-9.2` resolver. To change this modify `~/.stack/global-project/stack.yaml`. The Agda standard library version 0.13 is installed in `/usr/local/lib/agda/` an is symlinked to `~/agda-stdlib-0.13/`. The dependencies of Bigloo Scheme 4.3c have been installed via `apt-get`. Racket v7.0 is installed in `/usr/bin`. The `esterel-calculus` directory has been installed as a racket package, and bigloo scheme, hop, and hiphop.js have been installed in `~/Desktop/esterel-calculus/install-prefix`, as described in `~/Desktop/esterel-calculus/README.txt`.</p>
},
keywords = {Esterel, Operational Semantics}
}

@software{10.1145/3291624,
author = {Fragoso Santos, Jos\'{e} and Maksimovi?, Petar and Sampaio, Gabriela and Gardner, Philippa},
title = {Artifact accompanying the POPL'19 article "JaVerT 2.0: Compositional Symbolic Analysis for JavaScript"},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291624},
abstract = {
    <p>The artifact is a VirtualBox Virtual Machine (VM) for OSX, Version 5.2.18 r124139. It is 4.5Gb in size in the .ova format and needs to be imported into VirtualBox using its Import Appliance feature. The unzipped VM is around 16Gb in size. The VM is set to have 4 processors, 8GB of RAM, and a 25Gb solid-state drive. The operating system is Ubuntu 18.04.1 (Bionic Beaver). Guest Additions are installed, but may need to be reinstalled for your version of VirtualBox. You will be logged in automatically, but if you need sudo rights or to log in at some point, the username and the password are both javert. Using the instructions available in the artifact (README.md), one can reproduce the results of the paper. Moreover, the implementation itself can be partially re-used for implementing different types of analysis for different programming languages.</p>
},
keywords = {bi-abduction, Compositional program analysis, JavaScript, modular implementation design, program specification and verification, symbolic execution, trusted compilation}
}

@software{10.1145/3291629,
author = {Yi, Xin and Chen, Liqian and Mao, Xiaoguang and Ji, Tao},
title = {Replication Package for Article: Efficient Automated Repair of High Floating-Point Errors in Numerical Libraries},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291629},
abstract = {
    <p>The main goal of this artifact is to repeat this experimental evaluation in the section 5 of the article: Efficient Automated Repair of High Floating-Point Errors in Numerical Libraries The main structure of this artifact is as follows: * AutoRNP --&gt; source code of our tool * benchmarks --&gt; source code of 20 GSL functions that our experiments were conducted on * experiments --&gt; scripts for repeating our experiments * paper_data --&gt; original experimental results presented in our paper by AutoRNP * HBG --&gt; scripts and data for experiments on HBG</p>
},
keywords = {automated repair, Floating-point errors, numerical program}
}

@software{10.1145/3291630,
author = {Chen, Taolue and Hague, Matthew and Lin, Anthony W. and R\"{u}mmer, Philipp and Wu, Zhilin},
title = {OSTRICH String Constraint Solver and Results},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291630},
abstract = {
    <p>Contains source code, a prebuilt Jar file, and a disk image for the running of the OSTRICH tool. Also includes some of the benchmarks used in the paper, as well as logs of all experimental results.</p>
},
keywords = {Decision Procedures, ReplaceAll, Reverse, Straight-Line Programs, String Constraints, Transducers}
}

@software{10.1145/3291632,
author = {Biernacki, Dariusz and Pir\'{o}g, Maciej and Polesiuk, Piotr and Sieczkowski, Filip},
title = {Helium},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291632},
abstract = {
    <p>An experimental programming language that boasts advanced algebraic effects, sophisticated polymorphism and abstraction for types and effects through a simple module system in the style of ML.</p>
},
keywords = {effect handlers, modular abstraction, programming language}
}

@software{10.1145/3291642,
author = {Watt, Conrad and Renner, John and Popescu, Natalie and Cauligi, Sunjay and Stefan, Deian},
title = {Proofs, Source, and Evaluation Scripts for CT-Wasm: Type-Driven Secure Cryptography for the Web Ecosystem},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291642},
abstract = {
    <p>The artifact contains the source code for the Isabelle Proofs, both implementations of CT-Wasm, implementations of all cyrptographic algorithms mentioned in the paper, and scripts to reproduce all data in the evaluation section.</p>
},
keywords = {constant, constant-time, cryptography, Isabelle, nacl, node, salsa20, time, v8, Wasm, web, WebAssembly}
}

@software{10.1145/3291647,
author = {Kincaid, Zachary and Breck, Jason and Cyphert, John and Reps, Thomas},
title = {Replication Package for Article: Closed Forms for Numerical Loops},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291647},
abstract = {
    <p>This virtual machine contains an installation of ICRA, which is the tool that implements the ideas described in "Closed Forms for Numerical Loops."</p>
},
keywords = {decision procedures, Invariant generation, loop summarization}
}

@software{10.1145/3291649,
author = {Vassena, Marco and Russo, Alejandro and Garg, Deepak and Rajani, Vineet and Stefan, Deian},
title = {Mechanized Proofs: From Fine- to Coarse-Grained Dynamic Information Flow Control and Back},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291649},
abstract = {
    <p>The artifact consists of a docker repository containing Agda mechanized proofs of the paper "From Fine- to Coarse-Grained Dynamic Information Flow Control and Back" by Vassena, Russo, Vineet, Deepak, Stefan and all the software required to check them. The docker is self-contained and includes: - Proof scripts source files (`/root/granularity/src`) - Highlighted, hyperlinked html webpages generated from the scripts (`/root/granularity/html`) - Agda version 2.5.3 and the standard library v0.15 - The paper (/root/granularity.pdf) - The editor Emacs to browse both the proof scripts (`emacs src/Toc.agda`) and the generated html webpages (`emacs -f eww-open-file` and starting at file `html/Toc.html`).</p>
},
keywords = {Agda, Information-flow control, verified source-to-source transformations}
}

@software{10.1145/3291651,
author = {Bodin, Martin and Gardner, Philippa and Jensen, Thomas and Schmitt, Alan},
title = {Coq formalisation for Article: Skeletal Semantics and Their Interpretations},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291651},
abstract = {
    <p>This artefact is a formalisation of all the definitions, lemmas, and theorems of Sections 2 5 of the following paper: Martin Bodin, Philippa Gardner, Thomas Jensen, Alan Schmitt. 2019. Skeletal Semantics and their Interpretations. In ACM Symposium on Principles of Programming Languages (POPL 19). https://doi.org/10.1145/3290357</p>
},
keywords = {abstract interpretation, Coq, programming language, semantics}
}

@software{10.1145/3291614,
author = {Castro, David and Hu, Raymond and Jongmans, Sung-Shik and Ng, Nicholas and Yoshida, Nobuko},
title = {Artifact for Distributed Programming using Role-Parametric Session Types in Go},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291614},
abstract = {
    <p>The artifact is a virtual machine with Scribble-Go, a toolchain for safe distributed programming using role-parametric session types in Go, pre-installed. The purpose of this artifact is to support the practical claims of the paper: (1) Practical metholodogy for distributed programming of role-parameteric protocols in Go based on the theory (Sect. 3 and Sect. 5). (2) Run-time overhead benchmarks (Sect. 6.1). (3) Applications (Sec 6.2). Our artifact comprises four main components: (A) A VM machine.ova with our software pre-installed and graphical UI scripts for running the software. (B) This document, which explains: how to install and run the VM; how to browse and run the example demos and benchmark applications. (C) A supporting document tutorials.html, which guides a hands-on experience of using our tools through a few tutorials. (D) A package benchmarks.zip that allows to run our benchmarks outside the VM. Claim (1) is supported by (B) that allows to browse and run all of the examples listed in Fig. 15 of the paper implemented using our tools, and (C) that offers a more hands-on feel for using our tools. We have prepared (B) and (C) to demonstrate all the core features of our Scribble-Go framework: Protocol specification: core language constructs for parameterisation/foreach/indexed roles Distribution: variant inference, family inference, well-formedness checking and projection Practical application: Go API generation and endpoint implementations, with transport-independence (shared memory and TCP supported) Our software is installed in the VM by the following three (open source) git repository clones: scribble: our prototype extension of Scribble for Go (currently implemented over the master scribble-java codebase). The location of the git clone in the VM is: /home/ubuntu/scribble It is cloned from: https://github.com/scribble/scribble-java/tree/popl19-artifact. scribble-go-runtime: the Scribble-Go Runtime is used by our generated APIs to initialise session endpoints, perform connection actions and session I/O. It supports shared memory (shm) and TCP (tcp) as message transports. It is cloned in the VM at: /home/ubuntu/scribble-go-runtime It is symlinked (for the convenience of some import paths in the example Go programs) to: /home/ubuntu/go/src/github.com/rhu1/scribble-go-runtime. It is cloned from: https://github.com/rhu1/scribble-go-runtime/tree/popl19-artifact. scribble-go-examples: is our main examples and benchmarks repository. It is cloned in the VM at: /home/ubuntu/scribble-go-examples It is symlinked (for the convenience of some import paths in the example Go programs) to: /home/ubuntu/go/src/github.com/nickng/scribble-go-examples. It is cloned from: https://github.com/nickng/scribble-go-examples.</p>
},
keywords = {go, multiparty session types, scribble}
}

@software{10.1145/3291626,
author = {Cyphert, John and Breck, Jason and Kincaid, Zachary and Reps, Thomas},
title = {Replication Package for Article: Refinement of Path Expressions for Static Analysis},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291626},
abstract = {
    <p>The given virtual machine contains a version of the program analysis tool duet. duet contains implementations of the KCBR and ACI domains described in the paper "Refinement of Path Expressions for Static Analysis". The version of duet on this virtual machine contains an implementation of the refinement algorithm described in the paper on the git branch cra-refine.</p>
},
keywords = {abstract-interpretation precision, Algebraic program analysis, control-flow refinement}
}

@software{10.1145/3291641,
author = {Sp\"{a}th, Johannes and Ali, Karim and Bodden, Eric},
title = {Artifact for "Context-, Flow-, and Field-Sensitive Data-Flow Analysis using Synchronized Pushdown Systems"},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291641},
abstract = {
    <p>This is the artifact to the paper "Context-, Flow-, and Field-Sensitive Data-Flow Analysis using Synchronized Pushdown Systems". It can be used to reproduce the experiments conducted for research questions 1, 2, and 3. The artifact ships as a virtual machine image with a readily set up Eclipse instance. The workspace of Eclipse is set up with the projects and their source codes to run all experiments conducted within the paper.</p>
},
keywords = {access path, context-free language, data-flow, pointer analysis, program analysis, pushdown system, static analysis}
}

@software{10.1145/3291616,
author = {Toro, Mat\'{\i}as and Labrada, Elizabeth and Tanter, \'{E}ric},
title = {IGSF: Interactive Gradual System F},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291616},
abstract = {
    <p>IGSF is a web executable model of GSF implemented in Scala and React.js. IGSF shows interactive typing and reduction derivations for arbitrary source programs. In particular, it shows the evidence-augmented terms/derivations, and highlights the evidence combinations that occur at each reduction step.</p>
},
keywords = {Gradual typing, parametricity, polymorphism, React, Scala}
}

@software{10.1145/3291617,
author = {Fowler, Simon and Lindley, Sam and Morris, J. Garrett and Decova, S\'{a}ra},
title = {Exceptional Asynchronous Session Types: Session Types without Tiers (Companion Artifact)},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291617},
abstract = {
    <p>The artifact contains the modified Links programming language with session types and exceptions, and several example applications. These are packaged in a Docker image, and we have included scripts to launch the interpreter and the examples.</p>
},
keywords = {exceptions, functional programming languages, session types}
}

@software{10.1145/3291633,
author = {Meyer, Roland and Wolff, Sebastian},
title = {TMRexp},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291633},
abstract = {
    <p>Automatic linearizability checker for lock-free data structures using safe memory reclamation.</p>
},
keywords = {linearizability, lock-free data structures, memory management, safe memory reclamation, static analysis, verification}
}

@software{10.1145/3291635,
author = {Raad, Azalea and Doko, Marko and Ro?i?, Lovro and Lahav, Ori and Vafeiadis, Viktor},
title = {On Library Correctness under Weak Memory Consistency (artifact)},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291635},
abstract = {
    <p>This artifact contains Coq formalizations of some proofs presented in the paper.</p>
},
keywords = {concurrent libraries, linearisability, weak memory consistency}
}

@software{10.1145/3291637,
author = {Shi, Kensen and Steinhardt, Jacob and Liang, Percy},
title = {GitHub Repository for "FrAngel: Component-Based Synthesis with Control Structures"},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291637},
abstract = {
    <p>The source code for FrAngel, with documentation about its usage and instructions for replicating the experiments.</p>
},
keywords = {FrAngel, program synthesis, source code}
}

@software{10.1145/3291643,
author = {Bizjak, Ale\v{s} and Gratzer, Daniel and Krebbers, Robbert and Birkedal, Lars},
title = {Coq development for Iron: Managing Obligations in Higher-Order Concurrent Separation Logic},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291643},
abstract = {
    <p>This is the artifact for the paper Iron: Managing Obligations in Higher-Order Concurrent Separation Logic. The artifact comes as a virtual machine image with prebuilt sources, and also as a .zip archive containing sources and all of the dependencies. The latest version of the artifact and the paper can be downloaded at https://iris-project.org/iron/ .</p>

},
keywords = {concurrency, Coq formalization, resource management, Separation logic}
}

@software{10.5281/zenodo.1481957,
author = {Tassarotti, Joseph and Harper, Robert},
title = {Artifact for Article: A Separation Logic for Concurrent Randomized Programs},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.1481957},
abstract = {
    <p>This artifact contains the Coq formal proofs for the logic and examples described in the paper. The development is available both as a tar archive containing the source, and as a Virtual Machine with all dependencies installed.</p>
},
keywords = {concurrency, Coq, probability, separation logic}
}

@software{10.1145/3291615,
author = {Chatterjee, Krishnendu and Goharshady, Amir Kafshdar and Okati, Nastaran and Pavlogiannis, Andreas},
title = {Implementation of Algorithms in Article: Efficient Parameterized Algorithms for Data Packing},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291615},
abstract = {
    <p>We are considering the problem of data packing over a two-level memory system and providing an algorithm for solving it by exploiting the treewidth of the underlying access graphs. Our algorithm is exact and optimal, i.e. it outputs the minimal number of cache misses possible. This artifact contains the following: a) An implementation of our algorithms in Java: Our implementation relies on tree decompositions of the underlying access hypergraphs. These are obtained using the LibTW tool (a free software library for obtaining and manipulating tree decompositions). b) Implementation of Benchmarks: We use several common programs as benchmarks. These are all implemented in C++. c) Implementation of a Cache Simulator: We have implemented a cache simulator to count the number of cache misses caused by a data packing algorithm. d) Implementation of Several Heuristics: We have implemented several heuristics for data packing (in order to compare them with our optimal algorithm).</p>
},
keywords = {cache management, data packing, parameterized algorithms}
}

@software{10.1145/3291636,
author = {Alon, Uri and Zilberstein, Meital and Levy, Omer and Yahav, Eran},
title = {Implementation, data and a trained model for the code2vec paper},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291636},
abstract = {
    <p>This artifact contains data, trained models and code for the paper "code2vec: Learning Distributed Representations of Code". Updated instructions may be found in: https://github.com/tech-srl/code2vec</p>
},
keywords = {code summarization, code vectors, code2vec, Java, method names}
}

@software{10.1145/3291639,
author = {Blanchette, Jasmin Christian and Gheri, Lorenzo and Popescu, Andrei and Traytel, Dmitriy},
title = {Formalization Artifact for the paper "Bindings as Bounded Natural Functors"},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291639},
abstract = {
    <p>This archive contains the Isabelle formalization of binding-aware (co)datatypes and (co)recursors related to the paper Bindings as Bounded Natural Functors Jasmin Christian Blanchette, Lorenzo Gheri, Andrei Popescu, Dmitriy Traytel The repository also contains an extended version of the paper, which includes many appendices. We have also singled out the part of the appendix that is directly relevant for (and referenced in) the formalization artifact. The formal development can be browsed as a generated HTML page. A better way to study the included Isabelle sources, however, is to open them in Isabelle/jEdit.</p>
},
keywords = {inductive and coinductive datatypes, Isabelle/HOL, proof assistants, syntax with bindings}
}

@software{10.1145/3291644,
author = {Podkopaev, Anton and Lahav, Ori and Vafeiadis, Viktor},
title = {Mechanized in Coq Proofs for Article: Bridging the Gap between Programming Languages and Hardware Weak Memory Models},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291644},
abstract = {
    <p>This artifact is a VirtualBox image containing mechanized in Coq proofs related to the article "Bridging the Gap Between Programming Languages and Hardware Weak Memory Models" by Anton Podkopaev, Ori Lahav, and Viktor Vafeiadis.</p>
},
keywords = {coq, proof, weak memory models}
}

@software{10.1145/3291619,
author = {Unruh, Dominique},
title = {Verification tool for quantum relational Hoare Logic},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3291619},
abstract = {
    <p>A verification tool that allows to interactively prove judgments in qRHL (using a subset of the rules described in the paper "Quantum Relational Hoare Logic").</p>
},
keywords = {qRHL, Quantum relational Hoare logic, verification tool}
}

@software{10.5281/zenodo.1482574,
author = {Polikarpova, Nadia and Sergey, Ilya},
title = {SuSLik, Tool Implementation for Article: Structuring the Synthesis of Heap-Manipulating Programs},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.1482574},
abstract = {
    <p>The artifact of this work is a program synthesizer called SuSLik. The tool sources are provided along with the instructions for reproducing the evaluation reported in the paper, and with suggestions for exercising SuSLik beyond the original benchmark suite.</p>
},
keywords = {Program Synthesis, Proof Systems, Scala, Separation Logic, SMT, Type Theory}
}

@software{10.5281/zenodo.1412854,
author = {Mayer, Mika\"{e}l and Kuncak, Viktor and Chugh, Ravi},
title = {Implentation for: Bidirectional Evaluation with Direct Manipulation},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.1412854},
abstract = {
    <p>This release matches the code submitted for the OOPSLA 2018 artifact evaluation of the paper "Bidirectional Evaluation with Direct Manipulation" by Ravi Chugh and Mika l Mayer. The license has been updated with respect to the University of Chicago filing a patent on this technology.</p>
},
keywords = {Bidirectional Programming, Direct Manipulation, Sketch-n-Sketch}
}

@software{10.1145/3276927,
author = {Williams, Jack and Morris, J. Garrett and Wadler, Philip},
title = {TypeScript implementation for paper: The Root Cause of Blame: Contracts for Intersection and Union Types},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3276927},
abstract = {
    <p>This artifact consists of a TypeScript contract library that faithfully implements the blame semantics set out in the paper. The library uses JavaScript proxies to implement contracts and is intended for practical use.</p>
},
keywords = {blame, contracts, intersection, javascript, proxies, typescript, union}
}

@software{10.5281/zenodo.1294300,
author = {Davis, James C. and Coghlan, Christy A. and Servant, Francisco and Lee, Dongyoon},
title = {Artifact (software + dataset) for "The Impact of Regular Expression Denial of Service (ReDoS) in Practice: an Empirical Study at the Ecosystem Scale"},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.1294300},
abstract = {
    <p># Ecosystem-scale regexp study Welcome to the FSE'18 artifact for the ESEC/FSE paper *"The Impact of Regular Expression Denial of Service (ReDoS) in Practice: an Empirical Study at the Ecosystem Scale"*, by J.C. Davis, C.A Coghlan, F. Servant, and D. Lee, all of Virginia Tech. This paper describes a study in which we: - extracted regular expressions (regexes, regexps) from npm and pypi modules - analyzed the regexes along several dimensions Our artifact consists of: - Code to analyze a regex for super-linear performance (Table 1), degree of vulnerability (Table 2), semantic meaning (Table 3), and use of anti-patterns (Table 4). - Unique regexes collected from npm and pypi modules. We are releasing these regexes raw (without analysis or source module(s)) due to security concerns. In addition, we wrote code to statically extract regexes from npm and pypi modules. We released this code as part of our `vuln-regex-detector` software, available [here](https://github.com/davisjam/vuln-regex-detector). Regex extraction was uninteresting from a scientific perspective so we do not elaborate on it in this artifact. In addition to this directory's `README.md`, each sub-tree comes with one or more READMEs describing the software and tests. ## Installation ### By hand To install, execute the script `./configure` on an Ubuntu 16.04 machine with root privileges. This will obtain and install the various dependencies (OS packages, REDOS detectors, npm modules, and pypi modules). It will also initialize submodules. The final line of this script is `echo "Configuration complete. I hope everything works!"`. If you see this printed to the console, great! Otherwise...alas. ### Container To facilitate replication, we have published a [containerized version](https://hub.docker.com/r/jamiedavis/daviscoghlanservantlee-fse18-regexartifact/) of this project on hub.docker.com. The container is based on an Ubuntu 16.04 image so it is fairly large. For example, you might run: ``` docker pull jamiedavis/daviscoghlanservantlee-fse18-regexartifact docker run -ti jamiedavis/daviscoghlanservantlee-fse18-regexartifact &gt; vim .env # Set ECOSYSTEM_REGEXP_PROJECT_ROOT=/davis-fse18-artifact/EcosystemREDOS-FSE18 &gt; . .env &gt; ./full-analysis/analyze-regexp.pl ./full-analysis/test/vuln-email.json ```</p>
},
keywords = {ReDoS, regexes, Regular expressions}
}

@software{10.1145/3276916,
author = {Li, Peixuan and Zhang, Danfeng},
title = {Replication Package: A Derivation Framework for Dependent Security Label Inference},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3276916},
abstract = {
    <p>This package provides implementation of derivation solvers for dependent type inference. It consists of four constraint solvers, i.e., one-shot, early-accept, early-reject and hybrid solver along with two partition algorithms: sequential and combinational partitioning. A parser for the core constraint language and plotting scripts are also available in the package.</p>
},
keywords = {Dependent Types, Information Flow Analysis, Security Label Inference}
}

@software{10.1145/3276932,
author = {Li, Yue and Tan, Tian and M\o{}ller, Anders and Smaragdakis, Yannis},
title = {Artifact of Article: Precision-Guided Context Sensitivity for Pointer Analysis},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3276932},
abstract = {
    <p>This artifact is provided to enable the results of all three research questions (RQ1   RQ3) in Section 4 of our companion paper (including the results in Appendix) to be reproduced. To ease the users to examine all the experimental results or any results they are particularly interested in, we specially design and provide different commands to make such examinations convenient. The artifact also contains comprehensive guidance. To use the artifact, please refer to  readme.pdf  and  getting-started.pdf  in the artifact package. The artifact contains our implementation of Zipper (our tool), Doop framework (a state-of-the-art pointer analysis framework for Java), as well as the Java programs and the library to be analyzed in the evaluation. It also provides some expected output samples of this artifact for the user to examine without running the artifact.</p>
},
keywords = {Java, points-to analysis, static analysis}
}

@software{10.1145/3276987,
author = {Adamsen, Christoffer Quist and M\o{}ller, Anders and Alimadadi, Saba and Tip, Frank},
title = {Prototype Implementation for Article: Practical AJAX Race Detection for JavaScript Web Applications},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3276987},
abstract = {
    <p>This artifact contains the prototype implementation of AjaxRacer, which is presented in the article 'Practical AJAX Race Detection for JavaScript Web Applications'. The tool is implemented using JavaScript, and has been designed to detect post-initialization event races in client-side JavaScript web applications. The artifact's INSTALL.md and README.md files contains more information on how to install and use the tool.</p>
},
keywords = {dynamic analysis, event race detection, JavaScript}
}

@software{10.1145/3276926,
author = {Feltey, Daniel and Greenman, Ben and Scholliers, Christophe and Findler, Robert Bruce and St-Amour, Vincent},
title = {Artifact Virtual Machine Image for Collapsible Contracts: Fixing a Pathology of Gradual Typing},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3276926},
abstract = {
    <p>A virtual machine with the necessary software to reproduce the plots and experiments described in the paper "Collapsible Contracts: Fixing a Pathology of Gradual Typing"</p>
},
keywords = {contracts, gradual typing, migratory typing, performance evaluation}
}

@software{10.1145/3276914,
author = {Zappa Nardelli, Francesco and Belyakova, Julia and Pelenitsyn, Artem and Chung, Benjamin and Bezanson, Jeff and Vitek, Jan},
title = {Artifact for "Julia Subtyping: A Rational Reconstruction" paper},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3276914},
abstract = {
    <p>Software and data to reproduce the results of paper.</p>
},
keywords = {Julia programming language, multiple dispatch, subtyping}
}

@software{10.1145/3276993,
author = {Pauck, Felix and Bodden, Eric and Wehrheim, Heike},
title = {Replication Package for Article: Do Android Taint Analysis Tools Keep Their Promises?},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3276993},
abstract = {
    <p>The artifact includes all the software and data used and generated during the evaluation of the associated paper. Thus, the tools used and results achieved are contained. Along with that detailed instructions are provided which describe how to use the tools and how to review or reproduce the results.</p>
},
keywords = {Analysis Query Language, Android Taint Analysis, AQL, Benchmarks, Empirical Studies, Reproducibility, Tools}
}

@software{10.1145/3277000,
author = {Lehmann, Daniel and Pradel, Michael},
title = {Feedback-Directed Differential Testing of Interactive Debuggers (Artifact)},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3277000},
abstract = {
    <p>This artifact includes (1) the source code of a differential testing tool for interactive debuggers, matching the approach presented in the paper "Feedback-Directed Differential Testing of Interactive Debuggers", (2) the set of test programs and the specific browser versions of Firefox and Chromium used during evaluation of said paper, and (3) the list of found bugs with links to the official issue tracker entries and videos of the bugs appearing in the debuggers' user interfaces.</p>
},
keywords = {bugs, Chromium, debugger, differential testing, Firefox, JavaScript, TypeScript}
}

@software{10.1145/3276913,
author = {Muehlboeck, Fabian and Tate, Ross},
title = {Mechanically Verified Proofs from "Empowering Union and Intersection Types with Integrated Subtyping"},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3276913},
abstract = {
    <p>Mechanical verification of the claims in the paper that declarative and empowered subtyping are decidable due to equivalence to reductive and integrated subtyping, respectively, and that intersectors are composable.</p>
},
keywords = {decidability, distributivity, extensibility, intersections, subtyping, unions}
}

@software{10.5281/zenodo.1317760,
author = {Saini, Vaibhav and Farmahinifarahani, Farima and Lu, Yadong and Baldi, Pierre and Lopes, Cristina V.},
title = {Reusable Package for Article: Oreo: Detection of Clones in the Twilight Zone},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.5281/zenodo.1317760},
abstract = {
    <p>This artifact contains Oreo, a clone detector designed to find code clones in the Twilight zone, along with the input data needed for running this tool, and the materials used in evaluating it.</p>
},
keywords = {Clone detection, Information Retrieval, Machine Learning, Software Metrics}
}

@software{10.1145/3276910,
author = {Drechsler, Joscha and Mogk, Ragnar and Salvaneschi, Guido and Mezini, Mira},
title = {Example Project, Library Source and Benchmark Suite and Tools for Article "Thread-Safe Reactive Programming"},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3276910},
abstract = {
    <p>This Artifact contains four key components: (1) An example project using the thread-safe Reactive Programming library described in the article as an out-of-the-box maven dependency. (2) A copy of the library's source code. (3) The source code of all benchmarks used in the article's empirical evaluation. (4) The toolchain to process the benchmark results into the charts shown in the article.</p>
},
keywords = {Benchmarks, Concurrency Control, Reactive Programming, Scala}
}

@software{10.1145/3276911,
author = {Meier, Remigius and Rigo, Armin and Gross, Thomas R.},
title = {Replication Package for Article: Virtual Machine Design for Parallel Dynamic Programming Languages},
year = {2018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3276911},
abstract = {
    <p>VM image with pre-compiled binaries, evaluation data, source code, and documentation for reproducing the results as reported in the article.</p>
},
keywords = {dynamic language, parallel execution, virtual machine}
}

