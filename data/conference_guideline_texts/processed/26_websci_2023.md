1. **Self-Containment**: The VM should be self-contained to minimize issues related to version deprecation and backward compatibility, ensuring that all necessary data and code are included.
2. **Documentation**: Artifacts must be well-documented, including a README file that provides comprehensive information about the source code, datasets, hardware, and experimentation details.
3. **Replicability**: The ability of reviewers to replicate the experimental results using the provided VM and scripts, ensuring that all graphs and tables can be regenerated.
4. **Completeness**: The submission should include all raw data, scripts for pre-processing, and any other necessary components to fully replicate the experiments.
5. **Functionality**: Artifacts should be documented, consistent, complete, and exercisable, with evidence of verification and validation.
6. **Reusability**: Artifacts should be structured and documented to facilitate reuse and repurposing, adhering to community norms and standards.
7. **Public Accessibility**: Author-created artifacts should be placed in a publicly accessible archival repository, with a DOI or link provided.
8. **Hardware Specification**: Detailed information about the hardware used, including processor, memory, storage, and network specifications, to support reproducibility.
9. **Script Automation**: The inclusion of scripts for data preparation, software setup, and experiment execution to streamline the replication process.
10. **Software Licensing**: Encouraged but optional, providing a license for the software to clarify usage rights.
