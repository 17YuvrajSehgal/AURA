1. **Reproducibility**: Evaluates whether the artifact can be used to reproduce the results claimed in the paper, ensuring that the research findings are reliable and can be independently verified.
2. **Functionality**: Assesses whether the artifact works as intended and performs the functions described in the paper, confirming that the implementation is correct and complete.
3. **Documentation**: Checks the clarity and completeness of the artifact's documentation, including installation and usage instructions, to ensure that others can understand and use the artifact effectively.
4. **Automation**: Encourages the use of workflow scripts to automate the execution of experiments, reducing the need for manual intervention and making it easier for evaluators to verify the artifact's functionality.
5. **Hardware and Software Requirements**: Requires a detailed list of hardware and software needed to run the artifact, ensuring that evaluators have the necessary resources to test the artifact.
6. **Accessibility**: Ensures that the source code and other components of the artifact are available through publicly accessible repositories, facilitating wider access and use by the community.
7. **Anonymity**: Maintains a double-blind review process by anonymizing artifact submissions, preventing bias in the evaluation process.
8. **Remote Access**: Provides remote access to hardware-dependent artifacts when necessary, allowing evaluators to test the artifact even if they do not have the required hardware.
9. **ACM Badges**: Artifacts are evaluated for specific ACM badges, such as "Artifact Available," "Artifact Evaluated - Functional," and "Results Reproduced," which recognize different levels of artifact quality and reproducibility.
10. **Demo Videos**: In cases where experiments are complex or require specific conditions, authors may provide demo videos to demonstrate key functionalities, aiding evaluators in understanding and verifying the artifact's capabilities.
11. **Environmental Settings**: Ensures that any specific environmental conditions required for the artifact are clearly described and replicated during evaluation, maintaining consistency with the paper's claims.
12. **Time Constraints**: Considers the time required to run experiments, allowing for a reduced scope of experiments if necessary to fit within practical evaluation time frames.
13. **Human Subjects**: For artifacts involving human subjects, ensures that the system is deployed under the same conditions as described in the paper, with appropriate ethical considerations and approvals in place.
